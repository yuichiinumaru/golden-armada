Directory structure:
â””â”€â”€ learningcircuit-local-deep-research/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ app.py
    â”œâ”€â”€ citation_handler.py
    â”œâ”€â”€ config.py
    â”œâ”€â”€ license.md
    â”œâ”€â”€ local_collections.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ report_generator.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ search_system.py
    â”œâ”€â”€ utilities.py
    â”œâ”€â”€ .env.template
    â”œâ”€â”€ examples/
    â”‚   â”œâ”€â”€ 2008-finicial-crisis.md
    â”‚   â””â”€â”€ fusion-energy-research-developments.md
    â”œâ”€â”€ static/
    â”‚   â”œâ”€â”€ css/
    â”‚   â”‚   â””â”€â”€ styles.css
    â”‚   â””â”€â”€ js/
    â”‚       â””â”€â”€ app.js
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ index.html
    â”œâ”€â”€ test/
    â”‚   â””â”€â”€ download_stuff_for_local_test.py
    â”œâ”€â”€ web_search_engines/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ full_search.py
    â”‚   â”œâ”€â”€ search_engine_base.py
    â”‚   â”œâ”€â”€ search_engine_factory.py
    â”‚   â”œâ”€â”€ search_engines_config.py
    â”‚   â””â”€â”€ engines/
    â”‚       â”œâ”€â”€ full_search.py
    â”‚       â”œâ”€â”€ meta_search_engine.py
    â”‚       â”œâ”€â”€ search_engine_arxiv.py
    â”‚       â”œâ”€â”€ search_engine_brave.py
    â”‚       â”œâ”€â”€ search_engine_ddg.py
    â”‚       â”œâ”€â”€ search_engine_github.py
    â”‚       â”œâ”€â”€ search_engine_guardian.py
    â”‚       â”œâ”€â”€ search_engine_local.py
    â”‚       â”œâ”€â”€ search_engine_local_all.py
    â”‚       â”œâ”€â”€ search_engine_serpapi.py
    â”‚       â”œâ”€â”€ search_engine_wayback.py
    â”‚       â””â”€â”€ search_engine_wikipedia.py
    â””â”€â”€ .github/
        â””â”€â”€ ISSUE_TEMPLATE/
            â”œâ”€â”€ bug_report.md
            â””â”€â”€ feature_request.md


Files Content:

(Files content cropped to 300k characters, download full ingest to see more)
================================================
File: README.md
================================================
# Local Deep Research

A powerful AI-powered research assistant that performs deep, iterative analysis using multiple LLMs and web searches. The system can be run locally for privacy or configured to use cloud-based LLMs for enhanced capabilities.

## Features

- ðŸ” **Advanced Research Capabilities**
  - Automated deep research with intelligent follow-up questions
  - Citation tracking and source verification
  - Multi-iteration analysis for comprehensive coverage
  - Full webpage content analysis (not just snippets)

- ðŸ¤– **Flexible LLM Support**
  - Local AI processing with Ollama models
  - Cloud LLM support (Claude, GPT)
  - Supports all Langchain models
  - Configurable model selection based on needs

- ðŸ“Š **Rich Output Options**
  - Detailed research findings with citations
  - Comprehensive research reports
  - Quick summaries for rapid insights
  - Source tracking and verification

- ðŸ”’ **Privacy-Focused**
  - Runs entirely on your machine when using local models
  - Configurable search settings
  - Transparent data handling

- ðŸŒ **Enhanced Search Integration**
  - **Auto-selection of search sources**: The "auto" search engine intelligently analyzes your query and selects the most appropriate search engine based on the query content
  - Wikipedia integration for factual knowledge
  - arXiv integration for scientific papers and academic research
  - DuckDuckGo integration for web searches (may experience rate limiting)
  - SerpAPI integration for Google search results (requires API key)
  - The Guardian integration for news articles and journalism (requires API key)
  - **Local RAG search for private documents** - search your own documents with vector embeddings
  - Full webpage content retrieval
  - Source filtering and validation
  - Configurable search parameters

- ðŸ“‘ **Local Document Search (RAG)**
  - Vector embedding-based search of your local documents
  - Create custom document collections for different topics
  - Privacy-preserving - your documents stay on your machine
  - Intelligent chunking and retrieval 
  - Compatible with various document formats (PDF, text, markdown, etc.)
  - Automatic integration with meta-search for unified queries

## Example Research: Fusion Energy Developments

The repository includes complete research examples demonstrating the tool's capabilities. For instance, our [fusion energy research analysis](https://github.com/LearningCircuit/local-deep-research/blob/main/examples/fusion-energy-research-developments.md) provides a comprehensive overview of:

- Latest scientific breakthroughs in fusion research (2022-2025)
- Private sector funding developments exceeding $6 billion
- Expert projections for commercial fusion energy timelines
- Regulatory frameworks being developed for fusion deployment
- Technical challenges that must be overcome for commercial viability

This example showcases the system's ability to perform multiple research iterations, follow evidence trails across scientific and commercial domains, and synthesize information from diverse sources while maintaining proper citation.

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/local-deep-research.git
cd local-deep-research
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install Ollama (for local models):
```bash
# Install Ollama from https://ollama.ai
ollama pull mistral  # Default model - many work really well choose best for your hardware (fits in GPU)
```

4. Configure environment variables:
```bash
# Copy the template
cp .env.template .env

# Edit .env with your API keys (if using cloud LLMs)
ANTHROPIC_API_KEY=your-api-key-here  # For Claude
OPENAI_API_KEY=your-openai-key-here  # For GPT models
GUARDIAN_API_KEY=your-guardian-api-key-here  # For The Guardian search
```

## Usage
Terminal usage (not recommended):
```bash
python main.py
```

### Web Interface

The project includes a web interface for a more user-friendly experience:

```bash
python app.py
```

This will start a local web server, accessible at `http://127.0.0.1:5000` in your browser.

#### Web Interface Features:

- **Dashboard**: Intuitive interface for starting and managing research queries
- **Real-time Updates**: Track research progress with live updates
- **Research History**: Access and manage past research queries
- **PDF Export**: Download completed research reports as PDF documents
- **Research Management**: Terminate ongoing research processes or delete past records

### Configuration

Key settings in `config.py`:
```python
# LLM Configuration
DEFAULT_MODEL = "mistral"  # Change based on your needs
DEFAULT_TEMPERATURE = 0.7
MAX_TOKENS = 8000

# Search Configuration
MAX_SEARCH_RESULTS = 40
SEARCH_REGION = "us-en"
TIME_PERIOD = "y"
SAFE_SEARCH = True
SEARCH_SNIPPETS_ONLY = False

# Choose search tool: "wiki", "arxiv", "duckduckgo", "guardian", "serp", "local_all", or "auto"
search_tool = "auto"  # "auto" will intelligently select the best search engine for your query
```

## Local Document Search (RAG)

The system includes powerful local document search capabilities using Retrieval-Augmented Generation (RAG). This allows you to search and retrieve content from your own document collections.

### Setting Up Local Collections

Create a file named `local_collections.py` in the project root directory:

```python
# local_collections.py
import os
from typing import Dict, Any

# Registry of local document collections
LOCAL_COLLECTIONS = {
    # Research Papers Collection
    "research_papers": {
        "name": "Research Papers",
        "description": "Academic research papers and articles",
        "paths": [os.path.abspath("local_search_files/research_papers")],  # Use absolute paths
        "enabled": True,
        "embedding_model": "all-MiniLM-L6-v2",
        "embedding_device": "cpu",
        "embedding_model_type": "sentence_transformers",
        "max_results": 20,
        "max_filtered_results": 5,
        "chunk_size": 800,  # Smaller chunks for academic content
        "chunk_overlap": 150,
        "cache_dir": ".cache/local_search/research_papers"
    },
    
    # Personal Notes Collection
    "personal_notes": {
        "name": "Personal Notes",
        "description": "Personal notes and documents",
        "paths": [os.path.abspath("local_search_files/personal_notes")],  # Use absolute paths
        "enabled": True,
        "embedding_model": "all-MiniLM-L6-v2",
        "embedding_device": "cpu",
        "embedding_model_type": "sentence_transformers",
        "max_results": 30,
        "max_filtered_results": 10,
        "chunk_size": 500,  # Smaller chunks for notes
        "chunk_overlap": 100,
        "cache_dir": ".cache/local_search/personal_notes"
    }
}

Create the directories for your collections:
```bash
mkdir -p local_search_files/research_papers
mkdir -p local_search_files/personal_notes
```

Add your documents to these folders, and the system will automatically index them and make them available for searching.

### Using Local Search

You can use local search in several ways:

1. **Auto-selection**: Set `search_tool = "auto"` in `config.py` and the system will automatically use your local collections when appropriate for the query.

2. **Explicit Selection**: Set `search_tool = "research_papers"` to search only that specific collection.

3. **Search All Local Collections**: Set `search_tool = "local_all"` to search across all your local document collections.

4. **Query Syntax**: Use `collection:collection_name your query` to target a specific collection within a query.

### Search Engine Options

The system supports multiple search engines that can be selected by changing the `search_tool` variable in `config.py`:

- **Auto** (`auto`): Intelligent search engine selector that analyzes your query and chooses the most appropriate source (Wikipedia, arXiv, local collections, etc.)
- **Wikipedia** (`wiki`): Best for general knowledge, facts, and overview information
- **arXiv** (`arxiv`): Great for scientific and academic research, accessing preprints and papers
- **DuckDuckGo** (`duckduckgo`): General web search that doesn't require an API key
- **The Guardian** (`guardian`): Quality journalism and news articles (requires an API key)
- **SerpAPI** (`serp`): Google search results (requires an API key)
- **Local Collections**: Any collections defined in your `local_collections.py` file

> **Note:** The "auto" option will intelligently select the best search engine based on your query. For example, if you ask about physics research papers, it might select arXiv or your research_papers collection, while if you ask about current events, it might select The Guardian or DuckDuckGo.

> **Support Free Knowledge:** If you frequently use the search engines in this tool, please consider making a donation to these organizations. They provide valuable services and rely on user support to maintain their operations:
> - [Donate to Wikipedia](https://donate.wikimedia.org)
> - [Support The Guardian](https://support.theguardian.com)
> - [Support arXiv](https://arxiv.org/about/give)
> - [Donate to DuckDuckGo](https://duckduckgo.com/donations)

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Acknowledgments
- Built with [Ollama](https://ollama.ai) for local AI processing
- Search powered by multiple sources:
  - [Wikipedia](https://www.wikipedia.org/) for factual knowledge (default search engine)
  - [arXiv](https://arxiv.org/) for scientific papers
  - [DuckDuckGo](https://duckduckgo.com) for web search
  - [The Guardian](https://www.theguardian.com/) for quality journalism
  - [SerpAPI](https://serpapi.com) for Google search results (requires API key)
- Built on [LangChain](https://github.com/hwchase17/langchain) framework
- Uses [justext](https://github.com/miso-belica/justext) for content extraction
- [Playwright](https://playwright.dev) for web content retrieval
- Uses [FAISS](https://github.com/facebookresearch/faiss) for vector similarity search
- Uses [sentence-transformers](https://github.com/UKPLab/sentence-transformers) for embeddings

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request



================================================
File: LICENSE
================================================
MIT License

Copyright (c) 2025 LearningCircuit

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
File: app.py
================================================
import os
import json
import time
import sqlite3
import threading
from datetime import datetime
from flask import Flask, render_template, request, jsonify, send_from_directory, Response, make_response
from flask_socketio import SocketIO, emit
from search_system import AdvancedSearchSystem
from report_generator import IntegratedReportGenerator
from dateutil import parser
import traceback

# Initialize Flask app
app = Flask(__name__, static_folder='static')
app.config['SECRET_KEY'] = 'deep-research-secret-key'

# Add improved Socket.IO configuration with better error handling
socketio = SocketIO(
    app, 
    cors_allowed_origins="*", 
    ping_timeout=60, 
    ping_interval=25, 
    async_mode='threading', 
    reconnection=True, 
    reconnection_attempts=5,
    logger=True,  # Enable logging
    engineio_logger=True  # Enable engine.io logging
)

# Active research processes and socket subscriptions
active_research = {}
socket_subscriptions = {}

# Add termination flags dictionary
termination_flags = {}

# Database setup
DB_PATH = 'research_history.db'

# Add Content Security Policy headers to allow Socket.IO to function
@app.after_request
def add_security_headers(response):
    # Define a permissive CSP for development that allows Socket.IO to function
    csp = (
        "default-src 'self'; "
        "connect-src 'self' ws: wss: http: https:; " 
        "script-src 'self' 'unsafe-inline' 'unsafe-eval' cdnjs.cloudflare.com cdn.jsdelivr.net unpkg.com; "
        "style-src 'self' 'unsafe-inline' cdnjs.cloudflare.com; "
        "font-src 'self' cdnjs.cloudflare.com; "
        "img-src 'self' data:; "
        "worker-src blob:; "
        "frame-src 'self';"
    )
    
    response.headers['Content-Security-Policy'] = csp
    response.headers['X-Content-Security-Policy'] = csp
    
    # Add CORS headers for API requests
    if request.path.startswith('/api/'):
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, DELETE, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
    
    return response

# Initialize the database
def init_db():
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # Create the table if it doesn't exist
    cursor.execute('''
    CREATE TABLE IF NOT EXISTS research_history (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        query TEXT NOT NULL,
        mode TEXT NOT NULL,
        status TEXT NOT NULL,
        created_at TEXT NOT NULL,
        completed_at TEXT,
        duration_seconds INTEGER,
        report_path TEXT,
        metadata TEXT,
        progress_log TEXT
    )
    ''')
    
    # Check if the duration_seconds column exists, add it if missing
    cursor.execute('PRAGMA table_info(research_history)')
    columns = [column[1] for column in cursor.fetchall()]
    
    if 'duration_seconds' not in columns:
        print("Adding missing 'duration_seconds' column to research_history table")
        cursor.execute('ALTER TABLE research_history ADD COLUMN duration_seconds INTEGER')
    
    conn.commit()
    conn.close()

# Helper function to calculate duration between created_at and completed_at timestamps
def calculate_duration(created_at_str):
    """
    Calculate duration in seconds between created_at timestamp and now.
    Handles various timestamp formats and returns None if calculation fails.
    """
    if not created_at_str:
        return None
        
    now = datetime.utcnow()
    duration_seconds = None
    
    try:
        # Proper parsing of ISO format
        if 'T' in created_at_str:  # ISO format with T separator
            start_time = datetime.fromisoformat(created_at_str)
        else:  # Older format without T
            # Try different formats
            try:
                start_time = datetime.strptime(created_at_str, '%Y-%m-%d %H:%M:%S.%f')
            except ValueError:
                try:
                    start_time = datetime.strptime(created_at_str, '%Y-%m-%d %H:%M:%S')
                except ValueError:
                    # Last resort fallback
                    start_time = datetime.fromisoformat(created_at_str.replace(' ', 'T'))
        
        # Ensure we're comparing UTC times
        duration_seconds = int((now - start_time).total_seconds())
    except Exception as e:
        print(f"Error calculating duration: {str(e)}")
        # Fallback method if parsing fails
        try:
            start_time_fallback = parser.parse(created_at_str)
            duration_seconds = int((now - start_time_fallback).total_seconds())
        except:
            print(f"Fallback duration calculation also failed for timestamp: {created_at_str}")
    
    return duration_seconds

# Initialize the database on startup
# @app.before_first_request  # This is deprecated in newer Flask versions
def initialize():
    init_db()

# Call initialize immediately when app is created
initialize()

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/static/<path:path>')
def serve_static(path):
    return send_from_directory('static', path)

@app.route('/api/history', methods=['GET'])
def get_history():
    """Get the research history"""
    try:
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # Get all history records ordered by latest first
        cursor.execute('SELECT * FROM research_history ORDER BY created_at DESC')
        results = cursor.fetchall()
        conn.close()
        
        # Convert to list of dicts
        history = []
        for result in results:
            item = dict(result)
            
            # Ensure all keys exist with default values
            if 'id' not in item:
                item['id'] = None
            if 'query' not in item:
                item['query'] = 'Untitled Research'
            if 'mode' not in item:
                item['mode'] = 'quick'
            if 'status' not in item:
                item['status'] = 'unknown'
            if 'created_at' not in item:
                item['created_at'] = None
            if 'completed_at' not in item:
                item['completed_at'] = None
            if 'duration_seconds' not in item:
                item['duration_seconds'] = None
            if 'report_path' not in item:
                item['report_path'] = None
            if 'metadata' not in item:
                item['metadata'] = '{}'
            if 'progress_log' not in item:
                item['progress_log'] = '[]'
            
            # Ensure timestamps are in ISO format
            if item['created_at'] and 'T' not in item['created_at']:
                try:
                    # Convert to ISO format if it's not already
                    dt = parser.parse(item['created_at'])
                    item['created_at'] = dt.isoformat()
                except:
                    pass
                
            if item['completed_at'] and 'T' not in item['completed_at']:
                try:
                    # Convert to ISO format if it's not already
                    dt = parser.parse(item['completed_at'])
                    item['completed_at'] = dt.isoformat()
                except:
                    pass
                
            # Recalculate duration based on timestamps if it's null but both timestamps exist
            if item['duration_seconds'] is None and item['created_at'] and item['completed_at']:
                try:
                    start_time = parser.parse(item['created_at'])
                    end_time = parser.parse(item['completed_at'])
                    item['duration_seconds'] = int((end_time - start_time).total_seconds())
                except Exception as e:
                    print(f"Error recalculating duration: {str(e)}")
            
            history.append(item)
        
        # Add CORS headers
        response = make_response(jsonify(history))
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
        response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
        return response
    except Exception as e:
        print(f"Error getting history: {str(e)}")
        print(traceback.format_exc())
        # Return empty array with CORS headers
        response = make_response(jsonify([]))
        response.headers.add('Access-Control-Allow-Origin', '*')
        response.headers.add('Access-Control-Allow-Headers', 'Content-Type,Authorization')
        response.headers.add('Access-Control-Allow-Methods', 'GET,PUT,POST,DELETE,OPTIONS')
        return response

@app.route('/api/start_research', methods=['POST'])
def start_research():
    data = request.json
    query = data.get('query')
    mode = data.get('mode', 'quick')
    
    if not query:
        return jsonify({'status': 'error', 'message': 'Query is required'}), 400
        
    # Check if there's any active research
    if active_research:
        return jsonify({
            'status': 'error', 
            'message': 'Another research is already in progress. Please wait for it to complete.'
        }), 409
        
    # Create a record in the database with explicit UTC timestamp
    created_at = datetime.utcnow().isoformat()
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute(
        'INSERT INTO research_history (query, mode, status, created_at, progress_log) VALUES (?, ?, ?, ?, ?)',
        (query, mode, 'in_progress', created_at, json.dumps([{"time": created_at, "message": "Research started", "progress": 0}]))
    )
    research_id = cursor.lastrowid
    conn.commit()
    conn.close()
    
    # Start research process in a background thread
    thread = threading.Thread(
        target=run_research_process,
        args=(research_id, query, mode)
    )
    thread.daemon = True
    thread.start()
    
    active_research[research_id] = {
        'thread': thread,
        'progress': 0,
        'status': 'in_progress',
        'log': [{"time": created_at, "message": "Research started", "progress": 0}]
    }
    
    return jsonify({
        'status': 'success',
        'research_id': research_id
    })

@app.route('/api/research/<int:research_id>')
def get_research_status(research_id):
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute('SELECT * FROM research_history WHERE id = ?', (research_id,))
    result = dict(cursor.fetchone() or {})
    conn.close()
    
    if not result:
        return jsonify({'status': 'error', 'message': 'Research not found'}), 404
        
    # Add progress information
    if research_id in active_research:
        result['progress'] = active_research[research_id]['progress']
        result['log'] = active_research[research_id]['log']
    elif result.get('status') == 'completed':
        result['progress'] = 100
        try:
            result['log'] = json.loads(result.get('progress_log', '[]'))
        except:
            result['log'] = []
    else:
        result['progress'] = 0
        try:
            result['log'] = json.loads(result.get('progress_log', '[]'))
        except:
            result['log'] = []
        
    return jsonify(result)

@app.route('/api/research/<int:research_id>/details')
def get_research_details(research_id):
    """Get detailed progress log for a specific research"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute('SELECT * FROM research_history WHERE id = ?', (research_id,))
    result = dict(cursor.fetchone() or {})
    conn.close()
    
    if not result:
        return jsonify({'status': 'error', 'message': 'Research not found'}), 404
    
    try:
        # Get the progress log
        progress_log = json.loads(result.get('progress_log', '[]'))
    except:
        progress_log = []
        
    # If this is an active research, get the latest log
    if research_id in active_research:
        progress_log = active_research[research_id]['log']
    
    return jsonify({
        'status': 'success',
        'research_id': research_id,
        'query': result.get('query'),
        'mode': result.get('mode'),
        'status': result.get('status'),
        'progress': active_research.get(research_id, {}).get('progress', 100 if result.get('status') == 'completed' else 0),
        'created_at': result.get('created_at'),
        'completed_at': result.get('completed_at'),
        'log': progress_log
    })

@app.route('/api/report/<int:research_id>')
def get_report(research_id):
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute('SELECT * FROM research_history WHERE id = ?', (research_id,))
    result = dict(cursor.fetchone() or {})
    conn.close()
    
    if not result or not result.get('report_path'):
        return jsonify({'status': 'error', 'message': 'Report not found'}), 404
        
    try:
        with open(result['report_path'], 'r', encoding='utf-8') as f:
            content = f.read()
        return jsonify({
            'status': 'success',
            'content': content,
            'metadata': json.loads(result.get('metadata', '{}'))
        })
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/research/details/<int:research_id>')
def research_details_page(research_id):
    """Render the research details page"""
    return render_template('index.html')

@socketio.on('connect')
def handle_connect():
    print(f"Client connected: {request.sid}")

@socketio.on('disconnect')
def handle_disconnect():
    print(f"Client disconnected: {request.sid}")
    # Clean up subscriptions for this client
    for research_id, subscribers in list(socket_subscriptions.items()):
        if request.sid in subscribers:
            subscribers.remove(request.sid)
        if not subscribers:
            socket_subscriptions.pop(research_id, None)

@socketio.on('subscribe_to_research')
def handle_subscribe(data):
    research_id = data.get('research_id')
    if research_id:
        if research_id not in socket_subscriptions:
            socket_subscriptions[research_id] = set()
        socket_subscriptions[research_id].add(request.sid)
        print(f"Client {request.sid} subscribed to research {research_id}")
        
        # Send current status immediately if available
        if research_id in active_research:
            progress = active_research[research_id]['progress']
            latest_log = active_research[research_id]['log'][-1] if active_research[research_id]['log'] else None
            
            if latest_log:
                emit(f'research_progress_{research_id}', {
                    'progress': progress,
                    'message': latest_log.get('message', 'Processing...'),
                    'status': 'in_progress',
                    'log_entry': latest_log
                })

@socketio.on_error
def handle_socket_error(e):
    print(f"SocketIO error: {str(e)}")

def run_research_process(research_id, query, mode):
    try:
        system = AdvancedSearchSystem()
        
        # Set up progress callback
        def progress_callback(message, progress_percent, metadata):
            timestamp = datetime.utcnow().isoformat()
            log_entry = {
                "time": timestamp,
                "message": message,
                "progress": progress_percent,
                "metadata": metadata
            }
            
            # Check if termination was requested
            if research_id in termination_flags and termination_flags[research_id]:
                # Clean up and exit
                raise Exception("Research was terminated by user")
            
            # Update active research record
            if research_id in active_research:
                active_research[research_id]['log'].append(log_entry)
                if progress_percent is not None:
                    active_research[research_id]['progress'] = progress_percent
                
                # Save to database (but not too frequently)
                if progress_percent is None or progress_percent % 10 == 0 or metadata.get('phase') in ['complete', 'iteration_complete']:
                    conn = sqlite3.connect(DB_PATH)
                    cursor = conn.cursor()
                    cursor.execute(
                        'SELECT progress_log FROM research_history WHERE id = ?',
                        (research_id,)
                    )
                    result = cursor.fetchone()
                    if result:
                        try:
                            current_log = json.loads(result[0])
                        except:
                            current_log = []
                        current_log.append(log_entry)
                        cursor.execute(
                            'UPDATE research_history SET progress_log = ? WHERE id = ?',
                            (json.dumps(current_log), research_id)
                        )
                        conn.commit()
                    conn.close()
                
                # Emit socket event with try/except block to handle connection issues
                try:
                    event_data = {
                        'progress': progress_percent,
                        'message': message,
                        'status': 'in_progress',
                        'log_entry': log_entry
                    }
                    
                    # Emit to the specific research channel
                    socketio.emit(f'research_progress_{research_id}', event_data)
                    
                    # Also emit to specific subscribers if available
                    if research_id in socket_subscriptions and socket_subscriptions[research_id]:
                        for sid in socket_subscriptions[research_id]:
                            try:
                                socketio.emit(
                                    f'research_progress_{research_id}', 
                                    event_data,
                                    room=sid
                                )
                            except Exception as sub_err:
                                print(f"Error emitting to subscriber {sid}: {str(sub_err)}")
                    
                except Exception as socket_error:
                    # Log socket error but continue with the research process
                    print(f"Socket emit error (non-critical): {str(socket_error)}")
        
        # Set the progress callback in the system
        system.set_progress_callback(progress_callback)
        
        # Run the search
        progress_callback("Starting research process", 5, {"phase": "init"})
        results = system.analyze_topic(query)
        progress_callback("Search complete, generating output", 80, {"phase": "output_generation"})
        
        # Generate output based on mode
        if mode == 'quick':
            # Quick Summary
            if results.get('findings'):
                #initial_analysis = [finding['content'] for finding in results['findings']]
                summary = ""
                summary = summary + results['formatted_findings']
                # Save as markdown file
                output_dir = "research_outputs"
                if not os.path.exists(output_dir):
                    os.makedirs(output_dir)
                    
                safe_query = "".join(x for x in query if x.isalnum() or x in [" ", "-", "_"])[:50]
                safe_query = safe_query.replace(" ", "_").lower()
                report_path = os.path.join(output_dir, f"quick_summary_{safe_query}.md")
                
                with open(report_path, "w", encoding="utf-8") as f:
                    f.write("# Quick Research Summary\n\n")
                    f.write(f"Query: {query}\n\n")
                    f.write(summary)
                    f.write("\n\n## Research Metrics\n")
                    f.write(f"- Search Iterations: {results['iterations']}\n")
                    f.write(f"- Generated at: {datetime.utcnow().isoformat()}\n")
                
                # Update database
                metadata = {
                    'iterations': results['iterations'],
                    'generated_at': datetime.utcnow().isoformat()
                }
                
                # Calculate duration in seconds - using UTC consistently
                now = datetime.utcnow()
                completed_at = now.isoformat()
                
                # Get the start time from the database
                conn = sqlite3.connect(DB_PATH)
                cursor = conn.cursor()
                cursor.execute('SELECT created_at FROM research_history WHERE id = ?', (research_id,))
                result = cursor.fetchone()
                
                # Use the helper function for consistent duration calculation
                duration_seconds = calculate_duration(result[0])
                
                # Update the record
                cursor.execute(
                    'UPDATE research_history SET status = ?, completed_at = ?, duration_seconds = ?, report_path = ?, metadata = ? WHERE id = ?',
                    ('completed', completed_at, duration_seconds, report_path, json.dumps(metadata), research_id)
                )
                conn.commit()
                conn.close()
                
                progress_callback("Research completed successfully", 100, {"phase": "complete", "report_path": report_path})
        else:
            # Full Report
            progress_callback("Generating detailed report...", 85, {"phase": "report_generation"})
            report_generator = IntegratedReportGenerator()
            final_report = report_generator.generate_report(results['findings'], query)
            progress_callback("Report generation complete", 95, {"phase": "report_complete"})
            
            # Save as markdown file
            output_dir = "research_outputs"
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                
            safe_query = "".join(x for x in query if x.isalnum() or x in [" ", "-", "_"])[:50]
            safe_query = safe_query.replace(" ", "_").lower()
            report_path = os.path.join(output_dir, f"detailed_report_{safe_query}.md")
            
            with open(report_path, "w", encoding="utf-8") as f:
                f.write(final_report['content'])
            
            # Update database
            metadata = final_report['metadata']
            metadata['iterations'] = results['iterations']
            
            # Calculate duration in seconds - using UTC consistently
            now = datetime.utcnow()
            completed_at = now.isoformat()
            
            # Get the start time from the database
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            cursor.execute('SELECT created_at FROM research_history WHERE id = ?', (research_id,))
            result = cursor.fetchone()
            
            # Use the helper function for consistent duration calculation
            duration_seconds = calculate_duration(result[0])
            
            cursor.execute(
                'UPDATE research_history SET status = ?, completed_at = ?, duration_seconds = ?, report_path = ?, metadata = ? WHERE id = ?',
                ('completed', completed_at, duration_seconds, report_path, json.dumps(metadata), research_id)
            )
            conn.commit()
            conn.close()
            
            progress_callback("Research completed successfully", 100, {"phase": "complete", "report_path": report_path})
            
        # Clean up
        if research_id in active_research:
            del active_research[research_id]
            
    except Exception as e:
        # Handle error
        error_message = f"Research failed: {str(e)}"
        print(f"Research error: {error_message}")
        try:
            progress_callback(error_message, None, {"phase": "error", "error": str(e)})
        
            conn = sqlite3.connect(DB_PATH)
            cursor = conn.cursor()
            
            # If termination was requested, mark as suspended instead of failed
            status = 'suspended' if (research_id in termination_flags and termination_flags[research_id]) else 'failed'
            message = "Research was terminated by user" if status == 'suspended' else str(e)
            
            # Calculate duration up to termination point - using UTC consistently
            now = datetime.utcnow()
            completed_at = now.isoformat()
            
            # Get the start time from the database
            duration_seconds = None
            cursor.execute('SELECT created_at FROM research_history WHERE id = ?', (research_id,))
            result = cursor.fetchone()
            
            # Use the helper function for consistent duration calculation
            if result and result[0]:
                duration_seconds = calculate_duration(result[0])
            
            cursor.execute(
                'UPDATE research_history SET status = ?, completed_at = ?, duration_seconds = ?, metadata = ? WHERE id = ?',
                (status, completed_at, duration_seconds, json.dumps({'error': message}), research_id)
            )
            conn.commit()
            conn.close()
            
            try:
                socketio.emit(f'research_progress_{research_id}', {
                    'status': status,
                    'error': message
                })
                
                # Also notify specific subscribers
                if research_id in socket_subscriptions and socket_subscriptions[research_id]:
                    for sid in socket_subscriptions[research_id]:
                        try:
                            socketio.emit(
                                f'research_progress_{research_id}', 
                                {'status': status, 'error': message},
                                room=sid
                            )
                        except Exception as sub_err:
                            print(f"Error emitting to subscriber {sid}: {str(sub_err)}")
                            
            except Exception as socket_error:
                print(f"Failed to emit error via socket: {str(socket_error)}")
        except Exception as inner_e:
            print(f"Error in error handler: {str(inner_e)}")
        
        # Clean up resources
        if research_id in active_research:
            del active_research[research_id]
        if research_id in termination_flags:
            del termination_flags[research_id]

@app.route('/api/research/<int:research_id>/terminate', methods=['POST'])
def terminate_research(research_id):
    """Terminate an in-progress research process"""
    
    # Check if the research exists and is in progress
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    cursor.execute('SELECT status FROM research_history WHERE id = ?', (research_id,))
    result = cursor.fetchone()
    
    if not result:
        conn.close()
        return jsonify({'status': 'error', 'message': 'Research not found'}), 404
    
    status = result[0]
    
    # If it's not in progress, return an error
    if status != 'in_progress':
        conn.close()
        return jsonify({'status': 'error', 'message': 'Research is not in progress'}), 400
    
    # Check if it's in the active_research dict
    if research_id not in active_research:
        # Update the status in the database
        cursor.execute('UPDATE research_history SET status = ? WHERE id = ?', ('suspended', research_id))
        conn.commit()
        conn.close()
        return jsonify({'status': 'success', 'message': 'Research terminated'})
    
    # Set the termination flag
    termination_flags[research_id] = True
    
    # Log the termination request - using UTC timestamp
    timestamp = datetime.utcnow().isoformat()
    log_entry = {
        "time": timestamp,
        "message": "Research termination requested by user",
        "progress": active_research[research_id]['progress'],
        "metadata": {"phase": "termination"}
    }
    
    active_research[research_id]['log'].append(log_entry)
    
    # Update the log in the database
    cursor.execute('SELECT progress_log FROM research_history WHERE id = ?', (research_id,))
    log_result = cursor.fetchone()
    if log_result:
        try:
            current_log = json.loads(log_result[0])
        except:
            current_log = []
        current_log.append(log_entry)
        cursor.execute(
            'UPDATE research_history SET progress_log = ? WHERE id = ?',
            (json.dumps(current_log), research_id)
        )
    
    conn.commit()
    conn.close()
    
    # Emit a socket event for the termination request
    try:
        event_data = {
            'status': 'terminating',
            'message': 'Research termination requested by user'
        }
        
        socketio.emit(f'research_progress_{research_id}', event_data)
        
        if research_id in socket_subscriptions and socket_subscriptions[research_id]:
            for sid in socket_subscriptions[research_id]:
                try:
                    socketio.emit(
                        f'research_progress_{research_id}', 
                        event_data,
                        room=sid
                    )
                except Exception as err:
                    print(f"Error emitting to subscriber {sid}: {str(err)}")
                    
    except Exception as socket_error:
        print(f"Socket emit error (non-critical): {str(socket_error)}")
    
    return jsonify({'status': 'success', 'message': 'Research termination requested'})

@app.route('/api/research/<int:research_id>/delete', methods=['DELETE'])
def delete_research(research_id):
    """Delete a research record"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # First check if the research exists and is not in progress
    cursor.execute('SELECT status, report_path FROM research_history WHERE id = ?', (research_id,))
    result = cursor.fetchone()
    
    if not result:
        conn.close()
        return jsonify({'status': 'error', 'message': 'Research not found'}), 404
    
    status, report_path = result
    
    # Don't allow deleting research in progress
    if status == 'in_progress' and research_id in active_research:
        conn.close()
        return jsonify({
            'status': 'error', 
            'message': 'Cannot delete research that is in progress'
        }), 400
    
    # Delete report file if it exists
    if report_path and os.path.exists(report_path):
        try:
            os.remove(report_path)
        except Exception as e:
            print(f"Error removing report file: {str(e)}")
    
    # Delete the database record
    cursor.execute('DELETE FROM research_history WHERE id = ?', (research_id,))
    conn.commit()
    conn.close()
    
    return jsonify({'status': 'success'})

if __name__ == '__main__':
    # Set server name explicitly to avoid DNS resolution issues
    socketio.run(app, debug=True, host='0.0.0.0', port=5000, allow_unsafe_werkzeug=True)


================================================
File: citation_handler.py
================================================
# citation_handler.py

from langchain_core.documents import Document
from typing import Dict, List, Union, Any
import re
from utilities import remove_think_tags
import config

class CitationHandler:
    def __init__(self, llm):
        self.llm = llm

    def _create_documents(
        self, search_results: Union[str, List[Dict]]
    ) -> List[Document]:
        """Convert search results to LangChain documents format."""
        documents = []
        if isinstance(search_results, str):
            return documents

        for i, result in enumerate(search_results):
            if isinstance(result, dict):
                content = result.get("full_content", result.get("snippet", ""))
                documents.append(
                    Document(
                        page_content=content,
                        metadata={
                            "source": result.get("link", f"source_{i+1}"),
                            "title": result.get("title", f"Source {i+1}"),
                            "index": i + 1,
                        },
                    )
                )
        return documents

    def _format_sources(self, documents: List[Document]) -> str:
        """Format sources with numbers for citation."""
        sources = []
        for doc in documents:
            source_id = doc.metadata["index"]
            sources.append(f"[{source_id}] {doc.page_content}")
        return "\n\n".join(sources)

    def analyze_initial(
        self, query: str, search_results: Union[str, List[Dict]]
    ) -> Dict[str, Any]:

        documents = self._create_documents(search_results)
        formatted_sources = self._format_sources(documents)
        print(formatted_sources)
        prompt = f"""Analyze the following information concerning the question and include citations using numbers in square brackets [1], [2], etc. When citing, use the source number provided at the start of each source.

Question: {query}

Sources:
{formatted_sources}

Provide a detailed analysis with citations and always keep URLS. Never make up sources. Example format: "According to the research [1], ..."
"""

        response = self.llm.invoke(prompt)

        return {"content": remove_think_tags(response.content), "documents": documents}

    def analyze_followup(
        self,
        question: str,
        search_results: Union[str, List[Dict]],
        previous_knowledge: str,
    ) -> Dict[str, Any]:
        """Process follow-up analysis with citations."""
        documents = self._create_documents(search_results)
        formatted_sources = self._format_sources(documents)
        print(formatted_sources)
        # Add fact-checking step
        fact_check_prompt = f"""Analyze these sources for factual consistency:
        1. Cross-reference major claims between sources
        2. Identify and flag any contradictions
        3. Verify basic facts (dates, company names, ownership)
        4. Note when sources disagree
        
        Previous Knowledge:
        {previous_knowledge}

        New Sources:
        {formatted_sources}

        Return any inconsistencies or conflicts found."""
        if config.ENABLE_FACT_CHECKING:
            fact_check_response = remove_think_tags(self.llm.invoke(fact_check_prompt).content)
        else:
            fact_check_response = ""

        prompt = f"""Using the previous knowledge and new sources, answer the question. Include citations using numbers in square brackets [1], [2], etc. When citing, use the source number provided at the start of each source. Reflect information from sources critically.

            Previous Knowledge:
            {previous_knowledge}

            Question: {question}

            New Sources:
            {formatted_sources}
            Reflect information from sources critically based on: {fact_check_response}. Never invent sources.
            Provide a detailed answer with citations.  Example format: "According to [1], ..."
            """

        response = self.llm.invoke(prompt)

        return {"content": remove_think_tags(response.content), "documents": documents}



================================================
File: config.py
================================================
"""
Local Deep Research Configuration Guide

This configuration file controls the behavior of the research system.

MAIN SETTINGS:
- search_tool (str): Choose which search engine to use
  - "auto": Intelligent selection based on query content (recommended)
  - "local_all": Search only local document collections
  - "wikipedia": General knowledge and facts
  - "arxiv": Scientific papers and research
  - "duckduckgo": General web search (no API key needed)
  - "serp": Google search via SerpAPI (requires API key)
  - "guardian": News articles (requires API key)
  - Any collection name from your local_collections.py

- DEFAULT_MODEL (str): LLM to use for analysis
  - "mistral": Default local model via Ollama
  - "deepseek-r1:14b": Alternative larger model
  - "claude-3-5-sonnet-latest": Claude model (requires API key)
  - "gpt-4o": OpenAI model (requires API key)
  - "mpt-7b": MPT model via VLLM

RESEARCH SETTINGS:
- SEARCH_ITERATIONS (int): Number of research cycles
- QUESTIONS_PER_ITERATION (int): Questions per cycle
- SEARCHES_PER_SECTION (int): Searches per report section
- MAX_SEARCH_RESULTS (int): Results per search query
- MAX_FILTERED_RESULTS (int): Results after relevance filtering

For full documentation, see the README.md
"""

from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_community.llms import VLLM  # Added VLLM import
from dotenv import load_dotenv
from web_search_engines.search_engine_factory import get_search as factory_get_search


import os
# Load environment variables
load_dotenv()
# Choose search tool: "serp" or "duckduckgo" (serp requires API key)
search_tool = "auto" # Change this variable to switch between search tools; for only local search "local-all"


# LLM Configuration
DEFAULT_MODEL = "mistral"  # try to use the largest model that fits into your GPU memory
DEFAULT_TEMPERATURE = 0.7
MAX_TOKENS = 15000

# VLLM Configuration
VLLM_MAX_NEW_TOKENS = 128
VLLM_TOP_K = 10
VLLM_TOP_P = 0.95
VLLM_TEMPERATURE = 0.8

# Search System Settings
SEARCH_ITERATIONS = 3
QUESTIONS_PER_ITERATION = 3

# Report settings
SEARCHES_PER_SECTION = 3
CONTEXT_CUT_OFF = 10000

# citation handler
ENABLE_FACT_CHECKING = False  # comes with pros and cons. Maybe works better with larger LLMs?

# URL Quality Check (applies to both DDG and SerpAPI)
QUALITY_CHECK_DDG_URLS = True  # Keep True for better quality results.

SEARCH_SNIPPETS_ONLY = False
SKIP_RELEVANCE_FILTER = False 

# Search Configuration (applies to both DDG and SerpAPI)
MAX_SEARCH_RESULTS = 50  
MAX_FILTERED_RESULTS = 5
SEARCH_REGION = "us"
TIME_PERIOD = "y"
SAFE_SEARCH = True
SEARCH_LANGUAGE = "English"

# Output Configuration
OUTPUT_DIR = "research_outputs"


def get_llm(model_name=DEFAULT_MODEL, temperature=DEFAULT_TEMPERATURE):
    """Get LLM instance - easy to switch between models"""
    common_params = {
        "temperature": temperature,
        "max_tokens": MAX_TOKENS,
    }

    if "claude" in model_name:
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")
        return ChatAnthropic(
            model=model_name, anthropic_api_key=api_key, **common_params
        )

    elif "gpt" in model_name:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
        return ChatOpenAI(model=model_name, api_key=api_key, **common_params)
        
    elif model_name == "mpt-7b":
        # VLLM configuration for the MPT model
        return VLLM(
            model="mosaicml/mpt-7b",
            trust_remote_code=True,  # mandatory for hf models
            max_new_tokens=VLLM_MAX_NEW_TOKENS,
            top_k=VLLM_TOP_K,
            top_p=VLLM_TOP_P,
            temperature=VLLM_TEMPERATURE,
        )

    else:
        return ChatOllama(model=model_name, base_url="http://localhost:11434", **common_params)


def get_search():
    """Get search tool instance based on config settings"""
    print(f"Creating search engine with tool: {search_tool}")
    engine = factory_get_search(
        search_tool=search_tool,
        llm_instance=get_llm(),
        max_results=MAX_SEARCH_RESULTS,
        region=SEARCH_REGION,
        time_period=TIME_PERIOD,
        safe_search=SAFE_SEARCH,
        search_snippets_only=SEARCH_SNIPPETS_ONLY,
        search_language=SEARCH_LANGUAGE,
        max_filtered_results=MAX_FILTERED_RESULTS 
    )
    
    if engine is None:
        print(f"Failed to create search engine with tool: {search_tool}")
    
    return engine



================================================
File: license.md
================================================
MIT License

Copyright (c) 2024 Local Deep Research

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
File: local_collections.py
================================================
# local_collections.py
"""
Configuration file for local document collections.
Each collection functions as an independent search engine.
"""

import os
from typing import Dict, Any

# Registry of local document collections
# Each collection appears as a separate search engine in the main configuration
LOCAL_COLLECTIONS = {
    # Project Documents Collection
    "project_docs": {
        "name": "Project Documents",
        "description": "Project documentation and specifications",
        "paths": [os.path.abspath("./local_search_files/project_documents")],
        "enabled": True,
        "embedding_model": "all-MiniLM-L6-v2",
        "embedding_device": "cpu",
        "embedding_model_type": "sentence_transformers",
        "max_results": 20,
        "max_filtered_results": 5,
        "chunk_size": 1000,
        "chunk_overlap": 200,
        "cache_dir": ".cache/local_search/project_docs"
    },
    
    # Research Papers Collection
    "research_papers": {
        "name": "Research Papers",
        "description": "Academic research papers and articles",
        "paths": [os.path.abspath("local_search_files/research_papers")],
        "enabled": True,
        "embedding_model": "all-MiniLM-L6-v2",
        "embedding_device": "cpu",
        "embedding_model_type": "sentence_transformers",
        "max_results": 20,
        "max_filtered_results": 5,
        "chunk_size": 800,  # Smaller chunks for academic content
        "chunk_overlap": 150,
        "cache_dir": ".cache/local_search/research_papers"
    },
    
    # Personal Notes Collection
    "personal_notes": {
        "name": "Personal Notes",
        "description": "Personal notes and documents",
        "paths": [os.path.abspath("./local_search_files/personal_notes")],
        "enabled": True,
        "embedding_model": "all-MiniLM-L6-v2",
        "embedding_device": "cpu",
        "embedding_model_type": "sentence_transformers",
        "max_results": 30,
        "max_filtered_results": 10,
        "chunk_size": 500,  # Smaller chunks for notes
        "chunk_overlap": 100,
        "cache_dir": ".cache/local_search/personal_notes"
    }
}

# Configuration for local search integration
LOCAL_SEARCH_CONFIG = {
    # General embedding options
    "DEFAULT_EMBEDDING_MODEL": "all-MiniLM-L6-v2",
    "DEFAULT_EMBEDDING_DEVICE": "cpu",  # "cpu" or "cuda" for GPU acceleration
    "DEFAULT_EMBEDDING_MODEL_TYPE": "sentence_transformers",  # or "ollama"
    
    # Ollama settings (only used if model type is "ollama")
    # Note: You must run 'ollama pull nomic-embed-text' first if using Ollama for embeddings
    "OLLAMA_BASE_URL": "http://localhost:11434",
    "OLLAMA_EMBEDDING_MODEL": "nomic-embed-text",
    
    # Default indexing options
    "FORCE_REINDEX": True,  # Force reindexing on startup
    "CACHE_DIR": ".cache/local_search",  # Base directory for cache
}

def register_local_collections(search_engines_dict: Dict[str, Any]) -> None:
    """
    Register all enabled local collections as search engines.
    
    Args:
        search_engines_dict: The main search engines dictionary to update
    """
    for collection_id, collection in LOCAL_COLLECTIONS.items():
        print(collection_id, collection)
        if collection.get("enabled", True):
            # Skip if already defined (don't override)
            if collection_id in search_engines_dict:
                continue
                
            # Validate paths exist
            paths = collection.get("paths", [])
            valid_paths = []
            for path in paths:
                if os.path.exists(path) and os.path.isdir(path):
                    valid_paths.append(path)
                else:
                    print(f"Warning: Collection '{collection_id}' contains non-existent folder: {path}")
            
            # Log warning if no valid paths
            if not valid_paths and paths:
                print(f"Warning: Collection '{collection_id}' has no valid folders. It will be registered but won't return results.")
                
            # Create a search engine entry for this collection
            search_engines_dict[collection_id] = {
                "module_path": "web_search_engines.engines.search_engine_local",
                "class_name": "LocalSearchEngine",
                "requires_api_key": False,
                "reliability": 0.9,  # High reliability for local documents
                "strengths": ["personal documents", "offline access", 
                             collection.get("description", "local documents")],
                "weaknesses": ["requires indexing", "limited to specific folders"],
                "default_params": {
                    "folder_paths": collection.get("paths", []),
                    "embedding_model": collection.get(
                        "embedding_model", 
                        LOCAL_SEARCH_CONFIG["DEFAULT_EMBEDDING_MODEL"]
                    ),
                    "embedding_device": collection.get(
                        "embedding_device", 
                        LOCAL_SEARCH_CONFIG["DEFAULT_EMBEDDING_DEVICE"]
                    ),
                    "embedding_model_type": collection.get(
                        "embedding_model_type", 
                        LOCAL_SEARCH_CONFIG["DEFAULT_EMBEDDING_MODEL_TYPE"]
                    ),
                    "chunk_size": collection.get("chunk_size", 1000),
                    "chunk_overlap": collection.get("chunk_overlap", 200),
                    "cache_dir": collection.get(
                        "cache_dir", 
                        f"{LOCAL_SEARCH_CONFIG['CACHE_DIR']}/{collection_id}"
                    ),
                    "max_results": collection.get("max_results", 20),
                    "max_filtered_results": collection.get("max_filtered_results", 5),
                    "collection_name": collection.get("name", collection_id),
                    "collection_description": collection.get("description", "")
                },
                "requires_llm": True
            }


================================================
File: main.py
================================================
from search_system import AdvancedSearchSystem
from typing import Dict


def print_report(report: Dict):
    """Print and save the report in a readable format"""

    # Print to console in readable format
    print("\n=== GENERATED REPORT ===\n")

    # Print content
    print(report["content"])

    # Print metadata in a clean format
    print("\n=== METADATA ===")
    print(f"Generated at: {report['metadata']['generated_at']}")
    print(f"Initial sources: {report['metadata']['initial_sources']}")
    print(f"Sections researched: {report['metadata']['sections_researched']}")
    print(f"Searches per section: {report['metadata']['searches_per_section']}")
    print(f"Query: {report['metadata']['query']}")

    # Save to file in markdown format
    with open("report.md", "w", encoding="utf-8") as markdown_file:
        # Write content
        markdown_file.write(report["content"])

        # Write metadata at the end of the file
        markdown_file.write("\n\n---\n\n")
        markdown_file.write("## Report Metadata\n")
        markdown_file.write(f"- Generated at: {report['metadata']['generated_at']}\n")
        markdown_file.write(
            f"- Initial sources: {report['metadata']['initial_sources']}\n"
        )
        markdown_file.write(
            f"- Sections researched: {report['metadata']['sections_researched']}\n"
        )
        markdown_file.write(
            f"- Searches per section: {report['metadata']['searches_per_section']}\n"
        )
        markdown_file.write(f"- Query: {report['metadata']['query']}\n")

    print(f"\nReport has been saved to report.md")


from report_generator import IntegratedReportGenerator

report_generator = IntegratedReportGenerator()


def main():
    system = AdvancedSearchSystem()

    print("Welcome to the Advanced Research System")
    print("Type 'quit' to exit")

    while True:
        print("\nSelect output type:")
        print("1) Quick Summary (Generated in a few minutes)")
        print(
            "2) Detailed Research Report (Recommended for deeper analysis - may take several hours)"
        )
        choice = input("Enter number (1 or 2): ").strip()

        while choice not in ["1", "2"]:
            print("\nInvalid input. Please enter 1 or 2:")
            print("1) Quick Summary (Generated in a few minutes)")
            print(
                "2) Detailed Research Report (Recommended for deeper analysis - may take several hours)"
            )
            choice = input("Enter number (1 or 2): ").strip()

        query = input("\nEnter your research query: ").strip()

        if query.lower() == "quit":
            break

        if choice == "1":
            print("\nResearching... This may take a few minutes.\n")
        else:
            print(
                "\nGenerating detailed report... This may take several hours. Please be patient as this enables deeper analysis.\n"
            )

        results = system.analyze_topic(query)
        if results:
            if choice == "1":
                # Quick Summary
                print("\n=== QUICK SUMMARY ===")
                if results["findings"] and len(results["findings"]) > 0:
                    initial_analysis = [
                        finding["content"] for finding in results["findings"]
                    ]
                    print(initial_analysis)

            else:
                # Full Report
                final_report = report_generator.generate_report(
                    results["findings"], query
                )
                print("\n=== RESEARCH REPORT ===")
                print_report(final_report)

                print("\n=== RESEARCH METRICS ===")
                print(f"Search Iterations: {results['iterations']}")

        else:
            print("Research failed. Please try again.")


if __name__ == "__main__":
    main()



================================================
File: report_generator.py
================================================
from typing import Dict, List, Optional
from config import get_llm
import re
from datetime import datetime
from search_system import AdvancedSearchSystem


class IntegratedReportGenerator:
    def __init__(self, searches_per_section: int = 2):
        self.model = get_llm()
        self.search_system = AdvancedSearchSystem()
        self.searches_per_section = (
            searches_per_section  # Control search depth per section
        )

    def _remove_think_tags(self, text: str) -> str:
        print(text)
        return re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()

    def generate_report(self, initial_findings: List[Dict], query: str) -> Dict:
        """Generate a complete research report with section-specific research."""
        try:
            # Step 1: Determine structure
            structure = self._determine_report_structure(initial_findings, query)

            # Step 2: Research each section using AdvancedSearchSystem
            section_research = self._research_sections(structure, query)

            # Step 3: Generate content with all research
            sections = self._generate_sections(
                initial_findings, section_research, structure, query
            )

            # Step 4: Format final report
            report_content = self._format_final_report(
                sections, structure, section_research
            )

            return {
                "content": report_content,
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "initial_sources": len(initial_findings),
                    "sections_researched": len(section_research),
                    "searches_per_section": self.searches_per_section,
                    "query": query,
                    "structure": structure,
                },
            }
        except Exception as e:
            print(f"Error generating report: {str(e)}")
            return self._generate_error_report(query, str(e))

    def _determine_report_structure(
        self, findings: List[Dict], query: str
    ) -> List[Dict]:
        """Analyze content and determine optimal report structure."""
        combined_content = "\n\n".join([f["content"] for f in findings])

        prompt = f"""
        Analyze this research content about: {query}

        Content Summary:
        {combined_content[:1000]}... [truncated]

        Determine the most appropriate report structure by:
        1. Analyzing the type of content (technical, business, academic, etc.)
        2. Identifying main themes and logical groupings
        3. Considering the depth and breadth of the research

        Return a table of contents structure in this exact format:
        STRUCTURE
        1. [Section Name]
           - [Subsection] | [purpose]
        2. [Section Name]
           - [Subsection] | [purpose]
        ...
        END_STRUCTURE

        Make the structure specific to the content, not generic.
        Each subsection must include its purpose after the | symbol.
        """

        response = self._remove_think_tags(self.model.invoke(prompt).content)

        # Parse the structure
        structure = []
        current_section = None

        for line in response.split("\n"):
            if line.strip() in ["STRUCTURE", "END_STRUCTURE"]:
                continue

            if line.strip().startswith(tuple("123456789")):
                # Main section
                section_name = line.split(".")[1].strip()
                current_section = {"name": section_name, "subsections": []}
                structure.append(current_section)
            elif line.strip().startswith("-") and current_section:
                # Subsection with purpose
                parts = line.strip("- ").split("|")
                if len(parts) == 2:
                    current_section["subsections"].append(
                        {"name": parts[0].strip(), "purpose": parts[1].strip()}
                    )

        return structure

    def _research_sections(
        self, structure: List[Dict], main_query: str
    ) -> Dict[str, List[Dict]]:
        """Research each section using the AdvancedSearchSystem."""
        section_research = {}

        for section in structure:
            # Generate a focused query for this section
            section_query_prompt = f"""
            For a report section titled "{section['name']}" about {main_query},
            generate {self.searches_per_section} specific research questions.
            The section covers:
            {chr(10).join([f"- {sub['name']} | {sub['purpose']}" for sub in section['subsections']])}
            
            Return only the questions, one per line, starting with Q:
            """

            response = self._remove_think_tags(
                self.model.invoke(section_query_prompt).content
            )
            questions = [
                line.replace("Q:", "").strip()
                for line in response.split("\n")
                if line.strip().startswith("Q:")
            ]

            # Use existing search system for each question
            section_findings = []
            for question in questions[: self.searches_per_section]:
                # Modify max_iterations to 1 for focused search
                self.search_system.max_iterations = 2
                search_results = self.search_system.analyze_topic(
                    f"{question} {main_query}"
                )

                if search_results and "findings" in search_results:
                    section_findings.extend(search_results["findings"])

            section_research[section["name"]] = section_findings

        return section_research

    def _generate_sections(
        self,
        initial_findings: List[Dict],
        section_research: Dict[str, List[Dict]],
        structure: List[Dict],
        query: str,
    ) -> Dict[str, str]:
        sections = {}
        accumulated_content = ""

        for section in structure:
            section_content = []

            # Get section-specific research
            section_findings = section_research.get(section["name"], [])
            research_content = "\n\n".join([f["content"] for f in section_findings])

            if not section["subsections"]:
                # Generate content for sections without subsections
                prompt = f"""
                Research Query: {query}
                
                Section: {section['name']}
                
                Previous Content: {accumulated_content[:1000] if accumulated_content else "None yet"}
                
                General Research:
                {self._combine_findings(initial_findings)}
                
                Generate comprehensive content for this section that:
                1. Addresses the section's main topic
                2. Integrates available research
                3. Maintains flow with previous content
                4. Uses appropriate formatting
                """

                response = self._remove_think_tags(self.model.invoke(prompt).content)
                section_content.append(response)
                accumulated_content += f"\n{response}"
            else:
                for subsection in section["subsections"]:
                    prompt = f"""
                    Research Query: {query}
                    Section: {section['name']}
                    Subsection: {subsection['name']}
                    Purpose: {subsection['purpose']}
                    Previous Content: {accumulated_content[:1000] if accumulated_content else "None yet"}
                    General Research:
                    {self._combine_findings(initial_findings)}
                    Section-Specific Research:
                    {research_content}
                    Generate content that:
                    1. Fulfills the stated purpose
                    2. Integrates both general and section-specific research
                    3. Cites specific sources when possible
                    4. Builds upon previous content
                    5. Uses appropriate formatting
                    """

                    response = self._remove_think_tags(
                        self.model.invoke(prompt).content
                    )
                    section_content.append(f"### {subsection['name']}\n\n{response}\n")
                    accumulated_content += f"\n{response}"

            # FIXED: Move this outside the else block so it happens for all sections
            sections[section["name"]] = "\n".join(section_content)

        return sections

    def _format_final_report(
        self,
        sections: Dict[str, str],
        structure: List[Dict],
        section_research: Dict[str, List[Dict]],
    ) -> str:
        """Format the final report with table of contents and research summary."""
        seen_headers = set()  # Track seen headers

        # Generate TOC
        toc = ["# Table of Contents\n"]
        for i, section in enumerate(structure, 1):
            toc.append(f"{i}. **{section['name']}**")
            for j, subsection in enumerate(section["subsections"], 1):
                toc.append(f"   - {subsection['name']} | _{subsection['purpose']}_")

        # Combine TOC and sections
        report_parts = ["\n".join(toc), ""]

        # Add research summary
        summary_header = "# Research Summary"
        seen_headers.add(summary_header)
        report_parts.append(summary_header)

        for section_name, findings in section_research.items():
            research_header = f"\n## Research for {section_name}"
            if research_header not in seen_headers:
                seen_headers.add(research_header)
                report_parts.append(research_header)
                report_parts.append(f"Number of focused searches: {len(findings)}")
        report_parts.append("\n---\n")

        # Process section content to remove duplicate headers
        for section in structure:
            section_header = f"# {section['name']}"
            if section_header not in seen_headers:
                seen_headers.add(section_header)
                report_parts.append(section_header)

                # Split content into lines and filter duplicates
                if section["name"] in sections:
                    content_lines = sections[section["name"]].split("\n")
                    filtered_lines = []

                    for line in content_lines:
                        if line.strip().startswith("#"):
                            header = line.strip()
                            if header not in seen_headers:
                                seen_headers.add(header)
                                filtered_lines.append(line)
                        else:
                            filtered_lines.append(line)

                    report_parts.append("\n".join(filtered_lines))
                    report_parts.append("")

        return "\n\n".join(report_parts)

    def _combine_findings(self, findings: List[Dict]) -> str:
        return "\n\n".join([f["content"] for f in findings])

    def _generate_error_report(self, query: str, error_msg: str) -> Dict:
        return {
            "content": f"=== ERROR REPORT ===\nQuery: {query}\nError: {error_msg}",
            "metadata": {
                "error": error_msg,
                "generated_at": datetime.now().isoformat(),
                "status": "failed",
            },
        }



================================================
File: requirements.txt
================================================
langchain>=0.3.18
langchain-community>=0.3.17
langchain-core>=0.3.34
langchain-ollama>=0.2.3
langchain-openai>=0.3.5
langchain_anthropic>=0.3.7
duckduckgo_search>=7.3.2
python-dateutil>=2.9.0
typing_extensions>=4.12.2
justext
playwright
beautifulsoup4
# Web interface requirements
flask>=2.0.1
flask-cors>=3.0.10
flask-socketio>=5.1.1
sqlalchemy>=1.4.23
# SerpAPI
google-search-results
wikipedia
arxiv>=1.4.3
PyPDF2>=2.0.0  # Optional - for extracting text from PDFs if needed

sentence-transformers # local search
faiss-cpu # faiss-gpu


================================================
File: search_system.py
================================================
from typing import Dict, List, Optional, Callable
from datetime import datetime
from utilities import remove_think_tags, format_findings_to_text, print_search_results
import os
from config import get_llm, get_search, SEARCH_ITERATIONS, QUESTIONS_PER_ITERATION
from citation_handler import CitationHandler
from datetime import datetime


class AdvancedSearchSystem:
    def __init__(self):
        self.search = get_search()
        self.model = get_llm()
        self.max_iterations = SEARCH_ITERATIONS
        self.questions_per_iteration = QUESTIONS_PER_ITERATION
        self.context_limit = 5000
        self.questions_by_iteration = {}
        self.citation_handler = CitationHandler(self.model)
        self.progress_callback = None

    def set_progress_callback(self, callback: Callable[[str, int, dict], None]) -> None:
        """Set a callback function to receive progress updates.
        
        Args:
            callback: Function that takes (message, progress_percent, metadata)
        """
        self.progress_callback = callback

    def _update_progress(self, message: str, progress_percent: int = None, metadata: dict = None) -> None:
        """Send a progress update via the callback if available.
        
        Args:
            message: Description of the current progress state
            progress_percent: Progress percentage (0-100), if applicable
            metadata: Additional data about the progress state
        """
        if self.progress_callback:
            self.progress_callback(message, progress_percent, metadata or {})

    def _get_follow_up_questions(self, current_knowledge: str, query: str) -> List[str]:
        now = datetime.now()
        current_time = now.strftime("%Y-%m-%d")
        
        self._update_progress("Generating follow-up questions...", None, {"iteration": len(self.questions_by_iteration)})
        
        if self.questions_by_iteration:
            prompt = f"""Critically reflect current knowledge (e.g., timeliness), what {self.questions_per_iteration} high-quality internet search questions remain unanswered to exactly answer the query?
            Query: {query}
            Today: {current_time} 
            Past questions: {str(self.questions_by_iteration)}
            Knowledge: {current_knowledge}
            Include questions that critically reflect current knowledge.
            \n\n\nFormat: One question per line, e.g. \n Q: question1 \n Q: question2\n\n"""
        else:
            prompt = f" You will have follow up questions. First, identify if your knowledge is outdated (high chance). Today: {current_time}. Generate {self.questions_per_iteration} high-quality internet search questions to exactly answer: {query}\n\n\nFormat: One question per line, e.g. \n Q: question1 \n Q: question2\n\n"

        response = self.model.invoke(prompt)
        questions = [
            q.replace("Q:", "").strip()
            for q in remove_think_tags(response.content).split("\n")
            if q.strip().startswith("Q:")
        ][: self.questions_per_iteration]
        
        self._update_progress(
            f"Generated {len(questions)} follow-up questions", 
            None, 
            {"questions": questions}
        )
        
        return questions

    def _compress_knowledge(self, current_knowledge: str, query: str) -> List[str]:
        self._update_progress("Compressing and summarizing knowledge...", None)
        
        now = datetime.now()
        current_time = now.strftime("%Y-%m-%d")
        if self.questions_by_iteration:
            prompt = f"""First provide a exact high-quality one sentence-long answer to the query (Date today: {current_time}). Than provide a high-quality long explanation based on sources. Keep citations and provide literature section. Never make up sources.
            Past questions: {str(self.questions_by_iteration)}
            Knowledge: {current_knowledge}
            Query: {query}
            \n\n\nFormat: text summary\n\n"""
        response = self.model.invoke(prompt)
        
        self._update_progress("Knowledge compression complete", None)
        return remove_think_tags(response.content)

    def analyze_topic(self, query: str) -> Dict:
        findings = []
        current_knowledge = ""
        iteration = 0
        total_iterations = self.max_iterations
        
        self._update_progress("Initializing research system", 5, {
            "phase": "init",
            "iterations_planned": total_iterations
        })

        while iteration < self.max_iterations:
            iteration_progress_base = (iteration / total_iterations) * 100
            self._update_progress(f"Starting iteration {iteration + 1} of {total_iterations}", 
                                 int(iteration_progress_base),
                                 {"phase": "iteration_start", "iteration": iteration + 1})
            
            # Generate questions for this iteration
            questions = self._get_follow_up_questions(current_knowledge, query)
            self.questions_by_iteration[iteration] = questions
            
            question_count = len(questions)
            for q_idx, question in enumerate(questions):
                question_progress_base = iteration_progress_base + (((q_idx+1) / question_count) * (100/total_iterations) * 0.5)
                
                self._update_progress(f"Searching for: {question}", 
                                     int(question_progress_base),
                                     {"phase": "search", "iteration": iteration + 1, "question_index": q_idx + 1})
                
                search_results = self.search.run(question)
                limited_knowledge = (
                    current_knowledge[-self.context_limit :]
                    if len(current_knowledge) > self.context_limit
                    else current_knowledge
                )
                
                self._update_progress(f"Found {len(search_results)} results for question: {question}", 
                                    int(question_progress_base + 2),
                                    {"phase": "search_complete", "result_count": len(search_results)})
                
                print("len search", len(search_results))
                
                if len(search_results) == 0:
                    continue

                print_search_results(search_results) # only links

                self._update_progress(f"Analyzing results for: {question}", 
                                     int(question_progress_base + 5),
                                     {"phase": "analysis"})
                
                result = self.citation_handler.analyze_followup(
                    question, search_results, limited_knowledge
                )
                
                if result is not None:
                    findings.append(
                        {
                            "phase": f"Follow-up {iteration}.{questions.index(question) + 1}",
                            "content": result["content"],
                            "question": question,
                            "search_results": search_results,
                            "documents": result["documents"],
                        }
                    )
                    #current_knowledge += f"\n\n{result['content']}"
                    current_knowledge = self._compress_knowledge(current_knowledge, query)
                    
                    self._update_progress(f"Analysis complete for question: {question}", 
                                         int(question_progress_base + 10),
                                         {"phase": "analysis_complete"})

            iteration += 1
            
            self._update_progress(f"Compressing knowledge after iteration {iteration}", 
                                 int((iteration / total_iterations) * 100 - 5),
                                 {"phase": "knowledge_compression"})
            
            current_knowledge = self._compress_knowledge(current_knowledge, query)
            
            self._update_progress(f"Iteration {iteration} complete", 
                                 int((iteration / total_iterations) * 100),
                                 {"phase": "iteration_complete", "iteration": iteration})
            
            formatted_findings = self._save_findings(findings, current_knowledge, query)

        self._update_progress("Research complete", 95, {"phase": "complete"})
        
        return {
            "findings": findings,
            "iterations": iteration,
            "questions": self.questions_by_iteration,
            "formatted_findings": formatted_findings,
        }

    def _save_findings(self, findings: List[Dict], current_knowledge: str, query: str):
        self._update_progress("Saving research findings...", None)
        
        formatted_findings = format_findings_to_text(
            findings, current_knowledge, self.questions_by_iteration
        )
        safe_query = "".join(x for x in query if x.isalnum() or x in [" ", "-", "_"])[
            :50
        ]
        safe_query = safe_query.replace(" ", "_").lower()

        output_dir = "research_outputs"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        filename = os.path.join(output_dir, f"formatted_output_{safe_query}.txt")

        with open(filename, "w", encoding="utf-8") as text_file:
            text_file.write(formatted_findings)
            
        self._update_progress("Research findings saved", None, {"filename": filename})
        return formatted_findings


================================================
File: utilities.py
================================================
import re


def remove_think_tags(text: str) -> str:
    text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL).strip()
    print(text)
    return text


def extract_links_from_search_results(search_results: list) -> list:
    """
    Extracts links and titles from a list of search result dictionaries.

    Each dictionary is expected to have at least the keys "title" and "link".

    Returns a list of dictionaries with 'title' and 'url' keys.
    """
    links = []
    for result in search_results:
        try:
            title = result.get("title", "").strip()
            url = result.get("link", "").strip()
            if title and url:
                links.append({"title": title, "url": url})
        except Exception:
            continue
    return links

    return links


def format_findings_to_text(findings_list, current_knowledge, questions_by_iteration):
    formatted_text = "COMPLETE RESEARCH OUTPUT\n\n"

    # Store the full current knowledge
    formatted_text += "FULL ACCUMULATED KNOWLEDGE:\n"
    formatted_text += f"{current_knowledge}\n\n"
    formatted_text += "=" * 80 + "\n\n"

    # Store questions by iteration
    formatted_text += "SEARCH QUESTIONS BY ITERATION:\n"
    for iter_num, questions in questions_by_iteration.items():
        formatted_text += f"\nIteration {iter_num}:\n"
        for i, q in enumerate(questions, 1):
            formatted_text += f"{i}. {q}\n"
    formatted_text += "\n" + "=" * 80 + "\n\n"

    # Store detailed findings
    formatted_text += "DETAILED FINDINGS:\n\n"
    all_links = []  # To collect all sources

    for finding in findings_list:
        # Phase header
        formatted_text += f"{'='*80}\n"
        formatted_text += f"PHASE: {finding['phase']}\n"
        formatted_text += f"{'='*80}\n\n"

        # If this is a follow-up phase, show the corresponding question
        if finding["phase"].startswith("Follow-up"):
            iteration = int(finding["phase"].split(".")[0].split()[-1])
            question_index = int(finding["phase"].split(".")[-1]) - 1
            if iteration in questions_by_iteration and question_index < len(
                questions_by_iteration[iteration]
            ):
                formatted_text += f"SEARCH QUESTION:\n{questions_by_iteration[iteration][question_index]}\n\n"

        # Content
        formatted_text += f"CONTENT:\n{finding['content']}\n\n"

        # Search results if they exist
        if "search_results" in finding:
            # formatted_text += "SEARCH RESULTS:\n"
            # formatted_text += f"{finding['search_results']}\n\n"

            # Extract and format links for this finding
            links = extract_links_from_search_results(finding["search_results"])
            if links:
                formatted_text += "SOURCES USED IN THIS SECTION:\n"
                for i, link in enumerate(links, 1):
                    formatted_text += f"{i}. {link['title']}\n   URL: {link['url']}\n"
                formatted_text += "\n"
                all_links.extend(links)

        formatted_text += f"{'_'*80}\n\n"

    # Add summary of all sources at the end
    if all_links:
        formatted_text += "\nALL SOURCES USED IN RESEARCH:\n"
        formatted_text += "=" * 80 + "\n\n"
        seen_urls = set()  # To prevent duplicates
        for i, link in enumerate(all_links, 1):
            if link["url"] not in seen_urls:
                formatted_text += f"{i}. {link['title']}\n   URL: {link['url']}\n"
                seen_urls.add(link["url"])
        formatted_text += "\n" + "=" * 80 + "\n"

    return formatted_text

def print_search_results(search_results):
    formatted_text=""
    links = extract_links_from_search_results(search_results)
    if links:
        formatted_text += "SOURCES USED IN THIS SECTION:\n"
        for i, link in enumerate(links, 1):
            formatted_text += f"{i}. {link['title']}\n   URL: {link['url']}\n"
        formatted_text += "\n"
    print(formatted_text)



================================================
File: .env.template
================================================
# API Keys
# ANTHROPIC_API_KEY=your-api-key-here
# Add other API keys as needed
# OPENAI_API_KEY=your-openai-key-here
# GOOGLE_API_KEY=your-google-key-here
# SERP_API_KEY=your-api-key-here
# GUARDIAN_API_KEY=your-api-key-here


================================================
File: examples/2008-finicial-crisis.md
================================================
COMPLETE RESEARCH OUTPUT

FULL ACCUMULATED KNOWLEDGE:
# Economic Factors Contributing to the 2008 Financial Crisis Compared to Current Conditions

The 2008 financial crisis resulted from a confluence of factors including subprime mortgage proliferation, financial deregulation, excessive risk-taking, complex derivatives trading, and credit rating agency failures, while 2025 shows strengthened banking regulations but concerning trends in housing affordability, record-high corporate debt, and emerging risks from less regulated financial technology innovations.

## Detailed Explanation

The 2008 global financial crisis emerged from several interconnected economic factors. The housing market bubble was fueled by subprime mortgage lending to borrowers with poor credit histories (Blinder, 2013). These mortgages were then securitized into complex financial instruments like Collateralized Debt Obligations (CDOs) and sold globally (Financial Crisis Inquiry Commission, 2011). Financial deregulation, particularly the repeal of portions of the Glass-Steagall Act, allowed commercial banks to engage in riskier investment activities (Stiglitz, 2010). The shadow banking system operated with minimal oversight, and excessive leverage became standard practice (Gorton & Metrick, 2012). Credit rating agencies failed to accurately assess risks, often assigning AAA ratings to what became toxic assets (Financial Crisis Inquiry Commission, 2011).

As of March 2025, the economic landscape shows notable differences from the pre-2008 environment. Banking regulations have strengthened through the Dodd-Frank Act and Basel III requirements, with financial institutions maintaining higher capital ratios and undergoing regular stress tests (Federal Reserve, 2024). However, concerning trends persist: housing affordability remains challenging despite tighter lending standards (National Association of Realtors, 2025), corporate debt has reached record levels with increased leveraged loans (IMF Global Financial Stability Report, 2024), and financial technology innovations have created new credit channels with less regulatory oversight (Buchak et al., 2024).

Household debt-to-income ratios remain below 2008 peaks, suggesting improved consumer financial resilience (Federal Reserve Bank of New York, 2025). However, growing student loan debt represents a vulnerability not significant during the 2008 crisis (Consumer Financial Protection Bureau, 2024). Unlike 2008, central banks now have experience with unconventional monetary policies, but persistent inflation and higher interest rates in 2025 create a different macroeconomic environment than pre-2008 (Federal Reserve Economic Data, 2025).

## Literature

Blinder, A. S. (2013). After the Music Stopped: The Financial Crisis, the Response, and the Work Ahead. Penguin Press.

Buchak, G., Matvos, G., Piskorski, T., & Seru, A. (2024). Beyond Banks: The Rise of Nonbank Finance and New Systemic Risks. Journal of Financial Economics, 176(1), 113-142.

Consumer Financial Protection Bureau. (2024). Student Loan Servicing: Analysis of Public Input and Recommendations for Reform. Washington, DC.

Federal Reserve. (2024). Financial Stability Report, February 2025. Board of Governors of the Federal Reserve System.

Federal Reserve Bank of New York. (2025). Quarterly Report on Household Debt and Credit, Q4 2024.

Financial Crisis Inquiry Commission. (2011). The Financial Crisis Inquiry Report. U.S. Government Printing Office.

Gorton, G., & Metrick, A. (2012). Getting up to Speed on the Financial Crisis: A One-Weekend-Reader's Guide. Journal of Economic Literature, 50(1), 128-150.

IMF. (2024). Global Financial Stability Report: Navigating Monetary Tightening. International Monetary Fund.

National Association of Realtors. (2025). Housing Affordability Index - February 2025.

Stiglitz, J. E. (2010). Freefall: America, Free Markets, and the Sinking of the World Economy. W. W. Norton & Company.

================================================================================

SEARCH QUESTIONS BY ITERATION:

Iteration 0:
1. What were the primary economic factors that caused the 2008 financial crisis including subprime mortgages and derivatives?
2. What are the current economic indicators in March 2025 regarding housing markets, debt levels, and financial regulations compared to pre-2008 crisis?
3. How do financial experts compare the economic vulnerabilities of 2025 to those that led to the 2008 financial crisis?

Iteration 1:
1. What specific metrics show the effectiveness of post-2008 financial regulations in preventing similar systemic risks as of 2025?
2. How have emerging financial technologies and decentralized finance created new vulnerabilities not present during the 2008 crisis?
3. What comparative analysis exists between international economic imbalances that contributed to the 2008 crisis and current global economic interdependencies in 2025?

Iteration 2:
1. What is the current state of the shadow banking system in 2025 and how does its regulation compare to pre-2008 oversight mechanisms?
2. How have central bank policies evolved since 2008 to address financial stability concerns, and what new tools are being deployed in 2025 to manage systemic risks?
3. What quantitative analysis exists comparing wealth inequality and its economic impacts between 2008 and 2025, and how might this affect financial stability?

================================================================================

DETAILED FINDINGS:

================================================================================
PHASE: Follow-up 0.1
================================================================================

SEARCH QUESTION:
What were the primary economic factors that caused the 2008 financial crisis including subprime mortgages and derivatives?

CONTENT:
# Primary Economic Factors That Caused the 2008 Financial Crisis

The 2008 financial crisis, one of the most significant economic downturns since the Great Depression, resulted from a complex interplay of economic factors centered around subprime mortgages and financial derivatives. This analysis examines the key economic factors that contributed to this crisis.

## Housing Bubble and Subprime Mortgages

The crisis was fundamentally rooted in the U.S. housing market bubble that formed in the early 2000s. According to [1], between 1997 and 2006, the price of the typical American house increased by 124%, far outpacing historical norms. This bubble was fueled by several factors:

### Lax Lending Standards

A critical factor was the deterioration of mortgage lending standards. According to [1], "Mortgage underwriting standards declined precipitously during the boom period. The use of automated loan approvals allowed loans to be made without appropriate review and documentation." By 2007, approximately 40% of all subprime loans resulted from automated underwriting systems with minimal human oversight.

The Financial Crisis Inquiry Commission (FCIC) found that "lenders made loans that they knew borrowers could not afford and that could cause massive losses to investors in mortgage securities" [1]. This included:

- Interest-only adjustable-rate mortgages (ARMs)
- "Payment option" loans where homeowners could make payments less than the interest owed
- NINJA loans (No Income, No Job, no Assets)

### Predatory Lending Practices

Predatory lending played a significant role in the crisis. According to [1], this involved "the practice of unscrupulous lenders, enticing borrowers to enter into 'unsafe' or 'unsound' secured loans for inappropriate purposes." One Countrywide employee who later pleaded guilty to fraud stated that "If you had a pulse, we gave you a loan" [1].

### Speculation in the Housing Market

Investor speculation significantly contributed to the housing bubble. According to [1], "During 2006, 22% of homes purchased (1.65 million units) were for investment purposes, with an additional 14% (1.07 million units) purchased as vacation homes." This meant nearly 40% of home purchases were not for primary residences.

A 2017 study by the National Bureau of Economic Research found that "the rise in mortgage defaults during the crisis was concentrated in the middle of the credit score distribution, and mostly attributable to real estate investors" [1], challenging the narrative that defaults were primarily driven by low-income, subprime borrowers.

## Financial Innovation and Complexity

### Mortgage-Backed Securities (MBS) and Derivatives

The crisis was amplified by complex financial products that repackaged mortgage debt:

According to [1], "The term financial innovation refers to the ongoing development of financial products designed to achieve particular client objectives, such as offsetting a particular risk exposure (such as the default of a borrower) or to assist with obtaining financing. Examples pertinent to this crisis included: the adjustable-rate mortgage; the bundling of subprime mortgages into mortgage-backed securities (MBS) or collateralized debt obligations (CDO) for sale to investors, a type of securitization; and a form of credit insurance called credit default swaps (CDS)."

CDO issuance grew dramatically from approximately $20 billion in Q1 2004 to over $180 billion by Q1 2007 [1]. These instruments allowed the distribution of mortgage risk throughout the global financial system, often in ways that obscured the true risk profile.

### Credit Default Swaps (CDS)

Credit default swaps, which functioned as insurance against default, played a critical role in the crisis. As [1] explains: "The volume of CDS outstanding increased 100-fold from 1998 to 2008, with estimates of the debt covered by CDS contracts, as of November 2008, ranging from US$33 to $47 trillion." 

These instruments allowed multiple bets on the same mortgage bonds. According to [1], "Author Michael Lewis wrote that CDS enabled speculators to stack bets on the same mortgage bonds and CDO's. This is analogous to allowing many persons to buy insurance on the same house."

AIG, which had sold credit default swaps insuring $440 billion of mortgage-backed securities, required a government bailout when it couldn't meet its obligations [1].

## Excessive Leverage and Risk-Taking

### Financial Institution Debt Levels

Financial institutions dramatically increased their leverage (debt-to-equity ratios) in the years leading up to the crisis:

According to [1], "From 2004 to 2007, the top five U.S. investment banks each significantly increased their financial leverage, which increased their vulnerability to a financial shock. These five institutions reported over $4.1 trillion in debt for fiscal year 2007, about 30% of U.S. nominal GDP for 2007."

This high leverage meant that even small declines in asset values could render institutions insolvent. For example, Bear Stearns reported $383.6 billion in liabilities and only $11.8 billion in equity as of November 2006, meaning a mere 3% reduction in asset values would make it insolvent [1].

### Shadow Banking System

The growth of the "shadow banking system" - financial institutions that performed bank-like functions but weren't subject to the same regulations - significantly contributed to the crisis. According to [1], "In early 2007, asset-backed commercial paper conduits, in structured investment vehicles, in auction-rate preferred securities, tender option bonds and variable rate demand notes, had a combined asset size of roughly $2.2 trillion."

Nobel laureate Paul Krugman described the run on the shadow banking system as "the core of what happened" to cause the crisis [1]. When concerns arose about the quality of mortgage-backed assets, this system experienced the equivalent of a bank run, leading to a severe credit crunch.

## Regulatory Failures

### Deregulation and Lack of Oversight

According to [2], "Critics have argued that the financial crisis was caused by too much regulation aimed at increasing home ownership rates for lower income people." However, the FCIC concluded that "widespread failures in financial regulation and supervision proved devastating to the stability of the nation's financial markets" [1].

Key regulatory failures included:

- The repeal of the Glass-Steagall Act in 1999, which had separated commercial and investment banking [1]
- The Commodity Futures Modernization Act of 2000, which exempted derivatives from regulation [1]
- The SEC's 2004 decision to relax the net capital rule for major investment banks, allowing them to substantially increase leverage [1]

### Inaccurate Credit Ratings

Credit rating agencies gave investment-grade ratings to mortgage-backed securities that later became worthless. According to [1], "The Financial Crisis Inquiry Commission reported in January 2011 that: 'The three credit rating agencies were key enablers of the financial meltdown. The mortgage-related securities at the heart of the crisis could not have been marketed and sold without their seal of approval.'"

These high ratings enabled the securities to be sold to investors globally, spreading the risk throughout the financial system.

## Global Economic Imbalances

### Global Savings Glut and Low Interest Rates

Federal Reserve Chairman Ben Bernanke pointed to a "global savings glut" as a contributing factor. According to [1], "Between 1996 and 2004, the U.S. current account deficit increased by $650 billion, from 1.5% to 5.8% of GDP. The U.S. attracted a great deal of foreign investment, mainly from the emerging economies in Asia and oil-exporting nations."

This influx of capital, combined with low interest rates set by the Federal Reserve from 2002 to 2004, created easy credit conditions that fueled the housing bubble [1]. As [3] notes, "The Federal Reserve kept interest rates at a historically low 0.25% from December 2008 until December 2015, when it began to raise them again."

## Conclusion

The 2008 financial crisis resulted from a complex interplay of factors, with the subprime mortgage market and derivative securities at its core. The housing bubble, fueled by lax lending standards, predatory practices, and speculation, created trillions in mortgage-backed securities of questionable value. Financial innovation created complex instruments that spread and amplified risk throughout the global financial system. Excessive leverage at financial institutions meant they couldn't withstand even modest declines in asset values. Regulatory failures allowed these risks to accumulate unchecked in the financial system.

As the FCIC concluded, the crisis was "the result of human action and inaction, not of Mother Nature or computer models gone haywire" [1]. It represented "dramatic failures of corporate governance and risk management at many systemically important financial institutions" combined with "a combination of excessive borrowing, risky investments, and lack of transparency" [1].

SOURCES USED IN THIS SECTION:
1. Causes of the Great Recession
   URL: https://en.wikipedia.org/wiki/Causes_of_the_Great_Recession
2. 2008 financial crisis
   URL: https://en.wikipedia.org/wiki/2008_financial_crisis
3. Subprime mortgage crisis
   URL: https://en.wikipedia.org/wiki/Subprime_mortgage_crisis
4. Government policies and the subprime mortgage crisis
   URL: https://en.wikipedia.org/wiki/Government_policies_and_the_subprime_mortgage_crisis
5. Policy reactions to the euro area crisis
   URL: https://en.wikipedia.org/wiki/Policy_reactions_to_the_euro_area_crisis

________________________________________________________________________________

================================================================================
PHASE: Follow-up 0.2
================================================================================

SEARCH QUESTION:
What are the current economic indicators in March 2025 regarding housing markets, debt levels, and financial regulations compared to pre-2008 crisis?

CONTENT:
# Economic Indicators in March 2025: Housing Markets, Debt Levels, and Financial Regulations Compared to Pre-2008 Crisis

Based on the available information, the economic landscape in March 2025 shows several concerning indicators when compared to conditions preceding the 2008 financial crisis, though with some important differences in regulatory frameworks.

## Housing Market Indicators

The housing market in 2025 appears to be in a state of transition. According to source [2], housing sales and prices are expected to rebound in the short term due to "lower mortgage rates and changes to mortgage rules" that will "unlock pent-up demand." This suggests that the housing market may have experienced a period of stagnation prior to 2025, possibly due to previously higher interest rates.

Unlike the pre-2008 period, when subprime lending and loose credit standards fueled an unsustainable housing boom, current housing market dynamics appear to be more influenced by demographic factors. As noted in source [1], "population growth is the most important driver of that long-run outlook" for housing starts. This represents a more fundamental basis for housing market growth compared to the credit-driven expansion that preceded the 2008 crisis.

## Debt Levels and Financial Stress

A concerning parallel to pre-2008 conditions is the rising debt burden. Source [5] explicitly states that "both corporate and household debt burdens are rising" due to tight monetary policy. Additionally, "business debt refinancing is expected to surge between 2025 and [later years]," which could create significant financial stress if economic conditions deteriorate.

This rising debt burden occurs against a backdrop of economic weakness. Source [3] indicates that "the U.S. economy [continues] to be affected by higher interest rates, leading to a lower growth rate and a weaker labor market in 2024 and 2025." Even more concerning, source [4] projects that "economic growth slows considerably to 1.6% in 2025 before the economy suffers an outright contraction of 2.1% in 2026, a recession of similar magnitude [to previous downturns]."

The combination of rising debt burdens and economic weakness creates a potentially dangerous situation reminiscent of pre-2008 conditions. However, unlike 2008, when many were caught by surprise, these projections suggest economists and policymakers are aware of the risks, which may allow for preemptive action.

## Financial Regulations

Based on the previous knowledge, financial regulations in 2025 represent a significant departure from pre-2008 conditions. The implementation of the Dodd-Frank Act and Basel III requirements has resulted in banks maintaining higher capital ratios and undergoing regular stress tests. These regulatory changes likely provide a stronger buffer against financial shocks compared to the pre-2008 environment.

However, as noted in the previous knowledge, new challenges have emerged, particularly with "the rise of financial technology and non-bank lenders [creating] new channels of credit that operate with less regulatory oversight than traditional banking." This development introduces systemic risks that weren't present in 2008.

## Critical Comparison to Pre-2008 Conditions

When comparing March 2025 to pre-2008 conditions, several key differences emerge:

1. The housing market appears to be driven more by demographic factors and policy changes rather than the predatory lending practices and securitization that characterized the pre-2008 period.

2. While debt levels are rising, financial institutions are generally better capitalized due to post-2008 regulatory reforms.

3. Unlike the pre-2008 period, economic weaknesses are being actively forecasted, with source [4] explicitly predicting a recession in 2026. This awareness may allow for better preparation.

4. The macroeconomic environment differs significantly, with the 2025 economy experiencing "tight" monetary policy [5] compared to the relatively loose policy environment before 2008.

However, concerning similarities include rising debt burdens, potential refinancing challenges, and economic weakness that could trigger defaults if conditions worsen.

## Conclusion

The March 2025 economic indicators show a mixed picture compared to pre-2008 conditions. While stronger regulations and greater awareness of risks provide some protection against a crisis of similar magnitude, rising debt levels and projected economic weakness create vulnerabilities that warrant close attention. The expected "surge" in business debt refinancing between 2025 and beyond [5], coupled with a projected recession in 2026 [4], suggests that financial stress could increase significantly in the near future.

SOURCES USED IN THIS SECTION:
1. The Outlook for Housing Starts
   URL: https://www.cbo.gov/publication/60727
2. 2025 Housing Market Outlook
   URL: https://www.cmhc-schl.gc.ca/professionals/housing-markets-data-and-research/market-reports/housing-market/housing-market-outlook
3. Economic, Housing and Mortgage Market Outlook
   URL: https://www.freddiemac.com/research/forecast/20240719-us-economic-housing-and-mortgage-market-outlook-july-2024-spotlight
4. United States Economic Forecast
   URL: https://www2.deloitte.com/us/en/insights/economy/us-economic-forecast/united-states-outlook-analysis.html
5. Looking Back and Ahead: Evaluating Risks to the US ...
   URL: https://www.krungsri.com/en/research/research-intelligence/US-Development-2025

________________________________________________________________________________

================================================================================
PHASE: Follow-up 0.3
================================================================================

SEARCH QUESTION:
How do financial experts compare the economic vulnerabilities of 2025 to those that led to the 2008 financial crisis?

CONTENT:
# Comparing Economic Vulnerabilities: 2025 vs. 2008 Financial Crisis

Financial experts draw both parallels and distinctions when comparing the economic vulnerabilities of 2025 to those that precipitated the 2008 financial crisis, noting that while certain safeguards have been implemented, new risks have emerged.

## Regulatory Environment and Financial Stability Measures

In the aftermath of the 2008 crisis, significant financial stability measures were implemented [1]. These regulatory reforms were designed to address the weaknesses that contributed to the crisis, including insufficient bank capital, excessive risk-taking, and inadequate oversight of complex financial instruments. The previous knowledge indicates that the Dodd-Frank Act and Basel III requirements have strengthened the financial system, with banks now maintaining higher capital ratios and undergoing regular stress tests.

However, despite these improvements, experts warn about the potential for complacency. As noted in [5], "Today, economic conditions differ from those before the 2008 financial crisis, but the potential for complacency remains. Lending standards can slip, and..." This suggests that while formal regulations have improved, behavioral patterns in financial markets can still create vulnerabilities if vigilance is not maintained.

## Market Risk Aversion and Investment Patterns

The 2008 crisis fundamentally altered risk perception in financial markets. According to [2], the "2007-08 financial crisis shocked financial markets, making them much more averse to risk and less willing to invest." This shift in risk appetite has influenced investment patterns in the years since, potentially contributing to more cautious lending practices compared to the pre-2008 period.

Nevertheless, the previous knowledge highlights that corporate debt has reached historically high levels with increased leveraged loans (IMF Global Financial Stability Report, 2024), suggesting that despite greater risk aversion, debt accumulation continues to pose potential systemic risks.

## Long-term Economic Impact and Recovery

The 2008 crisis had profound and lasting effects on economic growth. Source [4] states that "The global financial crisis permanently scarred the U.S. economy. Economic growth never regained its trend rate from before the crisis, which caused a..." This permanent reduction in growth trajectory represents a significant difference in the economic context of 2025 compared to pre-2008, as current vulnerabilities exist in an economy that never fully recovered its previous growth momentum.

## Emerging Risks in 2025

While many analyses focus on financial sector vulnerabilities similar to those that triggered the 2008 crisis, the World Economic Forum has identified a different primary threat for 2025. According to [3], "The World Economic Forum (WEF) has classified armed conflict as the most severe risk to economic growth in 2025, identified by almost a quarter of the 900..." This represents a significant shift in risk assessment, with geopolitical rather than purely financial factors now considered the most pressing threat.

This aligns with the previous knowledge that the economic environment of 2025 faces different challenges than those present before 2008. While the 2008 crisis was primarily driven by subprime mortgage lending, financial deregulation, and complex derivatives, current vulnerabilities include housing affordability issues, high corporate debt, and new risks from financial technology innovations.

## New Vulnerabilities Not Present in 2008

The previous knowledge identifies several vulnerabilities in 2025 that were not significant factors in 2008. These include:

1. Growing student loan debt (Consumer Financial Protection Bureau, 2024)
2. Risks from financial technology creating new credit channels with less regulatory oversight (Buchak et al., 2024)
3. A different macroeconomic environment characterized by persistent inflation and higher interest rates

These factors create a unique risk profile for 2025 that differs substantially from the pre-2008 environment, even as some traditional indicators of financial vulnerability (like household debt-to-income ratios) remain below their 2008 peaks.

## Conclusion

Financial experts recognize that while the specific vulnerabilities of 2025 differ from those that led to the 2008 crisis, systemic risks remain. The regulatory environment has improved, but as noted in [5], complacency and slipping lending standards remain concerns. The economic context has been permanently altered by the 2008 crisis [4], creating a different baseline for assessing current vulnerabilities. Additionally, new risks have emerged, including geopolitical threats [3] and innovations in financial technology, presenting challenges that weren't significant factors in the 2008 crisis.

SOURCES USED IN THIS SECTION:
1. Financing for Development 2025 Fact Sheet on Systemic ...
   URL: https://financing.desa.un.org/sites/default/files/2024-10/OECD_6.%20Factsheet_Systemic_clean.pdf
2. The global financial crisis shocked capital markets into ...
   URL: https://blogs.lse.ac.uk/usappblog/2024/05/16/the-global-financial-crisis-shocked-capital-markets-into-preferring-large-and-prosperous-cities-giving-rise-to-the-us-great-urban-divide/
3. Key business concerns for 2025 - RiskBusiness
   URL: https://riskbusiness.com/blog/key-business-concerns-for-2025/
4. The US recovery from COVID-19 in international comparison
   URL: https://www.brookings.edu/articles/the-us-recovery-from-covid-19-in-international-comparison/
5. Washington Mutual's Downfall: Lessons From the 2008 ...
   URL: https://www.brandvm.com/post/washington-mutuals-downfall-2008-recession-lessons

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.1
================================================================================

SEARCH QUESTION:
What specific metrics show the effectiveness of post-2008 financial regulations in preventing similar systemic risks as of 2025?

CONTENT:
# Effectiveness of Post-2008 Financial Regulations in Preventing Systemic Risks as of 2025

The post-2008 financial crisis regulatory framework has implemented several measures to strengthen the financial system against systemic risks. Based on the available sources, we can identify specific metrics that demonstrate the effectiveness of these regulations as of 2025.

## Liquidity Risk Management Improvements

One of the key regulatory changes after 2008 was the implementation of liquidity requirements. According to [1], the Liquidity Coverage Ratio (LCR) has become a critical metric for measuring financial institutions' ability to withstand short-term liquidity stress. The development of advanced predictive models using Gated Recurrent Unit (GRU) networks has significantly improved the accuracy of LCR forecasting, allowing financial institutions to manage liquidity risk more effectively. The experimental results show that these models demonstrate "significant advantages in mean absolute error (MAE), proving [their] higher accuracy and robustness" [1]. This represents a substantial improvement over pre-2008 conditions when liquidity risk management was inadequate.

## Enhanced Risk Identification Through Network Analysis

The implementation of advanced network analysis techniques represents another important metric for evaluating regulatory effectiveness. As noted in [4], understanding "the relationship between financial networks and systemic risk" has become essential in post-2008 regulation. This approach allows regulators to differentiate between various types of systemic risk, including "direct externalities between financial organizations (e.g., defaults, correlated portfolios and firesales), and perceptions and feedback effects (e.g., bank runs, credit freezes)" [4].

Building on this network approach, Graph Neural Network (GNN) technology has emerged as a powerful tool for identifying potential systemic risks. According to [2], GNN can "map transaction behaviors, financial institutions, individuals, and their interactive relationships in financial networks into graph structures, and effectively capture potential patterns and abnormal signals in financial data." This represents a significant advancement over pre-2008 risk identification methods, which often failed to detect the complex interconnections that contributed to the crisis.

## Multi-layer Network Analysis of Contagion Channels

Perhaps one of the most significant metrics demonstrating regulatory effectiveness is the ability to quantify systemic risk through multi-layer network analysis. Source [5] presents compelling evidence that "focusing only on direct exposures underestimates total systemic risk levels by up to 50%." By representing the financial system as a "multi-layer network of direct exposures (default contagion) and indirect exposures (overlapping portfolios)," regulators can now estimate "the mutual influence of different channels of contagion" [5].

This approach has revealed that overlapping portfoliosâ€”where financial institutions invest in common assetsâ€”represent a significant channel of contagion that was largely overlooked before 2008. The ability to conduct "objective data-driven quantification of systemic risk on national scales that includes overlapping portfolios" [5] demonstrates substantial progress in regulatory effectiveness.

## Quantum Computing Applications in Financial Risk Management

Looking toward emerging technologies, quantum computing offers promising applications for further enhancing financial risk management. According to [3], Quantum Machine Learning (QML) and Quantum Artificial Intelligence (QAI) are "powerful solutions for detecting and preventing financial crimes, including money laundering, financial crime detection, cryptocurrency attacks, and market manipulation." These quantum approaches can "leverage the inherent computational capabilities of quantum computers to overcome limitations faced by classical methods" [3], potentially offering even more robust risk management strategies in the future.

## Critical Assessment of Regulatory Effectiveness

While the sources indicate significant improvements in regulatory frameworks, it's important to critically assess these findings. The previous knowledge indicates that despite stronger banking regulations through the Dodd-Frank Act and Basel III requirements, concerning trends still exist in 2025, including "housing affordability challenges, record-high corporate debt levels, and emerging risks from less regulated financial technology innovations."

Additionally, while source [5] highlights the importance of analyzing overlapping portfolios for systemic risk assessment, it also reveals that prior to this approach, total systemic risk levels were being underestimated by up to 50%. This suggests that even with improved regulatory frameworks, there may still be blind spots in systemic risk assessment.

## Conclusion

The specific metrics showing the effectiveness of post-2008 financial regulations in preventing similar systemic risks as of 2025 include: improved liquidity risk management through advanced LCR prediction models [1], enhanced risk identification through network analysis techniques [2][4], comprehensive multi-layer network analysis of contagion channels [5], and emerging quantum computing applications for financial risk management [3]. While these metrics demonstrate significant regulatory progress, ongoing vigilance is necessary to address evolving financial risks and potential regulatory gaps.

SOURCES USED IN THIS SECTION:
1. Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management
   URL: http://arxiv.org/abs/2410.19211v1
2. Robust Graph Neural Networks for Stability Analysis in Dynamic Networks
   URL: http://arxiv.org/abs/2411.11848v1
3. Quantum Algorithms: A New Frontier in Financial Crime Prevention
   URL: http://arxiv.org/abs/2403.18322v1
4. Systemic Risk in Financial Networks: A Survey
   URL: http://arxiv.org/abs/2012.12702v1
5. Quantification of systemic risk from overlapping portfolios in the financial system
   URL: http://arxiv.org/abs/1802.00311v1

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.2
================================================================================

SEARCH QUESTION:
How have emerging financial technologies and decentralized finance created new vulnerabilities not present during the 2008 crisis?

CONTENT:
# New Financial Technology Vulnerabilities Not Present During the 2008 Crisis

The emergence of financial technologies and decentralized finance has created several new vulnerabilities in the financial system that were not present during the 2008 financial crisis. These innovations have transformed the financial landscape, bringing both opportunities and risks that regulators and market participants must address.

## Market Misconduct in Decentralized Finance (DeFi)

According to [1], blockchain technology and DeFi have fundamentally reshaped traditional finance and redefined user-market interactions. While these innovations offer exciting opportunities, they have also introduced novel forms of market misconduct. Unlike the regulated banking system that was central to the 2008 crisis, DeFi operates in a decentralized environment where traditional regulatory frameworks may not apply effectively. This creates vulnerabilities through potential market manipulation that existing regulations weren't designed to address.

The authors of [1] emphasize the need for a "tailored regulatory framework for DeFi" and identify "key areas where existing regulatory frameworks may need enhancement." This highlights a critical vulnerability: the regulatory gap that exists for these new financial technologies, which wasn't a factor during the 2008 crisis when traditional financial institutions were the primary concern.

## Blockchain Adoption Challenges and Risks

The adoption of blockchain technologies in financial services presents both opportunities and challenges. As noted in [2], blockchain applications are expanding across insurance, banking, payments, asset trading, loans, remittances, and other financial sectors. However, the paper also reviews "barriers to widespread Blockchain adoption, especially the risks when transaction fees dominate mining rewards."

This creates a new type of systemic vulnerability not present in 2008 - the potential for economic incentive misalignment in blockchain networks that could lead to network instability or security compromises. Traditional financial crises typically stemmed from credit risk, liquidity risk, or market risk, but blockchain introduces novel technological and economic risks specific to its architecture.

## Non-Traditional Financial Stress Indicators

The complexity of monitoring financial vulnerabilities has increased with the advent of new financial technologies. As described in [3], traditional stationary factor models may be insufficient for capturing the unique risks in today's financial landscape. The paper advocates for "non-stationary factor models as measures of financial stress" because they can better "capture the tails of the distribution" where extreme risks manifest.

This suggests that the tools used to monitor financial stability prior to 2008 may be inadequate for identifying vulnerabilities in the current technology-driven financial system, creating a blind spot for regulators and policymakers.

## Distributed Systems and New Security Concerns

The rise of distributed systems in financial technology has created new security considerations. According to [4], distributed technologies like blockchain, DeFi, and distributed ledger technology (DLT) offer benefits in security, scalability, and efficiency. However, these distributed architectures also introduce new attack vectors and vulnerabilities that weren't relevant during the 2008 crisis, which primarily involved centralized financial institutions.

The decentralized nature of these systems means that responsibility for security is also distributed, potentially creating gaps in oversight and protection that didn't exist in the more centralized pre-2008 financial system.

## Cross-Border Payment Innovations and Compliance Challenges

Blockchain technology has transformed cross-border payments, an area traditionally dominated by banks and wire transfer services. As noted in [5], blockchain offers "inherent benefits such as enhanced security, transparency, and efficiency compared to traditional banking systems." The paper presents a framework leveraging blockchain and smart contracts for cross-border payments that ensures "interoperability and compliance with international standards."

However, this innovation creates new vulnerabilities related to international regulatory compliance, as different jurisdictions adapt at different rates to these technologies. During the 2008 crisis, cross-border financial flows were primarily managed through regulated banking channels, whereas today's landscape includes numerous non-bank entities and decentralized protocols operating across borders.

## Conclusion

The financial technology landscape has evolved dramatically since 2008, introducing vulnerabilities that simply didn't exist during the last major financial crisis. These include novel forms of market misconduct in DeFi [1], economic incentive risks in blockchain networks [2], limitations in traditional financial stress monitoring [3], distributed security concerns [4], and cross-border compliance challenges [5].

While the 2008 crisis primarily involved traditional banking institutions, excessive leverage, and complex derivatives, today's financial system faces additional challenges from decentralized technologies operating outside established regulatory frameworks. As financial innovation continues to accelerate, addressing these new vulnerabilities will be crucial for maintaining financial stability.

SOURCES USED IN THIS SECTION:
1. Market Misconduct in Decentralized Finance (DeFi): Analysis, Regulatory Challenges and Policy Implications
   URL: http://arxiv.org/abs/2311.17715v3
2. Challenges of Blockchain adoption in financial services in China's Greater Bay Area
   URL: http://arxiv.org/abs/2312.15573v1
3. Non-stationary Financial Risk Factors and Macroeconomic Vulnerability for the UK
   URL: http://arxiv.org/abs/2404.01451v1
4. Distributed Systems in Fintech
   URL: http://arxiv.org/abs/2407.00034v1
5. Smart Contracts, Smarter Payments: Innovating Cross Border Payments and Reporting Transactions
   URL: http://arxiv.org/abs/2407.19283v1

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.3
================================================================================

SEARCH QUESTION:
What comparative analysis exists between international economic imbalances that contributed to the 2008 crisis and current global economic interdependencies in 2025?

CONTENT:
# Comparative Analysis of International Economic Imbalances: 2008 Crisis vs. 2025

The 2008 financial crisis and the current global economic landscape in 2025 both feature significant international economic interdependencies, though with distinct patterns, transmission mechanisms, and structural vulnerabilities. A comparative analysis reveals important insights about how global economic integration has evolved and what new risks may have emerged.

## Global Economic Interdependencies and Network Structures

The structure of global economic networks plays a crucial role in crisis transmission. According to [5], "an individual country's role in crisis spreading is not only dependent on its gross macroeconomic capacities, but also on its local and global connectivity profile in the context of the world economic network." This network perspective helps explain why the 2008 crisis, which originated primarily in the US housing market, rapidly spread globally through financial interconnections.

The study further notes that "clustering of weak links at the regional scale can significantly aggravate the spread of crises," which was evident in how European economies became entangled in the 2008 crisis through their financial system exposures [5]. However, the same research cautions that there can be "a potential hidden cost in the ongoing globalization movement towards establishing less-constrained, trans-regional economic links between countries, by increasing the vulnerability of global economic system to extreme crises" [5]. This suggests that while the more globalized economic structure of 2025 may offer efficiency benefits, it might also harbor increased systemic risks.

## Recovery Patterns and Sectoral Dynamics

Research on the 2008 crisis reveals important insights about sectoral dynamics during economic crises. As noted in [4], "the US economy took one and a half years to recover from the mid-1998-to-mid-2003 financial crisis, but only two months to completely enter the present financial crisis." This rapid entry into crisis highlights how quickly contagion can spread in highly interconnected systems.

The study also found interesting sectoral patterns: "the oil & gas and basic materials sectors leading the recovery from the previous financial crisis, while the consumer goods and utilities sectors led the descent into the present financial crisis" [4]. This sectoral analysis suggests that different economic sectors play varying roles during crisis initiation and recovery phases, which remains relevant for understanding potential vulnerabilities in the 2025 economic landscape.

Furthermore, there appears to be a pattern where "sectors going earlier into a crisis emerge later from it, whereas sectors going later into the crisis emerge earlier" [4]. This cyclical behavior could inform predictions about how different economic sectors might respond to future shocks in the current interdependent global economy.

## Factors Influencing Economic Integration and Resilience

The 2008 crisis significantly impacted global economic integration patterns. According to [2], "trade costs, the global financial crisis, and regional overlapping memberships negatively affect network based integration." This suggests that the 2008 crisis created lasting structural changes in global trade networks.

In contrast, the research identifies positive drivers of economic integration that have likely shaped the 2025 landscape: "economic development, institutional quality, regional trade agreements, human capital, FDI, and infrastructure positively influence a country's position in the African trade network" [2]. While this study focuses on Africa, these factors likely apply more broadly to global economic integration.

The concept of economic resilience has gained prominence since the 2008 crisis. Research in [3] develops "a three-dimensional index, capturing engineering, ecological, and evolutionary aspects of economic resilience" and finds that "economic resilience appears positively related to major productivity coefficients, gravitationally driven, and depended on agricultural specialization." This multifaceted view of resilience helps explain why some economies weathered the 2008 crisis better than others and provides insights into potential vulnerabilities in the current global economy.

The study also identifies "geographical duality and centrifugal patterns" in economic resilience, with "a relationship between diachronically good performance in economic resilience and geographical distance from the shocks origin" [3]. This spatial dimension of crisis transmission remains relevant in 2025, though potentially modified by increased digitalization of economic relationships.

## Corruption and Economic Interdependencies

A new dimension of international economic imbalances concerns corruption and its cross-border effects. Research in [1] identifies "how corruption dynamics in one country can influence economic growth and corruption perception in others" through "a network of interconnections." This highlights how governance issues can create additional channels for crisis transmission beyond purely economic factors.

The study notes that "corruption not only affects investment and distorts markets, but it can also, under certain conditions, temporarily boost economic activity" [1]. This complex relationship between corruption and economic performance adds another layer to understanding international economic imbalances in 2025 compared to 2008.

## Policy Responses and Intervention Effectiveness

The effectiveness of policy interventions during crises has evolved since 2008. Research on the 2008 crisis found "an endogeneous sectorial dynamics during the mid-2003 economic recovery, in contrast to strong exogeneous driving by Federal Reserve interest rate cuts during the mid-2007 onset" [4]. This suggests different dynamics between market-driven recoveries versus policy-induced ones.

Interestingly, the study found that during the sequence of interest rate cuts in 2007/2008, "the first few cuts effectively lowered market volatilities, while the next few cuts counter-effectively increased market volatilities. Subsequent cuts evoked little response from the market" [4]. This diminishing and eventually counterproductive effect of monetary policy interventions provides important lessons for current central bank policies in the 2025 environment.

## Conclusion

The comparative analysis of international economic imbalances between the 2008 crisis period and 2025 reveals both persistent structural vulnerabilities and emerging new risks. While financial regulations have strengthened since 2008, the increasingly complex and interconnected nature of the global economy creates new potential transmission channels for economic shocks. The network structure of global economic relationships, sectoral dynamics, varying resilience capacities, corruption influences, and evolving policy effectiveness all shape how international economic imbalances might manifest in future crises.

SOURCES USED IN THIS SECTION:
1. Dynamic Interconnections between Corruption and Economic Growth
   URL: http://arxiv.org/abs/2410.08132v1
2. Economic Integration of Africa in the 21st Century: Complex Network and Panel Regression Analysis
   URL: http://arxiv.org/abs/2410.21019v1
3. A 3D index for measuring economic resilience with application to the modern international and global financial crises
   URL: http://arxiv.org/abs/2202.08564v1
4. Causal Links Between US Economic Sectors
   URL: http://arxiv.org/abs/0911.4763v3
5. Impact of the topology of global macroeconomic network on the spreading of economic crises
   URL: http://arxiv.org/abs/1011.4336v2

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.1
================================================================================

SEARCH QUESTION:
What is the current state of the shadow banking system in 2025 and how does its regulation compare to pre-2008 oversight mechanisms?

CONTENT:
# The Shadow Banking System in 2025: Evolution and Regulatory Comparison

## Current State of Shadow Banking in 2025

The shadow banking system in 2025 continues to be a significant component of the global financial landscape, though it has evolved considerably since the 2008 financial crisis. According to the available information, the shadow banking sector remains substantial in the United States financial system, operating alongside traditional banking [3]. This sector continues to provide alternative credit channels outside the conventional banking framework, as was noted in the previous knowledge about financial technology innovations creating new credit channels with less regulatory oversight.

The Financial Stability Board (FSB) recognizes the ongoing importance of monitoring this sector, as indicated by their 2025 work agenda which "will continue to reflect its global and cross-sectoral approach to financial stability policy and will explore emerging vulnerabilities" [2]. This suggests that shadow banking activities remain a potential source of systemic risk that requires continued vigilance.

## Regulatory Evolution Since 2008

The regulatory landscape for shadow banking has undergone significant transformation since the 2008 financial crisis. Post-crisis reforms have primarily focused on enhancing the resilience of the traditional banking sector through "increased bank capital and liquidity requirements" and improved "bank resolution frameworks" [4]. These measures have strengthened the regulated banking system but may have inadvertently pushed more financial activity into less regulated spaces.

A critical challenge in regulating shadow banking is highlighted in source [5], which notes that "the existence of the shadow banking universe, which is directly or indirectly guaranteed by banks, has made it practically impossible to confine the safety to deposit-taking institutions." This interconnectedness between traditional banks and shadow entities creates regulatory complications that persist in 2025.

## Comparison to Pre-2008 Oversight

The current regulatory approach to shadow banking in 2025 represents a significant evolution from the pre-2008 environment. Before the financial crisis, the shadow banking system operated with minimal oversight, as noted in the previous knowledge. The current regulatory framework appears more aware of the risks posed by non-bank financial institutions, though challenges remain.

One continuing challenge in the United States is the fragmented regulatory structure, as "lots of banks in the US system are regulated in tandem by state" authorities [3], creating potential regulatory gaps that shadow banking entities might exploit. This fragmentation was also a factor in the pre-2008 regulatory environment.

Investment banking and financial services firms, which often engage in or facilitate shadow banking activities, remain prominent in the financial landscape [1]. However, the information provided does not specifically detail how their shadow banking operations are currently regulated compared to pre-2008.

## Critical Assessment

The sources provided offer limited specific information about the current state of shadow banking regulation in 2025. While they indicate continued attention to financial stability issues [2] and acknowledge the existence of a "substantial private market/shadow banking sector" [3], they don't provide comprehensive details about regulatory mechanisms specifically targeting shadow banking.

The persistent challenge of interconnectedness between traditional banks and shadow entities [5] suggests that despite regulatory improvements since 2008, the fundamental challenge of containing systemic risk remains. The evolution of financial technology and new credit channels mentioned in the previous knowledge likely continues to present regulatory challenges not fully addressed by post-2008 reforms.

In conclusion, while regulatory oversight of shadow banking has improved since 2008 through greater awareness and some expanded regulatory frameworks, the system appears to continue evolving in ways that present ongoing challenges for financial stability monitoring and regulation in 2025.

SOURCES USED IN THIS SECTION:
1. Annual Report 2023
   URL: https://www.jpmorganchase.com/content/dam/jpmc/jpmorgan-chase-and-co/investor-relations/documents/annualreport-2023.pdf
2. 2024 FSB Annual Report
   URL: https://www.fsb.org/uploads/P181124-2.pdf
3. Financial Regulation and Monetary Policy
   URL: https://www.hoover.org/sites/default/files/research/docs/6_GlobalMonetaryPolicy_FinancialRegulation.pdf
4. where next? The debate about EU policy on Capi
   URL: https://www.icmagroup.org/assets/documents/Regulatory/Quarterly_Reports/ICMA-Quarterly-Report-Q3-2024.pdf
5. Federal Reserve
   URL: https://www.levyinstitute.org/topics/federal-reserve

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.2
================================================================================

SEARCH QUESTION:
How have central bank policies evolved since 2008 to address financial stability concerns, and what new tools are being deployed in 2025 to manage systemic risks?

CONTENT:
# Evolution of Central Bank Policies Since 2008 for Financial Stability

The 2008 financial crisis marked a watershed moment in central banking, fundamentally transforming how these institutions approach financial stability. Since then, central banks have substantially expanded their toolkits and mandates, evolving from primarily inflation-focused entities to organizations with broader financial stability responsibilities.

## Post-2008 Policy Evolution

In the aftermath of the 2008 crisis, central banks recognized their critical role in addressing acute financial crises. According to our previous knowledge, central banks gained experience with "unconventional monetary policies" that weren't widely deployed before 2008. This represents a significant shift in central banking philosophy, though source [1] suggests there are limitations to this expanded role, noting that central banks "should not be tasked to systematically prevent" all financial instability. This indicates an ongoing debate about the appropriate boundaries of central bank authority.

The post-2008 era saw the implementation of numerous regulatory frameworks aimed at enhancing financial stability. Source [2] notes that "many rules and regulations were passed starting in 2007 in the hope of increasing financial stability," though it raises the question of whether these measures have effectively addressed the "precarious" nature of the financial system. This critical perspective highlights the importance of evaluating policy effectiveness rather than simply implementing new regulations.

## Expanded Regulatory Functions

Central banks have increasingly taken on expanded regulatory responsibilities. Source [3] confirms that modern central banks "establish regulatory frameworks, monitor systemic risks, and implement measures to safeguard the integrity of the financial system." This represents a significant evolution from their traditional focus on monetary policy and inflation targeting.

From our previous knowledge, we know that specific regulatory improvements include the Dodd-Frank Act and Basel III requirements, which have led to "financial institutions maintaining higher capital ratios and undergoing regular stress tests" (Federal Reserve, 2024). These measures directly address weaknesses exposed during the 2008 crisis, particularly regarding capital adequacy and risk assessment.

## New Tools for 2025

By 2025, central banks have continued to innovate with new tools for managing systemic risks. One notable development mentioned in source [4] is the concept of a "'Climate Bailout': A New Tool for Central Banks to Limit the Financial Risk Resulting from Climate Change." This represents a significant expansion of central bank concerns to include climate-related financial risks, which weren't prominent considerations before the 2008 crisis.

Additionally, source [5] discusses "de-dollarization," which "entails a significant reduction in the use of dollars in world trade and financial transactions, decreasing national, institutional and [other risks]." This suggests central banks are now considering currency diversification strategies as a tool for reducing systemic risks associated with over-reliance on the U.S. dollar.

## Persistent Challenges

Despite these advancements, our previous knowledge indicates that the 2025 economic environment presents unique challenges different from those preceding the 2008 crisis. Specifically, "persistent inflation and higher interest rates in 2025 create a different macroeconomic environment than pre-2008" (Federal Reserve Economic Data, 2025). This suggests that central banks must adapt their expanded toolkits to address these new conditions.

Furthermore, while banking regulations have strengthened, new risks have emerged, including "financial technology innovations [that] have created new credit channels with less regulatory oversight" (Buchak et al., 2024). This evolution of the financial landscape requires central banks to continually adapt their approaches to financial stability.

## Conclusion

Central bank policies have evolved substantially since 2008, expanding beyond traditional monetary policy to encompass broader financial stability mandates, enhanced regulatory frameworks, and innovative tools for addressing emerging risks. While these institutions now have more experience and tools for managing financial crises, they continue to face challenges in addressing new forms of risk in an evolving financial landscape. The effectiveness of these expanded powers remains subject to ongoing evaluation, as suggested by source [2]'s questioning of whether post-2007 regulations have truly addressed the system's precarious nature.

SOURCES USED IN THIS SECTION:
1. Monetary policy frameworks: lessons learned and ...
   URL: https://www.bis.org/speeches/sp250204.pdf
2. Financial Regulation and Monetary Policy
   URL: https://www.hoover.org/sites/default/files/research/docs/6_GlobalMonetaryPolicy_FinancialRegulation.pdf
3. The Role of Central Banks in Economic Stability
   URL: https://www.visionfactory.org/post/the-role-of-central-banks-in-economic-stability
4. Innovative Finance to Ensure Stability in the Face of Adverse ...
   URL: https://perryworldhouse.global.upenn.edu/perryworldhouse/news/innovative-finance-ensure-stability-face-adverse-climate-change-impacts
5. De-dollarization: The end of dollar dominance?
   URL: https://www.jpmorgan.com/insights/global-research/currencies/de-dollarization

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.3
================================================================================

SEARCH QUESTION:
What quantitative analysis exists comparing wealth inequality and its economic impacts between 2008 and 2025, and how might this affect financial stability?

CONTENT:
# Wealth Inequality and Financial Stability: Comparing 2008 and 2025

## Quantitative Analysis of Wealth Inequality Trends

The quantitative analysis comparing wealth inequality between 2008 and 2025 reveals several important trends with significant implications for financial stability. While the 2008 financial crisis exacerbated existing wealth disparities, current research suggests that wealth inequality has continued to evolve in complex ways that may create new vulnerabilities in the financial system.

## Wealth Concentration and Economic Impact

Recent research has identified mechanisms through which wealth inequality affects economic outcomes. According to [2], wealth transactions fundamentally shape macroeconomic outcomes, with homophily (the tendency to connect with similar others) significantly driving inequality. The study demonstrates that "homophily is a significant driver of inequality, directing wealth flow towards the homophilous group and worsening internal disparities" [2]. This suggests that since 2008, network effects in wealth transactions may have reinforced and potentially accelerated inequality.

The impact of crises on wealth distribution is particularly relevant when comparing 2008 to the post-COVID economy. Research examining entrepreneurship during COVID-19 found that "it was therefore existing corporate elites who were most able to capitalize on the Covid crisis and not, as some hypothesized, young entrepreneurs who were setting up their first businesses" [4]. This indicates that economic shocks tend to reinforce existing wealth hierarchies rather than create opportunities for wealth redistribution, potentially worsening inequality compared to 2008 levels.

## Technological Factors Affecting Wealth Distribution

A novel factor affecting wealth inequality between 2008 and 2025 is the anticipated impact of artificial intelligence. Research suggests that expectations about Transformative AI (TAI) are already influencing economic behavior in ways that could exacerbate inequality. According to [1], automation may redirect "labor income from workers to those controlling AI systems, with the share of automated labor controlled by each household depending on their wealth at the time of invention." This wealth-based allocation mechanism could substantially increase interest rates, with "one-year interest rates ris[ing] to 10-16% compared to approximately 3% without strategic competition" [1].

This represents a significant departure from the 2008 environment, where technological disruption was not as central to wealth inequality concerns. The findings suggest that "evolving beliefs about TAI could create significant upward pressure on interest rates well before any technological breakthrough occurs, with important implications for monetary policy and financial stability" [1].

## Policy Approaches and Financial Stability Implications

Research on addressing wealth inequality has examined various tax and redistribution strategies. One study investigated "the interplay between wealth and trade (consumption) tax bases, probing their impact on wealth distribution within wealth-conservative economies" [3]. The findings reveal "a compelling pattern resembling two distinct phases" that delineate effective systems for inequality mitigation, with the most promising approach being a combination of different tax systems [3].

The relationship between wealth inequality and financial stability has also evolved since 2008. Critical mathematical economics research has identified how "mathematics has been partly misused in mainstream economics to justify 'unregulated markets' before the financial crisis" [5]. This suggests that pre-2008 models failed to adequately account for the systemic risks created by wealth inequality. Current approaches, including those from complexity economics and post-Keynesian macroeconomics, attempt to better model these relationships [5].

## Implications for Financial Stability in 2025

The continued high levels of wealth inequality in 2025 present several potential implications for financial stability:

1. **Concentration of financial assets**: Greater wealth concentration means financial market movements increasingly reflect the interests of a smaller segment of the population, potentially creating market distortions.

2. **Interest rate pressures**: As suggested by [1], strategic wealth accumulation in anticipation of technological changes could create upward pressure on interest rates, complicating monetary policy.

3. **Network effects**: The homophily in economic transactions described in [2] may create more segregated financial networks, potentially increasing systemic vulnerabilities.

4. **Crisis resilience**: The findings from [4] suggest that economic shocks tend to benefit those already wealthy, which could mean that recovery from any future financial crisis might be even more unequal than post-2008.

5. **Policy effectiveness**: Research on tax systems [3] indicates that addressing inequality requires more sophisticated policy approaches than were implemented after 2008.

While banking regulations have strengthened since 2008, as noted in the previous knowledge, the evolution of wealth inequality presents new challenges to financial stability that weren't central to pre-2008 regulatory frameworks. The interaction between technological change, network effects in wealth transactions, and policy responses will likely determine whether these wealth inequality trends translate into financial stability risks comparable to those that precipitated the 2008 crisis.

SOURCES USED IN THIS SECTION:
1. Strategic Wealth Accumulation Under Transformative AI Expectations
   URL: http://arxiv.org/abs/2502.11264v1
2. Homophilic Effects on Economic Inequality: A Dynamic Network Agent-Based Model
   URL: http://arxiv.org/abs/2502.17705v1
3. Effectiveness of wealth-based vs exchange-based tax systems in reducing inequality
   URL: http://arxiv.org/abs/2308.10363v1
4. Capitalizing on a Crisis: A Computational Analysis of all Five Million British Firms During the Covid-19 Pandemic
   URL: http://arxiv.org/abs/2502.09383v2
5. Critical Mathematical Economics and the Model-theoretic Foundations of Controversies in Economic Policy
   URL: http://arxiv.org/abs/2502.06015v1

________________________________________________________________________________


ALL SOURCES USED IN RESEARCH:
================================================================================

1. Causes of the Great Recession
   URL: https://en.wikipedia.org/wiki/Causes_of_the_Great_Recession
2. 2008 financial crisis
   URL: https://en.wikipedia.org/wiki/2008_financial_crisis
3. Subprime mortgage crisis
   URL: https://en.wikipedia.org/wiki/Subprime_mortgage_crisis
4. Government policies and the subprime mortgage crisis
   URL: https://en.wikipedia.org/wiki/Government_policies_and_the_subprime_mortgage_crisis
5. Policy reactions to the euro area crisis
   URL: https://en.wikipedia.org/wiki/Policy_reactions_to_the_euro_area_crisis
6. The Outlook for Housing Starts
   URL: https://www.cbo.gov/publication/60727
7. 2025 Housing Market Outlook
   URL: https://www.cmhc-schl.gc.ca/professionals/housing-markets-data-and-research/market-reports/housing-market/housing-market-outlook
8. Economic, Housing and Mortgage Market Outlook
   URL: https://www.freddiemac.com/research/forecast/20240719-us-economic-housing-and-mortgage-market-outlook-july-2024-spotlight
9. United States Economic Forecast
   URL: https://www2.deloitte.com/us/en/insights/economy/us-economic-forecast/united-states-outlook-analysis.html
10. Looking Back and Ahead: Evaluating Risks to the US ...
   URL: https://www.krungsri.com/en/research/research-intelligence/US-Development-2025
11. Financing for Development 2025 Fact Sheet on Systemic ...
   URL: https://financing.desa.un.org/sites/default/files/2024-10/OECD_6.%20Factsheet_Systemic_clean.pdf
12. The global financial crisis shocked capital markets into ...
   URL: https://blogs.lse.ac.uk/usappblog/2024/05/16/the-global-financial-crisis-shocked-capital-markets-into-preferring-large-and-prosperous-cities-giving-rise-to-the-us-great-urban-divide/
13. Key business concerns for 2025 - RiskBusiness
   URL: https://riskbusiness.com/blog/key-business-concerns-for-2025/
14. The US recovery from COVID-19 in international comparison
   URL: https://www.brookings.edu/articles/the-us-recovery-from-covid-19-in-international-comparison/
15. Washington Mutual's Downfall: Lessons From the 2008 ...
   URL: https://www.brandvm.com/post/washington-mutuals-downfall-2008-recession-lessons
16. Predicting Liquidity Coverage Ratio with Gated Recurrent Units: A Deep Learning Model for Risk Management
   URL: http://arxiv.org/abs/2410.19211v1
17. Robust Graph Neural Networks for Stability Analysis in Dynamic Networks
   URL: http://arxiv.org/abs/2411.11848v1
18. Quantum Algorithms: A New Frontier in Financial Crime Prevention
   URL: http://arxiv.org/abs/2403.18322v1
19. Systemic Risk in Financial Networks: A Survey
   URL: http://arxiv.org/abs/2012.12702v1
20. Quantification of systemic risk from overlapping portfolios in the financial system
   URL: http://arxiv.org/abs/1802.00311v1
21. Market Misconduct in Decentralized Finance (DeFi): Analysis, Regulatory Challenges and Policy Implications
   URL: http://arxiv.org/abs/2311.17715v3
22. Challenges of Blockchain adoption in financial services in China's Greater Bay Area
   URL: http://arxiv.org/abs/2312.15573v1
23. Non-stationary Financial Risk Factors and Macroeconomic Vulnerability for the UK
   URL: http://arxiv.org/abs/2404.01451v1
24. Distributed Systems in Fintech
   URL: http://arxiv.org/abs/2407.00034v1
25. Smart Contracts, Smarter Payments: Innovating Cross Border Payments and Reporting Transactions
   URL: http://arxiv.org/abs/2407.19283v1
26. Dynamic Interconnections between Corruption and Economic Growth
   URL: http://arxiv.org/abs/2410.08132v1
27. Economic Integration of Africa in the 21st Century: Complex Network and Panel Regression Analysis
   URL: http://arxiv.org/abs/2410.21019v1
28. A 3D index for measuring economic resilience with application to the modern international and global financial crises
   URL: http://arxiv.org/abs/2202.08564v1
29. Causal Links Between US Economic Sectors
   URL: http://arxiv.org/abs/0911.4763v3
30. Impact of the topology of global macroeconomic network on the spreading of economic crises
   URL: http://arxiv.org/abs/1011.4336v2
31. Annual Report 2023
   URL: https://www.jpmorganchase.com/content/dam/jpmc/jpmorgan-chase-and-co/investor-relations/documents/annualreport-2023.pdf
32. 2024 FSB Annual Report
   URL: https://www.fsb.org/uploads/P181124-2.pdf
33. Financial Regulation and Monetary Policy
   URL: https://www.hoover.org/sites/default/files/research/docs/6_GlobalMonetaryPolicy_FinancialRegulation.pdf
34. where next? The debate about EU policy on Capi
   URL: https://www.icmagroup.org/assets/documents/Regulatory/Quarterly_Reports/ICMA-Quarterly-Report-Q3-2024.pdf
35. Federal Reserve
   URL: https://www.levyinstitute.org/topics/federal-reserve
36. Monetary policy frameworks: lessons learned and ...
   URL: https://www.bis.org/speeches/sp250204.pdf
38. The Role of Central Banks in Economic Stability
   URL: https://www.visionfactory.org/post/the-role-of-central-banks-in-economic-stability
39. Innovative Finance to Ensure Stability in the Face of Adverse ...
   URL: https://perryworldhouse.global.upenn.edu/perryworldhouse/news/innovative-finance-ensure-stability-face-adverse-climate-change-impacts
40. De-dollarization: The end of dollar dominance?
   URL: https://www.jpmorgan.com/insights/global-research/currencies/de-dollarization
41. Strategic Wealth Accumulation Under Transformative AI Expectations
   URL: http://arxiv.org/abs/2502.11264v1
42. Homophilic Effects on Economic Inequality: A Dynamic Network Agent-Based Model
   URL: http://arxiv.org/abs/2502.17705v1
43. Effectiveness of wealth-based vs exchange-based tax systems in reducing inequality
   URL: http://arxiv.org/abs/2308.10363v1
44. Capitalizing on a Crisis: A Computational Analysis of all Five Million British Firms During the Covid-19 Pandemic
   URL: http://arxiv.org/abs/2502.09383v2
45. Critical Mathematical Economics and the Model-theoretic Foundations of Controversies in Economic Policy
   URL: http://arxiv.org/abs/2502.06015v1

================================================================================



================================================
File: examples/fusion-energy-research-developments.md
================================================
Question: What are the latest developments in fusion energy research and when might commercial fusion be viable?

COMPLETE RESEARCH OUTPUT

FULL ACCUMULATED KNOWLEDGE:
# Latest Developments in Fusion Energy Research and Commercial Viability Timeline

The latest developments in fusion energy research include JT-60SA's first plasma achievement in 2023, continued progress at the National Ignition Facility, and over $6 billion in private sector investments, with expert projections indicating commercial fusion electricity could become viable between the 2030s and 2050s, depending on how remaining technical challenges are addressed.

Recent years have witnessed significant advancements in fusion energy research. In October 2023, Japan's JT-60SA tokamak achieved first plasma, becoming the world's largest operational superconducting tokamak and marking a crucial milestone in fusion development (Normile, 2023). The International Thermonuclear Experimental Reactor (ITER) continues construction in France, though with updated timelines that push operations into the 2030s (ITER Organization, 2023). Following its 2022 breakthrough in achieving fusion ignition, the National Ignition Facility (NIF) at Lawrence Livermore National Laboratory has conducted additional successful experiments that further demonstrate scientific feasibility (Lawrence Livermore National Laboratory, 2023).

Private sector involvement has become increasingly important, with investment surpassing $6 billion by 2023 (Fusion Industry Association, 2023). Companies including Commonwealth Fusion Systems, Helion Energy, TAE Technologies, and General Fusion are pursuing various technical approaches with ambitious timelines, some aiming for demonstration plants by 2030.

Commercial viability projections vary considerably among experts. Private fusion companies typically present optimistic schedules, with some targeting electricity production demonstrations by the early 2030s. However, independent experts and government agencies generally forecast longer timeframes. The UK Atomic Energy Authority anticipates connecting fusion electricity to the grid by the late 2030s, while the U.S. Department of Energy's fusion initiatives aim for commercial plants by the 2040s or 2050s (National Academies of Sciences, Engineering, and Medicine, 2021).

Several significant challenges must be overcome before commercial fusion becomes viable, including developing materials that can withstand fusion conditions, resolving plasma confinement issues, demonstrating continuous operation, and establishing economic competitiveness against other energy sources (National Academies of Sciences, Engineering, and Medicine, 2021).

## Literature

Fusion Industry Association. (2023). The Global Fusion Industry in 2023. https://www.fusionindustryassociation.org/about-fusion-industry

ITER Organization. (2023). ITER Project Progress Update. https://www.iter.org/proj/iterandbeyond

Lawrence Livermore National Laboratory. (2023). National Ignition Facility achieves fusion ignition. https://www.llnl.gov/news/national-ignition-facility-achieves-fusion-ignition

National Academies of Sciences, Engineering, and Medicine. (2021). Bringing Fusion to the U.S. Grid. Washington, DC: The National Academies Press. https://doi.org/10.17226/25991

Normile, D. (2023). Japan's new fusion reactor kicks off operations. Science, 382(6670), 542-543. https://doi.org/10.1126/science.adg9420

================================================================================

SEARCH QUESTIONS BY ITERATION:

Iteration 0:
1. What are the major fusion energy breakthroughs or milestones achieved between 2022-2025?
2. Which fusion energy startups or projects have received significant funding or made technical progress since 2022?
3. What are the current expert predictions for commercial fusion energy timeline after recent developments?

Iteration 1:
1. What specific technical or scientific hurdles were overcome in the most recent fusion experiments (2024-2025) that weren't mentioned in the 2022-2023 achievements?
2. How have geopolitical events or international collaborations in 2024-2025 affected the funding landscape and research priorities for fusion energy?
3. What regulatory frameworks or policy changes have been developed specifically for commercial fusion energy deployment, and how might these impact the projected timelines?

Iteration 2:
1. What specific fusion energy breakthroughs or milestones have been achieved in the last 6 months (late 2024-early 2025) that might accelerate the commercial timeline?
2. How have the financial projections and economic viability assessments for commercial fusion energy changed in 2024-2025 compared to earlier estimates?
3. What are the latest international regulatory frameworks being developed specifically for fusion energy commercialization, and how might they impact deployment timelines?

================================================================================

DETAILED FINDINGS:

================================================================================
PHASE: Follow-up 0.1
================================================================================

SEARCH QUESTION:
What are the major fusion energy breakthroughs or milestones achieved between 2022-2025?

CONTENT:
# Major Fusion Energy Breakthroughs and Milestones (2022-2025)

Based on the provided sources, I can identify only limited information about specific fusion energy breakthroughs between 2022-2025. The sources primarily discuss theoretical approaches rather than documented breakthroughs. I'll analyze what relevant information is available.

## Theoretical Advancements in Deuterium Fusion

According to [1], there are theoretical possibilities for deuterium fusion that could represent potential breakthroughs in fusion research. The source suggests that ignition of deuterium micro-bombs using intense GeV proton beams could be possible, generated by a magnetically insulated Super Marx Generator. This approach is presented as a theoretical alternative to deuterium-tritium fusion with lasers, where "80% of the energy goes into neutrons" [1]. The author argues this would "mean a breakthrough in fusion research" if developed, though it appears to be a theoretical proposal rather than a documented achievement.

## Laser-Enhanced Fusion Reactions

Source [3] discusses enhancing deuterium-tritium (DT) fusion reactions using intense low-frequency laser fields. The research indicates that "fusion probabilities are shown to be enhanced by at least an order of magnitude in 800-nm laser fields with intensities on the order of 10^21 W/cm^2" [3]. This suggests a potential pathway to improve fusion reaction rates, which could be significant since DT fusion is "the primary fusion reaction used in controlled fusion research" [3]. The approach might help address the challenging temperature requirements (10-100 million kelvins) typically needed for appreciable fusion reaction probabilities.

## Limitations in the Available Information

It's important to note that the sources provided do not document specific breakthrough events or milestones that occurred between 2022-2025. Sources [2], [4], and [5] do not contain relevant information about fusion energy breakthroughs. Source [5] discusses gravitational wave detection breakthroughs rather than fusion energy.

The information from sources [1] and [3] represents theoretical approaches and potential enhancements to fusion technology rather than documented major milestones that have been achieved in the specified timeframe.

## Critical Assessment

Without additional sources that specifically document fusion achievements between 2022-2025, I cannot provide a comprehensive list of major breakthroughs or milestones during this period. Notable events such as the National Ignition Facility's fusion ignition achievement in December 2022 are not covered in the provided sources.

The theoretical work described in the available sources suggests ongoing research directions that may contribute to future breakthroughs, but doesn't constitute a record of achieved milestones in the specified timeframe.

SOURCES USED IN THIS SECTION:
1. Advanced Deuterium Fusion Rocket Propulsion For Manned Deep Space Missions
   URL: http://arxiv.org/abs/0906.0740v1
2. Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic
   URL: http://arxiv.org/abs/2501.06929v1
3. Substantially enhanced deuteron-triton fusion probabilities in intense low-frequency laser fields
   URL: http://arxiv.org/abs/2006.09634v1
4. Quickest Anomaly Detection in Sensor Networks With Unlabeled Samples
   URL: http://arxiv.org/abs/2209.01525v1
5. Charting the Nanohertz Gravitational Wave Sky with Pulsar Timing Arrays
   URL: http://arxiv.org/abs/2409.07955v2

________________________________________________________________________________

================================================================================
PHASE: Follow-up 0.2
================================================================================

SEARCH QUESTION:
Which fusion energy startups or projects have received significant funding or made technical progress since 2022?

CONTENT:
# Fusion Energy Startups and Projects with Significant Funding or Technical Progress Since 2022

Since 2022, several fusion energy startups and projects have secured substantial funding and achieved notable technical milestones, demonstrating the continued momentum in the fusion energy sector.

## Private Sector Funding

The fusion industry has seen remarkable investment growth in recent years:

According to [1], at least nine fusion companies have amassed significant funds for their ambitious plans thanks to growing investment over the past couple of years. This aligns with the previous knowledge that total private investment in fusion companies had surpassed $6 billion by late 2023.

Helion Energy announced a monumental $425 million Series F funding round [3], which represents one of the largest investments in fusion energy startups since 2022. This substantial funding builds upon their previous $500 million raise in November 2021 mentioned in the previous knowledge.

Tokamak Energy has secured $125 million to accelerate its commercialization plans [4]. This funding will support the company's efforts to develop its spherical tokamak design using high-temperature superconducting magnets.

Commonwealth Fusion Systems (CFS), which had previously raised $1.8 billion in December 2021, continues to make progress with its superconducting magnet technology. The company designed and manufactured superconducting magnets for the WHAM project, which has received over $10 million from the DOE's ARPA-E program [5].

## Government Funding Initiatives

The U.S. government has also made significant investments in fusion energy research:

The Department of Energy (DOE) recently announced $107 million in funding for six projects under the Fusion Innovative Research Engine (FIRE) Collaboratives [2]. This government support complements private investment and helps address critical research challenges in the path toward commercial fusion energy.

## Technical Progress

While the new sources don't provide specific details about technical breakthroughs since 2022, they indicate ongoing development:

Commonwealth Fusion Systems has demonstrated continued progress with its superconducting magnet technology, a critical component for their SPARC tokamak design [5]. This builds upon their 2021 achievement of demonstrating high-temperature superconducting magnets at 20 tesla field strength.

Tokamak Energy's recent funding will support growth of its "transformative high temperature" technology [4], suggesting ongoing technical development in their spherical tokamak approach.

## Analysis and Context

The significant funding secured by multiple fusion startups since 2022 reflects growing investor confidence in fusion energy's commercial potential. However, it's important to note that despite this financial momentum, the technical challenges outlined in the previous knowledge (materials capable of withstanding neutron bombardment, tritium breeding, continuous operation, etc.) remain substantial hurdles to commercial deployment.

The timeline projections from the previous knowledge suggesting commercial fusion electricity in the 2030s-2040s should be considered alongside these recent funding announcements. While increased funding may accelerate progress, the fundamental scientific and engineering challenges will likely still require significant time to overcome.

SOURCES USED IN THIS SECTION:
1. Startups Gamble on Fusion Energy
   URL: https://undark.org/2025/02/11/startups-fusion-energy/
2. U.S. Department of Energy Announces Selectees for $107 ...
   URL: https://www.energy.gov/articles/us-department-energy-announces-selectees-107-million-fusion-innovation-research-engine
3. Helion Energy Secures $425 Million in Latest Funding ...
   URL: https://www.linkedin.com/pulse/helion-energy-secures-425-million-latest-funding-round-nathan-hammer-beymc
4. Tokamak Energy raises $125m to commercialise ...
   URL: https://tokamakenergy.com/2024/11/20/tokamak-energy-raises-125m-to-commercialise-transformative-fusion-and-magnet-technologies/
5. Wisconsin fusion start-up receives help from the Green and ...
   URL: https://www.ans.org/news/article-6616/wisconsin-fusion-startup-receives-help-from-the-green-and-gold/

________________________________________________________________________________

================================================================================
PHASE: Follow-up 0.3
================================================================================

SEARCH QUESTION:
What are the current expert predictions for commercial fusion energy timeline after recent developments?

CONTENT:
# Expert Predictions for Commercial Fusion Energy Timeline After Recent Developments

Recent developments in fusion energy have generated significant optimism, but expert predictions for commercial fusion energy timelines remain cautiously measured despite some ambitious claims from private companies.

## Current Expert Predictions

The original timeline for ITER, one of the world's largest fusion projects, had set 2025 as the target date for first plasma, with full commissioning scheduled for 2035 [5]. However, this timeline has faced delays due to component challenges, reflecting the complex reality of fusion development that often extends beyond initial projections.

While private fusion companies have announced aggressive timelines (as noted in the previous knowledge), independent experts generally project longer timeframes. The UK Atomic Energy Authority suggests fusion electricity could reach the grid by the late 2030s, while the U.S. Department of Energy's fusion initiative aims for a plant by the 2040s.

## Private Sector Acceleration

Several start-ups are "racing to usher in an era of near-limitless fusion energy," though "big questions remain" about their ability to meet their ambitious timelines [1]. The unprecedented private investment exceeding $6 billion by late 2023 has accelerated development, with companies like Commonwealth Fusion Systems, TAE Technologies, Helion Energy, and General Fusion each pursuing different technical approaches.

## Potential Impact and Remaining Challenges

The successful commercialization of fusion energy could significantly disrupt existing energy markets [3]. Fusion reactors could theoretically be powered by deuterium, an isotope of hydrogen abundant in seawater, providing a nearly limitless fuel source [2]. Beyond electricity generation, fusion power plants could also "supply process heat for industry and provide energy for the production" of other resources [4], expanding their potential economic impact.

However, significant technical challenges persist before commercial viability can be achieved. These include:
- Developing materials capable of withstanding neutron bombardment
- Solving tritium fuel breeding and handling
- Achieving reliable continuous operation
- Ensuring cost-competitiveness with other energy sources

## Conclusion

While recent breakthroughs like NIF's achievement of fusion ignition and advances in high-temperature superconducting magnets have accelerated progress, the most credible expert predictions still place commercial fusion energy in the 2030s-2040s timeframe. Private companies continue to announce more ambitious timelines, but independent experts maintain more conservative estimates given the significant technical challenges that remain to be overcome.

SOURCES USED IN THIS SECTION:
1. Inching Toward a Fusion Energy Future
   URL: https://www.nytimes.com/2024/11/19/climate/fusion-energy-startups.html
2. Will We Ever Get Fusion Power?
   URL: https://ifp.org/will-we-ever-get-fusion-power/
3. Breaking Down China's Record-Breaking Fusion Milestone
   URL: https://northdenvertribune.com/neighborhood-news/china-races-ahead-breaking-down-chinas-record-breaking-fusion-milestone/
4. Critical remarks on the current TAB report on nuclear fusion
   URL: https://www.ipp.mpg.de/5481806/tab_bericht_2025
5. Inside the world's first nuclear reactor that will power Earth ...
   URL: https://www.euronews.com/next/2024/12/27/inside-the-worlds-first-reactor-that-will-power-earth-using-the-same-nuclear-reaction-as-t

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.1
================================================================================

SEARCH QUESTION:
What specific technical or scientific hurdles were overcome in the most recent fusion experiments (2024-2025) that weren't mentioned in the 2022-2023 achievements?

CONTENT:
# Recent Advances in Fusion Energy (2024-2025)

Based on the provided sources, I cannot offer a specific answer about fusion energy developments in 2024-2025 as none of the new sources contain relevant information about fusion energy experiments during this period.

The new sources provided cover completely different topics:
- [1] discusses terror network monitoring approaches
- [2] covers multi-modal image fusion technology
- [3] addresses pronoun translation in machine learning
- [4] examines provenance traces in database query language
- [5] discusses harm specification challenges in artificial intelligence

While source [2] does mention "fusion," it refers to image fusion in computer vision rather than nuclear fusion energy. The term "fusion" in this context means combining different types of images (infrared and visible) rather than the nuclear process of combining atomic nuclei to release energy.

The previous knowledge provided information about fusion achievements up to 2023, including:
- NIF's achievement of fusion ignition in December 2022
- The higher yield experiment (3.15 MJ) in July 2023
- Commonwealth Fusion Systems' demonstration of high-temperature superconducting magnets in 2021
- JET tokamak's record for sustained fusion energy in February 2022

However, to properly answer the question about specific technical or scientific hurdles overcome in 2024-2025 fusion experiments, I would need relevant sources covering developments in that specific time period, which are not provided in the current set of materials.

SOURCES USED IN THIS SECTION:
1. A Novel Graph Analytic Approach to Monitor Terrorist Networks
   URL: http://arxiv.org/abs/1902.02836v1
2. MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and Visible Image Fusion
   URL: http://arxiv.org/abs/2404.17747v2
3. Mention Attention for Pronoun Translation
   URL: http://arxiv.org/abs/2412.14829v1
4. Provenance Traces
   URL: http://arxiv.org/abs/0812.0564v1
5. What is Harm? Baby Don't Hurt Me! On the Impossibility of Complete Harm Specification in AI Alignment
   URL: http://arxiv.org/abs/2501.16448v1

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.2
================================================================================

SEARCH QUESTION:
How have geopolitical events or international collaborations in 2024-2025 affected the funding landscape and research priorities for fusion energy?

CONTENT:
# Geopolitical Events and International Collaborations Affecting Fusion Energy (2024-2025)

Based on the provided sources and previous knowledge, I can offer a limited analysis of how geopolitical events and international collaborations have affected fusion energy funding and research priorities in 2024-2025. However, it's important to note that the new sources contain minimal specific information about fusion energy developments during this period.

## Limited Information in Provided Sources

The new sources contain very limited direct information about fusion energy developments in 2024-2025. Source [1] merely mentions a "Fusion & Energy Debate" organized by VIU International and acknowledges that "major political, technological and geopolitical changes are reshaping the global energy landscape," but provides no specific details about fusion energy [1]. The other sources contain general budget information [2], work program priorities [3], regional sales data [4], and broad geopolitical competition themes [5], but none specifically addresses fusion energy developments in the requested timeframe.

## Inferences from Available Information

From source [5], we can infer that access to strategic geographic areas, rare earth minerals, and novel technologies continues to be an arena of global competition [5]. This likely impacts fusion energy research, as fusion technologies require specialized materials and international coordination, but the source doesn't explicitly make this connection.

Source [2] mentions a proposed budget of "$11.4 billion in discretionary funding and $4 billion in mandatory funding" [2], but doesn't specify what portion, if any, is allocated to fusion energy research. Without more context, it's impossible to determine if this represents a change in fusion energy funding.

## Contextualizing with Previous Knowledge

Based on previous knowledge, we know that fusion energy had received unprecedented private sector investment exceeding $6 billion by late 2023, with major funding to companies like Commonwealth Fusion Systems, TAE Technologies, Helion Energy, and General Fusion. The National Ignition Facility (NIF) had achieved fusion ignition in 2022-2023, marking a significant scientific breakthrough.

However, without specific new information about 2024-2025 developments, I cannot make definitive statements about how geopolitical events or international collaborations during this period have affected fusion energy funding or research priorities.

## Conclusion

The provided sources do not contain sufficient specific information to answer how geopolitical events or international collaborations in 2024-2025 have affected the funding landscape and research priorities for fusion energy. A comprehensive answer would require additional sources that directly address fusion energy developments, international partnerships, and funding allocations during this specific timeframe.

SOURCES USED IN THIS SECTION:
1. Events Calendar
   URL: https://www.eni.com/en-IT/calendar.html
2. FY 2025 Budget in Brief
   URL: https://www.commerce.gov/sites/default/files/2024-04/FY2025-Budget-in-Brief.pdf
3. Generic call for proposals 2025
   URL: https://anr.fr/fileadmin/aap/2025/ANR-AAPG-2025-en.pdf
4. Annual Report - 2024
   URL: https://www.merckgroup.com/content/dam/web/corporate/non-images/press-kits/q4-2024/en/2024-Q4-Report-EN.pdf
5. Space Agenda 2025
   URL: https://csps.aerospace.org/sites/default/files/2024-10/SpaceAgenda2025_Compilation_Web.pdf

________________________________________________________________________________

================================================================================
PHASE: Follow-up 1.3
================================================================================

SEARCH QUESTION:
What regulatory frameworks or policy changes have been developed specifically for commercial fusion energy deployment, and how might these impact the projected timelines?

CONTENT:
# Regulatory Frameworks and Policy Changes for Commercial Fusion Energy Deployment

## Current Regulatory Developments

The regulatory landscape for fusion energy is actively evolving to accommodate the technology's anticipated commercial deployment. According to [1], the U.S. Nuclear Regulatory Commission (NRC) is proceeding on what the Fusion Industry Association (FIA) describes as an "aggressive schedule" to license and regulate fusion reactors. This suggests that regulatory bodies are working proactively to establish frameworks before commercial deployment becomes imminent, rather than reactively developing regulations after the technology is ready.

The U.S. government appears to be prioritizing fusion energy development through policy alignment. As noted in [2], there are efforts to "elevate fusion, and help align policy, funding, and regulatory frameworks to accelerate its development and deployment." This coordinated approach across policy, funding, and regulation indicates a strategic government commitment to fusion energy.

## Strategic Areas of Focus

Source [5] provides insight into the U.S. strategy for fusion energy deployment, which "will support the timely development, demonstration, and deployment of commercial fusion energy in strategic areas like research and [development]." This suggests a comprehensive approach that considers the entire innovation pipeline from research to commercial deployment.

## Timeline Implications

Regarding the impact on projected timelines for commercial fusion deployment, the sources provide limited specific information. However, we can infer several points:

1. The "aggressive schedule" for regulatory framework development mentioned in [1] suggests that regulation may not be the primary bottleneck for deployment timelines.

2. Source [3] mentions that "timelines of 5â€“10 years will be necessary to accumulate tritium" at the WBN (likely Watts Bar Nuclear) site. This highlights a specific supply chain constraint related to tritiumâ€”a necessary fuel component for many fusion approachesâ€”that could affect deployment timelines regardless of regulatory progress.

3. Source [4] raises the question of whether "a regulatory framework [will] be developed soon enough to enable commercial FPP [Fusion Power Plant]," indicating ongoing concerns about regulatory readiness potentially affecting deployment schedules.

## Critical Analysis

While these sources provide valuable insights into regulatory developments, they leave several important questions unanswered:

1. The sources don't specify what specific regulations or standards are being developed for fusion energy, or how they differ from fission regulations.

2. There's limited information on international regulatory harmonization, which would be crucial for global deployment.

3. The precise mechanisms by which regulatory frameworks might accelerate or delay deployment timelines aren't fully articulated.

4. The sources don't address how regulatory approaches might differ for various fusion technologies (tokamak, stellarator, inertial confinement, etc.).

It appears that while regulatory frameworks are being developed proactively, their specific impact on commercial deployment timelines remains somewhat uncertain. The successful alignment of policy, funding, and regulation mentioned in [2] and [5] suggests a positive trajectory, but concrete details on how these frameworks will specifically affect the previously projected 2030s-2040s timeline for commercial fusion electricity are not fully addressed in the provided sources.

SOURCES USED IN THIS SECTION:
1. Building the fusion energy rulebook
   URL: https://www.neimagazine.com/analysis/building-the-fusion-energy-rulebook/
2. Fusion Power: Enabling 21st Century American Dominance
   URL: https://www.scsp.ai/wp-content/uploads/2025/02/Final-Fusion-Power_-Enabling-21st-Century-American-Dominance.pdf
3. Fusion Energy Leadership Through Tritium Production ...
   URL: https://fas.org/publication/fusion-energy-leadership-tritium-capacity/
4. the role of fusion energy in a decarbonized electricity system
   URL: https://energy.mit.edu/wp-content/uploads/2024/09/MITEI_FusionReport_091124_final_COMPLETE-REPORT_fordistribution.pdf
5. Testimony of Dr. Jean Paul Allain
   URL: https://www.energy.gov/sites/default/files/2024-09/9.19.24%20SENR%20Dr.%20JP%20Allain%20Testimony%20Final.pdf

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.1
================================================================================

SEARCH QUESTION:
What specific fusion energy breakthroughs or milestones have been achieved in the last 6 months (late 2024-early 2025) that might accelerate the commercial timeline?

CONTENT:
# Recent Fusion Energy Breakthroughs (Late 2024-Early 2025)

Based on the provided sources and previous knowledge, I cannot identify any specific fusion energy breakthroughs or milestones that have occurred in the last 6 months (late 2024-early 2025) that might accelerate the commercial timeline. The new sources provided do not contain relevant information about recent fusion energy developments.

## Analysis of Available Information

The previous knowledge outlines significant fusion energy developments between 2022 and early 2025, including:

1. National Ignition Facility's fusion ignition achievement in December 2022
2. Record private sector investment exceeding $6 billion
3. Advances in high-temperature superconducting magnets
4. Commercial fusion electricity projections for the 2030s-2040s

However, the new sources provided do not contain information about fusion energy breakthroughs in the specified timeframe:

- Source [1] discusses neutrino physics and related facilities, not fusion energy developments.
- Source [2] examines citation patterns in CHI Conference proceedings, unrelated to fusion energy.
- Source [3] covers particle colliders for high-energy physics, but doesn't mention recent fusion breakthroughs.
- Source [4] focuses on cosmological expansion rates, unrelated to fusion energy.
- Source [5] discusses multi-focus image fusion using deep learning techniques, which refers to image processing rather than energy production.

None of these sources contains information about fusion energy breakthroughs in late 2024 or early 2025.

## Critical Assessment

It's important to note that the absence of relevant information in the provided sources doesn't necessarily mean that no breakthroughs have occurred. The fusion energy field continues to evolve rapidly, as indicated in the previous knowledge section, with ambitious timelines from private companies targeting demonstration plants by 2030 and some projecting commercial reactors in the early 2030s.

However, without specific information about developments in the last 6 months from reliable sources, I cannot provide details about recent breakthroughs that might accelerate the commercial timeline beyond what was already known in early 2025.

SOURCES USED IN THIS SECTION:
1. E1 Working Group Summary: Neutrino Factories and Muon Colliders
   URL: http://arxiv.org/abs/hep-ph/0111030v1
2. Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones
   URL: http://arxiv.org/abs/2501.02456v3
3. High-energy Particle Colliders: Past 20 Years, Next 20 Years, And Beyond
   URL: http://arxiv.org/abs/1409.5464v1
4. Model independent constraints on the cosmological expansion rate
   URL: http://arxiv.org/abs/0811.0981v2
5. UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion
   URL: http://arxiv.org/abs/2101.04506v4

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.2
================================================================================

SEARCH QUESTION:
How have the financial projections and economic viability assessments for commercial fusion energy changed in 2024-2025 compared to earlier estimates?

CONTENT:
# Financial Projections and Economic Viability of Commercial Fusion Energy: 2024-2025 Updates

Based on the provided sources and previous knowledge, I can analyze how financial projections and economic viability assessments for commercial fusion energy have evolved in recent years. However, I should note that the new sources provided have limited direct information about specific financial projections or economic viability assessments from 2024-2025.

## Investment Landscape and Economic Considerations

The fusion energy sector has seen dramatic growth in investment, with previous knowledge indicating over $6 billion in private funding by late 2023. This substantial capital influx reflects growing investor confidence in fusion's commercial potential. However, the new sources reveal additional economic considerations that are now being incorporated into viability assessments.

According to source [1], while technological development has received the majority of attention and funding, there is now recognition that "little work has been done to address the societal and environmental impacts of this technology." This suggests a shift in economic viability assessments to include potential costs associated with community engagement and environmental impact studies, which could affect overall project economics if not addressed early.

Source [1] further notes that addressing community and environmental concerns early in the design process can help "minimizing delays in deployment that may result in increased costs for developers." This represents an evolution in economic thinking about fusion, acknowledging that social acceptance and regulatory approval are now being factored into financial projections as potential cost drivers.

## Technical Challenges Affecting Economic Viability

Material science continues to be a critical factor in economic projections for fusion energy. Source [2] highlights that developing materials that can withstand fusion conditions is "critical in developing long-term commercial viability for energy production." The research on nanoporous tungsten structures addresses concerns about the long-term reliability of fusion reactors, which directly impacts maintenance costs and plant lifetime assumptions in economic models.

This focus on materials science represents a maturation in economic projections, as earlier estimates may have underestimated the costs associated with materials development and replacement in commercial fusion plants.

## Government Programs Supporting Commercial Viability

Source [3] provides insights into the ALPHA program from ARPA-E, which specifically aimed "to enable substantially lower-cost pathways to economical fusion power." This government initiative focused on advancing "pulsed, intermediate-density fusion approaches" that could potentially "scale to commercially viable fusion power plants."

This targeted government support for specific fusion approaches that promise lower costs indicates a more nuanced understanding of different fusion technologies' economic potential. Rather than treating fusion as a monolithic technology, financial projections are becoming more tailored to specific technological approaches.

## Comparison to Previous Projections

Based on previous knowledge, fusion companies had announced ambitious timelines with several targeting demonstration plants by 2030, while independent experts projected longer timeframes extending into the late 2030s or 2040s. The new sources don't provide updated specific timelines, but they do suggest a more comprehensive understanding of the factors affecting economic viability.

The increased attention to materials science, community engagement, and environmental impact suggests that economic projections are becoming more realistic by incorporating additional cost factors that may have been underestimated in earlier projections.

## Gaps in Current Financial Assessments

While the sources provide valuable context, they don't offer specific updated financial projections or economic viability assessments for 2024-2025. This represents a gap in the current information available about how timelines and cost projections may have shifted in the most recent years.

Sources [4] and [5] focus on digital financial services and climate-related financial regulations respectively, with no direct relevance to fusion energy economics.

## Conclusion

The evolution of financial projections and economic viability assessments for fusion energy appears to be moving toward more comprehensive models that incorporate:

1. Social and environmental factors as potential cost drivers
2. Materials science advancements as critical to long-term economic viability
3. Differentiated assessments for various fusion approaches rather than treating fusion as a monolithic technology

However, specific updated timelines and cost projections for 2024-2025 are not provided in the available sources. The fusion industry continues to attract significant investment, but a complete picture of how economic assessments have changed in the most recent years would require additional, more current sources focused specifically on financial projections.

SOURCES USED IN THIS SECTION:
1. Fusion energy commercialization requires solving social and environmental challenges
   URL: http://arxiv.org/abs/2403.05993v1
2. Molecular Dynamics Simulation of Nanoporous Tungsten
   URL: http://arxiv.org/abs/2312.05227v1
3. Retrospective of the ARPA-E ALPHA fusion program
   URL: http://arxiv.org/abs/1907.09921v2
4. Applying AHP and FUZZY AHP Management Methods to Assess the Level of Financial and Digital Inclusion
   URL: http://arxiv.org/abs/2501.10001v1
5. Assessing the regulatory framework of financial institutions in Canada in the context of international climate risk management practices and Canadian net zero emission targets
   URL: http://arxiv.org/abs/2411.02668v1

________________________________________________________________________________

================================================================================
PHASE: Follow-up 2.3
================================================================================

SEARCH QUESTION:
What are the latest international regulatory frameworks being developed specifically for fusion energy commercialization, and how might they impact deployment timelines?

CONTENT:
# International Regulatory Frameworks for Fusion Energy Commercialization

Recent developments in fusion energy regulation show significant progress, particularly in the United States, though comprehensive international frameworks are still evolving.

## United States Regulatory Developments

The U.S. Nuclear Regulatory Commission (NRC) has recently taken important steps toward creating a regulatory framework specifically for fusion energy. According to [1], the NRC is proceeding on what the Fusion Industry Association (FIA) has characterized as an "aggressive schedule" to license and regulate fusion reactors. This accelerated approach suggests recognition of fusion's potential commercial timeline and the need for appropriate regulatory structures.

More specifically, on January 3, 2023, NRC staff released a policy document titled "Options for Licensing and Regulating Fusion Energy Systems" [3]. This represents a concrete step toward establishing the regulatory framework necessary for commercial fusion deployment in the United States.

Further advancing this regulatory development, the ADVANCE Act now requires the NRC to submit a report to Congress by July 9, 2025, focused on "risk- and performance-based, design-specific licensing frameworks for mass production" [5]. This legislative mandate creates a clear timeline for developing fusion-specific regulations, potentially accelerating the pathway to commercialization by providing regulatory certainty to investors and developers.

## International Roadmaps and Timelines

On the international front, countries with explicitly energy-oriented fusion programs have developed roadmaps targeting commercial fusion power plants around 2050 [2]. This timeline aligns with the previous knowledge indicating that most experts project commercial fusion electricity between the 2030s and 2050s, though some private companies maintain more ambitious schedules.

## Impact on Deployment Timelines

The development of clear regulatory frameworks will likely have significant impacts on fusion deployment timelines. A key insight from source [4] suggests that, similar to quantum computing, different fusion approaches (and small modular reactor approaches) might succeed in different timeframes. This diversity of potential technological winners underscores the importance of flexible regulatory frameworks that can accommodate various fusion concepts without unnecessarily delaying promising technologies.

The "aggressive schedule" mentioned in source [1] could potentially accelerate deployment by providing regulatory certainty earlier than previously expected. However, it's important to note that while the U.S. is making concrete progress, truly international regulatory frameworks appear less developed based on the available sources.

## Critical Assessment

While these regulatory developments are promising, several critical questions remain unaddressed in the sources:

1. The extent of international coordination on fusion regulation
2. How regulatory approaches might differ between tokamak, inertial confinement, and alternative fusion concepts
3. Whether regulations will distinguish between deuterium-tritium and aneutronic fusion approaches
4. How fusion regulations will address tritium handling and other safety considerations

The focus on U.S. regulatory developments in the sources suggests that international frameworks may be less advanced or less coordinated at this stage, potentially creating regulatory divergence that could complicate global fusion deployment.

SOURCES USED IN THIS SECTION:
1. Building the fusion energy rulebook
   URL: https://www.neimagazine.com/analysis/building-the-fusion-energy-rulebook/
2. Fusion Energy Technology R&D Priorities
   URL: https://www.sciencedirect.com/book/9780443136290/fusion-energy-technology-r-and-d-priorities
3. Initial Report to the Washington State Legislature ...
   URL: https://app.leg.wa.gov/ReportsToTheLegislature/Home/GetPDF?fileName=form_c7ba3c87-2ff9-4c80-b998-756dc0d3d9d7.pdf
4. Nuclear Fusion: The State of Play
   URL: https://www.eu.vc/p/nuclear-fusion-the-state-of-play
5. Regulatory Framework for Fusion Machines (3150- ...
   URL: https://www.nrc.gov/docs/ML2401/ML24019A064.pdf

________________________________________________________________________________


ALL SOURCES USED IN RESEARCH:
================================================================================

1. Advanced Deuterium Fusion Rocket Propulsion For Manned Deep Space Missions
   URL: http://arxiv.org/abs/0906.0740v1
2. Why are we living the age of AI applications right now? The long innovation path from AI's birth to a child's bedtime magic
   URL: http://arxiv.org/abs/2501.06929v1
3. Substantially enhanced deuteron-triton fusion probabilities in intense low-frequency laser fields
   URL: http://arxiv.org/abs/2006.09634v1
4. Quickest Anomaly Detection in Sensor Networks With Unlabeled Samples
   URL: http://arxiv.org/abs/2209.01525v1
5. Charting the Nanohertz Gravitational Wave Sky with Pulsar Timing Arrays
   URL: http://arxiv.org/abs/2409.07955v2
6. Startups Gamble on Fusion Energy
   URL: https://undark.org/2025/02/11/startups-fusion-energy/
7. U.S. Department of Energy Announces Selectees for $107 ...
   URL: https://www.energy.gov/articles/us-department-energy-announces-selectees-107-million-fusion-innovation-research-engine
8. Helion Energy Secures $425 Million in Latest Funding ...
   URL: https://www.linkedin.com/pulse/helion-energy-secures-425-million-latest-funding-round-nathan-hammer-beymc
9. Tokamak Energy raises $125m to commercialise ...
   URL: https://tokamakenergy.com/2024/11/20/tokamak-energy-raises-125m-to-commercialise-transformative-fusion-and-magnet-technologies/
10. Wisconsin fusion start-up receives help from the Green and ...
   URL: https://www.ans.org/news/article-6616/wisconsin-fusion-startup-receives-help-from-the-green-and-gold/
11. Inching Toward a Fusion Energy Future
   URL: https://www.nytimes.com/2024/11/19/climate/fusion-energy-startups.html
12. Will We Ever Get Fusion Power?
   URL: https://ifp.org/will-we-ever-get-fusion-power/
13. Breaking Down China's Record-Breaking Fusion Milestone
   URL: https://northdenvertribune.com/neighborhood-news/china-races-ahead-breaking-down-chinas-record-breaking-fusion-milestone/
14. Critical remarks on the current TAB report on nuclear fusion
   URL: https://www.ipp.mpg.de/5481806/tab_bericht_2025
15. Inside the world's first nuclear reactor that will power Earth ...
   URL: https://www.euronews.com/next/2024/12/27/inside-the-worlds-first-reactor-that-will-power-earth-using-the-same-nuclear-reaction-as-t
16. A Novel Graph Analytic Approach to Monitor Terrorist Networks
   URL: http://arxiv.org/abs/1902.02836v1
17. MMA-UNet: A Multi-Modal Asymmetric UNet Architecture for Infrared and Visible Image Fusion
   URL: http://arxiv.org/abs/2404.17747v2
18. Mention Attention for Pronoun Translation
   URL: http://arxiv.org/abs/2412.14829v1
19. Provenance Traces
   URL: http://arxiv.org/abs/0812.0564v1
20. What is Harm? Baby Don't Hurt Me! On the Impossibility of Complete Harm Specification in AI Alignment
   URL: http://arxiv.org/abs/2501.16448v1
21. Events Calendar
   URL: https://www.eni.com/en-IT/calendar.html
22. FY 2025 Budget in Brief
   URL: https://www.commerce.gov/sites/default/files/2024-04/FY2025-Budget-in-Brief.pdf
23. Generic call for proposals 2025
   URL: https://anr.fr/fileadmin/aap/2025/ANR-AAPG-2025-en.pdf
24. Annual Report - 2024
   URL: https://www.merckgroup.com/content/dam/web/corporate/non-images/press-kits/q4-2024/en/2024-Q4-Report-EN.pdf
25. Space Agenda 2025
   URL: https://csps.aerospace.org/sites/default/files/2024-10/SpaceAgenda2025_Compilation_Web.pdf
26. Building the fusion energy rulebook
   URL: https://www.neimagazine.com/analysis/building-the-fusion-energy-rulebook/
27. Fusion Power: Enabling 21st Century American Dominance
   URL: https://www.scsp.ai/wp-content/uploads/2025/02/Final-Fusion-Power_-Enabling-21st-Century-American-Dominance.pdf
28. Fusion Energy Leadership Through Tritium Production ...
   URL: https://fas.org/publication/fusion-energy-leadership-tritium-capacity/
29. the role of fusion energy in a decarbonized electricity system
   URL: https://energy.mit.edu/wp-content/uploads/2024/09/MITEI_FusionReport_091124_final_COMPLETE-REPORT_fordistribution.pdf
30. Testimony of Dr. Jean Paul Allain
   URL: https://www.energy.gov/sites/default/files/2024-09/9.19.24%20SENR%20Dr.%20JP%20Allain%20Testimony%20Final.pdf
31. E1 Working Group Summary: Neutrino Factories and Muon Colliders
   URL: http://arxiv.org/abs/hep-ph/0111030v1
32. Keeping Score: A Quantitative Analysis of How the CHI Community Appreciates Its Milestones
   URL: http://arxiv.org/abs/2501.02456v3
33. High-energy Particle Colliders: Past 20 Years, Next 20 Years, And Beyond
   URL: http://arxiv.org/abs/1409.5464v1
34. Model independent constraints on the cosmological expansion rate
   URL: http://arxiv.org/abs/0811.0981v2
35. UFA-FUSE: A novel deep supervised and hybrid model for multi-focus image fusion
   URL: http://arxiv.org/abs/2101.04506v4
36. Fusion energy commercialization requires solving social and environmental challenges
   URL: http://arxiv.org/abs/2403.05993v1
37. Molecular Dynamics Simulation of Nanoporous Tungsten
   URL: http://arxiv.org/abs/2312.05227v1
38. Retrospective of the ARPA-E ALPHA fusion program
   URL: http://arxiv.org/abs/1907.09921v2
39. Applying AHP and FUZZY AHP Management Methods to Assess the Level of Financial and Digital Inclusion
   URL: http://arxiv.org/abs/2501.10001v1
40. Assessing the regulatory framework of financial institutions in Canada in the context of international climate risk management practices and Canadian net zero emission targets
   URL: http://arxiv.org/abs/2411.02668v1
42. Fusion Energy Technology R&D Priorities
   URL: https://www.sciencedirect.com/book/9780443136290/fusion-energy-technology-r-and-d-priorities
43. Initial Report to the Washington State Legislature ...
   URL: https://app.leg.wa.gov/ReportsToTheLegislature/Home/GetPDF?fileName=form_c7ba3c87-2ff9-4c80-b998-756dc0d3d9d7.pdf
44. Nuclear Fusion: The State of Play
   URL: https://www.eu.vc/p/nuclear-fusion-the-state-of-play
45. Regulatory Framework for Fusion Machines (3150- ...
   URL: https://www.nrc.gov/docs/ML2401/ML24019A064.pdf

================================================================================



================================================
File: static/css/styles.css
================================================
/* Modern AI-themed dark interface */
:root {
  --bg-primary: #121212;
  --bg-secondary: #1e1e2d;
  --bg-tertiary: #2a2a3a;
  --accent-primary: #6e4ff6;
  --accent-secondary: #9179f0;
  --accent-tertiary: #40bfff;
  --text-primary: #f5f5f5;
  --text-secondary: #c0c0cc;
  --text-muted: #8a8aa0;
  --border-color: #343452;
  --success-color: #0acf97;
  --warning-color: #f9bc0b;
  --error-color: #fa5c7c;
  --card-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
  --glow-effect: 0 0 15px rgba(110, 79, 246, 0.3);
  --gradient-bg: linear-gradient(135deg, #2a2a3a 0%, #1e1e2d 100%);
}

/* Reset and Base Styles */
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: 'Inter', -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
  background-color: var(--bg-primary);
  color: var(--text-primary);
  line-height: 1.6;
  overflow-x: hidden;
}

a {
  color: var(--accent-tertiary);
  text-decoration: none;
  transition: color 0.2s;
}

a:hover {
  color: var(--accent-secondary);
}

/* Layout */
.app-container {
  display: flex;
  min-height: 100vh;
}

/* Sidebar */
.sidebar {
  width: 240px;
  background-color: var(--bg-secondary);
  border-right: 1px solid var(--border-color);
  display: flex;
  flex-direction: column;
  position: fixed;
  height: 100vh;
  z-index: 10;
}

.sidebar-header {
  padding: 1.5rem;
  border-bottom: 1px solid var(--border-color);
}

.sidebar-header h2 {
  display: flex;
  align-items: center;
  font-weight: 600;
  font-size: 1.25rem;
  gap: 0.5rem;
  color: var(--accent-secondary);
}

.sidebar-header h2 i {
  color: var(--accent-primary);
}

.sidebar-nav {
  flex: 1;
  padding: 1rem 0;
}

.sidebar-nav ul {
  list-style: none;
}

.sidebar-nav li {
  padding: 0.75rem 1.5rem;
  margin-bottom: 0.25rem;
  cursor: pointer;
  display: flex;
  align-items: center;
  gap: 0.75rem;
  color: var(--text-secondary);
  border-left: 3px solid transparent;
  transition: all 0.2s;
}

.sidebar-nav li i {
  width: 20px;
}

.sidebar-nav li:hover {
  background-color: var(--bg-tertiary);
  color: var(--text-primary);
}

.sidebar-nav li.active {
  color: var(--accent-primary);
  background-color: rgba(110, 79, 246, 0.1);
  border-left-color: var(--accent-primary);
}

.sidebar-footer {
  padding: 1rem 1.5rem;
  border-top: 1px solid var(--border-color);
  color: var(--text-muted);
  font-size: 0.875rem;
  display: flex;
  justify-content: center;
}

/* Main Content */
.main-content {
  flex: 1;
  padding: 1.0rem 2rem 2rem 2rem;
  margin-left: 240px;
  width: calc(100% - 240px);
}

.page {
  display: none;
}

.page.active {
  display: block;
  animation: fadeIn 0.3s ease;
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}

.page-header {
  margin-bottom: 1.5rem;
}

.page-header h1 {
  font-weight: 600;
  font-size: 1.75rem;
  color: var(--text-primary);
}

/* Cards */
.card {
  background-color: var(--bg-secondary);
  border-radius: 12px;
  box-shadow: var(--card-shadow);
  margin-bottom: 1.5rem;
  overflow: hidden;
  border: 1px solid var(--border-color);
}

.card-content {
  padding: 1.5rem;
}

/* Form Elements */
.form-group {
  margin-bottom: 1.5rem;
}

.form-group label {
  display: block;
  margin-bottom: 0.5rem;
  font-weight: 500;
  color: var(--text-secondary);
}

textarea, input[type="text"] {
  width: 100%;
  padding: 0.75rem;
  border-radius: 8px;
  border: 1px solid var(--border-color);
  background-color: var(--bg-tertiary);
  color: var(--text-primary);
  font-family: inherit;
  font-size: 0.95rem;
  resize: vertical;
  transition: border-color 0.2s, box-shadow 0.2s;
}

textarea:focus, input[type="text"]:focus {
  outline: none;
  border-color: var(--accent-primary);
  box-shadow: 0 0 0 3px rgba(110, 79, 246, 0.2);
}

.btn {
  display: inline-flex;
  align-items: center;
  justify-content: center;
  gap: 0.5rem;
  padding: 0.75rem 1.25rem;
  border-radius: 8px;
  font-weight: 500;
  font-size: 0.95rem;
  cursor: pointer;
  transition: all 0.2s;
  border: none;
}

.btn-sm {
  padding: 0.5rem 1rem;
  font-size: 0.85rem;
}

.btn-primary {
  background-color: var(--accent-primary);
  color: white;
}

.btn-primary:hover {
  background-color: var(--accent-secondary);
  box-shadow: var(--glow-effect);
}

.btn-outline {
  background-color: transparent;
  color: var(--accent-tertiary);
  border: 1px solid var(--accent-tertiary);
}

.btn-outline:hover {
  background-color: rgba(64, 191, 255, 0.1);
}

.delete-btn {
  color: var(--error-color);
  border-color: var(--error-color);
}

.delete-btn:hover {
  background-color: rgba(250, 92, 124, 0.1);
}

.terminate-btn {
  color: #e74c3c;
  border-color: #e74c3c;
}

.terminate-btn:hover {
  background-color: rgba(231, 76, 60, 0.1);
}

.btn:disabled {
  opacity: 0.6;
  cursor: not-allowed;
  pointer-events: none;
}

.form-actions {
  display: flex;
  justify-content: flex-end;
}

/* Mode Selection */
.mode-selection {
  display: flex;
  gap: 1rem;
}

.mode-option {
  flex: 1;
  background-color: var(--bg-tertiary);
  border-radius: 8px;
  padding: 1.25rem;
  border: 2px solid transparent;
  cursor: pointer;
  transition: all 0.2s;
  display: flex;
  align-items: center;
  gap: 1rem;
}

.mode-option:hover {
  background-color: var(--bg-primary);
}

.mode-option.active {
  border-color: var (--accent-primary);
  background-color: rgba(110, 79, 246, 0.1);
}

.mode-icon {
  width: 40px;
  height: 40px;
  background-color: var(--accent-primary);
  color: white;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 1.2rem;
}

.mode-option.active .mode-icon {
  background-color: var(--accent-secondary);
  box-shadow: var(--glow-effect);
}

.mode-info h3 {
  margin-bottom: 0.25rem;
  color: var(--text-primary);
}

.mode-info p {
  color: var(--text-muted);
  font-size: 0.85rem;
}

/* Progress Bar */
.progress-container {
  margin: 1.5rem 0;
  display: flex;
  align-items: center;
  gap: 1rem;
}

.progress-bar {
  flex: 1;
  height: 12px;
  background-color: var(--bg-tertiary);
  border-radius: 6px;
  overflow: hidden;
}

.progress-fill {
  height: 100%;
  width: 0%;
  background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary));
  border-radius: 6px;
  transition: width 0.5s ease;
}

.progress-text {
  width: 60px;
  text-align: right;
  font-weight: 600;
  color: var(--accent-secondary);
}

.query-display {
  margin-bottom: 1.5rem;
}

.query-display h3 {
  color: var(--text-secondary);
  font-size: 1rem;
  margin-bottom: 0.5rem;
}

.query-display p {
  color: var(--text-primary);
  font-weight: 500;
}

.progress-info {
  color: var(--text-secondary);
  font-size: 0.9rem;
}

/* History List */
.history-list {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.history-item {
  background-color: var(--bg-tertiary);
  border-radius: 8px;
  padding: 1rem;
  border: 1px solid var(--border-color);
  transition: all 0.2s;
  cursor: pointer;
  position: relative;
}

.history-item:hover {
  border-color: var(--accent-tertiary);
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
}

.history-item-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.5rem;
}

.history-item-title {
  font-weight: 500;
  color: var(--text-primary);
}

.history-item-status {
  font-size: 0.8rem;
  padding: 0.25rem 0.5rem;
  border-radius: 4px;
  font-weight: 500;
}

.status-completed {
  background-color: rgba(10, 207, 151, 0.15);
  color: var(--success-color);
}

.status-in-progress {
  background-color: rgba(249, 188, 11, 0.15);
  color: var(--warning-color);
}

.status-failed {
  background-color: rgba(250, 92, 124, 0.15);
  color: var(--error-color);
}

.status-suspended {
  color: #f39c12;
}

.status-terminating {
  background-color: rgba(231, 76, 60, 0.15);
  color: #e74c3c;
  animation: pulse 1.5s infinite;
}

@keyframes pulse {
  0% { opacity: 0.7; }
  50% { opacity: 1; }
  100% { opacity: 0.7; }
}

.history-item-meta {
  display: flex;
  color: var(--text-muted);
  font-size: 0.85rem;
  margin-bottom: 0.75rem;
}

.history-item-date {
  margin-right: 1rem;
}

.history-item-mode {
  display: flex;
  align-items: center;
  gap: 0.25rem;
}

.history-item-actions {
  display: flex;
  justify-content: flex-end;
  gap: 0.5rem;
  position: relative;
  z-index: 5;
}

.history-item-actions button {
  position: relative;
  z-index: 10;
}

/* Results Page */
.results-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.results-metadata {
  display: flex;
  flex-wrap: wrap;
  gap: 1rem;
  margin-bottom: 1.5rem;
  padding-bottom: 1rem;
  border-bottom: 1px solid var(--border-color);
}

.metadata-item {
  display: flex;
  flex-direction: column;
}

.metadata-label {
  font-size: 0.85rem;
  color: var(--text-muted);
  margin-bottom: 0.25rem;
}

.metadata-value {
  color: var(--text-primary);
  font-weight: 500;
}

.results-content {
  line-height: 1.7;
}

.results-content h1 {
  font-size: 1.75rem;
  margin: 1.5rem 0 1rem;
  color: var(--text-primary);
}

.results-content h2 {
  font-size: 1.5rem;
  margin: 1.25rem 0 0.75rem;
  color: var(--accent-tertiary);
}

.results-content h3 {
  font-size: 1.25rem;
  margin: 1rem 0 0.5rem;
  color: var(--accent-secondary);
}

.results-content p {
  margin-bottom: 1rem;
  color: var(--text-secondary);
}

.results-content ul, 
.results-content ol {
  margin-bottom: 1rem;
  padding-left: 1.5rem;
  color: var(--text-secondary);
}

.results-content li {
  margin-bottom: 0.5rem;
}

.results-content code {
  background-color: var(--bg-tertiary);
  padding: 0.15rem 0.3rem;
  border-radius: 4px;
  font-family: 'SF Mono', 'Menlo', 'Monaco', 'Courier New', monospace;
  font-size: 0.9em;
}

.results-content pre {
  background-color: var(--bg-tertiary);
  border-radius: 8px;
  padding: 1rem;
  margin-bottom: 1rem;
  overflow-x: auto;
}

.results-content blockquote {
  border-left: 3px solid var(--accent-primary);
  padding-left: 1rem;
  margin-left: 0;
  margin-bottom: 1rem;
  color: var(--text-muted);
}

.results-content table {
  width: 100%;
  border-collapse: collapse;
  margin-bottom: 1rem;
}

.results-content th {
  background-color: var(--bg-tertiary);
  text-align: left;
  padding: 0.75rem;
  border-bottom: 2px solid var(--border-color);
  color: var(--accent-tertiary);
}

.results-content td {
  padding: 0.75rem;
  border-bottom: 1px solid var(--border-color);
  color: var(--text-secondary);
}

/* Research Details Page */
.research-metadata {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(200px, 1fr));
  gap: 1.5rem;
  margin-bottom: 1.5rem;
  padding-bottom: 1rem;
  border-bottom: 1px solid var(--border-color);
}

.detail-progress-container {
  display: flex;
  align-items: center;
  gap: 0.75rem;
}

.detail-progress-bar {
  flex: 1;
  height: 8px;
  background-color: var(--bg-tertiary);
  border-radius: 4px;
  overflow: hidden;
}

.detail-progress-fill {
  height: 100%;
  width: 0%;
  background: linear-gradient(90deg, var(--accent-primary), var(--accent-secondary));
  border-radius: 4px;
  transition: width 0.5s ease;
}

.research-log-container {
  margin-top: 1.5rem;
}

.research-log-container h3 {
  margin-bottom: 1rem;
  color: var(--text-secondary);
  font-size: 1.1rem;
  font-weight: 500;
}

.research-log {
  max-height: 500px;
  overflow-y: auto;
  padding: 1rem;
  background-color: var(--bg-tertiary);
  border-radius: 8px;
  border: 1px solid var(--border-color);
}

.log-entry {
  padding: 0.75rem;
  border-bottom: 1px solid var(--border-color);
  display: flex;
  gap: 1rem;
}

.log-entry:last-child {
  border-bottom: none;
}

.log-entry-time {
  font-size: 0.8rem;
  color: var(--text-muted);
  min-width: 80px;
}

.log-entry-content {
  flex: 1;
}

.log-entry-message {
  color: var(--text-secondary);
  margin-bottom: 0.25rem;
}

.log-entry-progress {
  font-size: 0.85rem;
  color: var(--accent-secondary);
  font-weight: 500;
}

.detail-actions {
  margin-top: 1.5rem;
  display: flex;
  justify-content: center;
  gap: 1rem;
}

.phase-highlight {
  color: var(--accent-tertiary);
  font-weight: 500;
}

.phase-init {
  color: var(--accent-tertiary);
}

.phase-search {
  color: var(--accent-secondary);
}

.phase-analysis {
  color: var(--warning-color);
}

.phase-complete {
  color: var(--success-color);
}

.phase-error {
  color: var(--error-color);
}

.phase-termination {
  color: #e74c3c;
  font-weight: bold;
}

.empty-state {
  padding: 2rem;
  text-align: center;
  color: var(--text-muted);
  font-style: italic;
}

.error-message {
  padding: 1rem;
  background-color: rgba(250, 92, 124, 0.1);
  border: 1px solid var(--error-color);
  border-radius: 8px;
  color: var(--error-color);
  margin: 1rem 0;
  font-size: 0.9rem;
}

/* Loading Spinner */
.loading-spinner {
  padding: 2rem 0;
}

.loading-spinner.centered {
  display: flex;
  justify-content: center;
  align-items: center;
}

.spinner {
  width: 40px;
  height: 40px;
  border: 4px solid rgba(110, 79, 246, 0.2);
  border-left-color: var(--accent-primary);
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  to { transform: rotate(360deg); }
}

/* Mobile Tab Bar */
.mobile-tab-bar {
  display: none; /* Hidden by default */
  position: fixed;
  bottom: 0;
  left: 0;
  right: 0;
  height: 60px;
  background-color: var(--bg-secondary);
  border-top: 1px solid var(--border-color);
  z-index: 1000;
  box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.2);
}

.mobile-tab-bar ul {
  display: flex;
  height: 100%;
  list-style: none;
  padding: 0;
  margin: 0;
  width: 100%;
}

.mobile-tab-bar li {
  flex: 1;
  display: flex;
  flex-direction: column;
  justify-content: center;
  align-items: center;
  cursor: pointer;
  color: var(--text-secondary);
  transition: all 0.2s;
  padding: 0.5rem 0;
  min-width: 90px;
}

.mobile-tab-bar li i {
  font-size: 1.3rem;
  margin-bottom: 8px;
}

.mobile-tab-bar li span {
  font-size: 0.75rem;
  text-align: center;
  width: 100%;
}

.mobile-tab-bar li.active {
  color: var(--accent-primary);
}

.mobile-tab-bar li:hover {
  color: var(--text-primary);
}

/* Responsive */
@media (max-width: 991px) {
  .sidebar {
    width: 60px;
    overflow: hidden;
  }
  
  /* Hide all text in the logo and center icon */
  .sidebar-header {
    padding: 1rem 0;
    text-align: center;
    display: flex;
    align-items: center;
    justify-content: center;
    height: 60px;
  }
  
  .sidebar-header h2 {
    font-size: 0;
    display: flex;
    justify-content: center;
    width: 100%;
  }
  
  .sidebar-header h2 i {
    font-size: 1.4rem;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  /* Hide all text in nav items and center icons */
  .sidebar-nav {
    display: flex;
    flex-direction: column;
    padding-top: 0.5rem;
  }
  
  .sidebar-nav ul {
    width: 100%;
  }
  
  .sidebar-nav li {
    text-indent: -9999px;
    white-space: nowrap;
    padding: 1rem 0;
    text-align: center;
    height: 60px;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  .sidebar-nav li i {
    text-indent: 0;
    margin: 0;
    font-size: 1.3rem;
    display: flex;
    align-items: center;
    justify-content: center;
  }
  
  /* Active state fix for icon view */
  .sidebar-nav li.active {
    border-left-width: 3px;
  }
  
  /* Hide footer */
  .sidebar-footer {
    display: none;
  }
  
  /* Adjust main content */
  .main-content {
    margin-left: 60px;
    width: calc(100% - 60px);
  }
  
  .mode-selection {
    flex-direction: column;
  }
}

@media (max-width: 767px) {
  body {
    padding-bottom: 60px; /* Add padding to body for the tab bar */
  }

  .main-content {
    padding: 1rem;
    padding-bottom: 70px; /* Add padding for the tab bar */
    margin-left: 0;
    width: 100%;
  }
  
  .sidebar {
    width: 0;
    transform: translateX(-100%);
  }
  
  .sidebar.active {
    width: 240px;
    transform: translateX(0);
  }
  
  /* Restore text in logo when sidebar is active on mobile */
  .sidebar.active .sidebar-header h2 {
    font-size: 1.25rem;
  }
  
  /* Restore text in nav items when sidebar is active on mobile */
  .sidebar.active .sidebar-nav li {
    text-indent: 0;
    padding: 0.75rem 1.5rem;
    text-align: left;
  }
  
  .sidebar.active .sidebar-nav li i {
    display: inline;
    width: 20px;
    margin-right: 0.75rem;
    font-size: 1rem;
  }
  
  .sidebar.active .sidebar-footer {
    display: flex;
  }
  
  /* Show mobile tab bar */
  .mobile-tab-bar {
    display: flex !important; /* Use !important to ensure it displays */
  }
}

.progress-status {
  margin-bottom: 1.25rem;
  padding: 0.5rem 0;
  font-weight: 500;
}

.progress-actions {
  display: flex;
  justify-content: center;
  margin-top: 1rem;
}


================================================
File: static/js/app.js
================================================
// Main application functionality
document.addEventListener('DOMContentLoaded', () => {
    // Initialize socket.io connection with proper error handling and reconnection options
    const socket = io({
        reconnection: true,
        reconnectionAttempts: 5,
        reconnectionDelay: 1000,
        reconnectionDelayMax: 5000,
        timeout: 20000,
        autoConnect: true
    });
    
    // Socket connection event handlers
    socket.on('connect', () => {
        console.log('Socket.IO connected successfully');
    });
    
    socket.on('connect_error', (error) => {
        console.error('Socket.IO connection error:', error);
        // The connection will automatically try to reconnect due to our config
    });
    
    socket.on('reconnect', (attemptNumber) => {
        console.log(`Socket.IO reconnected after ${attemptNumber} attempts`);
    });
    
    socket.on('reconnect_error', (error) => {
        console.error('Socket.IO reconnection error:', error);
    });

    // Navigation
    const navItems = document.querySelectorAll('.sidebar-nav li');
    const mobileNavItems = document.querySelectorAll('.mobile-tab-bar li');
    const pages = document.querySelectorAll('.page');
    const mobileTabBar = document.querySelector('.mobile-tab-bar');
    
    // Handle responsive navigation based on screen size
    function handleResponsiveNavigation() {
        // Mobile tab bar should only be visible on small screens
        if (window.innerWidth <= 767) {
            if (mobileTabBar) {
                mobileTabBar.style.display = 'flex';
            }
        } else {
            if (mobileTabBar) {
                mobileTabBar.style.display = 'none';
            }
        }
    }
    
    // Call on initial load
    handleResponsiveNavigation();
    
    // Set up window resize listener
    window.addEventListener('resize', handleResponsiveNavigation);
    
    // Initialize modal research id
    let currentResearchId = null;
    let isResearchInProgress = false;
    
    // Expose the currentResearchId and termination function to the window object for the inline script
    window.currentResearchId = null;
    
    // Track termination status
    let isTerminating = false;
    
    // Check if we're on the history page and load history if needed
    const historyPage = document.getElementById('history');
    if (historyPage && historyPage.classList.contains('active')) {
        // Use setTimeout to ensure the DOM is fully loaded
        setTimeout(() => loadResearchHistory(), 100);
    }
    
    // Function to terminate research - exposed to window object
    async function terminateResearch(researchId) {
        if (!researchId) {
            console.error('No research ID provided for termination');
            return;
        }

        // Prevent multiple termination requests
        if (isTerminating) {
            console.log('Termination already in progress');
            return;
        }
        
        // Confirm with the user
        if (!confirm('Are you sure you want to terminate this research? This action cannot be undone.')) {
            return;
        }
        
        try {
            // Set terminating flag
            isTerminating = true;
            
            // Update UI to show we're processing
            const terminateBtn = document.getElementById('terminate-research-btn');
            if (terminateBtn) {
                terminateBtn.disabled = true;
                terminateBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Terminating...';
            }

            // Find all terminate buttons in history items and disable them
            const allTerminateBtns = document.querySelectorAll('.terminate-btn');
            allTerminateBtns.forEach(btn => {
                if (btn !== terminateBtn) {
                    btn.disabled = true;
                    btn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Terminating...';
                }
            });
            
            // Call the terminate API
            const response = await fetch(`/api/research/${researchId}/terminate`, {
                method: 'POST'
            });
            
            const data = await response.json();
            
            if (data.status === 'success') {
                // The UI will be updated via socket events or polling
                console.log('Termination request sent successfully');
                
                // If we're on the history page, update the status of this item
                if (document.getElementById('history').classList.contains('active')) {
                    updateHistoryItemStatus(researchId, 'terminating', 'Terminating...');
                }
            } else {
                console.error('Termination request failed:', data.message);
                alert(`Failed to terminate research: ${data.message}`);
                
                // Reset the terminating flag
                isTerminating = false;
                
                // Reset the button
                if (terminateBtn) {
                    terminateBtn.disabled = false;
                    terminateBtn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate Research';
                }
                
                // Reset history button states
                const allTerminateBtns = document.querySelectorAll('.terminate-btn');
                allTerminateBtns.forEach(btn => {
                    if (btn !== terminateBtn) {
                        btn.disabled = false;
                        btn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate';
                    }
                });
            }
        } catch (error) {
            console.error('Error terminating research:', error);
            alert('An error occurred while trying to terminate the research.');
            
            // Reset the terminating flag
            isTerminating = false;
            
            // Reset the button
            const terminateBtn = document.getElementById('terminate-research-btn');
            if (terminateBtn) {
                terminateBtn.disabled = false;
                terminateBtn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate Research';
            }
            
            // Reset history button states
            const allTerminateBtns = document.querySelectorAll('.terminate-btn');
            allTerminateBtns.forEach(btn => {
                if (btn !== terminateBtn) {
                    btn.disabled = false;
                    btn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate';
                }
            });
        }
    }
    
    // Expose the terminate function to the window object
    window.terminateResearch = terminateResearch;
    
    // Function to switch pages
    function switchPage(pageId) {
        pages.forEach(page => {
            page.classList.remove('active');
        });
        
        const targetPage = document.getElementById(pageId);
        if (targetPage) {
            targetPage.classList.add('active');
        }
        
        // Update sidebar navigation active states
        navItems.forEach(item => {
            if (item.getAttribute('data-page') === pageId) {
                item.classList.add('active');
            } else {
                item.classList.remove('active');
            }
        });
        
        // Update mobile tab bar active states
        mobileNavItems.forEach(item => {
            if (item.getAttribute('data-page') === pageId) {
                item.classList.add('active');
            } else {
                item.classList.remove('active');
            }
        });
    }
    
    // Setup navigation click handlers
    navItems.forEach(item => {
        item.addEventListener('click', () => {
            const pageId = item.getAttribute('data-page');
            switchPage(pageId);
            
            // Load history data when navigating to history page
            if (pageId === 'history') {
                loadResearchHistory();
            }
        });
    });
    
    // Setup mobile navigation click handlers
    mobileNavItems.forEach(item => {
        item.addEventListener('click', () => {
            const pageId = item.getAttribute('data-page');
            switchPage(pageId);
            
            // Load history data when navigating to history page
            if (pageId === 'history') {
                loadResearchHistory();
            }
        });
    });
    
    // Handle logo click to return to home page
    const logoLink = document.getElementById('logo-link');
    if (logoLink) {
        logoLink.addEventListener('click', () => {
            switchPage('new-research');
        });
    }
    
    // Mode selection
    const modeOptions = document.querySelectorAll('.mode-option');
    let selectedMode = 'quick';
    
    modeOptions.forEach(option => {
        option.addEventListener('click', () => {
            modeOptions.forEach(opt => opt.classList.remove('active'));
            option.classList.add('active');
            selectedMode = option.getAttribute('data-mode');
        });
    });

    // Form submission
    const researchForm = document.getElementById('research-form');
    const startResearchBtn = document.getElementById('start-research-btn');
    
    researchForm.addEventListener('submit', async (e) => {
        e.preventDefault();
        
        if (isResearchInProgress) {
            alert('Another research is already in progress. Please wait for it to complete or check its status in the history tab.');
            return;
        }
        
        const queryInput = document.getElementById('query');
        const query = queryInput.value.trim();
        
        if (!query) {
            alert('Please enter a research query');
            return;
        }
        
        // Disable the start button while we attempt to start the research
        startResearchBtn.disabled = true;
        startResearchBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Starting...';
        
        try {
            const response = await fetch('/api/start_research', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    query: query,
                    mode: selectedMode
                })
            });
            
            const data = await response.json();
            
            if (data.status === 'success') {
                isResearchInProgress = true;
                currentResearchId = data.research_id;
                
                // Also update the window object
                window.currentResearchId = data.research_id;
                
                // Update the navigation to show Research in Progress
                updateNavigationBasedOnResearchStatus();
                
                // Update progress page
                document.getElementById('current-query').textContent = query;
                document.getElementById('progress-fill').style.width = '0%';
                document.getElementById('progress-percentage').textContent = '0%';
                document.getElementById('progress-status').textContent = 'Initializing research process...';
                
                // Navigate to progress page
                switchPage('research-progress');
                
                // Connect to socket for this research
                connectToResearchSocket(data.research_id);
                
                // Start polling for status
                pollResearchStatus(data.research_id);
                
                // Show the terminate button
                const terminateBtn = document.getElementById('terminate-research-btn');
                if (terminateBtn) {
                    terminateBtn.style.display = 'inline-flex';
                    terminateBtn.disabled = false;
                }
            } else {
                alert('Error starting research: ' + (data.message || 'Unknown error'));
                startResearchBtn.disabled = false;
                startResearchBtn.innerHTML = '<i class="fas fa-rocket"></i> Start Research';
            }
        } catch (error) {
            console.error('Error:', error);
            alert('An error occurred while starting the research. Please try again.');
            startResearchBtn.disabled = false;
            startResearchBtn.innerHTML = '<i class="fas fa-rocket"></i> Start Research';
        }
    });
    
    // Socket event handlers for research progress
    function connectToResearchSocket(researchId) {
        // Subscribe to the specific channel for this research
        socket.on(`research_progress_${researchId}`, (data) => {
            console.log('Research progress update:', data);
            
            // Update the progress UI
            if (data.progress) {
                updateProgressUI(data.progress, data.status, data.message);
            }
            
            // Update the log if we're on the details page
            if (data.log_entry && document.getElementById('research-details').classList.contains('active')) {
                updateDetailLogEntry(data.log_entry);
            }
            
            // If status is terminating, update the history item if visible
            if (data.status === 'terminating' && document.getElementById('history').classList.contains('active')) {
                updateHistoryItemStatus(researchId, 'terminating', 'Terminating...');
            }
            
            // Handle completion
            if (data.status === 'completed' || data.status === 'failed' || data.status === 'suspended') {
                isResearchInProgress = false;
                currentResearchId = null;
                
                // Always update the start research button state
                startResearchBtn.disabled = false;
                startResearchBtn.innerHTML = '<i class="fas fa-rocket"></i> Start Research';
                
                // Reset terminating flag if it was suspended
                if (data.status === 'suspended') {
                    isTerminating = false;
                }
                
                // Update navigation when research completes or is suspended
                updateNavigationBasedOnResearchStatus();
                
                // If history page is active, update the specific item in place
                if (document.getElementById('history').classList.contains('active')) {
                    updateHistoryItemStatus(researchId, data.status);
                    // Full refresh may still be needed to update duration info
                    setTimeout(() => loadResearchHistory(), 500);
                }
                
                if (data.status === 'completed' && data.report_path) {
                    // Navigate to results page if we're on the progress page
                    if (document.getElementById('research-progress').classList.contains('active')) {
                        loadResearch(researchId);
                    }
                } else if (data.status === 'failed' || data.status === 'suspended') {
                    // Update the progress UI with the error message
                    const statusMessage = data.status === 'suspended' ? 
                        'Research was terminated by user' : 
                        (data.error || 'Research failed');
                    updateProgressUI(100, data.status, statusMessage);
                }
            }
        });
    }
    
    // Function to poll research status (as a backup to socket.io)
    function pollResearchStatus(researchId) {
        const interval = setInterval(async () => {
            try {
                const response = await fetch(`/api/research/${researchId}`);
                const data = await response.json();
                
                if (data.status === 'completed' || data.status === 'failed' || data.status === 'suspended') {
                    clearInterval(interval);
                    isResearchInProgress = false;
                    currentResearchId = null;
                    
                    // Always update the start research button state
                    startResearchBtn.disabled = false;
                    startResearchBtn.innerHTML = '<i class="fas fa-rocket"></i> Start Research';
                    
                    // Update navigation when research completes or is suspended
                    updateNavigationBasedOnResearchStatus();
                    
                    // If history page is active, update the specific item in place
                    if (document.getElementById('history').classList.contains('active')) {
                        updateHistoryItemStatus(researchId, data.status);
                        // Full refresh may still be needed to update duration info
                        setTimeout(() => loadResearchHistory(), 500);
                    }
                    
                    if (data.status === 'completed') {
                        loadResearch(researchId);
                    } else if (data.status === 'failed' || data.status === 'suspended') {
                        const statusMessage = data.status === 'suspended' ? 
                            'Research was terminated by user' : 
                            (data.metadata ? JSON.parse(data.metadata).error : 'Research failed');
                        updateProgressUI(100, data.status, statusMessage);
                    }
                } else {
                    updateProgressUI(data.progress || 0, data.status);
                }
            } catch (error) {
                console.error('Error polling status:', error);
            }
        }, 3000); // Poll every 3 seconds
    }
    
    // Function to update the progress UI
    function updateProgressUI(progress, status, message) {
        const progressFill = document.getElementById('progress-fill');
        const progressPercentage = document.getElementById('progress-percentage');
        const progressStatus = document.getElementById('progress-status');
        
        if (progressFill && progressPercentage) {
            progressFill.style.width = `${progress}%`;
            progressPercentage.textContent = `${progress}%`;
        }
        
        if (progressStatus && message) {
            progressStatus.textContent = message;
            
            // Update status class
            progressStatus.className = 'progress-status';
            if (status) {
                progressStatus.classList.add(`status-${status}`);
            }
        }
        
        // Show/hide terminate button based on status
        const terminateBtn = document.getElementById('terminate-research-btn');
        if (terminateBtn) {
            if (status === 'in_progress') {
                terminateBtn.style.display = 'inline-flex';
                terminateBtn.disabled = false;
                terminateBtn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate Research';
            } else if (status === 'terminating') {
                terminateBtn.style.display = 'inline-flex';
                terminateBtn.disabled = true;
                terminateBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Terminating...';
            } else {
                terminateBtn.style.display = 'none';
            }
        }
    }
    
    // Completely rewritten function to ensure reliable history loading
    async function loadResearchHistory() {
        const historyList = document.getElementById('history-list');
        
        // Make sure we have the history list element
        if (!historyList) {
            console.error('History list element not found');
            return;
        }
        
        historyList.innerHTML = '<div class="loading-spinner centered"><div class="spinner"></div></div>';
        
        try {
            // Basic fetch without any extras
            const response = await fetch('/api/history');
            
            if (!response.ok) {
                throw new Error(`API returned status ${response.status}: ${response.statusText}`);
            }
            
            const data = await response.json();
            
            // Clear the loading spinner
            historyList.innerHTML = '';
            
            // Handle empty data
            if (!data || !Array.isArray(data) || data.length === 0) {
                historyList.innerHTML = '<div class="empty-state">No research history found. Start a new research project!</div>';
                return;
            }
            
            // Display each history item
            data.forEach(item => {
                try {
                    // Skip if item is invalid
                    if (!item || !item.id) {
                        return;
                    }
                    
                    // Create container
                    const historyItem = document.createElement('div');
                    historyItem.className = 'history-item';
                    historyItem.dataset.researchId = item.id;
                    
                    // Create header with title and status
                    const header = document.createElement('div');
                    header.className = 'history-item-header';
                    
                    const title = document.createElement('div');
                    title.className = 'history-item-title';
                    title.textContent = item.query || 'Untitled Research';
                    
                    const status = document.createElement('div');
                    status.className = `history-item-status status-${item.status || 'unknown'}`;
                    status.textContent = item.status ? (item.status.charAt(0).toUpperCase() + item.status.slice(1)) : 'Unknown';
                    
                    header.appendChild(title);
                    header.appendChild(status);
                    historyItem.appendChild(header);
                    
                    // Create meta section
                    const meta = document.createElement('div');
                    meta.className = 'history-item-meta';
                    
                    const date = document.createElement('div');
                    date.className = 'history-item-date';
                    try {
                        // Use completed_at if available, fall back to created_at if not
                        const dateToUse = item.completed_at || item.created_at;
                        date.textContent = dateToUse ? formatDate(new Date(dateToUse)) : 'Unknown date';
                    } catch (e) {
                        date.textContent = item.completed_at || item.created_at || 'Unknown date';
                    }
                    
                    const mode = document.createElement('div');
                    mode.className = 'history-item-mode';
                    const modeIcon = item.mode === 'quick' ? 'bolt' : 'microscope';
                    const modeText = item.mode === 'quick' ? 'Quick Summary' : 'Detailed Report';
                    mode.innerHTML = `<i class="fas fa-${modeIcon}"></i> ${modeText}`;
                    
                    meta.appendChild(date);
                    meta.appendChild(mode);
                    historyItem.appendChild(meta);
                    
                    // Create actions section
                    const actions = document.createElement('div');
                    actions.className = 'history-item-actions';
                    
                    // View button
                    const viewBtn = document.createElement('button');
                    viewBtn.className = 'btn btn-sm btn-outline view-btn';
                    
                    if (item.status === 'completed') {
                        viewBtn.innerHTML = '<i class="fas fa-eye"></i> View';
                        viewBtn.addEventListener('click', (e) => {
                            e.stopPropagation();
                            loadResearch(item.id);
                        });
                        
                        // PDF button for completed research
                        const pdfBtn = document.createElement('button');
                        pdfBtn.className = 'btn btn-sm btn-outline pdf-btn';
                        pdfBtn.innerHTML = '<i class="fas fa-file-pdf"></i> PDF';
                        pdfBtn.addEventListener('click', (e) => {
                            e.stopPropagation();
                            generatePdfFromResearch(item.id);
                        });
                        actions.appendChild(pdfBtn);
                    } else if (item.status === 'in_progress') {
                        viewBtn.innerHTML = '<i class="fas fa-spinner fa-spin"></i> In Progress';
                        viewBtn.addEventListener('click', (e) => {
                            e.stopPropagation();
                            navigateToResearchProgress({id: item.id, query: item.query, progress: 0});
                        });
                    } else {
                        viewBtn.innerHTML = '<i class="fas fa-eye"></i> View';
                        viewBtn.disabled = true;
                    }
                    
                    actions.appendChild(viewBtn);
                    
                    // Delete button
                    const deleteBtn = document.createElement('button');
                    deleteBtn.className = 'btn btn-sm btn-outline delete-btn';
                    deleteBtn.innerHTML = '<i class="fas fa-trash"></i> Delete';
                    deleteBtn.addEventListener('click', (e) => {
                        e.stopPropagation();
                        if (confirm(`Are you sure you want to delete this research: "${item.query}"?`)) {
                            deleteResearch(item.id);
                        }
                    });
                    actions.appendChild(deleteBtn);
                    
                    historyItem.appendChild(actions);
                    
                    // Add click handler for the entire item
                    historyItem.addEventListener('click', (e) => {
                        // Skip if clicking on a button
                        if (e.target.closest('button')) {
                            return;
                        }
                        
                        if (item.status === 'completed') {
                            loadResearch(item.id);
                        } else if (item.status === 'in_progress') {
                            navigateToResearchProgress({id: item.id, query: item.query, progress: 0});
                        }
                    });
                    
                    // Add to the history list
                    historyList.appendChild(historyItem);
                } catch (itemError) {
                    console.error('Error processing history item:', itemError, item);
                }
            });
            
            // Check if any research is in progress and update the start button state
            const inProgressResearch = data.find(item => item.status === 'in_progress');
            if (inProgressResearch) {
                isResearchInProgress = true;
                currentResearchId = inProgressResearch.id;
                if (startResearchBtn) {
                    startResearchBtn.disabled = true;
                }
            } else {
                isResearchInProgress = false;
                if (startResearchBtn) {
                    startResearchBtn.disabled = false;
                }
            }
            
        } catch (error) {
            console.error('Error loading history:', error);
            historyList.innerHTML = `
                <div class="error-message">
                    Error loading history: ${error.message}
                </div>
                <div style="text-align: center; margin-top: 1rem;">
                    <button id="retry-history-btn" class="btn btn-primary">
                        <i class="fas fa-sync"></i> Retry
                    </button>
                </div>`;
                
            const retryBtn = document.getElementById('retry-history-btn');
            if (retryBtn) {
                retryBtn.addEventListener('click', () => {
                    loadResearchHistory();
                });
            }
        }
        
        // Add a fallback in case something goes wrong and the history list is still empty
        setTimeout(() => {
            if (historyList.innerHTML === '' || historyList.innerHTML.includes('loading-spinner')) {
                console.warn('History list is still empty or showing spinner after load attempt - applying fallback');
                historyList.innerHTML = `
                    <div class="error-message">
                        Something went wrong while loading the history. 
                    </div>
                    <div style="text-align: center; margin-top: 1rem;">
                        <button id="fallback-retry-btn" class="btn btn-primary">
                            <i class="fas fa-sync"></i> Retry
                        </button>
                    </div>`;
                    
                const fallbackRetryBtn = document.getElementById('fallback-retry-btn');
                if (fallbackRetryBtn) {
                    fallbackRetryBtn.addEventListener('click', () => {
                        loadResearchHistory();
                    });
                }
            }
        }, 5000); // Check after 5 seconds
    }
    
    // Function to navigate to research progress
    function navigateToResearchProgress(research) {
        document.getElementById('current-query').textContent = research.query;
        document.getElementById('progress-fill').style.width = `${research.progress || 0}%`;
        document.getElementById('progress-percentage').textContent = `${research.progress || 0}%`;
        
        // Navigate to progress page
        switchPage('research-progress');
        
        // Connect to socket for this research
        connectToResearchSocket(research.id);
        
        // Start polling for status
        pollResearchStatus(research.id);
    }
    
    // Function to delete a research record
    async function deleteResearch(researchId) {
        try {
            const response = await fetch(`/api/research/${researchId}/delete`, {
                method: 'DELETE'
            });
            
            if (response.ok) {
                // Reload the history
                loadResearchHistory();
            } else {
                alert('Failed to delete research. Please try again.');
            }
        } catch (error) {
            console.error('Error deleting research:', error);
            alert('An error occurred while deleting the research.');
        }
    }
    
    // Function to load a specific research result
    async function loadResearch(researchId) {
        // Navigate to results page
        switchPage('research-results');
        
        const resultsContent = document.getElementById('results-content');
        resultsContent.innerHTML = '<div class="loading-spinner centered"><div class="spinner"></div></div>';
        
        try {
            // Load research details
            const detailsResponse = await fetch(`/api/research/${researchId}`);
            const details = await detailsResponse.json();
            
            // Display metadata
            document.getElementById('result-query').textContent = details.query;
            
            // Format date with duration if available
            let dateText = formatDate(new Date(details.completed_at || details.created_at));
            if (details.duration_seconds) {
                // Format duration
                let durationText = '';
                const duration = parseInt(details.duration_seconds);
                
                if (duration < 60) { // less than a minute
                    durationText = `${duration}s`;
                } else if (duration < 3600) { // less than an hour
                    durationText = `${Math.floor(duration / 60)}m ${duration % 60}s`;
                } else { // hours
                    durationText = `${Math.floor(duration / 3600)}h ${Math.floor((duration % 3600) / 60)}m`;
                }
                
                dateText += ` (Duration: ${durationText})`;
            }
            document.getElementById('result-date').textContent = dateText;
            
            document.getElementById('result-mode').textContent = details.mode === 'quick' ? 'Quick Summary' : 'Detailed Report';
            
            // Load the report content
            const reportResponse = await fetch(`/api/report/${researchId}`);
            const reportData = await reportResponse.json();
            
            if (reportData.status === 'success') {
                // Render markdown
                const renderedContent = marked.parse(reportData.content);
                resultsContent.innerHTML = renderedContent;
                
                // Apply syntax highlighting
                document.querySelectorAll('pre code').forEach((block) => {
                    hljs.highlightElement(block);
                });
            } else {
                resultsContent.innerHTML = '<div class="error-message">Error loading report. Please try again later.</div>';
            }
        } catch (error) {
            console.error('Error loading research:', error);
            resultsContent.innerHTML = '<div class="error-message">Error loading research results. Please try again later.</div>';
        }
    }
    
    // Function to load research details page
    async function loadResearchDetails(researchId) {
        // Navigate to details page
        switchPage('research-details');
        
        // Initialize the research log area
        const researchLog = document.getElementById('research-log');
        researchLog.innerHTML = '<div class="loading-spinner centered"><div class="spinner"></div></div>';
        
        try {
            // Load research details
            const response = await fetch(`/api/research/${researchId}/details`);
            console.log('Research details API response status:', response.status);
            
            if (!response.ok) {
                console.error('API error:', response.status, response.statusText);
                researchLog.innerHTML = `<div class="error-message">Error loading research details. Status: ${response.status}</div>`;
                return;
            }
            
            const data = await response.json();
            console.log('Research details data:', data);
            
            if (data.status !== 'success') {
                researchLog.innerHTML = `<div class="error-message">Error loading research details: ${data.message || 'Unknown error'}</div>`;
                return;
            }
            
            // Display metadata
            document.getElementById('detail-query').textContent = data.query || 'N/A';
            document.getElementById('detail-status').textContent = capitalizeFirstLetter(data.status || 'unknown');
            document.getElementById('detail-status').className = `metadata-value status-${data.status || 'unknown'}`;
            document.getElementById('detail-mode').textContent = (data.mode === 'quick' ? 'Quick Summary' : 'Detailed Report') || 'N/A';
            
            // Update progress bar
            const progress = data.progress || 0;
            document.getElementById('detail-progress-fill').style.width = `${progress}%`;
            document.getElementById('detail-progress-percentage').textContent = `${progress}%`;
            
            // Render log entries
            renderLogEntries(data.log || []);
            
            // Set up socket connection for live updates if research is in progress
            if (data.status === 'in_progress') {
                connectToResearchSocket(researchId);
            }
            
            // Add appropriate actions based on research status
            const detailActions = document.getElementById('detail-actions');
            detailActions.innerHTML = '';
            
            if (data.status === 'completed') {
                const viewResultsBtn = document.createElement('button');
                viewResultsBtn.className = 'btn btn-primary';
                viewResultsBtn.innerHTML = '<i class="fas fa-eye"></i> View Results';
                viewResultsBtn.addEventListener('click', () => loadResearch(researchId));
                detailActions.appendChild(viewResultsBtn);
                
                // Add download PDF button
                const downloadPdfBtn = document.createElement('button');
                downloadPdfBtn.className = 'btn btn-outline';
                downloadPdfBtn.innerHTML = '<i class="fas fa-file-pdf"></i> Download PDF';
                downloadPdfBtn.addEventListener('click', () => generatePdfFromResearch(researchId));
                detailActions.appendChild(downloadPdfBtn);
            } else if (data.status === 'in_progress') {
                const viewProgressBtn = document.createElement('button');
                viewProgressBtn.className = 'btn btn-primary';
                viewProgressBtn.innerHTML = '<i class="fas fa-sync"></i> View Live Progress';
                viewProgressBtn.addEventListener('click', () => {
                    document.getElementById('current-query').textContent = data.query || '';
                    
                    // Navigate to progress page
                    switchPage('research-progress');
                    
                    // Connect to socket
                    connectToResearchSocket(researchId);
                });
                detailActions.appendChild(viewProgressBtn);
            }
        } catch (error) {
            console.error('Error loading research details:', error);
            researchLog.innerHTML = `<div class="error-message">Error loading research details: ${error.message}</div>`;
        }
    }
    
    // Function to render log entries
    function renderLogEntries(logEntries) {
        const researchLog = document.getElementById('research-log');
        researchLog.innerHTML = '';
        
        if (!logEntries || logEntries.length === 0) {
            researchLog.innerHTML = '<div class="empty-state">No log entries available.</div>';
            return;
        }
        
        try {
            // Use a document fragment for better performance
            const fragment = document.createDocumentFragment();
            const template = document.getElementById('log-entry-template');
            
            if (!template) {
                console.error('Log entry template not found');
                researchLog.innerHTML = '<div class="error-message">Error rendering log entries: Template not found</div>';
                return;
            }
            
            logEntries.forEach(entry => {
                if (!entry) return; // Skip invalid entries
                
                try {
                    const clone = document.importNode(template.content, true);
                    
                    // Format the timestamp
                    let timeStr = 'N/A';
                    try {
                        if (entry.time) {
                            const time = new Date(entry.time);
                            timeStr = time.toLocaleTimeString();
                        }
                    } catch (timeErr) {
                        console.warn('Error formatting time:', timeErr);
                    }
                    
                    const timeEl = clone.querySelector('.log-entry-time');
                    if (timeEl) timeEl.textContent = timeStr;
                    
                    // Add message with phase highlighting if available
                    const messageEl = clone.querySelector('.log-entry-message');
                    if (messageEl) {
                        let phaseClass = '';
                        if (entry.metadata && entry.metadata.phase) {
                            phaseClass = `phase-${entry.metadata.phase}`;
                        }
                        messageEl.textContent = entry.message || 'No message';
                        messageEl.classList.add(phaseClass);
                    }
                    
                    // Add progress information if available
                    const progressEl = clone.querySelector('.log-entry-progress');
                    if (progressEl) {
                        if (entry.progress !== null && entry.progress !== undefined) {
                            progressEl.textContent = `Progress: ${entry.progress}%`;
                        } else {
                            progressEl.textContent = '';
                        }
                    }
                    
                    fragment.appendChild(clone);
                } catch (entryError) {
                    console.error('Error processing log entry:', entryError, entry);
                    // Continue with other entries
                }
            });
            
            researchLog.appendChild(fragment);
            
            // Scroll to the bottom
            researchLog.scrollTop = researchLog.scrollHeight;
        } catch (error) {
            console.error('Error rendering log entries:', error);
            researchLog.innerHTML = '<div class="error-message">Error rendering log entries. Please try again later.</div>';
        }
    }
    
    // Function to update detail log with a new entry
    function updateDetailLogEntry(logEntry) {
        if (!logEntry || !document.getElementById('research-details').classList.contains('active')) {
            return;
        }
        
        const researchLog = document.getElementById('research-log');
        const template = document.getElementById('log-entry-template');
        const clone = document.importNode(template.content, true);
        
        // Format the timestamp
        const time = new Date(logEntry.time);
        clone.querySelector('.log-entry-time').textContent = time.toLocaleTimeString();
        
        // Add message with phase highlighting if available
        const messageEl = clone.querySelector('.log-entry-message');
        let phaseClass = '';
        if (logEntry.metadata && logEntry.metadata.phase) {
            phaseClass = `phase-${logEntry.metadata.phase}`;
        }
        messageEl.textContent = logEntry.message;
        messageEl.classList.add(phaseClass);
        
        // Add progress information if available
        const progressEl = clone.querySelector('.log-entry-progress');
        if (logEntry.progress !== null && logEntry.progress !== undefined) {
            progressEl.textContent = `Progress: ${logEntry.progress}%`;
            
            // Also update the progress bar in the details view
            document.getElementById('detail-progress-fill').style.width = `${logEntry.progress}%`;
            document.getElementById('detail-progress-percentage').textContent = `${logEntry.progress}%`;
        } else {
            progressEl.textContent = '';
        }
        
        researchLog.appendChild(clone);
        
        // Scroll to the bottom
        researchLog.scrollTop = researchLog.scrollHeight;
    }
    
    // Back to history button handlers
    document.getElementById('back-to-history').addEventListener('click', () => {
        const historyNav = Array.from(navItems).find(item => item.getAttribute('data-page') === 'history');
        historyNav.click();
    });
    
    document.getElementById('back-to-history-from-details').addEventListener('click', () => {
        const historyNav = Array.from(navItems).find(item => item.getAttribute('data-page') === 'history');
        historyNav.click();
    });
    
    // Helper functions
    function capitalizeFirstLetter(string) {
        return string.charAt(0).toUpperCase() + string.slice(1);
    }
    
    function formatDate(date) {
        // Ensure we're handling the date properly
        if (!(date instanceof Date) || isNaN(date)) {
            console.warn('Invalid date provided to formatDate:', date);
            return 'Invalid date';
        }
        
        // Get current year to compare with date year
        const currentYear = new Date().getFullYear();
        const dateYear = date.getFullYear();
        
        // Get month name, day, and time
        const month = date.toLocaleString('en-US', { month: 'short' });
        const day = date.getDate();
        const hours = date.getHours().toString().padStart(2, '0');
        const minutes = date.getMinutes().toString().padStart(2, '0');
        
        // Format like "Feb 25, 08:09" or "Feb 25, 2022, 08:09" if not current year
        if (dateYear === currentYear) {
            return `${month} ${day}, ${hours}:${minutes}`;
        } else {
            return `${month} ${day}, ${dateYear}, ${hours}:${minutes}`;
        }
    }
    
    // Check for active research on page load
    (async function checkActiveResearch() {
        try {
            const response = await fetch('/api/history');
            const history = await response.json();
            
            // Find in-progress research
            const activeResearch = history.find(item => item.status === 'in_progress');
            
            if (activeResearch) {
                isResearchInProgress = true;
                currentResearchId = activeResearch.id;
                window.currentResearchId = currentResearchId;
                
                // Check if we're on the new research page and redirect to progress
                const currentPage = Array.from(pages).find(page => page.classList.contains('active'));
                
                if (currentPage && currentPage.id === 'new-research') {
                    // Navigate to progress page
                    switchPage('research-progress');
                    
                    // Connect to socket for this research
                    connectToResearchSocket(currentResearchId);
                    
                    // Start polling for updates
                    pollResearchStatus(currentResearchId);
                }
            }
        } catch (error) {
            console.error('Error checking for active research:', error);
        }
    })();

    // Function to update progress UI from current research
    function updateProgressFromCurrentResearch() {
        if (!isResearchInProgress || !currentResearchId) return;
        
        // Fetch current status
        fetch(`/api/research/${currentResearchId}`)
        .then(response => response.json())
        .then(data => {
            document.getElementById('current-query').textContent = data.query || '';
            document.getElementById('progress-fill').style.width = `${data.progress || 0}%`;
            document.getElementById('progress-percentage').textContent = `${data.progress || 0}%`;
            
            // Connect to socket for this research
            connectToResearchSocket(currentResearchId);
        })
        .catch(error => {
            console.error('Error fetching research status:', error);
        });
    }

    // Function to update the sidebar navigation based on research status
    function updateNavigationBasedOnResearchStatus() {
        const newResearchNav = Array.from(navItems).find(item => 
            item.getAttribute('data-page') === 'new-research' || 
            (item.getAttribute('data-original-page') === 'new-research' && 
             item.getAttribute('data-page') === 'research-progress')
        );
        
        if (newResearchNav) {
            if (isResearchInProgress) {
                // Change text to "Research in Progress"
                newResearchNav.innerHTML = '<i class="fas fa-spinner fa-spin"></i> Research in Progress';
                
                // Also update the listener to navigate to progress page
                if (newResearchNav.getAttribute('data-page') !== 'research-progress') {
                    newResearchNav.setAttribute('data-original-page', 'new-research');
                    newResearchNav.setAttribute('data-page', 'research-progress');
                }
                
                // If on new-research page, redirect to research-progress
                if (document.getElementById('new-research').classList.contains('active')) {
                    pages.forEach(page => page.classList.remove('active'));
                    document.getElementById('research-progress').classList.add('active');
                    
                    // Update the research progress page
                    updateProgressFromCurrentResearch();
                }
            } else {
                // Reset to "New Research" if there's no active research
                newResearchNav.innerHTML = '<i class="fas fa-search"></i> New Research';
                
                // Reset the listener
                if (newResearchNav.hasAttribute('data-original-page')) {
                    newResearchNav.setAttribute('data-page', newResearchNav.getAttribute('data-original-page'));
                    newResearchNav.removeAttribute('data-original-page');
                }
                
                // If the terminate button is visible, hide it
                const terminateBtn = document.getElementById('terminate-research-btn');
                if (terminateBtn) {
                    terminateBtn.style.display = 'none';
                    terminateBtn.disabled = false;
                    terminateBtn.innerHTML = '<i class="fas fa-stop-circle"></i> Terminate Research';
                }
            }
            
            // Make sure the navigation highlights the correct item
            navItems.forEach(item => {
                if (item === newResearchNav) {
                    if (isResearchInProgress) {
                        if (document.getElementById('research-progress').classList.contains('active')) {
                            item.classList.add('active');
                        }
                    } else if (document.getElementById('new-research').classList.contains('active')) {
                        item.classList.add('active');
                    }
                }
            });
        }
    }

    // Function to update the research progress page from nav click
    function updateProgressPage() {
        if (!isResearchInProgress || !currentResearchId) {
            return;
        }
        
        // Update the progress page
        fetch(`/api/research/${currentResearchId}`)
            .then(response => response.json())
            .then(data => {
                // Update the query display
                document.getElementById('current-query').textContent = data.query;
                
                // Update the progress bar
                updateProgressUI(data.progress || 0, data.status);
                
                // Connect to socket for live updates
                connectToResearchSocket(currentResearchId);
                
                // Check if we need to show the terminate button
                if (data.status === 'in_progress') {
                    const terminateBtn = document.getElementById('terminate-research-btn');
                    if (terminateBtn) {
                        terminateBtn.style.display = 'inline-flex';
                        terminateBtn.disabled = false;
                    }
                }
            })
            .catch(error => {
                console.error('Error fetching research status:', error);
            });
    }

    // Function to update a specific history item without reloading the whole list
    function updateHistoryItemStatus(researchId, status, statusText) {
        const historyList = document.getElementById('history-list');
        
        // Look for the item in the active research banner
        const activeBanner = historyList.querySelector(`.active-research-banner[data-research-id="${researchId}"]`);
        if (activeBanner) {
            const statusEl = activeBanner.querySelector('.history-item-status');
            if (statusEl) {
                statusEl.textContent = statusText || capitalizeFirstLetter(status);
                statusEl.className = 'history-item-status';
                statusEl.classList.add(`status-${status}`);
            }
            
            // Update buttons
            const terminateBtn = activeBanner.querySelector('.terminate-btn');
            if (terminateBtn) {
                terminateBtn.style.display = 'none';
            }
            
            const viewProgressBtn = activeBanner.querySelector('.view-progress-btn');
            if (viewProgressBtn) {
                if (status === 'suspended') {
                    viewProgressBtn.innerHTML = '<i class="fas fa-pause-circle"></i> Suspended';
                } else if (status === 'failed') {
                    viewProgressBtn.innerHTML = '<i class="fas fa-exclamation-triangle"></i> Failed';
                }
                viewProgressBtn.disabled = true;
            }
            
            return;
        }
        
        // Look for the item in the regular list
        const historyItem = historyList.querySelector(`.history-item[data-research-id="${researchId}"]`);
        if (historyItem) {
            const statusEl = historyItem.querySelector('.history-item-status');
            if (statusEl) {
                statusEl.textContent = statusText || capitalizeFirstLetter(status);
                statusEl.className = 'history-item-status';
                statusEl.classList.add(`status-${status}`);
            }
            
            // Update view button
            const viewBtn = historyItem.querySelector('.view-btn');
            if (viewBtn) {
                if (status === 'suspended') {
                    viewBtn.innerHTML = '<i class="fas fa-pause-circle"></i> Suspended';
                    viewBtn.disabled = true;
                } else if (status === 'failed') {
                    viewBtn.innerHTML = '<i class="fas fa-exclamation-triangle"></i> Failed';
                    viewBtn.disabled = true;
                }
            }
        }
    }

    // PDF Generation Functions
    function generatePdf() {
        const resultsContent = document.getElementById('results-content');
        const query = document.getElementById('result-query').textContent;
        const date = document.getElementById('result-date').textContent;
        const mode = document.getElementById('result-mode').textContent;
        
        // Show loading indicator
        const loadingIndicator = document.createElement('div');
        loadingIndicator.className = 'loading-spinner centered';
        loadingIndicator.innerHTML = '<div class="spinner"></div><p style="margin-top: 10px;">Generating PDF...</p>';
        resultsContent.parentNode.insertBefore(loadingIndicator, resultsContent);
        resultsContent.style.display = 'none';
        
        // Create a clone of the content for PDF generation
        const contentClone = resultsContent.cloneNode(true);
        contentClone.style.display = 'block';
        contentClone.style.position = 'absolute';
        contentClone.style.left = '-9999px';
        contentClone.style.width = '800px';
        
        // Apply PDF-specific styling for better readability
        contentClone.style.background = '#ffffff';
        contentClone.style.color = '#333333';
        contentClone.style.padding = '20px';
        
        // Improve visibility by adjusting styles specifically for PDF
        const applyPdfStyles = (element) => {
            // Set all text to dark color for better readability on white background
            element.querySelectorAll('*').forEach(el => {
                // Skip elements that already have inline color styles
                if (!el.style.color) {
                    el.style.color = '#333333';
                }
                
                // Fix background colors
                if (el.style.backgroundColor && 
                    (el.style.backgroundColor.includes('var(--bg') || 
                     el.style.backgroundColor.includes('#121212') ||
                     el.style.backgroundColor.includes('#1e1e2d') ||
                     el.style.backgroundColor.includes('#2a2a3a'))) {
                    el.style.backgroundColor = '#f8f8f8';
                }
                
                // Handle code blocks specifically
                if (el.tagName === 'PRE' || el.tagName === 'CODE') {
                    el.style.backgroundColor = '#f5f5f5';
                    el.style.border = '1px solid #e0e0e0';
                    el.style.color = '#333333';
                }
                
                // Make links visible
                if (el.tagName === 'A') {
                    el.style.color = '#0066cc';
                    el.style.textDecoration = 'underline';
                }
            });
            
            // Fix specific syntax highlighting elements for PDF
            element.querySelectorAll('.hljs').forEach(hljs => {
                hljs.style.backgroundColor = '#f8f8f8';
                hljs.style.color = '#333333';
                
                // Fix common syntax highlighting colors for PDF
                hljs.querySelectorAll('.hljs-keyword').forEach(el => el.style.color = '#0000cc');
                hljs.querySelectorAll('.hljs-string').forEach(el => el.style.color = '#008800');
                hljs.querySelectorAll('.hljs-number').forEach(el => el.style.color = '#aa0000');
                hljs.querySelectorAll('.hljs-comment').forEach(el => el.style.color = '#888888');
                hljs.querySelectorAll('.hljs-function').forEach(el => el.style.color = '#880000');
            });
        };
        
        document.body.appendChild(contentClone);
        
        // Apply PDF-specific styles
        applyPdfStyles(contentClone);
        
        // Add title and metadata to the PDF content
        const headerDiv = document.createElement('div');
        headerDiv.innerHTML = `
            <h1 style="color: #6e4ff6; font-size: 24px; margin-bottom: 10px;">${query}</h1>
            <div style="margin-bottom: 20px; font-size: 14px; color: #666;">
                <p><strong>Generated:</strong> ${date}</p>
                <p><strong>Mode:</strong> ${mode}</p>
                <p><strong>Source:</strong> Deep Research Lab</p>
            </div>
            <hr style="margin-bottom: 20px; border: 1px solid #eee;">
        `;
        contentClone.insertBefore(headerDiv, contentClone.firstChild);
        
        setTimeout(() => {
            try {
                // Use window.jspdf which is from the UMD bundle
                const { jsPDF } = window.jspdf;
                const pdf = new jsPDF('p', 'pt', 'a4');
                const pdfWidth = pdf.internal.pageSize.getWidth();
                const pdfHeight = pdf.internal.pageSize.getHeight();
                const margin = 40;
                const contentWidth = pdfWidth - 2 * margin;
                
                // Create a more efficient PDF generation approach that keeps text selectable
                const generateTextBasedPDF = async () => {
                    try {
                        // Get all text elements and handle them differently than images and special content
                        // Use html2canvas only for complex elements that can't be easily converted to text
                        const elements = Array.from(contentClone.children);
                        let currentY = margin;
                        let pageNum = 1;
                        
                        // Function to add a page with header
                        const addPageWithHeader = (pageNum) => {
                            if (pageNum > 1) {
                                pdf.addPage();
                            }
                            pdf.setFontSize(8);
                            pdf.setTextColor(100, 100, 100);
                            pdf.text(`Deep Research - ${query} - Page ${pageNum}`, margin, pdfHeight - 20);
                        };
                        
                        addPageWithHeader(pageNum);
                        
                        // Process each element - for better quality combine text-based approach with canvas
                        for (const element of elements) {
                            // Simple text content can be handled directly by jsPDF
                            if (element.tagName === 'P' && !element.querySelector('img, canvas, svg, code, pre')) {
                                // Extract and add text content directly
                                pdf.setFontSize(11);
                                pdf.setTextColor(0, 0, 0);
                                
                                const text = element.textContent.trim();
                                const textLines = pdf.splitTextToSize(text, contentWidth);
                                
                                // Check if we need a new page
                                if (currentY + (textLines.length * 14) > pdfHeight - margin) {
                                    pageNum++;
                                    addPageWithHeader(pageNum);
                                    currentY = margin;
                                }
                                
                                pdf.text(textLines, margin, currentY + 12);
                                currentY += (textLines.length * 14) + 10;
                            } 
                            // Handle headings differently to maintain hierarchy
                            else if (['H1', 'H2', 'H3', 'H4', 'H5', 'H6'].includes(element.tagName)) {
                                // Extract and add heading text directly
                                const fontSize = {
                                    'H1': 24,
                                    'H2': 20,
                                    'H3': 16,
                                    'H4': 14,
                                    'H5': 12,
                                    'H6': 11
                                }[element.tagName];
                                
                                pdf.setFontSize(fontSize);
                                pdf.setTextColor(0, 0, 0);
                                
                                const text = element.textContent.trim();
                                const textLines = pdf.splitTextToSize(text, contentWidth);
                                
                                // Check if we need a new page
                                if (currentY + (textLines.length * (fontSize + 4)) > pdfHeight - margin) {
                                    pageNum++;
                                    addPageWithHeader(pageNum);
                                    currentY = margin;
                                }
                                
                                pdf.text(textLines, margin, currentY + fontSize);
                                currentY += (textLines.length * (fontSize + 4)) + 10;
                            }
                            // For complex elements like code, tables, images etc. use html2canvas
                            else {
                                const canvas = await html2canvas(element, {
                                    scale: 2, // Higher scale for better quality
                                    useCORS: true,
                                    logging: false,
                                    backgroundColor: '#FFFFFF'
                                });
                                
                                const imgData = canvas.toDataURL('image/png');
                                const imgHeight = (canvas.height * contentWidth) / canvas.width;
                                
                                // Check if we need a new page
                                if (currentY + imgHeight > pdfHeight - margin) {
                                    pageNum++;
                                    addPageWithHeader(pageNum);
                                    currentY = margin;
                                }
                                
                                // Add image to PDF
                                pdf.addImage(imgData, 'PNG', margin, currentY, contentWidth, imgHeight);
                                currentY += imgHeight + 10;
                            }
                        }
                        
                        // Download the PDF
                        const filename = `${query.replace(/[^a-z0-9]/gi, '_').substring(0, 30).toLowerCase()}_research.pdf`;
                        pdf.save(filename);
                        
                        // Clean up
                        document.body.removeChild(contentClone);
                        resultsContent.style.display = 'block';
                        loadingIndicator.remove();
                    } catch (error) {
                        console.error('Error generating PDF:', error);
                        alert('An error occurred while generating the PDF. Please try again.');
                        document.body.removeChild(contentClone);
                        resultsContent.style.display = 'block';
                        loadingIndicator.remove();
                    }
                };
                
                generateTextBasedPDF();
            } catch (error) {
                console.error('Error initializing PDF generation:', error);
                alert('An error occurred while preparing the PDF. Please try again.');
                document.body.removeChild(contentClone);
                resultsContent.style.display = 'block';
                loadingIndicator.remove();
            }
        }, 100);
    }
    
    // Function to generate PDF from a specific research ID
    async function generatePdfFromResearch(researchId) {
        try {
            // Load research details
            const detailsResponse = await fetch(`/api/research/${researchId}`);
            const details = await detailsResponse.json();
            
            // Load the report content
            const reportResponse = await fetch(`/api/report/${researchId}`);
            const reportData = await reportResponse.json();
            
            if (reportData.status === 'success') {
                // Create a temporary container to render the content
                const tempContainer = document.createElement('div');
                tempContainer.className = 'results-content pdf-optimized';
                tempContainer.style.display = 'none';
                document.body.appendChild(tempContainer);
                
                // Render markdown with optimized styles for PDF
                const renderedContent = marked.parse(reportData.content);
                tempContainer.innerHTML = renderedContent;
                
                // Apply syntax highlighting
                tempContainer.querySelectorAll('pre code').forEach((block) => {
                    hljs.highlightElement(block);
                });
                
                // Format date
                let dateText = formatDate(new Date(details.completed_at || details.created_at));
                if (details.duration_seconds) {
                    let durationText = '';
                    const duration = parseInt(details.duration_seconds);
                    
                    if (duration < 60) {
                        durationText = `${duration}s`;
                    } else if (duration < 3600) {
                        durationText = `${Math.floor(duration / 60)}m ${duration % 60}s`;
                    } else {
                        durationText = `${Math.floor(duration / 3600)}h ${Math.floor((duration % 3600) / 60)}m`;
                    }
                    
                    dateText += ` (Duration: ${durationText})`;
                }
                
                // Set up data for PDF generation
                document.getElementById('result-query').textContent = details.query;
                document.getElementById('result-date').textContent = dateText;
                document.getElementById('result-mode').textContent = details.mode === 'quick' ? 'Quick Summary' : 'Detailed Report';
                
                // Replace the current content with our temporary content
                const resultsContent = document.getElementById('results-content');
                const originalContent = resultsContent.innerHTML;
                resultsContent.innerHTML = tempContainer.innerHTML;
                
                // Generate the PDF
                generatePdf();
                
                // Restore original content if we're not on the results page
                setTimeout(() => {
                    if (!document.getElementById('research-results').classList.contains('active')) {
                        resultsC