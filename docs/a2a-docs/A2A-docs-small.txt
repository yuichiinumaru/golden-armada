A2A Documentation for AI Coder Agents
1. Introduction to A2A (Agent-to-Agent)
1.1. What is A2A?
A2A (Agent-to-Agent) is a protocol and a set of standards designed to enable Large Language Models (LLMs) and the AI agents built upon them to communicate and interact in a standardized way. The goal is to create an ecosystem where different agents, possibly developed by different organizations and using different LLMs, can discover each other's capabilities and invoke those capabilities (or "skills").
The A2A specification aims to facilitate interoperability between AI agents, allowing them to collaborate on complex tasks that a single agent might not be able to perform alone. It leverages standard web technologies like HTTP and JSON, and draws inspiration from RESTful API concepts and the OpenAPI specification for describing agent capabilities.
1.2. Why use A2A? Benefits
* Interoperability: Allows agents from different developers and platforms to work together seamlessly.
* Capability Discovery: Agents can advertise their skills and discover the skills of other agents dynamically via an "Agent Card."
* Skill Composition: Agents can chain skills from multiple agents to solve more complex problems, acting as building blocks.
* Standardization: Provides a common way for agent-to-agent interactions, reducing the need for custom integrations for each pair of agents and fostering a more cohesive ecosystem.
* Extensibility: Facilitates the addition of new skills and agents to the ecosystem without disrupting existing interactions.
* Tooling Focus: The specification is designed to be easily understood and used by LLMs so they can autonomously decide when and how to use other agents' skills.
1.3. Use Cases for Coder Agents
For AI Coder Agents (agents focused on software development tasks), A2A can enable:
* Task Delegation: A coder agent can delegate specific tasks (e.g., static code analysis, unit test execution, code optimization, code translation between languages, cloud infrastructure provisioning) to other specialized agents.
* Access to Tools and APIs: Interact with agents that expose development tools (e.g., compilers, debuggers, linters), third-party service APIs (e.g., GitHub, JIRA, SonarQube), or access to specific knowledge bases (e.g., framework documentation, Stack Overflow).
* Workflow Orchestration: A coder agent can act as an orchestrator, coordinating multiple agents to complete a development cycle (e.g., from creating a feature branch, through implementation, testing, to a merge request) or a CI/CD task.
* Knowledge Base Queries: Obtain information from agents that maintain and expose up-to-date technical documentation, coding best practices, reusable code snippets, or solutions to common programming problems.
* Real-time Collaboration: Multiple coder agents could collaborate on the same codebase, with an A2A agent coordinating interactions and preventing conflicts.
1.4. Supported LLMs (Context)
A2A is designed to be LLM-agnostic. Agents using the following LLMs (among others) can participate in A2A interactions:
* Gemini
* GPT (all versions)
* Claude
* Llama
* And other models capable of interacting with APIs and processing JSON.
2. Key A2A Concepts
Understanding these terms is fundamental to working with A2A:
* Agent: An LLM-powered application that can perform tasks or provide information through Skills. It is the entity that exposes (Skill Provider) and/or consumes (Skill Consumer) skills.
* Agent Host: The server or runtime environment that hosts the Agent and exposes its skills via the A2A API. It is responsible for receiving requests, forwarding them to the agent's logic, and returning responses.
* Agent Card: A manifest file in JSON format (usually ai-plugin.json or a2a-manifest.json served at /.well-known/a2a) that describes the Agent, its capabilities (skills), how to invoke them (by referencing an OpenAPI specification), authentication information, and other metadata. It is the primary mechanism for agent discovery.
* Skill: A specific capability or functionality that an Agent can perform. Each skill is defined in the Agent Card (indirectly via the OpenAPI specification) and can be invoked by other agents. A skill corresponds to an operation in an API.
* Agent Executor: A component (usually on the consumer side) that understands how to find agents, interpret their cards, construct skill invocation requests, and process responses. LLMs can act as the "brain" of an Agent Executor.
* Intent: The description of what the user or another agent wants to achieve. While A2A focuses on direct invocation of named skills, the concept of intent is used by the calling agent's LLM to select the appropriate skill and arguments.
* Invocation: The act of requesting an Agent to execute one of its Skills. This is done by sending a formatted HTTP request (usually POST) to the skill's endpoint on the Agent Host.
* Response: The result returned by an Agent after executing a Skill. The response can be synchronous, asynchronous (with polling), or streamed in parts.
* Session: A context for multi-turn interactions (multiple message exchanges) between agents, allowing them to maintain state (conversation history, temporary data) and continuity of the interaction. Usually managed via a session_id.
3. A2A Protocol Specification
This section details the technical aspects of the A2A protocol.
3.1. Architecture Overview
A typical A2A system involves:
1. Calling Agent (Consumer): The agent that wants to use a skill from another agent.
2. Calling Agent Host: Where the Calling Agent is hosted.
3. Skill Agent (Provider): The agent that exposes the skill.
4. Skill Agent Host: Where the Skill Agent is hosted and where the A2A API is implemented, including the Agent Card discovery endpoint and the skill endpoints.
The basic flow is:
1. Discovery: The Calling Agent discovers the Skill Agent and its capabilities by reading its Agent Card and the referenced OpenAPI specification.
2. Skill Selection: The Calling Agent's LLM determines which skill to invoke and with what arguments.
3. Request: The Calling Agent sends an HTTP Invocation Request to the skill's endpoint on the Skill Agent Host, as specified in the Skill Agent's OpenAPI.
4. Processing: The Skill Agent Host receives the request, authenticates (if necessary), validates arguments, and executes the skill logic.
5. Response: The Skill Agent Host returns an HTTP Response (synchronous, start of streaming, or acknowledgment for asynchronous) to the Calling Agent.
3.2. API Endpoints
3.2.1. Agent Discovery (Agent Card)
Agent Hosts must expose their Agent Card at a well-known location to facilitate discovery. Two patterns are common:
* Pattern 1 (OpenAI Plugin Style):
   * URL: https://<agent-host>/.well-known/ai-plugin.json
   * Method: GET
   * Response: The Agent Card in ai-plugin.json format.
* Pattern 2 (A2A Specific):
   * URL: https://<agent-host>/.well-known/a2a
   * Method: GET
   * Response: A JSON containing the A2A Agent Card (which might be the ai-plugin.json itself or a similar structure).
Example Agent Card (ai-plugin.json):
{
 "schema_version": "a2a_v1",
 "name_for_human": "My Example Code Agent",
 "name_for_model": "myExampleCodeAgent",
 "description_for_human": "This agent helps with Python code refactoring and analysis tasks.",
 "description_for_model": "Agent that can perform 'refactorPythonCode' and 'analyzeComplexity' skills. Use 'refactorPythonCode' to apply refactoring patterns to a Python code snippet. Arguments: 'code' (string), 'refactoring_pattern' (string). Use 'analyzeComplexity' to calculate cyclomatic complexity of a Python function. Arguments: 'function_code' (string).",
 "auth": {
   "type": "none"
 },
 "api": {
   "type": "openapi",
   "url": "[https://example.com/openapi.yaml](https://example.com/openapi.yaml)",
   "is_user_authenticated": false
 },
 "logo_url": "[https://example.com/logo.png](https://example.com/logo.png)",
 "contact_email": "dev-support@example.com",
 "legal_info_url": "[https://example.com/legal](https://example.com/legal)"
}

The description_for_model is crucial as it's used by the calling agent's LLM to understand how to use the skills. It should be clear, concise, and include skill names and their main arguments.
3.2.2. Skill Invocation
Endpoints for invoking skills are defined in the OpenAPI specification referenced in the Agent Card. Each skill corresponds to an OpenAPI operation.
* URL: As defined in the openapi.yaml file (e.g., /mySkill, /otherSkill/{path_param})
* Method: POST is common, but other HTTP methods (GET, PUT, DELETE) are allowed.
* Request Body: Usually JSON, with the argument structure defined in the OpenAPI operation's request schema.
* Response: Usually JSON, with the result structure defined in the OpenAPI operation's response schema.
The A2A specification also mentions a generic /invoke endpoint as an alternative, mainly if the agent doesn't expose individual OpenAPI paths for each skill.
3.3. Message Formats (JSON) - If using a generic /invoke endpoint
If a generic endpoint like /invoke is used, the formats below are relevant.
3.3.1. Invocation Request (InvocationRequest) for /invoke
{
 "skill_name": "skillName",
 "arguments": {
   "param1": "value1",
   "param2": 123
 },
 "session_id": "optionalSessionId123",
 "response_type": "sync",
 "user_context": {
   "user_id": "user_abc",
   "locale": "en_US"
 }
}

* skill_name (string, required): The name of the skill.
* arguments (object, optional): Skill arguments.
* session_id (string, optional): For multi-turn conversations.
* response_type (string, optional, default: "sync"): sync, async_poll, or streaming.
* user_context (object, optional): Contextual information.
3.3.2. Invocation Response (InvocationResponse) for /invoke
For synchronous responses (response_type: "sync"):
{
 "status": "success",
 "result": {
   "data": "Skill result here"
 },
 "error": null,
 "session_id": "optionalSessionId123"
}

For asynchronous responses (response_type: "async_poll" - initial response):
{
 "status": "pending",
 "task_id": "uniqueTask789",
 "poll_url": "[https://example.com/tasks/uniqueTask789/status](https://example.com/tasks/uniqueTask789/status)",
 "estimated_completion_time_seconds": 60,
 "session_id": "optionalSessionId123"
}

For error responses (synchronous or after polling):
{
 "status": "error",
 "result": null,
 "error": {
   "code": "SkillExecutionError",
   "message": "Detailed error description.",
   "details": {}
 },
 "session_id": "optionalSessionId123"
}

For streaming responses (response_type: "streaming"):
The HTTP connection remains open, and the server sends a series of StreamingChunks (NDJSON).
StreamingChunk:
{
 "type": "content_delta",
 "delta": "Incremental part of the content...",
 "sequence_id": 1,
 "is_last_chunk": false
}

StreamingChunk types: content_delta, tool_code (with tool_name, tool_input), tool_response (with tool_name, tool_output), final_response (with result), error_chunk (with error).
3.4. Error Handling
* HTTP Status Codes: Use standard HTTP codes (400, 401, 403, 404, 429, 500).
* Error Response Body: For 4xx/5xx errors, the response body should be a JSON InvocationResponse (or similar) with status: "error" and a detailed error object.
* Standardized Error Codes (in error.code object):
   * SkillUnavailable: Requested skill is not available or does not exist.
   * SkillExecutionError: Generic error during skill execution.
   * AuthError: Authentication or authorization failure.
   * InvalidArguments: Provided arguments are invalid, missing, or malformed.
   * RateLimitExceeded: Caller has exceeded the rate limit.
   * ServerError: An unexpected error occurred on the agent's server.
   * PollTimeout: (For async_poll) Polling time exceeded the limit without a final response.
* Idempotency: For state-modifying operations, consider supporting idempotency keys (e.g., Idempotency-Key header).
3.5. Authentication and Authorization
As specified in the Agent Card's auth field (none, oauth, user_http, service_http). The caller is responsible for including credentials (e.g., Authorization: Bearer <token> header).
3.6. Structured Data Exchange and JSON-RPC
A2A is fundamentally designed for structured data exchange to ensure clarity and interoperability between agents. All interactions, including skill arguments and results, are formatted as JSON messages.
* JSON Payloads: Whether using direct OpenAPI-defined endpoints or a generic /invoke endpoint, the arguments sent to a skill and the results returned are encapsulated in JSON. This allows for rich, structured data, including text, numbers, booleans, arrays, and nested objects.
   * Example Request Snippet (Conceptual for a skill):
{
 "code_snippet": "def hello():\n  print('Hello, A2A!')",
 "target_language": "javascript",
 "options": {
   "optimization_level": "high"
 }
}

   * Example Response Snippet (Conceptual for a skill):
{
 "status": "success",
 "translated_code": "function hello() {\n  console.log('Hello, A2A!');\n}",
 "confidence_score": 0.95,
 "warnings": []
}

   * JSON-RPC 2.0 over HTTP(S): Some A2A implementations or profiles may leverage JSON-RPC 2.0 for structuring requests and responses over HTTP(S). JSON-RPC provides a lightweight remote procedure call protocol using JSON.
   * A JSON-RPC request would typically include jsonrpc: "2.0", method (the skill name), params (the arguments, either as an array or object), and an id.
   * A JSON-RPC response would include jsonrpc: "2.0", result (the skill's output) or error (an error object), and the id from the request.
   * This approach further standardizes the message envelope for skill invocations.
   * Importance for LLMs: Clearly structured JSON inputs and outputs are vital for LLMs, as they can more reliably parse, interpret, and generate such data compared to unstructured text. This is key for enabling LLMs to effectively use agent skills. Best practices for skill design (see Section 6.5) emphasize defining clear schemas for these JSON structures, often using OpenAPI.
   * Comparison with ADK (Agent Development Kit): While frameworks like Google's ADK might use "function tools" that internally return Python dictionaries or Java maps, when these agents communicate externally via A2A, this structured data is serialized into JSON messages as per the A2A protocol. The A2A protocol itself focuses on the standardized JSON exchange format between agents, regardless of their internal implementation.
This standardized approach to structured data ensures that agents built on different platforms and with different internal representations can still communicate effectively and reliably.
4. Agent Interaction
4.1. Agent Discovery
   1. Well-Known Discovery Point: https://<agent-host>/.well-known/ai-plugin.json or .../.well-known/a2a.
   2. Card Retrieval and Parsing: GET to obtain the Agent Card (JSON).
   3. OpenAPI Retrieval and Parsing: Use the api.url from the card to get the OpenAPI specification, which details the skills.
4.2. Defining Skills and Agent Cards (Skill Provider Side)
   1. Identify Capabilities.
   2. Design the API (OpenAPI): Define operations, paths, methods, parameters (requestBody, query, path), and responses (schemas). operationId is the skill name.
   3. Implement Skill Logic.
   4. Create Agent Card (ai-plugin.json): Fill in metadata, auth, and api.url pointing to the OpenAPI.
   5. Expose Agent Card and OpenAPI.
   6. Implement Skill Endpoints.
4.3. Executing Skills (Skill Caller Side)
   1. Select Agent and Skill (using LLM, Card, and OpenAPI).
   2. Construct HTTP Request: As per OpenAPI (URL, method, body, headers).
   3. Send Request.
   4. Process HTTP Response (synchronous, streaming, or initiate polling for asynchronous).
4.4. Communication
4.4.1. Requests and Responses
Primarily HTTP with JSON bodies, following OpenAPI.
4.4.2. Streaming and Asynchronicity
   * Streaming: 2xx response with Content-Type: application/x-ndjson. Client reads NDJSON StreamingChunks.
   * Asynchronous with Polling (async_poll): Initial 202 Accepted response with task_id, poll_url. Client GETs poll_url.
   * Multi-Turn Conversations (Sessions): Use session_id in requests and responses to maintain context.
5. Developing A2A Agents with Python SDK (Google)
The google-a2a-sdk focuses on hosting A2A agents.
5.1. Python SDK Overview (for A2A Servers)
   * Agent definition (Agent) and Skills (@agent.skill).
   * Automatic generation of ai-plugin.json and openapi.json.
   * Web server (FastAPI).
   * Validation with Pydantic.
5.2. Environment Setup (Python)
pip install google-a2a-sdk # or similar name

Dependencies: Python 3.8+, FastAPI, Uvicorn.
5.3. Creating an Agent Server (Conceptual SDK Example)
import asyncio
from typing import AsyncGenerator
from pydantic import BaseModel, Field
from google_a2a_sdk import Agent, Settings # Hypothetical names

settings = Settings(port=8080, host="0.0.0.0")
agent = Agent(
   settings=settings,
   name_for_human="Advanced Code Agent",
   name_for_model="advancedCodeAgent",
   description_for_human="Agent with Python code analysis and generation skills.",
   description_for_model="""... Skills: 'analyze_code_complexity', 'generate_python_docstring', ...""",
   logo_url="[https://example.com/logo.png](https://example.com/logo.png)", # Use real or valid placeholder URLs
   contact_email="dev@example.com",
   legal_info_url="[https://example.com/legal](https://example.com/legal)",
   auth_type="none"
)

class AnalysisArgs(BaseModel):
   python_code: str = Field(..., description="The Python code to be analyzed.")

class AnalysisResult(BaseModel):
   complexity: int

@agent.skill(name="analyze_code_complexity", response_model=AnalysisResult)
def analyze_complexity(args: AnalysisArgs) -> AnalysisResult:
   # ... logic ...
   calculated_complexity = args.python_code.count("if ") + 1
   return AnalysisResult(complexity=calculated_complexity)

@agent.skill(name="progressive_count_stream")
async def progressive_count(args: dict) -> AsyncGenerator[str, None]: # args as dict if not using Pydantic model
   limit = int(args.get("limit", 5))
   for i in range(1, limit + 1):
       yield f"Counting: {i}"
       await asyncio.sleep(0.5)

if __name__ == "__main__":
   agent.run() # Or equivalent serve function

5.4. Interacting with an A2A Server (Python Client with httpx)
To call skills of an A2A agent (whether hosted with the SDK or not), a standard HTTP client like httpx is used, guided by the Agent Card and OpenAPI specification. The google-a2a-sdk primarily focuses on serving agents.
import httpx
import asyncio
import json

AGENT_BASE_URL = "http://localhost:8080" # URL of the A2A agent

async def get_openapi_url(agent_url: str) -> str | None:
   """Gets the OpenAPI specification URL from the Agent Card."""
   try:
       async with httpx.AsyncClient() as client:
           response = await client.get(f"{agent_url}/.well-known/ai-plugin.json")
           response.raise_for_status()
           plugin_json = response.json()
           return plugin_json.get("api", {}).get("url")
   except Exception as e:
       print(f"Error getting ai-plugin.json: {e}")
       return None

async def call_synchronous_skill(openapi_spec_url: str, base_url: str, skill_operation_id: str, arguments: dict):
   """
   Calls a synchronous skill.
   NOTE: This is a simplified example. A real client would need to parse OpenAPI
   to find the correct path, HTTP method, and how to format arguments.
   Here, we assume the skill_operation_id is part of the path and uses POST.
   """
   # In a real client, you'd parse openapi_spec_url to find the correct path and method.
   # For simplicity, let's assume the skill is exposed at /<skill_operation_id>
   skill_endpoint = f"{base_url}/{skill_operation_id}"
   print(f"Calling {skill_endpoint} with arguments: {arguments}")
   try:
       async with httpx.AsyncClient() as client:
           response = await client.post(skill_endpoint, json=arguments)
           response.raise_for_status() # Raises exception for HTTP 4xx/5xx errors
           print(f"Response from '{skill_operation_id}': {response.json()}")
           return response.json()
   except httpx.HTTPStatusError as e:
       print(f"HTTP error calling '{skill_operation_id}': {e.response.status_code} - {e.response.text}")
   except Exception as e:
       print(f"Error calling '{skill_operation_id}': {e}")

async def call_streaming_skill(base_url: str, skill_operation_id: str, arguments: dict):
   """Calls a skill that returns NDJSON streaming."""
   skill_endpoint = f"{base_url}/{skill_operation_id}" # Simplification
   print(f"Calling {skill_endpoint} (streaming) with arguments: {arguments}")
   try:
       async with httpx.AsyncClient() as client:
           async with client.stream("POST", skill_endpoint, json=arguments) as response:
               response.raise_for_status()
               print(f"Streaming response from '{skill_operation_id}':")
               async for line in response.aiter_lines():
                   if line:
                       try:
                           chunk = json.loads(line)
                           print(f"  Chunk: {chunk}")
                           # Process the chunk (e.g., chunk.get('delta') or chunk.get('content'))
                       except json.JSONDecodeError:
                           print(f"  Non-JSON line: {line}")
   except httpx.HTTPStatusError as e:
       print(f"HTTP error in streaming '{skill_operation_id}': {e.response.status_code} - {e.response.text}")
   except Exception as e:
       print(f"Error in streaming '{skill_operation_id}': {e}")


async def main_client_example():
   openapi_url = await get_openapi_url(AGENT_BASE_URL)
   if not openapi_url:
       print("Could not get OpenAPI URL. Exiting client.")
       return

   print(f"OpenAPI URL: {openapi_url}")
   # A robust client would download and parse openapi_url to guide calls.

   # Example synchronous call (assuming 'analyze_code_complexity' skill exists and is POST at /analyze_code_complexity)
   await call_synchronous_skill(
       openapi_spec_url=openapi_url,
       base_url=AGENT_BASE_URL,
       skill_operation_id="analyze_code_complexity", # operationId of the skill in OpenAPI
       arguments={"python_code": "def test(x):\n  if x > 10:\n    return True\n  return False"}
   )

   # Example streaming call (assuming 'progressive_count_stream' exists)
   await call_streaming_skill(
       base_url=AGENT_BASE_URL,
       skill_operation_id="progressive_count_stream",
       arguments={"limit": 3}
   )

if __name__ == "__main__":
   # To run the client, the agent server (section 5.3)
   # must be running in another process/terminal.
   # Example: asyncio.run(main_client_example())
   pass

6. Advanced Topics and Considerations
6.1. A2A and MCP (Multi-Party Computation)
A2A can coordinate interactions between agents that use MCP for secure computation over private data.
6.2. Enterprise Readiness
Consider: Robust security, observability (logging, tracing), scalability, reliability (retries, circuit breakers), governance (versioning, auditing).
6.3. Security
   * Input validation (use schemas).
   * Access control (AuthN/AuthZ).
   * Rate limiting.
   * HTTPS mandatory.
   * Secrets management.
   * Principle of least privilege.
   * Beware of LLM injection if arguments come from LLMs.
6.4. Next Steps and Community
Explore SDK tutorials, participate in A2A communities, and watch for partnerships in the ecosystem.
6.5. Best Practices for A2A Skill Design (for LLM consumption)
   * Clear and Concise Descriptions: The description for each skill (operation) in OpenAPI and the description_for_model in the Agent Card are crucial. They should explain:
   * What the skill does.
   * When to use it (typical use cases).
   * Key arguments and what they represent.
   * What the skill returns.
   * Intuitive Skill and Parameter Names: Use names (operationId for skills, parameter names) that are self-explanatory.
   * Simple and Structured Data Types: Prefer standard JSON data types (strings, numbers, booleans, arrays, objects). For complex data, define clear schemas.
   * Skill Granularity:
   * Avoid overly generic skills ("doEverything").
   * Create more atomic skills that can be composed by the calling LLM.
   * However, avoid excessively granular skills that require many calls for a simple task. Find a balance.
   * Informative Responses: Responses should contain all relevant data the calling LLM might need. For errors, provide clear messages and specific error codes.
   * Idempotency (where applicable): For skills that alter state, design them to be idempotent if possible, so retries are safe.
   * Examples (in OpenAPI): Including examples of requests and responses in the OpenAPI specification (examples or example keyword) can greatly help the LLM understand how to use the skill.
   * Consider LLM Context Limitations: If a skill can return a large amount of data, offer pagination or ways to filter/summarize the response.
7. Glossary
   * A2A (Agent-to-Agent): Protocol for communication between AI agents.
   * Agent: LLM-based application offering/consuming Skills.
   * Agent Card: JSON manifest (ai-plugin.json) describing an agent and its Skills.
   * Skill: Specific capability of an agent, mapped to an OpenAPI operation.
   * Agent Host: Server hosting an agent.
   * OpenAPI: Specification for describing RESTful APIs, used by A2A to detail Skills.
   * Invocation: Act of calling a Skill.
   * NDJSON (Newline Delimited JSON): Format for streaming multiple JSON objects.
   * LLM (Large Language Model): The "brain" of many agents.
This documentation aims to provide a solid and more complete foundation for AI Coder Agents to understand and interact within the A2A ecosystem. For more in-depth details and updates, always consult the official A2A specification and relevant SDK documentation.