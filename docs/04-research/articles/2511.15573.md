# Context Collapse in Role-Conditioned Agents

**Source:** [Two-Faced Social Agents: Context Collapse in Role-Conditioned Large Language Models](https://arxiv.org/html/2511.15573)

## Synthesis
This paper investigates the "Two-Faced" nature of LLMs when acting as role-conditioned agents (e.g., "Act as a low-SES student").
*   **The Phenomenon:** In low-stakes tasks (Preference reporting), agents maintain their persona (e.g., "I prefer safer investments"). However, in high-stakes cognitive tasks (SAT Math), they exhibit **Context Collapse**: they revert to their "optimal solver" identity, ignoring the persona's cognitive constraints (e.g., the low-SES agent solves complex calculus perfectly, unlike a real student with limited resources).
*   **Models Tested:** GPT-5 (Complete Collapse - 100% accuracy for all roles), Gemini 2.5 (Partial), Claude Sonnet 4.5 (Inverted - Low-SES agents outperformed High-SES ones, likely due to "safety" alignment over-correcting stereotypes).
*   **Implication:** Simulating diverse user bases for product testing or surveys using LLMs is flawed if the task involves reasoning. The agents will act as "super-users" regardless of the persona.

## Core Strategic Ideas
1.  **Cognitive Load as a filter:** If we want to detect if a user is an AI agent, give them a complex reasoning task. They will likely "break character" and solve it perfectly.
2.  **Persona Fragility:** We cannot rely on simple system prompts ("You are a Junior Dev") to limit an agent's capability. A "Junior Dev" agent might still refactor the entire kernel if the LLM finds it optimal.
3.  **Forced Constraints:** To truly simulate a "Junior Dev" or a specific user type, we must *externally* constrain the agent (e.g., limit the tools they can use, the files they can see, or the complexity of code they can output), rather than relying on the LLM to "roleplay" incompetence.

## Integration Plan (Agno + SurrealDB + Gemini 3)
For CodeSwarm, this is critical for our **"Junior/Senior" Agent roles**:

1.  **Hard Constraints vs. Soft Prompts:**
    *   Instead of just prompting `Role: Junior Developer`, we should implement **Tool-Level Constraints**.
    *   `JuniorDevAgent`: Can only edit files in `src/components`. Cannot touch `src/core`. Can only use `git_commit`, not `git_force_push`.
    *   `SeniorDevAgent`: Full access.

2.  **Simulation Testing:**
    *   When we run simulations (e.g., "How would a new user interact with this API?"), we must be aware of Context Collapse. The "New User" agent might instantly understand the complex API.
    *   **Mitigation:** Inject "Artificial Noise" or "Knowledge Gaps" into the agent's context. Explicitly *hide* documentation pages from the "New User" agent to force them to struggle.

3.  **SurrealDB Access Control:**
    *   Implement "Persona Views" in SurrealDB.
    *   A "Junior" persona query only returns "Basic" documentation.
    *   A "Senior" persona query returns "Advanced" architecture docs.
    *   This forces the agent to reason based *only* on what it "knows", preventing the "Omniscient Solver" problem.
