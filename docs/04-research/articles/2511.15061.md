# Arxiv Analysis: Beyond GeneGPT: A Multi-Agent Architecture with Open-Source LLMs (OpenBioLLM)

**ID:** 2511.15061
**Date:** 2025-11-18
**Link:** https://arxiv.org/html/2511.15061

## 1. Executive Summary
This paper introduces **OpenBioLLM**, a modular multi-agent framework for genomic question answering. It replaces the monolithic GeneGPT (which relied on deprecated OpenAI Codex) with a team of specialized open-source agents (Router, Evaluator, Generator, and Tool Agents). A key finding is that **smaller, specialized models (14B)** often outperform larger ones (32B/72B) for specific tool tasks because they are less prone to "reasoning shortcuts" (hallucinating answers instead of using tools).

## 2. Detailed Key Concepts

### 2.1. Modular Multi-Agent Architecture
The system is decomposed into:
-   **Pipeline Controllers:**
    -   **Router:** Classifies query and directs to the right tool agent.
    -   **Evaluator:** Checks if the retrieved information is sufficient. Outputs JSON: `{ "next_step": "...", "reason": "..." }`.
    -   **Generator:** Synthesizes the final answer citing sources.
-   **Tool Agents:**
    -   **Eutils Agent:** Specialized in NCBI E-utilities (fetching IDs, summaries).
    -   **BLAST Agent:** Handles sequence alignment (submission + polling).
    -   **Web Search Agent:** Fallback for general queries.

### 2.2. The "Small Model Advantage"
The authors found that a **32B Controller + 14B Tool Agents** configuration outperformed a full 32B/72B setup.
-   **Reason:** Larger models sometimes "skip" steps (e.g., guessing a gene location instead of querying the API) or try to solve multi-step problems in one go, leading to errors. Smaller models followed the rigid tool protocols more faithfully.

### 2.3. Evaluator Loop
The **Evaluator** explicitly acts as a gate. It reviews the Tool Agent's output. If incomplete, it routes back to the Router. This "Sufficiency Check" prevents premature answering.

## 3. Gap Analysis

| Feature/Concept | Current CodeSwarm | Gap |
| :--- | :--- | :--- |
| **Sufficiency Check** | Revisor (Post-hoc) | **Medium:** We check *after* the work is done. OpenBioLLM checks *during* information gathering. |
| **Model Specialization** | Gemini Pro (Uniform) | **High:** We use the same powerful model for everything. We could use Gemini Flash for simple tool tasks (Git, File Reading). |
| **Explicit Router** | Admin Agent | **Low:** Admin already routes tasks. |

## 4. Implementation Plan (Agno + SurrealDB + Gemini)

### Phase 1: Model tiering (Gemini Flash vs Pro)
-   **Action:** Update `codeswarm/config.py` to support `TOOL_MODEL` (Flash) and `REASONING_MODEL` (Pro).
-   **Apply:** Assign `TOOL_MODEL` to "mechanical" agents (e.g., a new `GitAgent` or `SearchAgent`) and `REASONING_MODEL` to Planner/Admin/Dev.

### Phase 2: The Evaluator Loop
-   **Action:** Implement a `ContextEvaluator` agent.
-   **Logic:** Before `DevAgent` starts coding, `ContextEvaluator` reviews the `KnowledgeAgent`'s output.
-   **Prompt:** "Do we have enough context to solve this task? If no, what is missing?" -> If missing, trigger KnowledgeAgent again.

### Phase 3: Tool-Specific Agents
-   **Action:** Extract heavy tool usage (e.g., complex search, static analysis) into dedicated agents that just *run the tool* and return structured JSON, preventing the main DevAgent from "hallucinating" tool outputs or shortcuts.
