# TIM: Transaction Intent Mining (Reflective Multi-Agent Framework)

**Source:** [Know Your Intent: An Autonomous Multi-Perspective LLM Agent Framework for DeFi User Transaction Intent Mining](https://arxiv.org/html/2511.15456)

## Synthesis
This paper proposes **TIM**, a framework for inferring the "intent" behind complex DeFi transactions (e.g., "Is this user arbitrage trading or providing liquidity?"). It addresses the challenge that raw data (hex logs) is opaque and single-pass analysis is insufficient.

The core architecture consists of four layer types:
1.  **Meta-Level Planner (MP):** Dynamically decides which "Perspectives" are needed to analyze a transaction (e.g., "Smart Contract Structure", "Temporal History", "Market Conditions"). It doesn't do the work; it routes the task.
2.  **Perspective-Specific Domain Experts (DE):** specialized agents that break down their specific perspective into a list of **Questions**.
3.  **Question Solvers (QS):** The execution layer. Each QS takes *one* question, uses tools (Reflective Multimodal Retrieval) to get the answer, and passes it back.
4.  **Cognition Evaluator (CE):** A final filter that grades the resulting report on **Verifiability** (Is there proof?) and **Relevance**.

A key innovation is **Reflective Multimodal Live Data Retrieval**. The agents don't just "query"; they query, inspect the result, critique it (e.g., "This result is too noisy"), and re-query if necessary before answering the question.

## Core Strategic Ideas
1.  **Question-Driven Context Gathering:** Instead of "Gather context about X", the system generates specific questions ("What is the function signature?", "Who called this function?"). This forces the agents to be precise and verifiable.
2.  **Meta-Planning for Dynamic Context:** Not every task needs every expert. A simple bug fix might only need a "Syntax Expert". A feature request might need "Database", "Frontend", and "Security" experts. The MP dynamically allocates these resources.
3.  **Reflective Retrieval Loop:** In a codebase, "reading a file" is often not enough. A reflective loop would allow an agent to: Read File -> See Import -> Read Imported File -> See Class Inheritance -> Read Parent Class. This mimics how a human developer navigates code.
4.  **Factuality Evaluation:** The CE explicitly checks if the "intent" (or in our case, the "plan") is backed by evidence found in the code, reducing hallucination.

## Integration Plan (Agno + SurrealDB + Gemini 3)
We can implement the **TIM** pattern for **"Deep Context Analysis"** before coding:

1.  **Architecture (`codeswarm/patterns/tim_analysis.py`):**
    *   **MetaPlanner:** Analyzes the GitHub Issue. Determines necessary perspectives (e.g., "Database Schema", "API Endpoint", "Frontend Component").
    *   **DomainExperts:** For each perspective, generate a list of questions. (e.g., Database Expert asks: "What tables are involved?", "Are there foreign keys?").
    *   **QuestionSolvers:** Use `Agno` tools to run `grep`, `ls`, `read_file`. They store their "Answers" in `SurrealDB` linked to the Issue ID.
    *   **Evaluator:** Reviews the gathered answers. If an answer is "I couldn't find it", it triggers a re-try or flags the issue as ambiguous.

2.  **Reflective Tooling:**
    *   Create a `ReflectiveCodeReader` tool. If the content contains `import x`, it optionally fetches `x` automatically if it's a local file.

3.  **SurrealDB Schema:**
    *   `DEFINE TABLE observation SCHEMAFULL;`
    *   `DEFINE FIELD question ON observation TYPE string;`
    *   `DEFINE FIELD answer ON observation TYPE string;`
    *   `DEFINE FIELD evidence_path ON observation TYPE string;`
    *   This builds a "Knowledge Graph" of the issue before any code is written.

4.  **Gemini 3 Integration:**
    *   Gemini's large context window is perfect for the **Cognition Evaluator**. We can feed it *all* the questions, answers, and raw code snippets and ask: "Is the proposed solution supported by these facts?"
