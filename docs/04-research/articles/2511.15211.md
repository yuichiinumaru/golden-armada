# Arxiv Analysis: OEMA: Ontology-Enhanced Multi-Agent Collaboration for Zero-Shot Clinical NER

**ID:** 2511.15211
**Date:** 2025-11-19 (Revised)
**Link:** https://arxiv.org/html/2511.15211

## 1. Executive Summary
OEMA addresses the challenges of Zero-Shot Clinical NER (Named Entity Recognition). It identifies that standard RAG (retrieving similar sentences) is too coarse for token-level tasks like NER. It proposes a multi-agent framework where a **Discriminator Agent** uses a domain ontology (SNOMED CT) to select highly relevant *token-level* examples, and a **Predictor Agent** uses these examples + entity type descriptions to perform the task. It achieves near-supervised performance.

## 2. Detailed Key Concepts

### 2.1. The Agent Trio
1.  **Self-Annotator:** Uses a zero-shot prompt to "guess" labels for unlabeled data, creating a candidate pool.
2.  **Discriminator:** The core innovation. It retrieves $K$ candidates via vector search, but then filters them down to $k$ best examples using **Ontology Matching**. It asks: "Does this example share the same medical concepts (SNOMED CT) as the target query?"
3.  **Predictor:** Combines the selected examples with detailed "Entity Type Descriptions" (Type Priors) to generate the final answer.

### 2.2. Granularity Mismatch
The paper argues that "Sentence-level similarity" (standard RAG) introduces noise for "Token-level tasks" (NER). You need to match specific concepts, not general sentence meaning.

## 3. Gap Analysis

| Feature/Concept | Current CodeSwarm | Gap |
| :--- | :--- | :--- |
| **Ontology-Guided Retrieval** | Vector Search | **High:** We search by embedding similarity. We don't filter by "Code Ontology" (e.g., "Is this an Abstract Factory pattern?"). |
| **Self-Annotation** | None | **Medium:** We don't generate training data from our own repo to improve future performance. |
| **Granularity Control** | File/Chunk level | **Medium:** We retrieve chunks. Sometimes we need "Function Signature" or "Variable Definition" level precision. |

## 4. Implementation Plan (Agno + SurrealDB + Gemini)

### Phase 1: Code Ontology Map
-   **Action:** Build a simple "Ontology" of the codebase in SurrealDB.
    -   Nodes: `Class`, `Function`, `Variable`, `Import`.
    -   Edges: `calls`, `inherits`, `imports`.
-   **Usage:** When `KnowledgeAgent` searches, filter results using this graph (e.g., "Find examples of *classes* that inherit from `BaseAgent`", not just text about agents).

### Phase 2: The Discriminator Agent
-   **Action:** Create a `DiscriminatorAgent` that filters RAG results.
-   **Prompt:** "I found these 10 code snippets. Which 3 are most relevant for implementing a *retry logic*? Discard the others."

### Phase 3: Self-Documenting Loop (Self-Annotator)
-   **Action:** Run a background job where an agent reads undocumented code, writes docstrings/specs (Self-Annotation), and stores them in the Knowledge Base.
