Directory structure:
â””â”€â”€ vrsen-agency-swarm/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ CONTRIBUTING.md
    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ pyproject.toml
    â”œâ”€â”€ setup.py
    â”œâ”€â”€ .cursorrules
    â”œâ”€â”€ .pre-commit-config.yaml
    â”œâ”€â”€ .prettierignore
    â”œâ”€â”€ agency_swarm/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ cli.py
    â”‚   â”œâ”€â”€ constants.py
    â”‚   â”œâ”€â”€ agency/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ agency.py
    â”‚   â”‚   â””â”€â”€ genesis/
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”œâ”€â”€ GenesisAgency.py
    â”‚   â”‚       â”œâ”€â”€ manifesto.md
    â”‚   â”‚       â”œâ”€â”€ util.py
    â”‚   â”‚       â”œâ”€â”€ AgentCreator/
    â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”‚   â”œâ”€â”€ AgentCreator.py
    â”‚   â”‚       â”‚   â”œâ”€â”€ instructions.md
    â”‚   â”‚       â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â”‚       â”œâ”€â”€ CreateAgentTemplate.py
    â”‚   â”‚       â”‚       â”œâ”€â”€ ImportAgent.py
    â”‚   â”‚       â”‚       â”œâ”€â”€ ReadManifesto.py
    â”‚   â”‚       â”‚       â””â”€â”€ util/
    â”‚   â”‚       â”‚           â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”‚           â””â”€â”€ get_modules.py
    â”‚   â”‚       â”œâ”€â”€ GenesisCEO/
    â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”‚   â”œâ”€â”€ GenesisCEO.py
    â”‚   â”‚       â”‚   â”œâ”€â”€ instructions.md
    â”‚   â”‚       â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â”‚       â”œâ”€â”€ CreateAgencyFolder.py
    â”‚   â”‚       â”‚       â”œâ”€â”€ FinalizeAgency.py
    â”‚   â”‚       â”‚       â””â”€â”€ ReadRequirements.py
    â”‚   â”‚       â”œâ”€â”€ OpenAPICreator/
    â”‚   â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”‚   â”œâ”€â”€ instructions.md
    â”‚   â”‚       â”‚   â”œâ”€â”€ OpenAPICreator.py
    â”‚   â”‚       â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â”‚       â””â”€â”€ CreateToolsFromOpenAPISpec.py
    â”‚   â”‚       â””â”€â”€ ToolCreator/
    â”‚   â”‚           â”œâ”€â”€ __init__.py
    â”‚   â”‚           â”œâ”€â”€ instructions.md
    â”‚   â”‚           â”œâ”€â”€ ToolCreator.py
    â”‚   â”‚           â””â”€â”€ tools/
    â”‚   â”‚               â”œâ”€â”€ CreateTool.py
    â”‚   â”‚               â””â”€â”€ TestTool.py
    â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ agent.py
    â”‚   â”‚   â”œâ”€â”€ BrowsingAgent/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ BrowsingAgent.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ instructions.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ requirements.txt
    â”‚   â”‚   â”‚   â””â”€â”€ tools/
    â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ ClickElement.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ ExportFile.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ GoBack.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ ReadURL.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ Scroll.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ SelectDropdown.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ SendKeys.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ SolveCaptcha.py
    â”‚   â”‚   â”‚       â”œâ”€â”€ WebPageSummarizer.py
    â”‚   â”‚   â”‚       â””â”€â”€ util/
    â”‚   â”‚   â”‚           â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚           â”œâ”€â”€ get_b64_screenshot.py
    â”‚   â”‚   â”‚           â”œâ”€â”€ highlights.py
    â”‚   â”‚   â”‚           â””â”€â”€ selenium.py
    â”‚   â”‚   â””â”€â”€ Devid/
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”œâ”€â”€ Devid.py
    â”‚   â”‚       â”œâ”€â”€ instructions.md
    â”‚   â”‚       â””â”€â”€ tools/
    â”‚   â”‚           â”œâ”€â”€ __init__.py
    â”‚   â”‚           â”œâ”€â”€ ChangeFile.py
    â”‚   â”‚           â”œâ”€â”€ CheckCurrentDir.py
    â”‚   â”‚           â”œâ”€â”€ CommandExecutor.py
    â”‚   â”‚           â”œâ”€â”€ DirectoryNavigator.py
    â”‚   â”‚           â”œâ”€â”€ FileMover.py
    â”‚   â”‚           â”œâ”€â”€ FileReader.py
    â”‚   â”‚           â”œâ”€â”€ FileWriter.py
    â”‚   â”‚           â”œâ”€â”€ ListDir.py
    â”‚   â”‚           â””â”€â”€ util/
    â”‚   â”‚               â”œâ”€â”€ __init__.py
    â”‚   â”‚               â””â”€â”€ format_file_deps.py
    â”‚   â”œâ”€â”€ integrations/
    â”‚   â”‚   â”œâ”€â”€ fastapi.py
    â”‚   â”‚   â””â”€â”€ fastapi_utils/
    â”‚   â”‚       â”œâ”€â”€ endpoint_handlers.py
    â”‚   â”‚       â””â”€â”€ request_models.py
    â”‚   â”œâ”€â”€ messages/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ message_output.py
    â”‚   â”œâ”€â”€ threads/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ thread.py
    â”‚   â”‚   â””â”€â”€ thread_async.py
    â”‚   â”œâ”€â”€ tools/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ BaseTool.py
    â”‚   â”‚   â”œâ”€â”€ ToolFactory.py
    â”‚   â”‚   â”œâ”€â”€ mcp/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â””â”€â”€ server.py
    â”‚   â”‚   â”œâ”€â”€ oai/
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ CodeInterpreter.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ FileSearch.py
    â”‚   â”‚   â”‚   â””â”€â”€ Retrieval.py
    â”‚   â”‚   â””â”€â”€ send_message/
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â”œâ”€â”€ SendMessage.py
    â”‚   â”‚       â”œâ”€â”€ SendMessageAsyncThreading.py
    â”‚   â”‚       â”œâ”€â”€ SendMessageBase.py
    â”‚   â”‚       â”œâ”€â”€ SendMessageQuick.py
    â”‚   â”‚       â””â”€â”€ SendMessageSwarm.py
    â”‚   â”œâ”€â”€ user/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â””â”€â”€ user.py
    â”‚   â””â”€â”€ util/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ errors.py
    â”‚       â”œâ”€â”€ files.py
    â”‚       â”œâ”€â”€ oai.py
    â”‚       â”œâ”€â”€ openapi.py
    â”‚       â”œâ”€â”€ schema.py
    â”‚       â”œâ”€â”€ shared_state.py
    â”‚       â”œâ”€â”€ validators.py
    â”‚       â”œâ”€â”€ cli/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ create_agent_template.py
    â”‚       â”‚   â””â”€â”€ import_agent.py
    â”‚       â”œâ”€â”€ helpers/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ get_available_agent_descriptions.py
    â”‚       â”‚   â”œâ”€â”€ list_available_agents.py
    â”‚       â”‚   â””â”€â”€ sync_async.py
    â”‚       â”œâ”€â”€ streaming/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ agency_event_handler.py
    â”‚       â”‚   â”œâ”€â”€ gradio_event_handler.py
    â”‚       â”‚   â””â”€â”€ term_event_handler.py
    â”‚       â””â”€â”€ tracking/
    â”‚           â”œâ”€â”€ __init__.py
    â”‚           â”œâ”€â”€ langchain_types.py
    â”‚           â”œâ”€â”€ local_callback_handler.py
    â”‚           â””â”€â”€ tracking_manager.py
    â”œâ”€â”€ docs/
    â”‚   â”œâ”€â”€ analise_docs.py
    â”‚   â”œâ”€â”€ docs.json
    â”‚   â”œâ”€â”€ faq.mdx
    â”‚   â”œâ”€â”€ mintlify.cursorrules
    â”‚   â”œâ”€â”€ openapi.json
    â”‚   â”œâ”€â”€ .prettierrc
    â”‚   â”œâ”€â”€ additional-features/
    â”‚   â”‚   â”œâ”€â”€ asynchronous-execution.mdx
    â”‚   â”‚   â”œâ”€â”€ azure-openai.mdx
    â”‚   â”‚   â”œâ”€â”€ deployment-to-production.mdx
    â”‚   â”‚   â”œâ”€â”€ fastapi-integration.mdx
    â”‚   â”‚   â”œâ”€â”€ few-shot-examples.mdx
    â”‚   â”‚   â”œâ”€â”€ observability.mdx
    â”‚   â”‚   â”œâ”€â”€ open-source-models.mdx
    â”‚   â”‚   â”œâ”€â”€ output-validation.mdx
    â”‚   â”‚   â”œâ”€â”€ shared-state.mdx
    â”‚   â”‚   â”œâ”€â”€ streaming.mdx
    â”‚   â”‚   â””â”€â”€ custom-communication-flows/
    â”‚   â”‚       â”œâ”€â”€ common-use-cases.mdx
    â”‚   â”‚       â””â”€â”€ overview.mdx
    â”‚   â”œâ”€â”€ contributing/
    â”‚   â”‚   â””â”€â”€ contributing.mdx
    â”‚   â”œâ”€â”€ core-framework/
    â”‚   â”‚   â”œâ”€â”€ state-management.mdx
    â”‚   â”‚   â”œâ”€â”€ agencies/
    â”‚   â”‚   â”‚   â”œâ”€â”€ agency-parameters.mdx
    â”‚   â”‚   â”‚   â”œâ”€â”€ communication-flows.mdx
    â”‚   â”‚   â”‚   â”œâ”€â”€ overview.mdx
    â”‚   â”‚   â”‚   â””â”€â”€ running-agency.mdx
    â”‚   â”‚   â”œâ”€â”€ agents/
    â”‚   â”‚   â”‚   â”œâ”€â”€ advanced-configuration.mdx
    â”‚   â”‚   â”‚   â”œâ”€â”€ built-in-tools.mdx
    â”‚   â”‚   â”‚   â””â”€â”€ overview.mdx
    â”‚   â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â”œâ”€â”€ mcp-integration.mdx
    â”‚   â”‚       â”œâ”€â”€ openapi-schemas.mdx
    â”‚   â”‚       â”œâ”€â”€ overview.mdx
    â”‚   â”‚       â”œâ”€â”€ tool-factory.mdx
    â”‚   â”‚       â””â”€â”€ custom-tools/
    â”‚   â”‚           â”œâ”€â”€ best-practices.mdx
    â”‚   â”‚           â”œâ”€â”€ configuration.mdx
    â”‚   â”‚           â”œâ”€â”€ pydantic-is-all-you-need.mdx
    â”‚   â”‚           â””â”€â”€ step-by-step-guide.mdx
    â”‚   â”œâ”€â”€ extras/
    â”‚   â”‚   â””â”€â”€ extras.mdx
    â”‚   â”œâ”€â”€ images/
    â”‚   â”‚   â”œâ”€â”€ additional-instructions-example.webp
    â”‚   â”‚   â”œâ”€â”€ custom-gpt-screenshot.webp
    â”‚   â”‚   â””â”€â”€ integrations/
    â”‚   â”‚       â”œâ”€â”€ slack-integration/
    â”‚   â”‚       â”œâ”€â”€ whatsapp-integration/
    â”‚   â”‚       â””â”€â”€ zapier-integration/
    â”‚   â”œâ”€â”€ platform/
    â”‚   â”‚   â”œâ”€â”€ additional-instructions.mdx
    â”‚   â”‚   â”œâ”€â”€ overview.mdx
    â”‚   â”‚   â””â”€â”€ integrations/
    â”‚   â”‚       â”œâ”€â”€ slack-integration.mdx
    â”‚   â”‚       â”œâ”€â”€ web-api.mdx
    â”‚   â”‚       â”œâ”€â”€ whatsapp-integration.mdx
    â”‚   â”‚       â””â”€â”€ zapier-integration.mdx
    â”‚   â”œâ”€â”€ references/
    â”‚   â”‚   â””â”€â”€ api.mdx
    â”‚   â”œâ”€â”€ tutorials/
    â”‚   â”‚   â””â”€â”€ tutorials.mdx
    â”‚   â””â”€â”€ welcome/
    â”‚       â”œâ”€â”€ ai-agency-vs-other-frameworks.mdx
    â”‚       â”œâ”€â”€ installation.mdx
    â”‚       â”œâ”€â”€ overview.mdx
    â”‚       â””â”€â”€ getting-started/
    â”‚           â”œâ”€â”€ cursor-ide.mdx
    â”‚           â”œâ”€â”€ from-scratch.mdx
    â”‚           â””â”€â”€ genesis-agency.mdx
    â”œâ”€â”€ notebooks/
    â”‚   â”œâ”€â”€ agency_async.ipynb
    â”‚   â”œâ”€â”€ azure.ipynb
    â”‚   â”œâ”€â”€ genesis_agency.ipynb
    â”‚   â”œâ”€â”€ os_models_with_astra_assistants_api.ipynb
    â”‚   â””â”€â”€ web_browser_agent.ipynb
    â”œâ”€â”€ tests/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ test_agency.py
    â”‚   â”œâ”€â”€ test_communication.py
    â”‚   â”œâ”€â”€ test_mcp.py
    â”‚   â”œâ”€â”€ test_tool_factory.py
    â”‚   â”œâ”€â”€ data/
    â”‚   â”‚   â”œâ”€â”€ files/
    â”‚   â”‚   â”‚   â”œâ”€â”€ csv-test.csv
    â”‚   â”‚   â”‚   â”œâ”€â”€ favorite_books.txt
    â”‚   â”‚   â”‚   â”œâ”€â”€ favorite_cities.txt
    â”‚   â”‚   â”‚   â”œâ”€â”€ favorite_songs.txt
    â”‚   â”‚   â”‚   â”œâ”€â”€ generated_data.json
    â”‚   â”‚   â”‚   â”œâ”€â”€ test-docx.docx
    â”‚   â”‚   â”‚   â”œâ”€â”€ test-html.html
    â”‚   â”‚   â”‚   â”œâ”€â”€ test-md.md
    â”‚   â”‚   â”‚   â”œâ”€â”€ test-txt.txt
    â”‚   â”‚   â”‚   â””â”€â”€ test-xml.xml
    â”‚   â”‚   â”œâ”€â”€ schemas/
    â”‚   â”‚   â”‚   â”œâ”€â”€ ga4.json
    â”‚   â”‚   â”‚   â”œâ”€â”€ get-headers-params.json
    â”‚   â”‚   â”‚   â”œâ”€â”€ get-weather.json
    â”‚   â”‚   â”‚   â””â”€â”€ relevance.json
    â”‚   â”‚   â””â”€â”€ tools/
    â”‚   â”‚       â””â”€â”€ ExampleTool1.py
    â”‚   â”œâ”€â”€ demos/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ demo_gradio.py
    â”‚   â”‚   â”œâ”€â”€ demo_mcp.py
    â”‚   â”‚   â”œâ”€â”€ demo_observability.py
    â”‚   â”‚   â”œâ”€â”€ streaming_demo.py
    â”‚   â”‚   â””â”€â”€ term_demo.py
    â”‚   â””â”€â”€ scripts/
    â”‚       â””â”€â”€ server.py
    â””â”€â”€ .github/
        â””â”€â”€ workflows/
            â”œâ”€â”€ close-issues.yml
            â”œâ”€â”€ publish.yml
            â””â”€â”€ test.yml

================================================
FILE: README.md
================================================
# ðŸ Agency Swarm

![Framework](https://firebasestorage.googleapis.com/v0/b/vrsen-ai/o/public%2Fgithub%2FLOGO_BG_large_bold_shadow%20(1).jpg?alt=media&token=8c681331-2a7a-4a69-b21b-3ab1f9bf1a23)

## Overview

Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyone to create collaborative swarm of agents (Agencies), each with distinct roles and capabilities. By thinking about automation in terms of real world entities, such as agencies and specialized agent roles, we make it a lot more intuitive for both the agents and the users.

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1qGVyK-vIoxZD0dMrMVqCxCsgL1euMLKj)
[![Docs](https://img.shields.io/website?label=Docs&up_message=available&url=https://vrsen.github.io/agency-swarm/)](https://vrsen.github.io/agency-swarm/)
[![Subscribe on YouTube](https://img.shields.io/youtube/channel/subscribers/UCSv4qL8vmoSH7GaPjuqRiCQ)](https://youtube.com/@vrsen/)
[![Follow on Twitter](https://img.shields.io/twitter/follow/__vrsen__.svg?style=social&label=Follow%20%40__vrsen__)](https://twitter.com/__vrsen__)
[![Join our Discord!](https://img.shields.io/discord/1200037936352202802?label=Discord)](https://discord.gg/cw2xBaWfFM)
[![Agents-as-a-Service](https://img.shields.io/website?label=Agents-as-a-Service&up_message=For%20Business&url=https%3A%2F%2Fvrsen.ai)](https://agents.vrsen.ai)

### Key Features

- **Customizable Agent Roles**: Define roles like CEO, virtual assistant, developer, etc., and customize their functionalities with [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview).
- **Full Control Over Prompts**: Avoid conflicts and restrictions of pre-defined prompts, allowing full customization.
- **Type-Safe Tools**: Create reliable tools with automatic type validation and error correction.
- **Efficient Communication**: Agents communicate through a specially designed messaging tool based on their own descriptions.
- **State Management**: Agency Swarm efficiently manages the state of your assistants on OpenAI, maintaining it in a special `settings.json` file.
- **Production Ready**: Built for reliability and easy deployment in production environments.

## Installation

```bash
pip install -U agency-swarm
```

## Getting Started

1. **Set Your OpenAI Key**:
    ```python
    from agency_swarm import set_openai_key
    set_openai_key("YOUR_API_KEY")
    ```

2. **Create Tools**:
Define your custom tools by extending the `BaseTool` class:
    ```python
    from agency_swarm.tools import BaseTool
    from pydantic import Field

    class MyCustomTool(BaseTool):
        """
        A brief description of what the custom tool does.
        The docstring should clearly explain the tool's purpose and functionality.
        It will be used by the agent to determine when to use this tool.
        """

        # Define the fields with descriptions using Pydantic Field
        example_field: str = Field(
            ..., description="Description of the example field, explaining its purpose and usage for the Agent."
        )
        # Additional fields as required
        # ...

        def run(self):
            """
            The implementation of the run method, where the tool's main functionality is executed.
            """
            # Your custom tool logic goes here
            do_something(self.example_field)

            # Return the result of the tool's operation
            return "Result of MyCustomTool operation"
    ```

    or convert from OpenAPI schemas:

    ```python
    from agency_swarm.tools import ToolFactory
    # using local file
    with open("schemas/your_schema.json") as f:
        tools = ToolFactory.from_openapi_schema(
            f.read(),
        )

    # using requests
    tools = ToolFactory.from_openapi_schema(
        requests.get("https://api.example.com/openapi.json").json(),
    )
    ```


3. **Define Agent Roles**: Start by defining the roles of your agents. For example, a CEO agent for managing tasks and a developer agent for executing tasks.

    ```python
    from agency_swarm import Agent

    ceo = Agent(
        name="CEO",
        description="Responsible for client communication, task planning and management.",
        instructions="You must converse with other agents to ensure complete task execution.", # can be a file like ./instructions.md
        files_folder="./files", # files to be uploaded to OpenAI
        schemas_folder="./schemas", # OpenAPI schemas to be converted into tools
        tools=[MyCustomTool],
        temperature=0.3, # temperature for the agent
        max_prompt_tokens=25000, # max tokens in conversation history
    )
    ```

    Import from existing agents:

   ```bash
   agency-swarm import-agent --name "Devid" --destination "./"
   ```

   This will import Devid (Software Developer) Agent locally, including all source code files, so you have full control over your system. Currently, available agents are: `Devid`, `BrowsingAgent`.


4. **Define Agency Communication Flows**:
Establish how your agents will communicate with each other.

    ```python
    from agency_swarm import Agency
    # if importing from local files
    from Developer import Developer
    from VirtualAssistant import VirtualAssistant

    dev = Developer()
    va = VirtualAssistant()

    agency = Agency([
            ceo,  # CEO will be the entry point for communication with the user
            [ceo, dev],  # CEO can initiate communication with Developer
            [ceo, va],   # CEO can initiate communication with Virtual Assistant
            [dev, va]    # Developer can initiate communication with Virtual Assistant
        ],
        shared_instructions='agency_manifesto.md', # shared instructions for all agents
        temperature=0.3, # default temperature for all agents
        max_prompt_tokens=25000 # default max tokens in conversation history
    )
    ```

     In Agency Swarm, communication flows are directional, meaning they are established from left to right in the agency_chart definition. For instance, in the example above, the CEO can initiate a chat with the developer (dev), and the developer can respond in this chat. However, the developer cannot initiate a chat with the CEO. The developer can initiate a chat with the virtual assistant (va) and assign new tasks.

5. **Run Demo**:
Run the demo to see your agents in action!

    Web interface:

    ```python
    agency.demo_gradio(height=900)
    ```

    Terminal version:

    ```python
    agency.run_demo()
    ```

    Backend version:

    ```python
    completion_output = agency.get_completion("Please create a new website for our client.")
    ```

# CLI

## Genesis Agency

The `genesis` command starts the genesis agency in your terminal to help you create new agencies and agents.

#### **Command Syntax:**

```bash
agency-swarm genesis [--openai_key "YOUR_API_KEY"]
```

Make sure to include:
- Your mission and goals.
- The agents you want to involve and their communication flows.
- Which tools or APIs each agent should have access to, if any.

## Importing Existing Agents

This CLI command allows you to import existing agents from local files into your agency.

#### **Command Syntax:**

```bash
agency-swarm import-agent --name "AgentName" --destination "/path/to/directory"
```

To check available agents, simply run this command without any arguments.

## Creating Agent Templates Locally

This CLI command simplifies the process of creating a structured environment for each agent.

#### **Command Syntax:**

```bash
agency-swarm create-agent-template --name "AgentName" --description "Agent Description" [--path "/path/to/directory"] [--use_txt]
```

### Folder Structure

When you run the `create-agent-template` command, it creates the following folder structure for your agent:

```
/your-specified-path/
â”‚
â”œâ”€â”€ agency_manifesto.md or .txt # Agency's guiding principles (created if not exists)
â””â”€â”€ AgentName/                  # Directory for the specific agent
    â”œâ”€â”€ files/                  # Directory for files that will be uploaded to openai
    â”œâ”€â”€ schemas/                # Directory for OpenAPI schemas to be converted into tools
    â”œâ”€â”€ tools/                  # Directory for tools to be imported by default.
    â”œâ”€â”€ AgentName.py            # The main agent class file
    â”œâ”€â”€ __init__.py             # Initializes the agent folder as a Python package
    â”œâ”€â”€ instructions.md or .txt # Instruction document for the agent
    â””â”€â”€ tools.py                # Custom tools specific to the agent

```

This structure ensures that each agent has its dedicated space with all necessary files to start working on its specific tasks. The `tools.py` can be customized to include tools and functionalities specific to the agent's role.

## Future Enhancements

1. [x] Creation of agencies that can autonomously create other agencies.
2. [x] Asynchronous communication and task handling.
3. [ ] Inter-agency communication for a self-expanding system.

## Contributing

For details on how to contribute you agents and tools to Agency Swarm, please refer to the [Contributing Guide](CONTRIBUTING.md).

## License

Agency Swarm is open-source and licensed under [MIT](https://opensource.org/licenses/MIT).



## Need Help?

If you need help creating custom agent swarms for your business, check out our [Agents-as-a-Service](https://agents.vrsen.ai/) subscription, or schedule a consultation with me at https://calendly.com/vrsen/ai-project-consultation



================================================
FILE: CONTRIBUTING.md
================================================
# Contributing to Agency Swarm
Each agent or tool you add to Agency Swarm will automatically be available for import by the Genesis Swarm, which will help us create an exponentially larger and smarter system.

This document provides guidelines for contributing new agents and tools to the framework.

## Prerequisites

- Python 3.10 or higher
- Pip
- Git

## Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/VRSEN/agency-swarm.git
   cd agency-swarm
   ```
2. Create and activate a virtual environment (recommended):
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`
   ```
3. Install dependencies including development tools:
   ```bash
   pip install -e ".[dev]"
   ```

4. Install Pre-Commit Hooks:
   ```bash
   pip install pre-commit
   pre-commit install
   ```

## Running Tests

To ensure your changes haven't broken existing functionality, please run the test suite. First, make sure you have installed the development dependencies:

```bash
pip install -e ".[dev]"
```

Then, run pytest from the root directory:

```bash
pytest
```

3. **Check Test Coverage**

   Check the test coverage:

   ```bash
   pytest --cov=agency_swarm tests/
   ```

## Folder Structure for Tools

Tools should be added in the `agency_swarm/tools/{category}/` directory as shown below. Each tool should be placed in its specific category folder like `coding`, `browsing`, `investing`, etc.

Your tool file should be named `YourNewTool.py`. Tests should be added in `agency_swarm/tests/test_tools.py`.

```bash
agency_swarm/tools/your-tool-category/
â”‚
â”œâ”€â”€ YourNewTool.py          # The main tool class file
â””â”€â”€ __init__.py             # Make sure to import your tool here
```

### Adding Tests For Your Tools

For each tool, please add the following test case in `agency_swarm/tests/test_tools.py`:

```python
def test_my_tool_example():
    tool = MyCustomTool(example_field="test value")
    result = tool.run()
    assert "expected output" in result
```

---

Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.

1. **Install Test Dependencies**

   If there are any additional test dependencies, install them:

   ```bash
   pip install -e ".[dev]"
   ```

2. **Run Tests with Pytest**

   We use `pytest` for running tests.

   ```bash
   pytest
   ```

3. **Check Test Coverage**

   To check test coverage, run:

   ```bash
   pytest --cov=agency_swarm tests/
   ```

## Folder Structure for Agents

Agents should be placed in `agency_swarm/agents/` directory. Each agent should have its dedicated folder named `AgentName` like below. Make sure to use **CamelCase** for the agent name and the folder.

```
agency_swarm/agents/AgentName/
â”‚
â””â”€â”€ AgentName/                  # Directory for the specific agent
    â”œâ”€â”€ files/                  # Directory for files that will be uploaded to OpenAI (if any)
    â”œâ”€â”€ tools/                  # Directory for tools to be used by the agent
    â”œâ”€â”€ schemas/                # Directory for OpenAPI schemas to be converted into tools (if any)
    â”œâ”€â”€ AgentName.py            # The main agent class file
    â”œâ”€â”€ __init__.py             # Initializes the agent folder as a Python package
    â””â”€â”€ instructions.md         # Instruction document for the agent
```

### Creating an Agent

1. Use the following structure in your `AgentName.py` as a guideline.
2. Import all tools (except schemas) from the `agency_swarm/tools/...` folder.

```python
from agency_swarm import Agent
from agency_swarm.tools.example import ExampleTool

class AgentName(Agent):
    def __init__(self):
        super().__init__(
            name="AgentName",
            description="Description of the agent",
            instructions="instructions.md",
            tools=[ExampleTool],
        )
```

---

Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.

## Code Style and Linting

This project uses `ruff` for linting and code formatting. Configuration for this tool can be found in `pyproject.toml`.

### Formatting and Linting Code

Before committing your changes, please check and fix linting errors:

```bash
ruff check . --fix
```

It's recommended to install these tools in your development environment. If you followed the setup instructions, they should already be installed via:

```bash
pip install -e ".[dev]"
```

## Submitting Pull Requests

To submit a pull request, please follow these steps:

1. **Fork the Repository**

   Fork the repository to your GitHub account.

2. **Clone the Forked Repository**

   Clone the forked repository to your local machine:

   ```bash
   git clone https://github.com/your-username/agency-swarm.git
   cd agency-swarm
   ```

3. **Create a New Branch**

   Create a new branch for your changes:

   ```bash
   git checkout -b feature-new-tool
   ```

4. **Make Your Changes**

   Make the necessary changes to the code.

5. **Commit Your Changes**

   Commit your changes with a meaningful commit message:

   ```bash
   git add .
   git commit -m "Added new tool: YourNewTool"
   ```

6. **Push Your Changes**

   Push your changes to your forked repository:

   ```bash
   git push origin feature-new-tool
   ```

7. **Create a Pull Request**

   Go to your forked repository on GitHub and click on "Pull requests". Click on "New pull request" and follow the instructions to create a pull request.

Thank you for contributing to Agency Swarm! Your efforts help us build a more robust and versatile framework.



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2023 Arsenii Shatokhin

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.



================================================
FILE: pyproject.toml
================================================
[build-system]
requires = ["setuptools>=61.0", "setuptools_scm>=8"]
build-backend = "setuptools.build_meta"

[project]
name = "agency-swarm"
dynamic = ["version"]
authors = [{ name = "VRSEN", email = "me@vrsen.ai" }]
description = "An open source agent orchestration framework built on top of the latest OpenAI Assistants API."
readme = "README.md"
license-files = ["LICENSE"]
classifiers = [
    "Intended Audience :: Developers",
    "Topic :: Software Development :: Build Tools",
]
dependencies = [
    "datamodel-code-generator~=0.30.1",
    "deepdiff==8.5.0",
    "docstring_parser~=0.16",
    "jsonref~=1.1.0",
    "openai>=1.66.0,<2.0.0",
    "pydantic>=2.8.2,<2.12.0",
    "python-dotenv~=1.1.0",
    "rich>=13.9.4,<14.0.0",
    "termcolor>=2.3.0,<3.0.0",
    "mcp>=1.6.0,<2.0.0",
    "packaging<25.0",
    "click==8.1.8"
]
requires-python = ">=3.10"
urls = { homepage = "https://github.com/VRSEN/agency-swarm" }

[project.optional-dependencies]
dev = [
    "pip-tools",
    "gradio",
    "langchain==0.3.13",
    "langchain-community==0.3.13",
    "mcp-server-git",
    "pytest",
    "pytest-asyncio",
    "ruff>=0.11.0"
]
fastapi = [
    "fastapi>=0.115.0",
    "uvicorn[standard]>=0.34.0",
    "anyio>=4.9.0"
]

[project.scripts]
agency-swarm = "agency_swarm.cli:main"

[tool.setuptools_scm]

[tool.pytest.ini_options]
asyncio_mode = "strict"
asyncio_default_fixture_loop_scope = "function"

[tool.setuptools.packages.find]
where = ["."] # Specifies to look in the current directory
exclude = [
    "tests",
    "tests.*",
    "agency_swarm.agency.genesis",
    "agency_swarm.agency.genesis.*"
]

[tool.ruff]
target-version = "py310"
line-length = 120
# Enable linting and formatting
lint.select = ["E", "F", "I"]
format.quote-style = "double"



================================================
FILE: setup.py
================================================
from setuptools import setup

# All configuration is now in pyproject.toml
setup()



================================================
FILE: .cursorrules
================================================
# AI Agent Creator Instructions for Agency Swarm Framework

Agency Swarm is a framework that allows anyone to create a collaborative swarm of agents (Agencies), each with distinct roles and capabilities. Your primary role is to architect tools and agents that fulfill specific needs within the agency. This involves:

1. **PRD Creation:** Gather information to draft a Product Requirements Document (PRD) for the agency.
2. **Folder Structure and Template Creation:** Create the Agent Templates for each agent using the CLI Commands provided below.
3. **Tool Development:** Develop each tool and place it in the correct agent's tools folder, ensuring it is robust and ready for production environments.
4. **Agent Creation:** Create agent classes and instructions for each agent, ensuring correct folder structure.
5. **Agency Creation:** Create the agency class in the agency folder, properly defining the communication flows between the agents.
6. **Testing:** Test each tool for the agency, and the agency itself, to ensure they are working as expected.
7. **Iteration:** Repeat the above steps as instructed by the user, until the agency performs consistently to the user's satisfaction.

You will find a detailed guide for each of the steps below.

# Step 1: PRD Creation

First, ask the user to provide all necessary details:
- Agency Name
- Purpose (a high-level description of what the agency aims to achieve, its target market, and its value proposition)
- Communication Flows (between agents and from agents to user)
- Agents (for each agent: name, role, tools with descriptions)

Once you have gathered all details, create the file `agency_name/prd.txt` using the following template:

```md
# [Agency Name]

---

- **Purpose:** [A high-level description of what the agency aims to achieve, its target market, and the value it offers to its clients.]
- **Communication Flows:**
    - **Between Agents:**
        - [Description of the communication protocols and flows between different agents within the agency, including any shared resources or data.]
        - **Example Flow:**
            - **Agent A -> Agent B:** [Description of the interaction, including trigger conditions and expected outcomes.]
            - **Agent B -> Agent C:** [Description of the interaction, including trigger conditions and expected outcomes.]
    - **Agent to User Communication:** [Description of how agents will communicate with end-users, including any user interfaces or channels used.]

---

## Agent Name

### **Role within the Agency**

[Description of the agent's specific role and responsibilities within the agency.]

### Tools

- **ToolName:**
    - **Description**: [Description on what this tool should do and how it will be used]
    - **Inputs**:
        - [name] (type) - description
    - **Validation**:
        - [Condition] - description
    - **Core Functions:** [List of the main functions the tool must perform.]
    - **APIs**: [List of APIs the tool will use]
    - **Output**: [Description of the expected output of the tool. Output must be a string or a JSON object.]

---

...repeat for each agent
```

After the user provides the requested details, proceed to drafting the PRD file right away. Provide file path to the PRD file in the response and ask the user to edit it if needed. Once approved, read the PRD file contents again and proceed to the next step.

### Best Practices

- **4-16 Tools Per Agent**: Each agent should have between 4 and 16 tools. Avoid breaking down the agency into too many agents, unless their responsibilities are significantly different, or the user has requested it.

# Step 2: Folder Structure and Template Creation

After creating the PRD file, create the folder structure and agent templates, for each agent using the CLI command below:

```bash
agency-swarm create-agent-template --name "AgentName" --description "Agent Description" --path "agency_name"
```

Repeat this step for each agent in the agency. Make sure to correctly specify the path to the agency folder.

**Folder Structure**:

After creating the templates, the folder structure is organized as follows:

```
agency_name/
â”œâ”€â”€ agent_name/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent_name.py
â”‚   â”œâ”€â”€ instructions.md
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ tool_name1.py
â”‚       â”œâ”€â”€ tool_name2.py
â”‚       â”œâ”€â”€ tool_name3.py
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ another_agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ another_agent.py
â”‚   â”œâ”€â”€ instructions.md
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ tool_name1.py
â”‚       â”œâ”€â”€ tool_name2.py
â”‚       â”œâ”€â”€ tool_name3.py
â”‚       â”œâ”€â”€ ...
â”œâ”€â”€ agency.py
â”œâ”€â”€ agency_manifesto.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€...
```

**Folder Structure Rules**:

- Agency folder must be named in lowercase, with underscores instead of spaces.
- Each agency and agent has its own dedicated folder.
- Within each agent folder:

  - A 'tools' folder contains all tools for that agent.
  - An 'instructions.md' file provides agent-specific instructions.
  - An '**init**.py' file contains the import of the agent.

- Tool Import Process:

  - Create a file in the 'tools' folder with the same name as the tool class.
  - Tools are automatically imported to the agent class.
  - All new requirements must be added to the requirements.txt file.

- Agency Configuration:
  - The 'agency.py' file is the main file where all new agents are imported.
  - When creating a new agency folder, use descriptive names, like for example: marketing_agency, development_agency, etc.
  - Create a `.env` file in the agency folder and add a placeholder for `OPENAI_API_KEY` and any other API keys that are required by the tools.

Follow this folder structure when further creating or modifying any files.

# Step 3: Tool Creation

Tools are the specific actions that agents can perform. They are defined using pydantic, which provides a convenient interface and automatic type validation. To create a tool:

1. Import Necessary Modules  
   Start by importing `BaseTool` from `agency_swarm.tools` and `Field` from `pydantic`. These imports will serve as the foundation for your custom tool class. Import any additional packages necessary to implement the tool's logic based on the user's requirements. Import `load_dotenv` from `dotenv` to load the environment variables.

2. Define Your Tool Class and Docstring  
   Create a new class that inherits from `BaseTool`. Write a clear docstring describing the tool's purpose. This docstring is crucial as it helps agents understand how to use the tool. `BaseTool` extends `BaseModel` from pydantic.

3. Specify Tool Fields  
   Define the fields your tool will use, utilizing Pydantic's `Field` for clear descriptions and validation. These fields represent the inputs your tool will work with, including only variables that vary with each use. Define any constant variables globally.

4. Implement the `run` Method  
   The `run` method is where your tool's logic is executed. Use the fields defined earlier to perform the tool's intended task. It must contain the actual fully functional correct python code. It can utilize various python packages, previously imported in step 1.

5. Test the Tool  
   Add a test case at the bottom of the file in if **name** == "**main**": block. It will be used to test the tool later.

### Best Practices

- **Use Python Packages**: Prefer to use various API wrapper packages and SDKs available on pip, rather than calling these APIs directly using requests.
- **Documentation**: The documentation should clearly describe the purpose and functionality of the tool, as well as how to use it.
- **Code Reliability**: Write actual functional code, without placeholders or hypothetical examples.
- **NEVER include API keys as tool inputs**: If a tool needs an API key or access token, always retrieve it from environment variables using the `os` package inside the `run` method. Do not define API keys or tokens as input fields for the tool.
- **Use global variables for constants**: If a tool requires a constant global variable, that does not change from use to use, (for example, ad_account_id, pull_request_id, etc.), define them as constant global variables above the tool class, instead of inside Pydantic `Field`.
- **Add a test case at the bottom of the file**: Add a test case for each tool in if **name** == "**main**": block. It will be used to test the tool later.

### Complete Example of a Tool File

```python
# MyCustomTool.py
from agency_swarm.tools import BaseTool
from pydantic import Field
import os
from dotenv import load_dotenv

load_dotenv() # always load the environment variables

class MyCustomTool(BaseTool):
    """
    A brief description of what the custom tool does.
    The docstring should clearly explain the tool's purpose and functionality.
    It will be used by the agent to determine when to use this tool.
    """
    # Define the fields with descriptions using Pydantic Field
    example_field: str = Field(
        ..., description="Description of the example field, explaining its purpose and usage for the Agent."
    )

    def run(self):
        """
        The implementation of the run method, where the tool's main functionality is executed.
        This method should utilize the fields defined above to perform the task.
        """
        # Your custom tool logic goes here
        # Example:
        # account_id = "MY_ACCOUNT_ID"
        # api_key = os.getenv("MY_API_KEY") # or access_token = os.getenv("MY_ACCESS_TOKEN")
        # do_something(self.example_field, api_key, account_id)

        # Return the result of the tool's operation as a string
        return "Result of MyCustomTool operation"

if __name__ == "__main__":
    tool = MyCustomTool(example_field="example value")
    print(tool.run())
```

Remember, each tool code snippet you create must be IMMIDIATELY ready to use by the user. It must not contain any mocks, placeholders or hypothetical examples.

### Shared State

Tools can access and modify a global state across the agency to store and share data without using extra tokens in conversations.

```python
def run(self):
    self._shared_state.set("my_key", "my_value")  # Store data
    data = self._shared_state.get("my_key", "default_value")  # Retrieve data with a default
```

Use this for:
- Large data structures expensive to pass between agents
- Maintaining state across multiple tool calls
- Sharing data among tools and agents

Best Practices:
- Use descriptive keys to avoid conflicts
- Provide default values when retrieving
- Clean up unneeded data

### MCP Integration

Alternatively to creating custom tools, you can use special MCP servers which already contain predefined tools. In this case, you don't need to create custom tool files for the same functionality or add them to the PRD. You can use MCPs interchangeably with custom tools

```python
from agency_swarm.tools.mcp import MCPServerStdio

filesystem_server = MCPServerStdio(
    # This name determines how the agent accesses the tools (e.g., Filesystem_Server.list_files)
    name="Filesystem_Server",
    params={
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", "."], 
    },
    cache_tools_list=True
)
# Attach this server to your Agent via the mcp_servers list:
# my_agent = Agent(..., mcp_servers=[sse_server])
# Reference: https://agency-swarm.ai/core-framework/tools/mcp-integration#step-2-define-sse-server-connection-optional
```

# Step 4: Agent Creation

To create an agent:

1. **Create an Agent class in the agent's folder.**

   To create an agent, import `Agent` from `agency_swarm` and create a class that inherits from `Agent`. Inside the class you can adjust the following parameters:

   ```python
   from agency_swarm import Agent

   class CEO(Agent):
       def __init__(self):
           super().__init__(
               name="CEO",
               description="Responsible for client communication, task planning and management.",
               instructions="./instructions.md", # instructions for the agent
               tools_folder="./tools", # folder containing the tools for the agent
               temperature=0.5,
               max_prompt_tokens=25000,
           )
   ```

   - **name**: The agent's name, reflecting its role.
   - **description**: A brief summary of the agent's responsibilities.
   - **instructions**: Path to a markdown file containing detailed instructions for the agent.
   - **tools_folder**: A folder containing the tools for the agent. Tools will be imported automatically. Each tool class must be named the same as the tool file. For example, if the tool class is named `MyTool`, the tool file must be named `MyTool.py`.
   - **Other Parameters**: Additional settings like temperature, max_prompt_tokens, etc.

   Make sure to create a separate folder for each agent, as described in the folder structure above. After creating the agent, you need to import it into the agency.py file.

2. **Create an `instructions.md` file in the agent's folder.**

   Each agent also needs to have an `instructions.md` file, which is the system prompt for the agent. Inside those instructions, you need to define the following:

   - **Agent Role**: A description of the role of the agent.
   - **Goals**: A list of goals that the agent should achieve, aligned with the agency's mission.
   - **Process Workflow**: A step by step guide on how the agent should perform its tasks. Each step must be aligned with the other agents in the agency, and with the tools available to this agent.

   Use the following template for the instructions.md file:

   ```md
    # Role
    You are **[insert role, e.g., "a helpful expert" or "a creative storyteller".]**

    # Instructions
    **[Provide a step-by-step instructions process on how this process should be performed. Use a numbered list.]**

    # Additional Notes
    - **[Specify any additional notes here, if any. Use bullet points if needed.]**
    ```

### Best Practices

   **Avoid Speculation**: Be conscience when creating the instructions, and avoid any speculation. If certain information is not available, simply leave it blank.

# Step 5: Agency Creation

Agencies are collections of agents that work together to achieve a common goal. They are defined in the `agency.py` file, which you need to create in the agency folder.

1. **Create an `agency.py` file in the agency folder.**

   To create an agency, import `Agency` from `agency_swarm` and create a class that inherits from `Agency`. Import all agents from the agency folder.

   ```python
   from agency_swarm import Agency
   from CEO import CEO
   from Developer import Developer
   from VirtualAssistant import VirtualAssistant
   from dotenv import load_dotenv

   load_dotenv()

   dev = Developer()
   va = VirtualAssistant()

   agency = Agency([
           ceo,  # CEO will be the entry point for communication with the user
           [ceo, dev],  # CEO can initiate communication with Developer
           [ceo, va],   # CEO can initiate communication with Virtual Assistant
           [dev, va]    # Developer can initiate communication with Virtual Assistant
           ],
           shared_instructions='agency_manifesto.md', #shared instructions for all agents
           temperature=0.5, # default temperature for all agents
           max_prompt_tokens=25000 # default max tokens in conversation history
   )

   if __name__ == "__main__":
       agency.run_demo() # starts the agency in terminal
   ```

   **A Note on Communication Flows**:

   In Agency Swarm, communication flows are directional, meaning they are established from left to right in the `agency_chart` definition. For instance, in the example above, the CEO can initiate a chat with the developer (dev), and the developer can respond in this chat. However, the developer cannot initiate a chat with the CEO. The developer can initiate a chat with the virtual assistant (va) and assign new tasks.

   To allow agents to communicate with each other, simply add them in the second level list inside the `agency_chart` like this: `[ceo, dev], [ceo, va], [dev, va]`. The agent on the left will be able to communicate with the agent on the right.

2. **Define the `agency_manifesto.md` file.**

   Agency manifesto is a file that contains shared instructions for all agents in the agency. It is a markdown file that is located in the agency folder. Please write the manifesto file when creating a new agency. Include the following details:

   - **Agency Description**: A brief description of the agency.
   - **Mission Statement**: A concise statement that encapsulates the purpose and guiding principles of the agency.
   - **Context**: Additional information provided by the user. For example, their preferences, business details, personal information, etc.

# Step 6: Testing

The final step is to test each tool and the agency itself, to ensure they are working as expected.

1. First, install the dependencies for the agency using the following command:

   ```bash
   pip install -r agency_name/requirements.txt
   ```

2. Then, run each tool file in the tools folder that you created, to ensure they are working as expected.

   ```bash
   python agency_name/agent_name/tools/tool_name.py
   ```

   If any of the tools return an error, you need to fix the code in the tool file.

3. Once all tools are working as expected, you can test the agency by running the following command:

   ```bash
   python agency_name/agency.py
   ```

   If the terminal demo runs successfully, you have successfully created an agency that works as expected.

**Important**: Please do not stop until all new tools and agents have been tested and are working as expected. Do not ask for confirmation or wait for the user to respond. Just keep iterating until the agency performs as expected.

# Step 7: Iteration

Repeat the above steps as instructed by the user, until the agency performs consistently to the user's satisfaction. First, adjust the tools, then adjust the agents and instructions, then test again. Make sure to repeat each step accordingly.

# Final Notes

- NEVER output code snippets or file contents in the chat. Always create or modify the actual files in the file system. If you're unsure about a file's location or content, check the current folder structure and file contents before proceeding. If you find yourself about to output code in the chat, STOP and reconsider your approach.

- When creating or modifying files:

1. Use the appropriate file creation or modification syntax (e.g., ```python:path/to/file.py for Python files).
2. Write the full content of the file, not just snippets or placeholders.
3. Ensure all necessary imports and dependencies are included.
4. Follow the specified file creation order rigorously: 1. tools, 2. agents, 3. agency, 4. requirements.txt.


================================================
FILE: .pre-commit-config.yaml
================================================
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v5.0.0
    hooks:
      - id: trailing-whitespace
      - id: end-of-file-fixer
      - id: check-yaml
      - id: check-toml
      - id: debug-statements
        language_version: python3

  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.7.4
    hooks:
      - id: ruff
        args: [--fix, --select=I]
      - id: ruff-format



================================================
FILE: .prettierignore
================================================
*.mdx
*.md


================================================
FILE: agency_swarm/__init__.py
================================================
from .agency import Agency
from .agents import Agent
from .tools import BaseTool
from .util import (
    get_callback_handler,
    get_openai_client,
    init_tracking,
    llm_validator,
    set_openai_client,
    set_openai_key,
)
from .util.streaming import AgencyEventHandler

__all__ = [
    "Agency",
    "AgencyEventHandler",
    "Agent",
    "BaseTool",
    "get_callback_handler",
    "get_openai_client",
    "init_tracking",
    "llm_validator",
    "set_openai_client",
    "set_openai_key",
]



================================================
FILE: agency_swarm/cli.py
================================================
import argparse
import os

from dotenv import load_dotenv

from agency_swarm.util.helpers import list_available_agents


def main():
    parser = argparse.ArgumentParser(description="Agency Swarm CLI.")

    subparsers = parser.add_subparsers(
        dest="command", help="Utility commands to simplify the agent creation process."
    )
    subparsers.required = True

    # create-agent-template
    create_parser = subparsers.add_parser(
        "create-agent-template", help="Create agent template folder locally."
    )
    create_parser.add_argument(
        "--path", type=str, default="./", help="Path to create agent folder."
    )
    create_parser.add_argument(
        "--use_txt",
        action="store_true",
        default=False,
        help="Use txt instead of md for instructions and manifesto.",
    )
    create_parser.add_argument("--name", type=str, help="Name of agent.")
    create_parser.add_argument("--description", type=str, help="Description of agent.")

    # genesis-agency
    genesis_parser = subparsers.add_parser("genesis", help="Start genesis agency.")
    genesis_parser.add_argument(
        "--openai_key", default=None, type=str, help="OpenAI API key."
    )
    genesis_parser.add_argument(
        "--with_browsing",
        default=False,
        action="store_true",
        help="Enable browsing agent.",
    )

    # import-agent
    import_parser = subparsers.add_parser(
        "import-agent", help="Import pre-made agent by name to a local directory."
    )
    available_agents = list_available_agents()
    import_parser.add_argument(
        "--name",
        type=str,
        required=True,
        choices=available_agents,
        help="Name of the agent to import.",
    )
    import_parser.add_argument(
        "--destination",
        type=str,
        default="./",
        help="Destination path to copy the agent files.",
    )

    args = parser.parse_args()

    if args.command == "create-agent-template":
        from agency_swarm.util import create_agent_template

        create_agent_template(args.name, args.description, args.path, args.use_txt)
    elif args.command == "genesis":
        load_dotenv()
        if not os.getenv("OPENAI_API_KEY") and not args.openai_key:
            print(
                "OpenAI API key not set. "
                "Please set it with --openai_key argument or by setting OPENAI_API_KEY environment variable."
            )
            return

        if args.openai_key:
            from agency_swarm import set_openai_key

            set_openai_key(args.openai_key)

        from agency_swarm.agency.genesis import GenesisAgency

        agency = GenesisAgency(with_browsing=args.with_browsing)
        agency.run_demo()
    elif args.command == "import-agent":
        from agency_swarm.util import import_agent

        import_agent(args.name, args.destination)


if __name__ == "__main__":
    main()



================================================
FILE: agency_swarm/constants.py
================================================
DEFAULT_MODEL = "gpt-4o"
DEFAULT_MODEL_MINI = "gpt-4o-mini"



================================================
FILE: agency_swarm/agency/__init__.py
================================================
from .agency import Agency



================================================
FILE: agency_swarm/agency/agency.py
================================================
import asyncio
import inspect
import json
import logging
import os
import atexit
import queue
import threading
import uuid
from enum import Enum
from typing import (
    Any,
    Callable,
    Dict,
    Generator,
    List,
    Literal,
    Type,
    TypedDict,
    TypeVar,
    Union,
)

from openai.lib._parsing._completions import type_to_response_format_param
from openai.types.beta import AssistantToolChoice
from openai.types.beta.threads.message import Attachment
from pydantic import BaseModel, Field, field_validator
from rich.console import Console

from agency_swarm.agents import Agent
from agency_swarm.messages.message_output import MessageOutput
from agency_swarm.threads import Thread
from agency_swarm.threads.thread_async import ThreadAsync
from agency_swarm.tools import BaseTool, CodeInterpreter, FileSearch
from agency_swarm.tools.send_message import SendMessage, SendMessageBase
from agency_swarm.user import User
from agency_swarm.util.errors import RefusalError
from agency_swarm.util.files import get_file_purpose, get_tools
from agency_swarm.util.shared_state import SharedState
from agency_swarm.util.streaming import (
    AgencyEventHandler,
    create_gradio_handler,
    create_term_handler,
)
from agency_swarm.util.tracking.tracking_manager import TrackingManager

from dotenv import load_dotenv

load_dotenv(".env")

console = Console()
T = TypeVar("T", bound=BaseModel)

logger = logging.getLogger(__name__)


class SettingsCallbacks(TypedDict):
    load: Callable[[], List[Dict]]
    save: Callable[[List[Dict]], Any]


class ThreadsCallbacks(TypedDict):
    load: Callable[[], Dict]
    save: Callable[[Dict], Any]


class Agency:
    def __init__(
        self,
        agency_chart: List,
        name: str = None,
        shared_instructions: str = "",
        shared_files: Union[str, List[str]] = None,
        async_mode: Literal["threading", "tools_threading"] = None,
        send_message_tool_class: Type[SendMessageBase] = SendMessage,
        settings_path: str = "./settings.json",
        settings_callbacks: SettingsCallbacks = None,
        threads_callbacks: ThreadsCallbacks = None,
        temperature: float = 0.3,
        top_p: float = 1.0,
        max_prompt_tokens: int = None,
        max_completion_tokens: int = None,
        truncation_strategy: dict = None,
    ):
        """
        Initializes the Agency object, setting up agents, threads, and core functionalities.

        Parameters:
            agency_chart: The structure defining the hierarchy and interaction of agents within the agency.
            name (str, optional): The name of the agency. Used for identification and routing. Defaults to None.
            shared_instructions (str, optional): A path to a file containing shared instructions for all agents. Defaults to an empty string.
            shared_files (Union[str, List[str]], optional): A path to a folder or a list of folders containing shared files for all agents. Defaults to None.
            async_mode (str, optional): Specifies the mode for asynchronous processing. In "threading" mode, all sub-agents run in separate threads. In "tools_threading" mode, all tools run in separate threads, but agents do not. Defaults to None.
            send_message_tool_class (Type[SendMessageBase], optional): The class to use for the send_message tool. For async communication, use `SendMessageAsyncThreading`. Defaults to SendMessage.
            settings_path (str, optional): The path to the settings file for the agency. Must be json. If file does not exist, it will be created. Defaults to None.
            settings_callbacks (SettingsCallbacks, optional): A dictionary containing functions to load and save settings for the agency. The keys must be "load" and "save". Both values must be defined. Defaults to None.
            threads_callbacks (ThreadsCallbacks, optional): A dictionary containing functions to load and save threads for the agency. The keys must be "load" and "save". Both values must be defined. Defaults to None.
            temperature (float, optional): The temperature value to use for the agents. Agent-specific values will override this. Defaults to 0.3.
            top_p (float, optional): The top_p value to use for the agents. Agent-specific values will override this. Defaults to None.
            max_prompt_tokens (int, optional): The maximum number of tokens allowed in the prompt for each agent. Agent-specific values will override this. Defaults to None.
            max_completion_tokens (int, optional): The maximum number of tokens allowed in the completion for each agent. Agent-specific values will override this. Defaults to None.
            truncation_strategy (dict, optional): The truncation strategy to use for the completion for each agent. Agent-specific values will override this. Defaults to None.

        This constructor initializes various components of the Agency, including CEO, agents, threads, and user interactions. It parses the agency chart to set up the organizational structure and initializes the messaging tools, agents, and threads necessary for the operation of the agency. Additionally, it prepares a main thread for user interactions.
        """
        self.name = name
        self.ceo = None
        self.user = User()
        self.agents = []
        self.agents_and_threads = {}
        self.main_recipients = []
        self.main_thread = None
        self.recipient_agents = None  # for autocomplete
        self.shared_files = shared_files if shared_files else []
        self.async_mode = async_mode
        self.send_message_tool_class = send_message_tool_class
        self.settings_path = settings_path
        self.settings_callbacks = settings_callbacks
        self.threads_callbacks = threads_callbacks
        self.temperature = temperature
        self.top_p = top_p
        self.max_prompt_tokens = max_prompt_tokens
        self.max_completion_tokens = max_completion_tokens
        self.truncation_strategy = truncation_strategy

        # set thread type based send_message_tool_class async mode
        if (
            hasattr(send_message_tool_class.ToolConfig, "async_mode")
            and send_message_tool_class.ToolConfig.async_mode
        ):
            self._thread_type = ThreadAsync
        else:
            self._thread_type = Thread

        if self.async_mode == "threading":
            from agency_swarm.tools.send_message import SendMessageAsyncThreading

            logger.warning(
                "'threading' mode is deprecated. Please use send_message_tool_class = SendMessageAsyncThreading to use async communication."
            )
            self.send_message_tool_class = SendMessageAsyncThreading
        elif self.async_mode == "tools_threading":
            Thread.async_mode = "tools_threading"
            logger.warning(
                "'tools_threading' mode is deprecated. Use tool.ToolConfig.async_mode = 'threading' instead."
            )
        elif self.async_mode is None:
            pass
        else:
            raise Exception(
                "Please select async_mode = 'threading' or 'tools_threading'."
            )

        if os.path.isfile(
            os.path.join(self._get_class_folder_path(), shared_instructions)
        ):
            self._read_instructions(
                os.path.join(self._get_class_folder_path(), shared_instructions)
            )
        elif os.path.isfile(shared_instructions):
            self._read_instructions(shared_instructions)
        else:
            self.shared_instructions = shared_instructions

        self.shared_state = SharedState()

        self._parse_agency_chart(agency_chart)
        self._init_threads()
        self._create_special_tools()
        self._init_agents()

        atexit.register(self.mcp_cleanup)

        self.tracking_manager = TrackingManager()

    def get_completion(
        self,
        message: str | list[dict],
        message_files: list[str] | None = None,
        yield_messages: bool = False,
        recipient_agent: Agent | None = None,
        additional_instructions: str | None = None,
        attachments: list[Attachment] | None = None,
        tool_choice: AssistantToolChoice | None = None,
        verbose: bool = False,
        response_format: dict | None = None,
    ) -> Generator[MessageOutput, None, str] | str:
        """
        Retrieves the completion for a given message from the main thread.

        Parameters:
            message (str | list[dict]): A message or an array of messages (following openai format: https://platform.openai.com/docs/api-reference/messages/createMessage) for which completion is to be retrieved.
            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.
            yield_messages (bool, optional): Flag to determine if intermediate messages should be yielded. Defaults to False.
            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.
            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.
            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.
            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.
            verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.
            response_format (dict, optional): The response format to use for the completion.

        Returns:
            Generator or final response: Depending on the 'yield_messages' flag, this method returns either a generator yielding intermediate messages (when yield_messages=True) or the final response from the main thread.
        """
        if verbose and yield_messages:
            raise Exception("Verbose mode is not compatible with yield_messages=True")

        chain_id = self.tracking_manager.start_chain(message, "Agency: chain start")

        try:
            res = self.main_thread.get_completion(
                message=message,
                message_files=message_files,
                attachments=attachments,
                recipient_agent=recipient_agent,
                additional_instructions=additional_instructions,
                tool_choice=tool_choice,
                yield_messages=yield_messages or verbose,
                response_format=response_format,
                parent_run_id=chain_id,
            )

            if not yield_messages and not verbose:
                while True:
                    try:
                        message = next(res)
                    except StopIteration as e:
                        final_output = e.value
                        self.tracking_manager.end_chain(final_output, chain_id)
                        return final_output

            def wrapped_generator():
                while True:
                    try:
                        message = next(res)
                        yield message
                    except StopIteration as e:
                        self.tracking_manager.end_chain(e.value, chain_id)
                        return e.value

            return wrapped_generator()

        except Exception as e:
            self.tracking_manager.track_chain_error(e, chain_id)
            raise e

    def get_completion_stream(
        self,
        message: str | list[dict],
        event_handler: Type[AgencyEventHandler],
        message_files: list[str] | None = None,
        recipient_agent: Agent | None = None,
        additional_instructions: str | None = None,
        attachments: list[Attachment] | None = None,
        tool_choice: dict | None = None,
        response_format: dict | None = None,
    ) -> str:
        """
        Generates a stream of completions for a given message from the main thread.

        Parameters:
            message (str | list[dict]): A message or an array of messages (following openai format: https://platform.openai.com/docs/api-reference/messages/createMessage) for which completion is to be retrieved.
            event_handler (Type[AgencyEventHandler]): The event handler class to handle the completion stream. https://github.com/openai/openai-python/blob/main/helpers.md
            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.
            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.
            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.
            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.
            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.

        Returns:
            Final response: Final response from the main thread.
        """
        if not inspect.isclass(event_handler):
            raise Exception("Event handler must not be an instance.")

        chain_id = self.tracking_manager.start_chain(message, "Agency: chain start")

        res = self.main_thread.get_completion_stream(
            message=message,
            event_handler=event_handler,
            message_files=message_files,
            attachments=attachments,
            recipient_agent=recipient_agent,
            additional_instructions=additional_instructions,
            tool_choice=tool_choice,
            response_format=response_format,
            parent_run_id=chain_id,
        )

        while True:
            try:
                next(res)
            except StopIteration as e:
                event_handler.on_all_streams_end()
                self.tracking_manager.end_chain(e.value, chain_id)

                return e.value
            except Exception as e:
                self.tracking_manager.track_chain_error(e, chain_id)
                raise e

    def get_completion_parse(
        self,
        message: str,
        response_format: Type[T],
        message_files: List[str] = None,
        recipient_agent: Agent = None,
        additional_instructions: str = None,
        attachments: List[dict] = None,
        tool_choice: dict = None,
        verbose: bool = False,
    ) -> T:
        """
        Retrieves the completion for a given message from the main thread and parses the response using the provided pydantic model.

        Parameters:
            message (str): The message for which completion is to be retrieved.
            response_format (Type[BaseModel]): The response format to use for the completion.
            message_files (list, optional): A list of file ids to be sent as attachments with the message. When using this parameter, files will be assigned both to file_search and code_interpreter tools if available. It is recommended to assign files to the most sutiable tool manually, using the attachments parameter.  Defaults to None.
            recipient_agent (Agent, optional): The agent to which the message should be sent. Defaults to the first agent in the agency chart.
            additional_instructions (str, optional): Additional instructions to be sent with the message. Defaults to None.
            attachments (List[dict], optional): A list of attachments to be sent with the message, following openai format. Defaults to None.
            tool_choice (dict, optional): The tool choice for the recipient agent to use. Defaults to None.
            verbose (bool, optional): Whether to print the intermediary messages in console. Defaults to False.

        Returns:
            Final response: The final response from the main thread, parsed using the provided pydantic model.
        """
        response_model = None
        if isinstance(response_format, type):
            response_model = response_format
            response_format = type_to_response_format_param(response_format)

        res = self.get_completion(
            message=message,
            message_files=message_files,
            recipient_agent=recipient_agent,
            additional_instructions=additional_instructions,
            attachments=attachments,
            tool_choice=tool_choice,
            response_format=response_format,
            verbose=verbose,
        )

        try:
            return response_model.model_validate_json(res)
        except:
            parsed_res = json.loads(res)
            if "refusal" in parsed_res:
                raise RefusalError(parsed_res["refusal"])
            else:
                raise Exception("Failed to parse response: " + res)

    def demo_gradio(self, height=450, dark_mode=True, **kwargs):
        """
        Launches a Gradio-based demo interface for the agency chatbot.

        Parameters:
            height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 450.
            dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.
            **kwargs: Additional keyword arguments to be passed to the Gradio interface.
        This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.
        """

        try:
            import gradio as gr
        except ImportError:
            raise Exception("Please install gradio: pip install gradio")

        js = """function () {
            gradioURL = window.location.href
            if (!gradioURL.endsWith('?__theme={theme}')) {
                window.location.replace(gradioURL + '?__theme={theme}');
            }
        }"""

        if dark_mode:
            js = js.replace("{theme}", "dark")
        else:
            js = js.replace("{theme}", "light")

        attachments = []
        images = []
        message_file_names = None
        uploading_files = False
        recipient_agent_names = [agent.name for agent in self.main_recipients]
        recipient_agent = self.main_recipients[0]

        chatbot_queue = queue.Queue()
        gradio_handler_class = create_gradio_handler(chatbot_queue=chatbot_queue)

        with gr.Blocks(js=js) as demo:
            chatbot = gr.Chatbot(height=height)
            with gr.Row():
                with gr.Column(scale=9):
                    dropdown = gr.Dropdown(
                        label="Recipient Agent",
                        choices=recipient_agent_names,
                        value=recipient_agent.name,
                    )
                    msg = gr.Textbox(label="Your Message", lines=4)
                with gr.Column(scale=1):
                    file_upload = gr.Files(label="OpenAI Files", type="filepath")
            button = gr.Button(value="Send", variant="primary")

            def handle_dropdown_change(selected_option):
                nonlocal recipient_agent
                recipient_agent = self._get_agent_by_name(selected_option)

            def handle_file_upload(file_list):
                nonlocal attachments
                nonlocal message_file_names
                nonlocal uploading_files
                nonlocal images
                uploading_files = True
                attachments = []
                message_file_names = []
                if file_list:
                    try:
                        for file_obj in file_list:
                            purpose = get_file_purpose(file_obj.name)

                            with open(file_obj.name, "rb") as f:
                                # Upload the file to OpenAI
                                file = self.main_thread.client.files.create(
                                    file=f, purpose=purpose
                                )

                            if purpose == "vision":
                                images.append(
                                    {
                                        "type": "image_file",
                                        "image_file": {"file_id": file.id},
                                    }
                                )
                            else:
                                attachments.append(
                                    {
                                        "file_id": file.id,
                                        "tools": get_tools(file.filename),
                                    }
                                )

                            message_file_names.append(file.filename)
                            logger.info(f"Uploaded file ID: {file.id}")
                        return attachments
                    except Exception as e:
                        logger.error(f"Error: {e}", exc_info=True)
                        return str(e)
                    finally:
                        uploading_files = False

                uploading_files = False
                return "No files uploaded"

            def user(user_message, history):
                if not user_message.strip():
                    return user_message, history

                nonlocal message_file_names
                nonlocal uploading_files
                nonlocal images
                nonlocal attachments
                nonlocal recipient_agent

                # Check if attachments contain file search or code interpreter types
                def check_and_add_tools_in_attachments(attachments, recipient_agent):
                    for attachment in attachments:
                        for tool in attachment.get("tools", []):
                            if tool["type"] == "file_search":
                                if not any(
                                    isinstance(t, FileSearch)
                                    for t in recipient_agent.tools
                                ):
                                    # Add FileSearch tool if it does not exist
                                    recipient_agent.tools.append(FileSearch)
                                    recipient_agent.client.beta.assistants.update(
                                        recipient_agent.id,
                                        tools=recipient_agent.get_oai_tools(),
                                    )
                                    logger.info(
                                        "Added FileSearch tool to recipient agent to analyze the file."
                                    )
                            elif tool["type"] == "code_interpreter":
                                if not any(
                                    isinstance(t, CodeInterpreter)
                                    for t in recipient_agent.tools
                                ):
                                    # Add CodeInterpreter tool if it does not exist
                                    recipient_agent.tools.append(CodeInterpreter)
                                    recipient_agent.client.beta.assistants.update(
                                        recipient_agent.id,
                                        tools=recipient_agent.get_oai_tools(),
                                    )
                                    logger.info(
                                        "Added CodeInterpreter tool to recipient agent to analyze the file."
                                    )
                    return None

                check_and_add_tools_in_attachments(attachments, recipient_agent)

                if history is None:
                    history = []

                original_user_message = user_message

                # Append the user message with a placeholder for bot response
                if recipient_agent:
                    user_message = (
                        f"ðŸ‘¤ User ðŸ—£ï¸ @{recipient_agent.name}:\n" + user_message.strip()
                    )
                else:
                    user_message = "ðŸ‘¤ User:" + user_message.strip()

                if message_file_names:
                    user_message += "\n\nðŸ“Ž Files:\n" + "\n".join(message_file_names)

                return original_user_message, history + [[user_message, None]]

            def bot(original_message, history, dropdown):
                nonlocal attachments
                nonlocal message_file_names
                nonlocal recipient_agent
                nonlocal recipient_agent_names
                nonlocal images
                nonlocal uploading_files

                if not original_message:
                    return (
                        "",
                        history,
                        gr.update(
                            value=recipient_agent.name,
                            choices=set([*recipient_agent_names, recipient_agent.name]),
                        ),
                    )

                if uploading_files:
                    history.append([None, "Uploading files... Please wait."])
                    yield (
                        "",
                        history,
                        gr.update(
                            value=recipient_agent.name,
                            choices=set([*recipient_agent_names, recipient_agent.name]),
                        ),
                    )
                    return (
                        "",
                        history,
                        gr.update(
                            value=recipient_agent.name,
                            choices=set([*recipient_agent_names, recipient_agent.name]),
                        ),
                    )

                logger.info(f"Message files: {attachments}")
                logger.info(f"Images: {images}")

                if images and len(images) > 0:
                    original_message = [
                        {
                            "type": "text",
                            "text": original_message,
                        },
                        *images,
                    ]

                completion_thread = threading.Thread(
                    target=self.get_completion_stream,
                    args=(
                        original_message,
                        gradio_handler_class,
                        [],
                        recipient_agent,
                        "",
                        attachments,
                        None,
                    ),
                )
                completion_thread.start()

                attachments = []
                message_file_names = []
                images = []
                uploading_files = False

                new_message = True
                while True:
                    try:
                        bot_message = chatbot_queue.get(block=True)

                        if bot_message == "[end]":
                            completion_thread.join()
                            break

                        if bot_message == "[new_message]":
                            new_message = True
                            continue

                        if bot_message == "[change_recipient_agent]":
                            new_agent_name = chatbot_queue.get(block=True)
                            recipient_agent = self._get_agent_by_name(new_agent_name)
                            yield (
                                "",
                                history,
                                gr.update(
                                    value=new_agent_name,
                                    choices=set(
                                        [*recipient_agent_names, recipient_agent.name]
                                    ),
                                ),
                            )
                            continue

                        if new_message:
                            history.append([None, bot_message])
                            new_message = False
                        else:
                            history[-1][1] += bot_message

                        yield (
                            "",
                            history,
                            gr.update(
                                value=recipient_agent.name,
                                choices=set(
                                    [*recipient_agent_names, recipient_agent.name]
                                ),
                            ),
                        )
                    except queue.Empty:
                        break

            button.click(user, inputs=[msg, chatbot], outputs=[msg, chatbot]).then(
                bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]
            )
            dropdown.change(handle_dropdown_change, dropdown)
            file_upload.change(handle_file_upload, file_upload)
            msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
                bot, [msg, chatbot, dropdown], [msg, chatbot, dropdown]
            )

            # Enable queuing for streaming intermediate outputs
            demo.queue(default_concurrency_limit=10)

            # Workaround for bug caused by mcp tool usage
            # TODO: Find the root cause and fix it
            if hasattr(demo, "_queue"):
                if getattr(demo._queue, "pending_message_lock", None) is None:
                    demo._queue.pending_message_lock = asyncio.Lock()
                if getattr(demo._queue, "delete_lock", None) is None:
                    demo._queue.delete_lock = asyncio.Lock()

        # Launch the demo
        demo.launch(**kwargs)
        return demo

    def _setup_autocomplete(self):
        """
        Sets up readline with the completer function.
        """
        try:
            import readline
        except ImportError:
            # Attempt to import pyreadline for Windows compatibility
            try:
                import pyreadline as readline
            except ImportError:
                logger.warning(
                    "Module 'readline' not found. Autocomplete will not work. If you are using Windows, try installing 'pyreadline3'."
                )
                return

        if not readline:
            return

        def recipient_agent_completer(text, state):
            """
            Autocomplete completer for recipient agent names.
            """
            options = [
                agent
                for agent in self.recipient_agents
                if agent.lower().startswith(text.lower())
            ]
            if state < len(options):
                return options[state]
            else:
                return None

        try:
            readline.set_completer(recipient_agent_completer)
            readline.parse_and_bind("tab: complete")
        except Exception as e:
            logger.error(
                f"Error setting up autocomplete for agents in terminal: {e}. Autocomplete will not work.",
                exc_info=True,
            )

    def run_demo(self):
        """
        Executes agency in the terminal with autocomplete for recipient agent names.
        """
        term_handler_class = create_term_handler(agency=self)

        self.recipient_agents = [str(agent.name) for agent in self.main_recipients]

        self._setup_autocomplete()  # Prepare readline for autocomplete

        while True:
            console.rule()
            text = input("ðŸ‘¤ USER: ")

            if not text:
                continue

            if text.lower() == "exit":
                break

            recipient_agent = None
            if "@" in text:
                recipient_agent = text.split("@")[1].split(" ")[0]
                text = text.replace(f"@{recipient_agent}", "").strip()
                try:
                    recipient_agent = [
                        agent
                        for agent in self.recipient_agents
                        if agent.lower() == recipient_agent.lower()
                    ][0]
                    recipient_agent = self._get_agent_by_name(recipient_agent)
                except Exception as e:
                    logger.error(
                        f"Recipient agent {recipient_agent} not found.", exc_info=True
                    )
                    continue

            self.get_completion_stream(
                message=text,
                event_handler=term_handler_class,
                recipient_agent=recipient_agent,
            )

    def get_customgpt_schema(self, url: str):
        """Returns the OpenAPI schema for the agency from the CEO agent, that you can use to integrate with custom gpts.

        Parameters:
            url (str): Your server url where the api will be hosted.
        """

        return self.ceo.get_openapi_schema(url)

    def plot_agency_chart(self):
        pass

    def _init_agents(self):
        """
        Initializes all agents in the agency with unique IDs, shared instructions, and OpenAI models.

        This method iterates through each agent in the agency, assigns a unique ID, adds shared instructions, and initializes the OpenAI models for each agent.

        There are no input parameters.

        There are no output parameters as this method is used for internal initialization purposes within the Agency class.
        """
        if self.settings_callbacks:
            loaded_settings = self.settings_callbacks["load"]()
            with open(self.settings_path, "w") as f:
                json.dump(loaded_settings, f, indent=4)

        for agent in self.agents:
            if "temp_id" in agent.id:
                agent.id = None

            agent.add_shared_instructions(self.shared_instructions)
            agent.settings_path = self.settings_path

            if self.shared_files:
                if isinstance(self.shared_files, str):
                    self.shared_files = [self.shared_files]

                if isinstance(agent.files_folder, str):
                    agent.files_folder = [agent.files_folder]
                    agent.files_folder += self.shared_files
                elif isinstance(agent.files_folder, list):
                    agent.files_folder += self.shared_files

            if self.temperature is not None and agent.temperature is None:
                agent.temperature = self.temperature
            if self.top_p and agent.top_p is None:
                agent.top_p = self.top_p
            if self.max_prompt_tokens is not None and agent.max_prompt_tokens is None:
                agent.max_prompt_tokens = self.max_prompt_tokens
            if (
                self.max_completion_tokens is not None
                and agent.max_completion_tokens is None
            ):
                agent.max_completion_tokens = self.max_completion_tokens
            if (
                self.truncation_strategy is not None
                and agent.truncation_strategy is None
            ):
                agent.truncation_strategy = self.truncation_strategy

            if not agent.shared_state:
                agent.shared_state = self.shared_state

            agent.init_oai()

        if self.settings_callbacks:
            with open(self.agents[0].get_settings_path(), "r") as f:
                settings = f.read()
            settings = json.loads(settings)
            self.settings_callbacks["save"](settings)

    def _init_threads(self):
        """
        Initializes threads for communication between agents within the agency.

        This method creates Thread objects for each pair of interacting agents as defined in the agents_and_threads attribute of the Agency. Each thread facilitates communication and task execution between an agent and its designated recipient agent.

        No input parameters.

        Output Parameters:
            This method does not return any value but updates the agents_and_threads attribute with initialized Thread objects.
        """
        self.main_thread = Thread(self.user, self.ceo)

        # load thread ids
        loaded_thread_ids = {}
        if self.threads_callbacks:
            loaded_thread_ids = self.threads_callbacks["load"]()
            if "main_thread" in loaded_thread_ids and loaded_thread_ids["main_thread"]:
                self.main_thread.id = loaded_thread_ids["main_thread"]
            else:
                self.main_thread.init_thread()

        # Save main_thread into agents_and_threads
        self.agents_and_threads["main_thread"] = self.main_thread

        # initialize threads
        for agent_name, threads in self.agents_and_threads.items():
            if agent_name == "main_thread":
                continue
            for other_agent, items in threads.items():
                # create thread class
                self.agents_and_threads[agent_name][other_agent] = self._thread_type(
                    self._get_agent_by_name(items["agent"]),
                    self._get_agent_by_name(items["recipient_agent"]),
                )

                # load thread id if available
                if (
                    agent_name in loaded_thread_ids
                    and other_agent in loaded_thread_ids[agent_name]
                ):
                    self.agents_and_threads[agent_name][
                        other_agent
                    ].id = loaded_thread_ids[agent_name][other_agent]
                # init threads if threre are threads callbacks so the ids are saved for later use
                elif self.threads_callbacks:
                    self.agents_and_threads[agent_name][other_agent].init_thread()

        # save thread ids
        if self.threads_callbacks:
            loaded_thread_ids = {}
            for agent_name, threads in self.agents_and_threads.items():
                if agent_name == "main_thread":
                    continue
                loaded_thread_ids[agent_name] = {}
                for other_agent, thread in threads.items():
                    loaded_thread_ids[agent_name][other_agent] = thread.id

            loaded_thread_ids["main_thread"] = self.main_thread.id

            self.threads_callbacks["save"](loaded_thread_ids)

    def _parse_agency_chart(self, agency_chart):
        """
        Parses the provided agency chart to initialize and organize agents within the agency.

        Parameters:
            agency_chart: A structure representing the hierarchical organization of agents within the agency.
                    It can contain Agent objects and lists of Agent objects.

        This method iterates through each node in the agency chart. If a node is an Agent, it is set as the CEO if not already assigned.
        If a node is a list, it iterates through the agents in the list, adding them to the agency and establishing communication
        threads between them. It raises an exception if the agency chart is invalid or if multiple CEOs are defined.
        """
        if not isinstance(agency_chart, list):
            raise Exception("Invalid agency chart.")

        if len(agency_chart) == 0:
            raise Exception("Agency chart cannot be empty.")

        for node in agency_chart:
            if isinstance(node, Agent):
                if not self.ceo:
                    self.ceo = node
                    self._add_agent(self.ceo)
                else:
                    self._add_agent(node)
                self._add_main_recipient(node)

            elif isinstance(node, list):
                for i, agent in enumerate(node):
                    if not isinstance(agent, Agent):
                        raise Exception("Invalid agency chart.")

                    index = self._add_agent(agent)

                    if i == len(node) - 1:
                        continue

                    if agent.name not in self.agents_and_threads.keys():
                        self.agents_and_threads[agent.name] = {}

                    if i < len(node) - 1:
                        other_agent = node[i + 1]
                        if other_agent.name == agent.name:
                            continue
                        if (
                            other_agent.name
                            not in self.agents_and_threads[agent.name].keys()
                        ):
                            self.agents_and_threads[agent.name][other_agent.name] = {
                                "agent": agent.name,
                                "recipient_agent": other_agent.name,
                            }
            else:
                raise Exception("Invalid agency chart.")

    def _add_agent(self, agent):
        """
        Adds an agent to the agency, assigning a temporary ID if necessary.

        Parameters:
            agent (Agent): The agent to be added to the agency.

        Returns:
            int: The index of the added agent within the agency's agents list.

        This method adds an agent to the agency's list of agents. If the agent does not have an ID, it assigns a temporary unique ID. It checks for uniqueness of the agent's name before addition. The method returns the index of the agent in the agency's agents list, which is used for referencing the agent within the agency.
        """
        if not agent.id:
            # assign temp id
            agent.id = "temp_id_" + str(uuid.uuid4())
        if agent.id not in self._get_agent_ids():
            if agent.name in self._get_agent_names():
                raise Exception("Agent names must be unique.")
            self.agents.append(agent)
            return len(self.agents) - 1
        else:
            return self._get_agent_ids().index(agent.id)

    def _add_main_recipient(self, agent):
        """
        Adds an agent to the agency's list of main recipients.

        Parameters:
            agent (Agent): The agent to be added to the agency's list of main recipients.

        This method adds an agent to the agency's list of main recipients. These are agents that can be directly contacted by the user.
        """
        main_recipient_ids = [agent.id for agent in self.main_recipients]

        if agent.id not in main_recipient_ids:
            self.main_recipients.append(agent)

    def _read_instructions(self, path):
        """
        Reads shared instructions from a specified file and stores them in the agency.

        Parameters:
            path (str): The file path from which to read the shared instructions.

        This method opens the file located at the given path, reads its contents, and stores these contents in the 'shared_instructions' attribute of the agency. This is used to provide common guidelines or instructions to all agents within the agency.
        """
        path = path
        with open(path, "r") as f:
            self.shared_instructions = f.read()

    def _create_special_tools(self):
        """
        Creates and assigns 'SendMessage' tools to each agent based on the agency's structure.

        This method iterates through the agents and threads in the agency, creating SendMessage tools for each agent. These tools enable agents to send messages to other agents as defined in the agency's structure. The SendMessage tools are tailored to the specific recipient agents that each agent can communicate with.

        No input parameters.

        No output parameters; this method modifies the agents' toolset internally.
        """
        for agent_name, threads in self.agents_and_threads.items():
            if agent_name == "main_thread":
                continue
            recipient_names = list(threads.keys())
            recipient_agents = self._get_agents_by_names(recipient_names)
            if len(recipient_agents) == 0:
                continue
            agent = self._get_agent_by_name(agent_name)
            agent.add_tool(self._create_send_message_tool(agent, recipient_agents))
            if self._thread_type == ThreadAsync:
                agent.add_tool(self._create_get_response_tool(agent, recipient_agents))

    def _create_send_message_tool(self, agent: Agent, recipient_agents: List[Agent]):
        """
        Creates a SendMessage tool to enable an agent to send messages to specified recipient agents.


        Parameters:
            agent (Agent): The agent who will be sending messages.
            recipient_agents (List[Agent]): A list of recipient agents who can receive messages.

        Returns:
            SendMessage: A SendMessage tool class that is dynamically created and configured for the given agent and its recipient agents. This tool allows the agent to send messages to the specified recipients, facilitating inter-agent communication within the agency.
        """
        recipient_names = [agent.name for agent in recipient_agents]
        recipients = Enum("recipient", {name: name for name in recipient_names})

        agent_descriptions = ""
        for recipient_agent in recipient_agents:
            if not recipient_agent.description:
                continue
            agent_descriptions += recipient_agent.name + ": "
            agent_descriptions += recipient_agent.description + "\n"

        class SendMessage(self.send_message_tool_class):
            recipient: recipients = Field(..., description=agent_descriptions)

            @field_validator("recipient")
            @classmethod
            def check_recipient(cls, value):
                if value.value not in recipient_names:
                    raise ValueError(
                        f"Recipient {value} is not valid. Valid recipients are: {recipient_names}"
                    )
                return value

        SendMessage._caller_agent = agent
        SendMessage._agents_and_threads = self.agents_and_threads

        return SendMessage

    def _create_get_response_tool(self, agent: Agent, recipient_agents: List[Agent]):
        """
        Creates a CheckStatus tool to enable an agent to check the status of a task with a specified recipient agent.
        """
        recipient_names = [agent.name for agent in recipient_agents]
        recipients = Enum("recipient", {name: name for name in recipient_names})

        outer_self = self

        class GetResponse(BaseTool):
            """This tool allows you to check the status of a task or get a response from a specified recipient agent, if the task has been completed. You must always use 'SendMessage' tool with the designated agent first."""

            recipient: recipients = Field(
                ...,
                description=f"Recipient agent that you want to check the status of. Valid recipients are: {recipient_names}",
            )

            @field_validator("recipient")
            def check_recipient(cls, value):
                if value.value not in recipient_names:
                    raise ValueError(
                        f"Recipient {value} is not valid. Valid recipients are: {recipient_names}"
                    )
                return value

            def run(self):
                thread = outer_self.agents_and_threads[self._caller_agent.name][
                    self.recipient.value
                ]

                return thread.check_status()

        GetResponse._caller_agent = agent

        return GetResponse

    def _get_agent_by_name(self, agent_name):
        """
        Retrieves an agent from the agency based on the agent's name.

        Parameters:
            agent_name (str): The name of the agent to be retrieved.

        Returns:
            Agent: The agent object with the specified name.

        Raises:
            Exception: If no agent with the given name is found in the agency.
        """
        for agent in self.agents:
            if agent.name == agent_name:
                return agent
        raise Exception(f"Agent {agent_name} not found.")

    def _get_agents_by_names(self, agent_names):
        """
        Retrieves a list of agent objects based on their names.

        Parameters:
            agent_names: A list of strings representing the names of the agents to be retrieved.

        Returns:
            A list of Agent objects corresponding to the given names.
        """
        return [self._get_agent_by_name(agent_name) for agent_name in agent_names]

    def _get_agent_ids(self):
        """
        Retrieves the IDs of all agents currently in the agency.

        Returns:
            List[str]: A list containing the unique IDs of all agents.
        """
        return [agent.id for agent in self.agents]

    def _get_agent_names(self):
        """
        Retrieves the names of all agents in the agency.

        Returns:
            List[str]: A list of names of all agents currently part of the agency.
        """
        return [agent.name for agent in self.agents]

    def _get_class_folder_path(self):
        """
        Retrieves the absolute path of the directory containing the class file.

        Returns:
            str: The absolute path of the directory where the class file is located.
        """
        return os.path.abspath(os.path.dirname(inspect.getfile(self.__class__)))

    def delete(self):
        """
        This method deletes the agency and all its agents, cleaning up any files and vector stores associated with each agent.
        """
        for agent in self.agents:
            agent.delete()

    def mcp_cleanup(self):
        for agent in self.agents:
            for server in reversed(agent.mcp_servers):
                logger.info(f"Shutting down MCP server: {server.name}")
                server.cleanup()

    def run_fastapi(self, host: str = "0.0.0.0", port: int = 8000, app_token_env: str = "APP_TOKEN"):
        """
        Launch a FastAPI server exposing the agency's completion and streaming endpoints using the shared integrations.fastapi.run_fastapi utility.
        """
        from agency_swarm.integrations.fastapi import run_fastapi
        run_fastapi(agencies=[self], host=host, port=port, app_token_env=app_token_env)


================================================
FILE: agency_swarm/agency/genesis/__init__.py
================================================
from .GenesisAgency import GenesisAgency



================================================
FILE: agency_swarm/agency/genesis/GenesisAgency.py
================================================
from agency_swarm import Agency
from agency_swarm.util.helpers import get_available_agent_descriptions

from .AgentCreator import AgentCreator
from .GenesisCEO import GenesisCEO
from .OpenAPICreator import OpenAPICreator
from .ToolCreator import ToolCreator


class GenesisAgency(Agency):
    def __init__(self, with_browsing=True, **kwargs):
        if "max_prompt_tokens" not in kwargs:
            kwargs["max_prompt_tokens"] = 25000

        if "agency_chart" not in kwargs:
            agent_creator = AgentCreator()
            genesis_ceo = GenesisCEO()
            tool_creator = ToolCreator()
            openapi_creator = OpenAPICreator()
            kwargs["agency_chart"] = [
                genesis_ceo,
                tool_creator,
                agent_creator,
                [genesis_ceo, agent_creator],
                [agent_creator, tool_creator],
            ]

            if with_browsing:
                from agency_swarm.agents.BrowsingAgent import BrowsingAgent

                browsing_agent = BrowsingAgent()

                browsing_agent.instructions += """\n
# BrowsingAgent's Primary instructions
1. Browse the web to find the API documentation requested by the user. Prefer searching google directly for this API documentation page.
2. Navigate to the API documentation page and ensure that it contains the necessary API endpoints descriptions. You can use the AnalyzeContent tool to check if the page contains the necessary API descriptions. If not, try perform another search in google and keep browsing until you find the right page.
3. If you have confirmed that the page contains the necessary API documentation, export the page with ExportFile tool. Then, send the file_id back to the user along with a brief description of the API.
4. Repeat these steps for each new agent, as requested by the user.
                """
                kwargs["agency_chart"].append(openapi_creator)
                kwargs["agency_chart"].append([openapi_creator, browsing_agent])

        if "shared_instructions" not in kwargs:
            kwargs["shared_instructions"] = "./manifesto.md"

        super().__init__(**kwargs)



================================================
FILE: agency_swarm/agency/genesis/manifesto.md
================================================
# Genesis Agency Manifesto

You are a part of a Genesis Agency for a framework called Agency Swarm. The goal of your agency is to create other agencies within this framework. Below is a brief description of the framework.

**Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the AI agent creation process and enable anyone to create a collaborative swarms of agents (Agencies), each with distinct roles and capabilities. These agents must function autonomously, yet collaborate with other agents to achieve a common goal.**

Keep in mind that communication with the other agents within your agency via the `SendMessage` tool is synchronous. Other agents will not be executing any tasks post response. Please instruct the recipient agent to continue its execution, if needed. Do not report to the user before the recipient agent has completed its task. If the agent proposes the next steps, for example, you must instruct the recipient agent to execute them.



================================================
FILE: agency_swarm/agency/genesis/util.py
================================================
import os
from pathlib import Path


def check_agency_path(self):
    if not self._shared_state.get("default_folder"):
        self._shared_state.set("default_folder", Path.cwd())

    if not self._shared_state.get("agency_path") and not self.agency_name:
        available_agencies = os.listdir("./")
        available_agencies = [
            agency for agency in available_agencies if os.path.isdir(agency)
        ]
        raise ValueError(
            f"Please specify an agency. Available agencies are: {available_agencies}"
        )
    elif not self._shared_state.get("agency_path") and self.agency_name:
        if not os.path.exists(os.path.join("./", self.agency_name)):
            available_agencies = os.listdir("./")
            available_agencies = [
                agency for agency in available_agencies if os.path.isdir(agency)
            ]
            raise ValueError(
                f"Agency {self.agency_name} not found. Available agencies are: {available_agencies}"
            )
        self._shared_state.set("agency_path", os.path.join("./", self.agency_name))


def check_agent_path(self):
    agent_path = os.path.join(self._shared_state.get("agency_path"), self.agent_name)
    if not os.path.exists(agent_path):
        available_agents = os.listdir(self._shared_state.get("agency_path"))
        available_agents = [
            agent
            for agent in available_agents
            if os.path.isdir(os.path.join(self._shared_state.get("agency_path"), agent))
        ]
        raise ValueError(
            f"Agent {self.agent_name} not found. Available agents are: {available_agents}"
        )



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/__init__.py
================================================
from .AgentCreator import AgentCreator



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/AgentCreator.py
================================================
from agency_swarm import Agent

from .tools.CreateAgentTemplate import CreateAgentTemplate
from .tools.ImportAgent import ImportAgent
from .tools.ReadManifesto import ReadManifesto


class AgentCreator(Agent):
    def __init__(self):
        super().__init__(
            description="This agent is responsible for creating new agents for the agency.",
            instructions="./instructions.md",
            tools=[ImportAgent, CreateAgentTemplate, ReadManifesto],
            temperature=0.3,
        )



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/instructions.md
================================================
# AgentCreator Agent Instructions

You are an agent that creates other agents as instructed by the user.

The user will communicate to you each agent that needs to be created. Below are your instructions that needs to be followed for each agent communicated by the user.

**Primary Instructions:**
1. First, read the manifesto using `ReadManifesto` tool if you have not already done so. This file contains the agency manifesto that describes the agency's purpose and goals.
2. If a similar agent to the requested one is accessible through the `ImportAgent` tool, import this agent and inform the user that the agent has been created. Skip the following steps.
3. If not, create a new agent using `CreateAgentTemplate` tool.
4. Tell the `ToolCreator` agent to create tools or APIs for this agent. Make sure to also communicate the agent description, name and a summary of the processes that it needs to perform. CEO Agents do not need to utilize any tools, so you can skip this and the following steps.
5. If there are no issues and tools have been successfully created, notify the user that the agent has been created. Otherwise, try to resolve any issues with the tool creator before reporting back to the user.
6. Repeat this process for each agent that needs to be created, as instructed by the user.



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/tools/CreateAgentTemplate.py
================================================
import os
import shutil
from typing import List

from pydantic import Field, model_validator

from agency_swarm import BaseTool
from agency_swarm.agency.genesis.util import check_agency_path
from agency_swarm.util import create_agent_template

allowed_tools: List = ["CodeInterpreter"]

web_developer_example_instructions = """# Web Developer Agent Instructions

You are an agent that builds responsive web applications using Next.js and Material-UI (MUI). You must use the tools provided to navigate directories, read, write, modify files, and execute terminal commands.

### Primary Instructions:
1. Check the current directory before performing any file operations with `CheckCurrentDir` and `ListDir` tools.
2. Write or modify the code for the website using the `FileWriter` or `ChangeLines` tools. Make sure to use the correct file paths and file names. Read the file first if you need to modify it.
3. Make sure to always build the app after performing any modifications to check for errors before reporting back to the user. Keep in mind that all files must be reflected on the current website
4. Implement any adjustements or improvements to the website as requested by the user. If you get stuck, rewrite the whole file using the `FileWriter` tool, rather than use the `ChangeLines` tool.
"""


class CreateAgentTemplate(BaseTool):
    """
    This tool creates a template folder for a new agent. Always use this tool first, before creating tools or APIs for the agent.
    """

    agent_name: str = Field(
        ...,
        description="Name of the agent to be created. Cannot include special characters or spaces.",
    )
    agent_description: str = Field(
        ..., description="Description of the agent to be created."
    )
    instructions: str = Field(
        ...,
        description="Instructions for the agent to be created in markdown format. "
        "Instructions should include a decription of the role and a specific step by step process "
        "that this agent need to perform in order to execute the tasks. "
        "The process must also be aligned with all the other agents in the agency. Agents should be "
        "able to collaborate with each other to achieve the common goal of the agency.",
        examples=[
            web_developer_example_instructions,
        ],
    )
    default_tools: List[str] = Field(
        [],
        description=f"List of default tools to be included in the agent. Possible values are {allowed_tools}."
        f"CodeInterpreter allows the agent to execute python code in a remote python environment.",
        example=["CodeInterpreter"],
    )
    agency_name: str = Field(
        None,
        description="Name of the agency to create the tool for. Defaults to the agency currently being created.",
    )

    def run(self):
        if not self._shared_state.get("manifesto_read"):
            raise ValueError(
                "Please read the manifesto first with the ReadManifesto tool."
            )

        self._shared_state.set("agent_name", self.agent_name)

        os.chdir(self._shared_state.get("agency_path"))

        # remove folder if it already exists
        if os.path.exists(self.agent_name):
            shutil.rmtree(self.agent_name)

        create_agent_template(
            self.agent_name,
            self.agent_description,
            instructions=self.instructions,
            code_interpreter=True if "CodeInterpreter" in self.default_tools else None,
            include_example_tool=False,
        )

        # # create or append to init file
        path = self._shared_state.get("agency_path")
        class_name = self.agent_name.replace(" ", "").strip()
        if not os.path.isfile("__init__.py"):
            with open("__init__.py", "w") as f:
                f.write(f"from .{class_name} import {class_name}")
        else:
            with open("__init__.py", "a") as f:
                f.write(f"\nfrom .{class_name} import {class_name}")

        # add agent on second line to agency.py
        with open("agency.py", "r") as f:
            lines = f.readlines()
            lines.insert(1, f"from {class_name} import {class_name}\n")

        with open("agency.py", "w") as f:
            f.writelines(lines)

        os.chdir(self._shared_state.get("default_folder"))

        if "ceo" in self.agent_name.lower():
            return f"You can tell the user that the process of creating {self.agent_name} has been completed, because CEO agent does not need to utilizie any tools or APIs."

        return f"Agent template has been created for {self.agent_name}. Please now tell ToolCreator to create tools for this agent or OpenAPICreator to create API schemas, if this agent needs to utilize any tools or APIs. If this is unclear, please ask the user for more information."

    @model_validator(mode="after")
    def validate_tools(self):
        check_agency_path(self)

        for tool in self.default_tools:
            if tool not in allowed_tools:
                raise ValueError(
                    f"Tool {tool} is not allowed. Allowed tools are: {allowed_tools}"
                )



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/tools/ImportAgent.py
================================================
import os

from pydantic import Field, field_validator

from agency_swarm import BaseTool
from agency_swarm.util.cli import import_agent
from agency_swarm.util.helpers import (
    get_available_agent_descriptions,
    list_available_agents,
)


class ImportAgent(BaseTool):
    """
    This tool imports an existing agent from agency swarm framework. Please make sure to first use the GetAvailableAgents tool to get the list of available agents.
    """

    agent_name: str = Field(..., description=get_available_agent_descriptions())
    agency_path: str = Field(
        None,
        description="Path to the agency where the agent will be imported. Default is the current agency.",
    )

    def run(self):
        if not self._shared_state.get("default_folder"):
            self._shared_state.set("default_folder", os.getcwd())

        if not self._shared_state.get("agency_path") and not self.agency_path:
            return "Error: You must set the agency_path."

        if self._shared_state.get("agency_path"):
            os.chdir(self._shared_state.get("agency_path"))
        else:
            os.chdir(self.agency_path)

        import_agent(self.agent_name, "./")

        # add agent on second line to agency.py
        with open("agency.py", "r") as f:
            lines = f.readlines()
            lines.insert(1, f"from {self.agent_name} import {self.agent_name}\n")

        with open("agency.py", "w") as f:
            f.writelines(lines)

        os.chdir(self._shared_state.get("default_folder"))

        return (
            f"Success. {self.agent_name} has been imported. "
            f"You can now tell the user to user proceed with next agents."
        )

    @field_validator("agent_name", mode="after")
    @classmethod
    def agent_name_exists(cls, v):
        available_agents = list_available_agents()
        if v not in available_agents:
            raise ValueError(
                f"Agent with name {v} does not exist. Available agents are: {available_agents}"
            )
        return v


if __name__ == "__main__":
    tool = ImportAgent(agent_name="Devid")
    tool._shared_state.set("agency_path", "./")
    tool.run()



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/tools/ReadManifesto.py
================================================
import os

from pydantic import Field

from agency_swarm import BaseTool


class ReadManifesto(BaseTool):
    """
    This tool reads a manifesto for the agency being created from a markdown file.
    """

    agency_name: str = Field(
        None,
        description="Name of the agency to create the tool for. Defaults to the agency currently being created.",
    )

    def run(self):
        if not self._shared_state.get("default_folder"):
            self._shared_state.set("default_folder", os.getcwd())

        if not self._shared_state.get("agency_path") and not self.agency_name:
            raise ValueError(
                "Please specify the agency name. Ask user for clarification if needed."
            )

        if self.agency_name:
            os.chdir("./" + self.agency_name)
        else:
            os.chdir(self._shared_state.get("agency_path"))

        with open("agency_manifesto.md", "r") as f:
            manifesto = f.read()

        os.chdir(self._shared_state.get("default_folder"))

        self._shared_state.set("manifesto_read", True)

        return manifesto



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/tools/util/__init__.py
================================================
from .get_modules import get_modules



================================================
FILE: agency_swarm/agency/genesis/AgentCreator/tools/util/get_modules.py
================================================
import importlib.resources
import pathlib


def get_modules(module_name):
    """
    Get all submodule names from a given module based on file names, without importing them,
    excluding those containing '.agent' or '.genesis' in their paths.

    Args:
    - module_name: The name of the module to search through.

    Returns:
    - A list of submodule names found within the given module.
    """
    submodule_names = []

    try:
        # Using importlib.resources to access the package contents
        with importlib.resources.path(module_name, "") as package_path:
            # Walk through the package directory using pathlib
            for path in pathlib.Path(package_path).rglob("*.py"):
                if path.name != "__init__.py":
                    # Construct the module name from the file path
                    relative_path = path.relative_to(package_path)
                    module_path = ".".join(relative_path.with_suffix("").parts)

                    submodule_names.append(f"{module_name}.{module_path}")

    except ImportError:
        print(f"Module {module_name} not found.")
        return submodule_names

    submodule_names = [
        name
        for name in submodule_names
        if not name.endswith(".agent")
        and ".genesis" not in name
        and "util" not in name
        and "oai" not in name
        and "ToolFactory" not in name
        and "BaseTool" not in name
    ]

    # remove repetition at the end of the path like 'agency_swarm.agents.coding.CodingAgent.CodingAgent'
    for i in range(len(submodule_names)):
        splitted = submodule_names[i].split(".")
        if splitted[-1] == splitted[-2]:
            submodule_names[i] = ".".join(splitted[:-1])

    return submodule_names



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/__init__.py
================================================
from .GenesisCEO import GenesisCEO



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/GenesisCEO.py
================================================
from pathlib import Path

from agency_swarm import Agent

from .tools.CreateAgencyFolder import CreateAgencyFolder
from .tools.FinalizeAgency import FinalizeAgency
from .tools.ReadRequirements import ReadRequirements


class GenesisCEO(Agent):
    def __init__(self):
        super().__init__(
            description="Acts as the overseer and communicator across the agency, ensuring alignment with the "
            "agency's goals.",
            instructions="./instructions.md",
            tools=[CreateAgencyFolder, FinalizeAgency, ReadRequirements],
            temperature=0.4,
        )



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/instructions.md
================================================
# GenesisCEO Agent Instructions

As a Genesis CEO Agent within the Agency Swarm framework, your mission is to help users define the structure of their agency and create the initial agents.

1. Pick a name for the agency, determine its goals and mission. Ask the user for any clarification if needed.
2. Propose an initial structure for the agency, including the roles of the agents, their communication flows and what APIs or Tools each agent can use, if specified by the user. Focus on creating at most 2 agents, plus CEO, unless instructed otherwise by the user. Do not name the CEO agent GenesisCEO. It's name must be tailored for the purpose of the agency. Output the code snippet like below. Adjust it accordingly, based on user's input.
3. Upon confirmation of the agency structure, use `CreateAgencyFolder` tool to create a folder for the agency. If any modifications are required please use this tool again with the same agency name and it will overwrite the existing folder.
4. Tell AgentCreator to create these agents one by one, starting with the CEO. Each agent should be sent in a separate message using the `SendMessage` tool. Please make sure to include the agent description, summary of the processes it needs to perform and the APIs or Tools that it can use via the message parameter.
5. Once all agents are created, please use the `FinalizeAgency` tool, and tell the user that he can now navigate to the agency folder and start it with `python agency.py` command.


### Example of communication flows

Here is an example of how communication flows are defined in agency swarm. Essentially, agents that are inside a double array can initiate communication with each other. Agents that are in the top level array can communicate with the user.

```python
agency = Agency([
    ceo, dev,  # CEO and Developer will be the entry point for communication with the user
    [ceo, dev],  # CEO can initiate communication with Developer
    [ceo, va],   # CEO can initiate communication with Virtual Assistant
    [dev, va]    # Developer can initiate communication with Virtual Assistant
], shared_instructions='agency_manifesto.md') # shared instructions for all agents
```
Keep in mind that this is just an example and you should replace it with the actual agents you are creating. Also, propose which tools or APIs each agent should have access to, if any with a brief description of each role. Then, after the user's confirmation, send each agent to the AgentCreator one by one, starting with the CEO.



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/tools/CreateAgencyFolder.py
================================================
import os
import shutil
from pathlib import Path

from pydantic import Field, field_validator

import agency_swarm.agency.genesis.GenesisAgency
from agency_swarm import BaseTool


class CreateAgencyFolder(BaseTool):
    """
    This tool creates or modifies an agency folder. You can use it again with the same agency_name to modify a previously created agency, if the user wants to change the agency chart or the manifesto.
    """

    agency_name: str = Field(
        ...,
        description="Name of the agency to be created. Must not contain spaces or special characters.",
        examples=["AgencyName", "MyAgency", "ExampleAgency"],
    )
    agency_chart: str = Field(
        ...,
        description="Agency chart to be passed into the Agency class.",
        examples=["[ceo, [ceo, dev], [ceo, va], [dev, va]]"],
    )
    manifesto: str = Field(
        ...,
        description="Manifesto for the agency, describing its goals and additional context shared by all agents "
        "in markdown format. It must include information about the working environment, the mission "
        "and the goals of the agency. Do not add descriptions of the agents themselves or the agency structure.",
    )

    def run(self):
        if not self._shared_state.get("default_folder"):
            self._shared_state.set("default_folder", Path.cwd())

        if self._shared_state.get("agency_name") is None:
            os.mkdir(self.agency_name)
            os.chdir("./" + self.agency_name)
            self._shared_state.set("agency_name", self.agency_name)
            self._shared_state.set("agency_path", Path("./").resolve())
        elif self._shared_state.get(
            "agency_name"
        ) == self.agency_name and os.path.exists(self._shared_state.get("agency_path")):
            os.chdir(self._shared_state.get("agency_path"))
            for file in os.listdir():
                if file != "__init__.py" and os.path.isfile(file):
                    os.remove(file)
        else:
            os.mkdir(self._shared_state.get("agency_path"))
            os.chdir("./" + self.agency_name)

        # check that agency chart is valid
        if not self.agency_chart.startswith("[") or not self.agency_chart.endswith("]"):
            raise ValueError(
                "Agency chart must be a list of lists, except for the first agents."
            )

        # add new lines after every comma, except for those inside second brackets
        # must transform from "[ceo, [ceo, dev], [ceo, va], [dev, va] ]"
        # to "[ceo, [ceo, dev],\n [ceo, va],\n [dev, va] ]"
        agency_chart = self.agency_chart.replace("],", "],\n")

        # create init file
        with open("__init__.py", "w") as f:
            f.write("")

        # create agency.py
        with open("agency.py", "w") as f:
            f.write(agency_py.format(agency_chart=agency_chart))

        # write manifesto
        path = os.path.join("agency_manifesto.md")
        with open(path, "w") as f:
            f.write(self.manifesto)

        os.chdir(self._shared_state.get("default_folder"))

        return f"Agency folder has been created. You can now tell AgentCreator to create agents for {self.agency_name}.\n"


agency_py = """from agency_swarm import Agency


agency = Agency({agency_chart},
                shared_instructions='./agency_manifesto.md', # shared instructions for all agents
                max_prompt_tokens=25000, # default tokens in conversation for all agents
                temperature=0.3, # default temperature for all agents
                )

if __name__ == '__main__':
    agency.demo_gradio()
"""



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/tools/FinalizeAgency.py
================================================
import os
from typing import List

from pydantic import Field, field_validator, model_validator

from agency_swarm import BaseTool, get_openai_client
from agency_swarm.util import create_agent_template


class FinalizeAgency(BaseTool):
    """
    This tool finalizes the agency structure and it's imports. Please make sure to use at only at the very end, after all agents have been created.
    """

    agency_path: str = Field(
        None,
        description="Path to the agency folder. Defaults to the agency currently being created.",
    )

    def run(self):
        agency_path = None
        if self._shared_state.get("agency_path"):
            os.chdir(self._shared_state.get("agency_path"))
            agency_path = self._shared_state.get("agency_path")
        else:
            os.chdir(self.agency_path)
            agency_path = self.agency_path

        client = get_openai_client()

        # read agency.py
        with open("./agency.py", "r") as f:
            agency_py = f.read()
            f.close()

        res = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=examples
            + [
                {"role": "user", "content": agency_py},
            ],
            temperature=0.0,
        )

        message = res.choices[0].message.content

        # write agency.py
        with open("./agency.py", "w") as f:
            f.write(message)
            f.close()

        return f"Successfully finalized {agency_path} structure. You can now instruct the user to run the agency.py file."

    @model_validator(mode="after")
    def validate_agency_path(self):
        if not self._shared_state.get("agency_path") and not self.agency_path:
            raise ValueError(
                "Agency path not found. Please specify the agency_path. Ask user for clarification if needed."
            )


SYSTEM_PROMPT = """"Please read the file provided by the user and fix all the imports and indentation accordingly.

Only output the full valid python code and nothing else."""

example_input = """
from agency_swarm import Agency

from CEO import CEO
from NewsAnalysisAgent import NewsAnalysisAgent
from PriceTrackingAgent import PriceTrackingAgent


agency = Agency([ceo, [ceo, news_analysis],
 [ceo, price_tracking],
 [news_analysis, price_tracking]],
shared_instructions='./agency_manifesto.md')

if __name__ == '__main__':
    agency.demo_gradio()
"""

example_output = """from agency_swarm import Agency
from CEO import CEO
from NewsAnalysisAgent import NewsAnalysisAgent
from PriceTrackingAgent import PriceTrackingAgent

ceo = CEO()
news_analysis = NewsAnalysisAgent()
price_tracking = PriceTrackingAgent()

agency = Agency([ceo, [ceo, market_analyst],
                 [ceo, news_curator],
                 [market_analyst, news_curator]],
                shared_instructions='./agency_manifesto.md')

if __name__ == '__main__':
    agency.demo_gradio()"""

examples = [
    {"role": "system", "content": SYSTEM_PROMPT},
    {"role": "user", "content": example_input},
    {"role": "assistant", "content": example_output},
]



================================================
FILE: agency_swarm/agency/genesis/GenesisCEO/tools/ReadRequirements.py
================================================
import os

from pydantic import Field

from agency_swarm.tools import BaseTool


class ReadRequirements(BaseTool):
    """
    Use this tool to read the agency requirements if user provides them as a file.
    """

    file_path: str = Field(
        ..., description="The path to the file that needs to be read."
    )

    def run(self):
        """
        Checks if the file exists, and if so, opens the specified file, reads its contents, and returns them.
        If the file does not exist, raises a ValueError.
        """
        if not os.path.exists(self.file_path):
            raise ValueError(f"File path does not exist: {self.file_path}")

        try:
            with open(self.file_path, "r", encoding="utf-8") as file:
                content = file.read()
            return content
        except Exception as e:
            return f"An error occurred while reading the file: {str(e)}"



================================================
FILE: agency_swarm/agency/genesis/OpenAPICreator/__init__.py
================================================
from .OpenAPICreator import OpenAPICreator



================================================
FILE: agency_swarm/agency/genesis/OpenAPICreator/instructions.md
================================================
# OpenAPICreator Instructions

You are an agent that creates tools from OpenAPI schemas. User will provide you with a description of the agent's role. If the provided description does not require any API calls, please notify the user.

**Here are your primary instructions:**
1. Think which API is needed for this agent's role, as communicated by the user. Then, tell the BrowsingAgent to find this API documentation page.
2. Explore the provided file from the BrowsingAgent with the `myfiles_broswer` tool to determine which endpoints are needed for this agent's role.
3. If the file does not contain the actual API documentation page, please notify the BrowsingAgent. Keep in mind that you do not need the full API documentation. You can make an educated guess if some information is not available.
4. Use `CreateToolsFromOpenAPISpec` to create the tools by defining the OpenAPI schema accordingly. Make sure to include all the relevant API endpoints that are needed for this agent to execute its role from the provided file. Do not truncate the schema.
5. Repeat these steps for each new agent that needs to be created, as instructed by the user.



================================================
FILE: agency_swarm/agency/genesis/OpenAPICreator/OpenAPICreator.py
================================================
from agency_swarm import Agent

from .tools.CreateToolsFromOpenAPISpec import CreateToolsFromOpenAPISpec


class OpenAPICreator(Agent):
    def __init__(self):
        super().__init__(
            description="This agent is responsible for creating new tools from an OpenAPI specifications.",
            instructions="./instructions.md",
            tools=[CreateToolsFromOpenAPISpec],
        )



================================================
FILE: agency_swarm/agency/genesis/OpenAPICreator/tools/CreateToolsFromOpenAPISpec.py
================================================
import json
import os

from pydantic import Field, field_validator, model_validator

from agency_swarm import BaseTool
from agency_swarm.agency.genesis.util import check_agency_path, check_agent_path
from agency_swarm.tools import ToolFactory
from agency_swarm.util.openapi import validate_openapi_spec


class CreateToolsFromOpenAPISpec(BaseTool):
    """
    This tool creates a set of tools from an OpenAPI specification. Each method in the specification is converted to a separate tool.
    """

    agent_name: str = Field(
        ...,
        description="Name of the agent to create the API for. Must be an existing agent.",
    )
    openapi_spec: str = Field(
        ...,
        description="OpenAPI specification for the tool to be created as a valid JSON string. Only the relevant "
        "endpoints must be included. Responses are not required. Each method should contain "
        "an operation id and a description. Do not truncate this schema. "
        "It must be a full valid OpenAPI 3.1.0 specification.",
        examples=[
            '{\n  "openapi": "3.1.0",\n  "info": {\n    "title": "Get weather data",\n    "description": "Retrieves current weather data for a location.",\n    "version": "v1.0.0"\n  },\n  "servers": [\n    {\n      "url": "https://weather.example.com"\n    }\n  ],\n  "paths": {\n    "/location": {\n      "get": {\n        "description": "Get temperature for a specific location",\n        "operationId": "GetCurrentWeather",\n        "parameters": [\n          {\n            "name": "location",\n            "in": "query",\n            "description": "The city and state to retrieve the weather for",\n            "required": true,\n            "schema": {\n              "type": "string"\n            }\n          }\n        ],\n        "deprecated": false\n      }\n    }\n  },\n  "components": {\n    "schemas": {}\n  }\n}'
        ],
    )
    agency_name: str = Field(
        None,
        description="Name of the agency to create the tool for. Defaults to the agency currently being created.",
    )

    def run(self):
        os.chdir(self._shared_state.get("agency_path"))

        os.chdir(self.agent_name)

        try:
            try:
                tools = ToolFactory.from_openapi_schema(self.openapi_spec)
            except Exception as e:
                raise ValueError(f"Error creating tools from OpenAPI Spec: {e}")

            if len(tools) == 0:
                return "No tools created. Please check the OpenAPI specification."

            tool_names = [tool.__name__ for tool in tools]

            # save openapi spec
            folder_path = "./" + self.agent_name + "/"
            os.chdir(folder_path)

            api_name = json.loads(self.openapi_spec)["info"]["title"]

            api_name = api_name.replace("API", "Api").replace(" ", "")

            api_name = "".join(
                ["_" + i.lower() if i.isupper() else i for i in api_name]
            ).lstrip("_")

            with open("schemas/" + api_name + ".json", "w") as f:
                f.write(self.openapi_spec)

            return "Successfully added OpenAPI Schema to " + self._shared_state.get(
                "agent_name"
            )
        finally:
            os.chdir(self._shared_state.get("default_folder"))

    @field_validator("openapi_spec", mode="before")
    @classmethod
    def validate_openapi_spec(cls, v):
        try:
            validate_openapi_spec(v)
        except json.JSONDecodeError as e:
            raise ValueError("Invalid JSON format:", e)
        except Exception as e:
            raise ValueError("Error validating OpenAPI schema:", e)
        return v

    @model_validator(mode="after")
    def validate_agent_name(self):
        check_agency_path(self)

        check_agent_path(self)



================================================
FILE: agency_swarm/agency/genesis/ToolCreator/__init__.py
================================================
from .ToolCreator import ToolCreator



================================================
FILE: agency_swarm/agency/genesis/ToolCreator/instructions.md
================================================
# ToolCreator Agent Instructions

As a ToolCreator Agent within the Agency Swarm framework, your mission is to develop tools that enhance the capabilities of other agents. These tools are pivotal for enabling agents to communicate, collaborate, and efficiently achieve their collective objectives. Below are detailed instructions to guide you through the process of creating tools, ensuring they are both functional and align with the framework's standards.

**Here are your primary instructions:**
1. Determine which tools the agent must utilize to perform it's role. Make an educated guess if the user has not specified any tools or APIs. Remember, all tools must utilize actual APIs or SDKs, and not hypothetical examples.
2. Create these tools one at a time, using `CreateTool` tool.
3. Test each tool with the `TestTool` function to ensure it is working as expected. Do not ask the user, always test the tool yourself, if it does not require any API keys and all the inputs can be mocked.
4. Only after all the necessary tools are created, notify the user.



================================================
FILE: agency_swarm/agency/genesis/ToolCreator/ToolCreator.py
================================================
from agency_swarm import Agent

from .tools.CreateTool import CreateTool
from .tools.TestTool import TestTool


class ToolCreator(Agent):
    def __init__(self):
        super().__init__(
            description="This agent is responsible for creating new tools for the agency using python code.",
            instructions="./instructions.md",
            tools=[CreateTool, TestTool],
            temperature=0,
        )



================================================
FILE: agency_swarm/agency/genesis/ToolCreator/tools/CreateTool.py
================================================
import os
import re
from typing import Literal

from pydantic import Field, field_validator, model_validator

from agency_swarm import get_openai_client
from agency_swarm.agency.genesis.util import check_agency_path
from agency_swarm.tools import BaseTool

prompt = """# Agency Swarm Overview

Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyone to create a collaborative swarm of agents (Agencies), each with distinct roles and capabilities.

# ToolCreator Agent Instructions for Agency Swarm Framework

As a ToolCreator Agent within the Agency Swarm framework, your mission is to develop tools that enhance the capabilities of other agents. These tools are pivotal for enabling agents to communicate, collaborate, and efficiently achieve their collective objectives. Below are detailed instructions to guide you through the process of creating tools, ensuring they are both functional and align with the framework's standards.

### Tool Creation Guide

When creating a tool, you are essentially defining a new class that extends `BaseTool`. This process involves several key steps, outlined below.

#### 1. Import Necessary Modules

Start by importing `BaseTool` from `agency_swarm.tools` and `Field` from `pydantic`. These imports will serve as the foundation for your custom tool class. Import any additional packages necessary to implement the tool's logic.

#### 2. Define Your Tool Class

Create a new class that inherits from `BaseTool`. This class will encapsulate the functionality of your tool. `BaseTool` class inherits from the Pydantic's `BaseModel` class.

#### 3. Specify Tool Fields

Define the fields your tool will use, utilizing Pydantic's `Field` for clear descriptions and validation. These fields represent the inputs your tool will work with, including only variables that vary with each use. Define any constant variables like api keys globally.

#### 4. Implement the `run` Method

The `run` method is where your tool's logic is executed. Use the fields defined earlier to perform the tool's intended task. It must contain the actual fully functional correct python code. It can utilize various python packages, previously imported in step 1. Do not include any placeholders or hypothetical examples in the code.

### Example of a Custom Tool

```python
from agency_swarm.tools import BaseTool
from pydantic import Field
import os

account_id = "MY_ACCOUNT_ID"
api_key = os.getenv("MY_API_KEY") # or access_token = os.getenv("MY_ACCESS_TOKEN")

class MyCustomTool(BaseTool):
    \"\"\"
    A brief description of what the custom tool does.
    The docstring should clearly explain the tool's purpose and functionality.
    It will be used by the agent to determine when to use this tool.
    \"\"\"

    # Define the fields with descriptions using Pydantic Field
    example_field: str = Field(
        ..., description="Description of the example field, explaining its purpose and usage for the Agent."
    )

    def run(self):
        \"\"\"
        The implementation of the run method, where the tool's main functionality is executed.
        This method should utilize the fields defined above to perform the task.
        \"\"\"
        # Your custom tool logic goes here
        # Example:
        # do_something(self.example_field, api_key, account_id)

        # Return the result of the tool's operation as a string
        return "Result of MyCustomTool operation"
```

To share state between 2 or more tools, you can use the `shared_state` attribute of the tool. It is a dictionary that can be used to store and retrieve values across different tools. This can be useful for passing information between tools or agents. Here is an example of how to use the `shared_state`:

```python
class MyCustomTool(BaseTool):
    def run(self):
        # Access the shared state
        value = self._shared_state.get("key")

        # Update the shared state
        self._shared_state.set("key", "value")

        return "Result of MyCustomTool operation"

# Access shared state in another tool
class AnotherTool(BaseTool):
    def run(self):
        # Access the shared state
        value = self._shared_state.get("key")

        return "Result of AnotherTool operation"
```

This is useful to pass information between tools or agents or to verify the state of the system.

Remember, you must output the resulting python tool code as a whole in a code block, so the user can just copy and paste it into his program. Each tool code snippet must be ready to use. It must not contain any placeholders or hypothetical examples."""

history = [
    {"role": "system", "content": prompt},
]


class CreateTool(BaseTool):
    """This tool creates other custom tools for the agent, based on your requirements and details."""

    agent_name: str = Field(
        ..., description="Name of the agent to create the tool for."
    )
    tool_name: str = Field(
        ...,
        description="Name of the tool class in camel case.",
        examples=["ExampleTool"],
    )
    requirements: str = Field(
        ...,
        description="The comprehensive requirements explaning the primary functionality of the tool. It must not contain any code or implementation details.",
    )
    details: str = Field(
        None,
        description="Additional details or error messages, class, function, and variable names.",
    )
    mode: Literal["write", "modify"] = Field(
        ...,
        description="The mode of operation for the tool. 'write' is used to create a new tool or overwrite an existing one. 'modify' is used to modify an existing tool.",
    )
    agency_name: str = Field(
        None,
        description="Name of the agency to create the tool for. Defaults to the agency currently being created.",
    )

    class ToolConfig:
        one_call_at_a_time: bool = True

    def run(self):
        if self.agency_name:
            os.chdir("./" + self.agency_name)
        else:
            os.chdir(self._shared_state.get("agency_path"))
        os.chdir(self.agent_name)

        client = get_openai_client()

        if self.mode == "write":
            message = f"Please create a '{self.tool_name}' tool that meets the following requirements: '{self.requirements}'.\n\nThe tool class must be named '{self.tool_name}'."
        else:
            message = f"Please rewrite a '{self.tool_name}' according to the following requirements: '{self.requirements}'.\n\nThe tool class must be named '{self.tool_name}'."

        if self.details:
            message += f"\nAdditional Details: {self.details}"

        if self.mode == "modify":
            message += f"\nThe existing file content is as follows:"

            try:
                with open("./tools/" + self.tool_name + ".py", "r") as file:
                    prev_content = file.read()
                    message += f"\n\n```{prev_content}```"
            except Exception as e:
                os.chdir(self._shared_state.get("default_folder"))
                return f"Error reading {self.tool_name}: {e}"

        history.append({"role": "user", "content": message})

        messages = history.copy()

        # use the last 6 messages
        messages = messages[-6:]

        # add system message upfront
        messages.insert(0, history[0])

        n = 0
        code = ""
        content = ""
        while n < 3:
            resp = client.chat.completions.create(
                messages=messages,
                model="gpt-4o",
                temperature=0,
            )

            content = resp.choices[0].message.content

            messages.append({"role": "assistant", "content": content})

            pattern = r"```(?:[a-zA-Z]+\n)?(.*?)```"
            match = re.findall(pattern, content, re.DOTALL)
            if match:
                code = match[-1].strip()
                history.append({"role": "assistant", "content": content})
                break
            else:
                messages.append(
                    {
                        "role": "user",
                        "content": f"Error: Could not find the python code block in the response. Please try again.",
                    }
                )

            n += 1

        if n == 3 or not code:
            # remove last message from history
            history.pop()
            os.chdir(self._shared_state.get("default_folder"))
            return "Error: Could not generate a valid file."
        try:
            with open("./tools/" + self.tool_name + ".py", "w") as file:
                file.write(code)

            os.chdir(self._shared_state.get("default_folder"))
            return f"{content}\n\nPlease make sure to now test this tool if possible."
        except Exception as e:
            os.chdir(self._shared_state.get("default_folder"))
            return f"Error writing to file: {e}"

    @field_validator("requirements", mode="after")
    @classmethod
    def validate_requirements(cls, v):
        if "placeholder" in v:
            raise ValueError(
                "Requirements contain placeholders. "
                "Please never user placeholders. Instead, implement only the code that you are confident about."
            )

        # check if code is included in requirements
        pattern = r"(```)((.*\n){5,})(```)"
        if re.search(pattern, v):
            raise ValueError(
                "Requirements contain a code snippet. Please never include code snippets in requirements. "
                "Requirements must be a description of the complete file to be written. You can include specific class, function, and variable names, but not the actual code."
            )

        return v

    @field_validator("details", mode="after")
    @classmethod
    def validate_details(cls, v):
        if len(v) == 0:
            raise ValueError(
                "Details are required. Remember this tool does not have access to other files. Please provide additional details like relevant documentation, error messages, or class, function, and variable names from other files that this file depends on."
            )
        return v

    @model_validator(mode="after")
    def validate_agency_name(self):
        if not self.agent_name and not self._shared_state.get("agent_name"):
            raise ValueError("Please provide agent name.")

        check_agency_path(self)


if __name__ == "__main__":
    tool = CreateTool(
        requirements="Write a program that takes a list of integers as input and returns the sum of all the integers in the list.",
        mode="write",
        file_path="test.py",
    )
    print(tool.run())



================================================
FILE: agency_swarm/agency/genesis/ToolCreator/tools/TestTool.py
================================================
import os
from typing import Optional

from pydantic import Field, model_validator

from agency_swarm.agency.genesis.util import check_agency_path
from agency_swarm.tools import BaseTool, ToolFactory


class TestTool(BaseTool):
    """
    This tool tests other tools defined in tools.py file with the given arguments. Make sure to define the run method before testing.
    """

    agent_name: str = Field(..., description="Name of the agent to test the tool for.")
    chain_of_thought: str = Field(
        ...,
        description="Think step by step to determine the correct arguments for testing.",
        exclude=True,
    )
    tool_name: str = Field(..., description="Name of the tool to be run.")
    arguments: Optional[str] = Field(
        ...,
        description="Arguments to be passed to the tool for testing "
        "in serialized JSON format.",
    )
    agency_name: str = Field(
        None,
        description="Name of the agency to create the tool for. Defaults to the agency currently being created.",
    )

    def run(self):
        if self.agency_name:
            os.chdir("./" + self.agency_name)
        else:
            os.chdir(self._shared_state.get("agency_path"))
        os.chdir(self.agent_name)

        # import tool by self.tool_name from local tools.py file
        try:
            tool = ToolFactory.from_file(f"./tools/{self.tool_name}.py")
        except Exception as e:
            raise ValueError(f"Error importing tool {self.tool_name}: {e}")
        finally:
            os.chdir(self._shared_state.get("default_folder"))

        try:
            if not self.arguments:
                output = tool().run()
            else:
                output = tool(**eval(self.arguments)).run()
        except Exception as e:
            raise ValueError(f"Error running tool {self.tool_name}: {e}")
        finally:
            os.chdir(self._shared_state.get("default_folder"))

        if not output:
            raise ValueError(f"Tool {self.tool_name} did not return any output.")

        return f"Successfully initialized and ran tool. Output: '{output}'"

    @model_validator(mode="after")
    def validate_tool_name(self):
        check_agency_path(self)

        if not self.agent_name and not self._shared_state.get("agent_name"):
            raise ValueError("Please provide agent name.")

        agent_name = self.agent_name or self._shared_state.get("agent_name")

        tool_path = os.path.join(self._shared_state.get("agency_path"), agent_name)
        tool_path = os.path.join(str(tool_path), "tools")
        tool_path = os.path.join(tool_path, self.tool_name + ".py")

        # check if tools.py file exists
        if not os.path.isfile(tool_path):
            available_tools = os.listdir(
                os.path.join(self._shared_state.get("agency_path"), agent_name)
            )
            available_tools = [tool for tool in available_tools if tool.endswith(".py")]
            available_tools = [
                tool
                for tool in available_tools
                if not tool.startswith("__") and not tool.startswith(".")
            ]
            available_tools = [tool.replace(".py", "") for tool in available_tools]
            available_tools = ", ".join(available_tools)
            raise ValueError(
                f"Tool {self.tool_name} not found. Available tools are: {available_tools}"
            )

        agent_path = os.path.join(
            self._shared_state.get("agency_path"), self.agent_name
        )
        if not os.path.exists(agent_path):
            available_agents = os.listdir(self._shared_state.get("agency_path"))
            available_agents = [
                agent
                for agent in available_agents
                if os.path.isdir(
                    os.path.join(self._shared_state.get("agency_path"), agent)
                )
            ]
            raise ValueError(
                f"Agent {self.agent_name} not found. Available agents are: {available_agents}"
            )

        return True


if __name__ == "__main__":
    TestTool._shared_state.data = {
        "agency_path": "/Users/vrsen/Projects/agency-swarm/agency-swarm/TestAgency",
        "default_folder": "/Users/vrsen/Projects/agency-swarm/agency-swarm/TestAgency",
    }
    test_tool = TestTool(
        agent_name="TestAgent",
        tool_name="PrintTestTool",
        arguments="{}",
        chain_of_thought="",
    )
    print(test_tool.run())



================================================
FILE: agency_swarm/agents/__init__.py
================================================
from .agent import Agent
from .BrowsingAgent import BrowsingAgent
from .Devid import Devid



================================================
FILE: agency_swarm/agents/agent.py
================================================
import copy
import inspect
import json
import logging
import os
from typing import Any, Dict, List, Literal, Optional, Type, TypedDict, Union

from deepdiff import DeepDiff
from openai import NotFoundError
from openai.lib._parsing._completions import type_to_response_format_param
from openai.types.beta.assistant import ToolResources

from agency_swarm.constants import DEFAULT_MODEL
from agency_swarm.tools import (
    BaseTool,
    CodeInterpreter,
    FileSearch,
    Retrieval,
    ToolFactory,
)
from agency_swarm.tools.oai.FileSearch import FileSearchConfig
from agency_swarm.util.oai import get_openai_client
from agency_swarm.util.openapi import validate_openapi_spec
from agency_swarm.util.shared_state import SharedState

logger = logging.getLogger(__name__)

class ExampleMessage(TypedDict):
    role: Literal["user", "assistant"]
    content: str
    attachments: Optional[List[dict]]
    metadata: Optional[Dict[str, str]]


class Agent:
    _shared_state: SharedState = None

    @property
    def assistant(self):
        if not hasattr(self, "_assistant") or self._assistant is None:
            raise Exception(
                "Assistant is not initialized. Please run init_oai() first."
            )
        return self._assistant

    @assistant.setter
    def assistant(self, value):
        self._assistant = value

    @property
    def functions(self):
        return [tool for tool in self.tools if issubclass(tool, BaseTool)]

    @property
    def shared_state(self):
        return self._shared_state

    @shared_state.setter
    def shared_state(self, value):
        self._shared_state = value
        for tool in self.tools:
            if issubclass(tool, BaseTool):
                tool._shared_state = value

    def response_validator(self, message: str | list) -> str:
        """
        Validates the response from the agent. If the response is invalid, it must raise an exception with instructions
        for the caller agent on how to proceed.

        Parameters:
            message (str): The response from the agent.

        Returns:
            str: The validated response.
        """
        return message

    def __init__(
        self,
        id: str = None,
        name: str = None,
        description: str = "",
        instructions: str = "",
        tools: List[
            Union[
                Type[BaseTool], Type[FileSearch], Type[CodeInterpreter], type[Retrieval]
            ]
        ] = None,
        tool_resources: ToolResources = None,
        temperature: float = None,
        top_p: float = 1.0,
        response_format: Union[str, dict, type] = "auto",
        tools_folder: str = None,
        files_folder: Union[List[str], str] = None,
        schemas_folder: Union[List[str], str] = None,
        api_headers: Dict[str, Dict[str, str]] = None,
        api_params: Dict[str, Dict[str, str]] = None,
        file_ids: List[str] = None,
        metadata: Dict[str, str] = None,
        model: str = DEFAULT_MODEL,
        reasoning_effort: Literal["low", "medium", "high"] = "medium",
        validation_attempts: int = 1,
        max_prompt_tokens: int = None,
        max_completion_tokens: int = None,
        truncation_strategy: dict = None,
        examples: List[ExampleMessage] = None,
        file_search: FileSearchConfig = None,
        parallel_tool_calls: bool = True,
        refresh_from_id: bool = True,
        mcp_servers: List = None,
    ):
        """
        Initializes an Agent with specified attributes, tools, and OpenAI client.

        Parameters:
            id (str, optional): Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Defaults to None.
            name (str, optional): Name of the agent. Defaults to the class name if not provided.
            description (str, optional): A brief description of the agent's purpose. Defaults to empty string.
            instructions (str, optional): Path to a file containing specific instructions for the agent. Defaults to an empty string.
            tools (List[Union[Type[BaseTool], Type[Retrieval], Type[CodeInterpreter]]], optional): A list of tools (as classes) that the agent can use. Defaults to an empty list.
            tool_resources (ToolResources, optional): A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the code_interpreter tool requires a list of file IDs, while the file_search tool requires a list of vector store IDs. Defaults to None.
            temperature (float, optional): The temperature parameter for the OpenAI API. Defaults to None.
            top_p (float, optional): The top_p parameter for the OpenAI API. Defaults to 1.0.
            response_format (Union[str, Dict, type], optional): The response format for the OpenAI API. If BaseModel is provided, it will be converted to a response format. Defaults to None.
            tools_folder (str, optional): Path to a directory containing tools associated with the agent. Each tool must be defined in a separate file. File must be named as the class name of the tool. Defaults to None.
            files_folder (Union[List[str], str], optional): Path or list of paths to directories containing files associated with the agent. Defaults to None.
            schemas_folder (Union[List[str], str], optional): Path or list of paths to directories containing OpenAPI schemas associated with the agent. Defaults to None.
            api_headers (Dict[str,Dict[str, str]], optional): Headers to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.
            api_params (Dict[str, Dict[str, str]], optional): Extra params to be used for the openapi requests. Each key must be a full filename from schemas_folder. Defaults to an empty dictionary.
            metadata (Dict[str, str], optional): Metadata associated with the agent. Defaults to an empty dictionary.
            model (str, optional): The model identifier for the OpenAI API. Defaults to "gpt-4o".
            reasoning_effort (Literal["low", "medium", "high"], optional): The reasoning effort for the model. Only for o-series models. Defaults to "medium".
            validation_attempts (int, optional): Number of attempts to validate the response with response_validator function. Defaults to 1.
            max_prompt_tokens (int, optional): Maximum number of tokens allowed in the prompt. Defaults to None.
            max_completion_tokens (int, optional): Maximum number of tokens allowed in the completion. Defaults to None.
            truncation_strategy (TruncationStrategy, optional): Truncation strategy for the OpenAI API. Defaults to None.
            examples (List[Dict], optional): A list of example messages for the agent. Defaults to None.
            file_search (FileSearchConfig, optional): A dictionary containing the file search tool configuration. Defaults to None.
            parallel_tool_calls (bool, optional): Whether to enable parallel function calling during tool use. Defaults to True.
            refresh_from_id (bool, optional): Whether to load and update the agent from the OpenAI assistant ID when provided. Defaults to True.
            mcp_servers (List, optional): A list of MCP servers to use for tools. Defaults to None.

        This constructor sets up the agent with its unique properties, initializes the OpenAI client, reads instructions if provided, and uploads any associated files.
        """
        # public attributes
        self.id = id
        self.name = name if name else self.__class__.__name__
        self.description = description
        self.instructions = instructions
        self.tools = tools[:] if tools is not None else []
        self.tools = [tool for tool in self.tools if tool.__name__ != "ExampleTool"]
        self.tool_resources = tool_resources
        self.temperature = temperature
        self.top_p = top_p
        self.response_format = response_format
        # use structured outputs if response_format is a BaseModel
        if isinstance(self.response_format, type):
            self.response_format = type_to_response_format_param(self.response_format)
        self.tools_folder = tools_folder
        self.files_folder = files_folder if files_folder else []
        self.schemas_folder = schemas_folder if schemas_folder else []
        self.api_headers = api_headers if api_headers else {}
        self.api_params = api_params if api_params else {}
        self.metadata = metadata if metadata else {}
        self.model = model
        self.reasoning_effort = reasoning_effort
        self.validation_attempts = validation_attempts
        self.max_prompt_tokens = max_prompt_tokens
        self.max_completion_tokens = max_completion_tokens
        self.truncation_strategy = truncation_strategy
        self.examples = examples
        self.file_search = file_search
        self.parallel_tool_calls = parallel_tool_calls
        self.refresh_from_id = refresh_from_id
        self.mcp_servers = mcp_servers if mcp_servers else []

        self.settings_path = "./settings.json"

        # private attributes
        self._assistant: Any = None
        self._shared_instructions = None

        # init methods
        self.client = get_openai_client()
        self._read_instructions()

        # upload files
        self._upload_files()
        if file_ids:
            logger.warning(
                "'file_ids' parameter is deprecated. Please use 'tool_resources' parameter instead."
            )
            self.add_file_ids(file_ids, "file_search")

        self._parse_schemas()
        self._parse_tools_folder()
        if self.mcp_servers:
            self._add_mcp_tools()

    # --- OpenAI Assistant Methods ---

    def init_oai(self):
        """
        Initializes the OpenAI assistant for the agent.

        This method handles the initialization and potential updates of the agent's OpenAI assistant. It loads the assistant based on a saved ID, updates the assistant if necessary, or creates a new assistant if it doesn't exist. After initialization or update, it saves the assistant's settings.

        Output:
            self: Returns the agent instance for chaining methods or further processing.
        """
        # check if settings.json exists
        path = self.get_settings_path()

        # o-series models
        if self.model.startswith("o"):
            self.temperature = None
            self.top_p = None
        else:
            self.reasoning_effort = None

        # load assistant from id
        if self.id:
            if not self.refresh_from_id:
                return self

            self.assistant = self.client.beta.assistants.retrieve(self.id)
            # Assign attributes to self if they are None
            self.instructions = self.instructions or self.assistant.instructions
            self.name = (
                self.name
                if self.name != self.__class__.__name__
                else self.assistant.name
            )
            self.description = self.description or self.assistant.description
            self.temperature = (
                self.assistant.temperature
                if self.temperature is None
                else self.temperature
            )
            self.top_p = self.top_p if self.top_p is not None else self.assistant.top_p
            self.response_format = (
                self.response_format or self.assistant.response_format
            )
            if not isinstance(self.response_format, str):
                self.response_format = (
                    self.response_format or self.response_format.model_dump()
                )
            else:
                self.response_format = (
                    self.response_format or self.assistant.response_format
                )
            self.tool_resources = (
                self.tool_resources or self.assistant.tool_resources.model_dump()
            )
            self.metadata = self.metadata or self.assistant.metadata
            self.model = self.model or self.assistant.model
            self.tool_resources = (
                self.tool_resources or self.assistant.tool_resources.model_dump()
            )

            for tool in self.assistant.tools:
                # update assistants created with v1
                if tool.type == "retrieval":
                    self.client.beta.assistants.update(
                        self.id, tools=self.get_oai_tools()
                    )

            # update assistant if parameters are different
            if not self._check_parameters(self.assistant.model_dump()):
                logger.info("Updating agent... " + self.name)
                self._update_assistant()

            return self

        # load assistant from settings
        if os.path.exists(path):
            with open(path, "r") as f:
                settings = json.load(f)
                # iterate settings and find the assistant with the same name
                for assistant_settings in settings:
                    if assistant_settings["name"] == self.name:
                        try:
                            self.assistant = self.client.beta.assistants.retrieve(
                                assistant_settings["id"]
                            )
                            self.id = assistant_settings["id"]

                            # update assistant if parameters are different
                            if not self._check_parameters(self.assistant.model_dump()):
                                logger.info("Updating agent... " + self.name)
                                self._update_assistant()

                            if self.assistant.tool_resources:
                                self.tool_resources = (
                                    self.assistant.tool_resources.model_dump()
                                )

                            self._update_settings()
                            return self
                        except NotFoundError:
                            continue

        # create assistant if settings.json does not exist or assistant with the same name does not exist
        self.assistant = self._create_assistant()

        if self.assistant.tool_resources:
            self.tool_resources = self.assistant.tool_resources.model_dump()

        self.id = self.assistant.id

        self._save_settings()

        return self

    def _create_assistant(self):
        """Creates a new OpenAI assistant with the agent's current configuration."""
        params = {
            "model": self.model,
            "name": self.name,
            "description": self.description,
            "instructions": self.instructions,
            "tools": self.get_oai_tools(),
            "tool_resources": self.tool_resources,
            "metadata": self.metadata,
            "temperature": self.temperature,
            "top_p": self.top_p,
            "response_format": self.response_format,
            "reasoning_effort": self.reasoning_effort,
        }

        return self.client.beta.assistants.create(**params)

    def _update_assistant(self):
        """
        Updates the existing assistant's parameters on the OpenAI server.

        This method updates the assistant's details such as name, description, instructions, tools, file IDs, metadata, and the model. It only updates parameters that have non-empty values. After updating the assistant, it also updates the local settings file to reflect these changes.

        No input parameters are directly passed to this method as it uses the agent's instance attributes.

        No output parameters are returned, but the method updates the assistant's details on the OpenAI server and locally updates the settings file.
        """
        tool_resources = copy.deepcopy(self.tool_resources)
        if tool_resources and tool_resources.get("file_search"):
            tool_resources["file_search"].pop("vector_stores", None)

        params = {
            "name": self.name,
            "description": self.description,
            "instructions": self.instructions,
            "tools": self.get_oai_tools(),
            "tool_resources": tool_resources,
            "temperature": self.temperature,
            "top_p": self.top_p,
            "response_format": self.response_format,
            "metadata": self.metadata,
            "model": self.model,
            "reasoning_effort": self.reasoning_effort,
        }

        self.assistant = self.client.beta.assistants.update(self.id, **params)

        self._update_settings()

    def _upload_files(self):
        def add_id_to_file(f_path, id):
            """Add file id to file name"""
            if os.path.isfile(f_path):
                file_name, file_ext = os.path.splitext(f_path)
                f_path_new = file_name + "_" + id + file_ext
                os.rename(f_path, f_path_new)
                return f_path_new

        def get_id_from_file(f_path):
            """Get file id from file name"""
            if os.path.isfile(f_path):
                file_name, file_ext = os.path.splitext(f_path)
                file_name = os.path.basename(file_name)
                file_name = file_name.split("_")
                if len(file_name) > 1:
                    return file_name[-1] if "file-" in file_name[-1] else None
                else:
                    return None

        files_folders = (
            self.files_folder
            if isinstance(self.files_folder, list)
            else [self.files_folder]
        )

        file_search_ids = []
        code_interpreter_ids = []

        for files_folder in files_folders:
            if isinstance(files_folder, str):
                f_path = files_folder

                if not os.path.isdir(f_path):
                    f_path = os.path.join(self.get_class_folder_path(), files_folder)
                    f_path = os.path.normpath(f_path)

                if os.path.isdir(f_path):
                    f_paths = os.listdir(f_path)

                    f_paths = [f for f in f_paths if not f.startswith(".")]

                    f_paths = [os.path.join(f_path, f) for f in f_paths]

                    code_interpreter_file_extensions = [
                        ".json",  # JSON
                        ".csv",  # CSV
                        ".xml",  # XML
                        ".jpeg",  # JPEG
                        ".jpg",  # JPEG
                        ".gif",  # GIF
                        ".png",  # PNG
                        ".zip",  # ZIP
                    ]

                    for f_path in f_paths:
                        file_ext = os.path.splitext(f_path)[1]

                        f_path = f_path.strip()
                        file_id = get_id_from_file(f_path)
                        if file_id:
                            logger.info(
                                "File already uploaded. Skipping... "
                                + os.path.basename(f_path)
                            )
                        else:
                            logger.info(
                                "Uploading new file... " + os.path.basename(f_path)
                            )
                            with open(f_path, "rb") as f:
                                file_id = (
                                    self.client.with_options(
                                        timeout=80 * 1000,
                                    )
                                    .files.create(file=f, purpose="assistants")
                                    .id
                                )
                                f.close()  # fix permission error on windows
                            add_id_to_file(f_path, file_id)

                        if file_ext in code_interpreter_file_extensions:
                            code_interpreter_ids.append(file_id)
                        else:
                            file_search_ids.append(file_id)
                else:
                    logger.warning(
                        f"Files folder '{f_path}' is not a directory. Skipping...",
                    )
            else:
                logger.warning(
                    "Files folder path must be a string or list of strings. Skipping... ",
                    files_folder,
                )

        if FileSearch not in self.tools and file_search_ids:
            logger.info("Detected files without FileSearch. Adding FileSearch tool...")
            self.add_tool(FileSearch)
        if CodeInterpreter not in self.tools and code_interpreter_ids:
            logger.info(
                "Detected files without CodeInterpreter. Adding CodeInterpreter tool..."
            )
            self.add_tool(CodeInterpreter)

        self.add_file_ids(file_search_ids, "file_search")
        self.add_file_ids(code_interpreter_ids, "code_interpreter")

    # --- Tool Methods ---

    # TODO: fix 2 methods below
    def add_tool(self, tool):
        if not isinstance(tool, type):
            raise Exception("Tool must not be initialized.")

        subclasses = [FileSearch, CodeInterpreter, Retrieval]
        for subclass in subclasses:
            if issubclass(tool, subclass):
                if not any(issubclass(t, subclass) for t in self.tools):
                    self.tools.append(tool)
                return

        if issubclass(tool, BaseTool):
            if tool.__name__ == "ExampleTool":
                logger.info("Skipping importing ExampleTool...")
                return
            self.tools = [t for t in self.tools if t.__name__ != tool.__name__]
            self.tools.append(tool)
        else:
            raise Exception("Invalid tool type.")

    def get_oai_tools(self):
        tools = []
        for tool in self.tools:
            if not isinstance(tool, type):
                logger.error(tool)
                raise Exception("Tool must not be initialized.")

            if issubclass(tool, FileSearch):
                tools.append(
                    tool(file_search=self.file_search).model_dump(exclude_none=True)
                )
            elif issubclass(tool, CodeInterpreter):
                tools.append(tool().model_dump())
            elif issubclass(tool, Retrieval):
                tools.append(tool().model_dump())
            elif issubclass(tool, BaseTool):
                tools.append({"type": "function", "function": tool.openai_schema})
            else:
                raise Exception("Invalid tool type.")
        return tools

    def _parse_schemas(self):
        schemas_folders = (
            self.schemas_folder
            if isinstance(self.schemas_folder, list)
            else [self.schemas_folder]
        )

        for schemas_folder in schemas_folders:
            if isinstance(schemas_folder, str):
                f_path = schemas_folder

                if not os.path.isdir(f_path):
                    f_path = os.path.join(self.get_class_folder_path(), schemas_folder)
                    f_path = os.path.normpath(f_path)

                if os.path.isdir(f_path):
                    f_paths = os.listdir(f_path)

                    f_paths = [f for f in f_paths if not f.startswith(".")]

                    f_paths = [os.path.join(f_path, f) for f in f_paths]

                    for f_path in f_paths:
                        with open(f_path, "r") as f:
                            openapi_spec = f.read()
                            f.close()  # fix permission error on windows
                        try:
                            validate_openapi_spec(openapi_spec)
                        except Exception as e:
                            logger.error(
                                "Invalid OpenAPI schema: " + os.path.basename(f_path)
                            )
                            raise e
                        try:
                            headers = None
                            params = None
                            if os.path.basename(f_path) in self.api_headers:
                                headers = self.api_headers[os.path.basename(f_path)]
                            if os.path.basename(f_path) in self.api_params:
                                params = self.api_params[os.path.basename(f_path)]
                            tools = ToolFactory.from_openapi_schema(
                                openapi_spec, headers=headers, params=params
                            )
                        except Exception as e:
                            logger.error(
                                "Error parsing OpenAPI schema: "
                                + os.path.basename(f_path),
                                exc_info=True,
                            )
                            raise e
                        for tool in tools:
                            self.add_tool(tool)
                else:
                    logger.warning(
                        "Schemas folder path is not a directory. Skipping... ", f_path
                    )
            else:
                logger.warning(
                    "Schemas folder path must be a string or list of strings. Skipping... ",
                    schemas_folder,
                )

    def _parse_tools_folder(self):
        if not self.tools_folder:
            return

        if not os.path.isdir(self.tools_folder):
            self.tools_folder = os.path.join(
                self.get_class_folder_path(), self.tools_folder
            )
            self.tools_folder = os.path.normpath(self.tools_folder)

        if os.path.isdir(self.tools_folder):
            f_paths = os.listdir(self.tools_folder)
            f_paths = [
                f for f in f_paths if not f.startswith(".") and not f.startswith("__")
            ]
            f_paths = [os.path.join(self.tools_folder, f) for f in f_paths]
            for f_path in f_paths:
                if not f_path.endswith(".py"):
                    continue
                if os.path.isfile(f_path):
                    try:
                        tool = ToolFactory.from_file(f_path)
                        self.add_tool(tool)
                    except Exception as e:
                        logger.error(
                            f"Error parsing tool file {os.path.basename(f_path)}: {e}. Skipping...",
                            exc_info=True,
                        )
                else:
                    logger.warning(
                        "Items in tools folder must be files. Skipping... ", f_path
                    )
        else:
            logger.warning(
                "Tools folder path is not a directory. Skipping... ", self.tools_folder
            )

    def get_openapi_schema(self, url):
        """Get openapi schema that contains all tools from the agent as different api paths. Make sure to call this after agency has been initialized."""
        if self.assistant is None:
            raise Exception(
                "Assistant is not initialized. Please initialize the agency first, before using this method"
            )

        return ToolFactory.get_openapi_schema(self.tools, url)

    def _add_mcp_tools(self):
        """Process MCP servers and add their tools to the agent."""
        if not self.mcp_servers:
            return

        for server in self.mcp_servers:
            # Get tools from the MCP server
            mcp_tools = ToolFactory.from_mcp(server)
            try:
                logger.info(f"\n--- Adding Tools from MCP Server: {server.name} ---")
                # Add each tool to the agent and print its name
                for tool in mcp_tools:
                    self.add_tool(tool)
                    logger.info(f"  - Added MCP tool: {tool.__name__}")
                logger.info(
                    f"--- Finished adding {len(mcp_tools)} tools from {server.name} ---\n"
                )
            except Exception as e:
                logger.error(f"Error processing {server.name} MCP server: {e}", exc_info=True)
                raise Exception(f"Error starting {server.name} MCP server: {e}")

    # --- Settings Methods ---

    def _check_parameters(self, assistant_settings, debug=False):
        """
        Checks if the agent's parameters match with the given assistant settings.

        Parameters:
            assistant_settings (dict): A dictionary containing the settings of an assistant.
            debug (bool): If True, prints debug statements. Default is False.

        Returns:
            bool: True if all the agent's parameters match the assistant settings, False otherwise.

        This method compares the current agent's parameters such as name, description, instructions, tools, file IDs, metadata, and model with the given assistant settings. It uses DeepDiff to compare complex structures like tools and metadata. If any parameter does not match, it returns False; otherwise, it returns True.
        """
        if self.name != assistant_settings["name"]:
            if debug:
                logger.debug(
                    f"Name mismatch: {self.name} != {assistant_settings['name']}"
                )
            return False

        if self.description != assistant_settings["description"]:
            if debug:
                logger.debug(
                    f"Description mismatch: {self.description} != {assistant_settings['description']}"
                )
            return False

        if self.instructions != assistant_settings["instructions"]:
            if debug:
                logger.debug(
                    f"Instructions mismatch: {self.instructions} != {assistant_settings['instructions']}"
                )
            return False

        def clean_tool(tool):
            if isinstance(tool, dict):
                if (
                    "function" in tool
                    and "strict" in tool["function"]
                    and not tool["function"]["strict"]
                ):
                    tool["function"].pop("strict", None)
            return tool

        local_tools = [clean_tool(tool) for tool in self.get_oai_tools()]
        assistant_tools = [clean_tool(tool) for tool in assistant_settings["tools"]]

        # find file_search and code_interpreter tools in local_tools and assistant_tools
        # Find file_search tools in local and assistant tools
        local_file_search = next(
            (tool for tool in local_tools if tool["type"] == "file_search"), None
        )
        assistant_file_search = next(
            (tool for tool in assistant_tools if tool["type"] == "file_search"), None
        )

        if local_file_search:
            # If local file_search doesn't have a 'file_search' key, use assistant's if available
            if (
                "file_search" not in local_file_search
                and assistant_file_search
                and "file_search" in assistant_file_search
            ):
                local_file_search["file_search"] = assistant_file_search["file_search"]
            elif "file_search" in local_file_search:
                # Update max_num_results if not set locally but available in assistant
                if (
                    "max_num_results" not in local_file_search["file_search"]
                    and assistant_file_search
                    and assistant_file_search["file_search"].get("max_num_results")
                    is not None
                ):
                    local_file_search["file_search"]["max_num_results"] = (
                        assistant_file_search["file_search"]["max_num_results"]
                    )

                # Update ranking_options if not set locally but available in assistant
                if (
                    "ranking_options" not in local_file_search["file_search"]
                    and assistant_file_search
                    and assistant_file_search["file_search"].get("ranking_options")
                    is not None
                ):
                    local_file_search["file_search"]["ranking_options"] = (
                        assistant_file_search["file_search"]["ranking_options"]
                    )

        local_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))
        assistant_tools.sort(key=lambda x: json.dumps(x, sort_keys=True))

        tools_diff = DeepDiff(local_tools, assistant_tools, ignore_order=True)
        if tools_diff:
            if debug:
                logger.debug(f"Tools mismatch: {tools_diff}")
                logger.debug(f"Local tools: {local_tools}")
                logger.debug(f"Assistant tools: {assistant_tools}")
            return False

        if self.temperature != assistant_settings[
            "temperature"
        ] and not self.model.startswith("o"):
            if debug:
                logger.debug(
                    f"Temperature mismatch: {self.temperature} != {assistant_settings['temperature']}"
                )
            return False

        if self.top_p != assistant_settings["top_p"] and not self.model.startswith("o"):
            if debug:
                logger.debug(
                    f"Top_p mismatch: {self.top_p} != {assistant_settings['top_p']}"
                )
            return False

        # adjust differences between local and assistant tool resources
        tool_resources_settings = copy.deepcopy(self.tool_resources)
        if tool_resources_settings is None:
            tool_resources_settings = {}
        if tool_resources_settings.get("file_search"):
            tool_resources_settings["file_search"].pop("vector_stores", None)
        if tool_resources_settings.get("file_search") is None:
            tool_resources_settings["file_search"] = {"vector_store_ids": []}
        if tool_resources_settings.get("code_interpreter") is None:
            tool_resources_settings["code_interpreter"] = {"file_ids": []}

        assistant_tool_resources = assistant_settings["tool_resources"]
        if assistant_tool_resources is None:
            assistant_tool_resources = {}
        if assistant_tool_resources.get("code_interpreter") is None:
            assistant_tool_resources["code_interpreter"] = {"file_ids": []}
        if assistant_tool_resources.get("file_search") is None:
            assistant_tool_resources["file_search"] = {"vector_store_ids": []}

        tool_resources_diff = DeepDiff(
            tool_resources_settings, assistant_tool_resources, ignore_order=True
        )
        if tool_resources_diff != {}:
            if debug:
                logger.debug(f"Tool resources mismatch: {tool_resources_diff}")
                logger.debug(f"Local tool resources: {tool_resources_settings}")
                logger.debug(
                    f"Assistant tool resources: {assistant_settings['tool_resources']}"
                )
            return False

        metadata_diff = DeepDiff(
            self.metadata, assistant_settings["metadata"], ignore_order=True
        )
        if metadata_diff != {}:
            if debug:
                logger.debug(f"Metadata mismatch: {metadata_diff}")
            return False

        if self.model != assistant_settings["model"]:
            if debug:
                logger.debug(
                    f"Model mismatch: {self.model} != {assistant_settings['model']}"
                )
            return False

        response_format_diff = DeepDiff(
            self.response_format,
            assistant_settings["response_format"],
            ignore_order=True,
        )
        if response_format_diff != {}:
            if debug:
                logger.debug(f"Response format mismatch: {response_format_diff}")
            return False

        if self.model.startswith("o"):
            reasoning_effort_diff = DeepDiff(
                self.reasoning_effort,
                assistant_settings["reasoning_effort"],
                ignore_order=True,
            )
            if reasoning_effort_diff != {}:
                if debug:
                    logger.debug(f"Reasoning effort mismatch: {reasoning_effort_diff}")
                return False

        return True

    def _save_settings(self):
        path = self.get_settings_path()
        # check if settings.json exists
        if not os.path.isfile(path):
            with open(path, "w") as f:
                json.dump([self.assistant.model_dump()], f, indent=4)
        else:
            settings = []
            with open(path, "r") as f:
                settings = json.load(f)
                settings.append(self.assistant.model_dump())
            with open(path, "w") as f:
                json.dump(settings, f, indent=4)

    def _update_settings(self):
        path = self.get_settings_path()
        # check if settings.json exists
        if os.path.isfile(path):
            settings = []
            with open(path, "r") as f:
                settings = json.load(f)
                for i, assistant_settings in enumerate(settings):
                    if assistant_settings["id"] == self.id:
                        settings[i] = self.assistant.model_dump()
                        break
            with open(path, "w") as f:
                json.dump(settings, f, indent=4)

    # --- Helper Methods ---

    def add_file_ids(
        self,
        file_ids: List[str],
        tool_resource: Literal["code_interpreter", "file_search"],
    ):
        if not file_ids:
            return

        if self.tool_resources is None:
            self.tool_resources = {}

        if tool_resource == "code_interpreter":
            if CodeInterpreter not in self.tools:
                raise Exception("CodeInterpreter tool not found in tools.")

            if (
                tool_resource not in self.tool_resources
                or self.tool_resources[tool_resource] is None
            ):
                self.tool_resources[tool_resource] = {"file_ids": file_ids}

            self.tool_resources[tool_resource]["file_ids"] = file_ids
        elif tool_resource == "file_search":
            if FileSearch not in self.tools:
                raise Exception("FileSearch tool not found in tools.")

            if (
                tool_resource not in self.tool_resources
                or self.tool_resources[tool_resource] is None
            ):
                self.tool_resources[tool_resource] = {
                    "vector_stores": [{"file_ids": file_ids}]
                }
            elif not self.tool_resources[tool_resource].get("vector_store_ids"):
                self.tool_resources[tool_resource]["vector_stores"] = [
                    {"file_ids": file_ids}
                ]
            else:
                vector_store_id = self.tool_resources[tool_resource][
                    "vector_store_ids"
                ][0]
                self.client.vector_stores.file_batches.create(
                    vector_store_id=vector_store_id, file_ids=file_ids
                )
        else:
            raise Exception("Invalid tool resource.")

    def get_settings_path(self):
        return self.settings_path

    def _read_instructions(self):
        class_instructions_path = os.path.normpath(
            os.path.join(self.get_class_folder_path(), self.instructions)
        )
        if os.path.isfile(class_instructions_path):
            with open(class_instructions_path, "r") as f:
                self.instructions = f.read()
        elif os.path.isfile(self.instructions):
            with open(self.instructions, "r") as f:
                self.instructions = f.read()
        elif (
            "./instructions.md" in self.instructions
            or "./instructions.txt" in self.instructions
        ):
            raise Exception("Instructions file not found.")

    def get_class_folder_path(self):
        try:
            # First, try to use the __file__ attribute of the module
            return os.path.abspath(os.path.dirname(self.__module__.__file__))
        except (TypeError, OSError, AttributeError) as e:
            # If that fails, fall back to inspect
            try:
                class_file = inspect.getfile(self.__class__)
            except (TypeError, OSError, AttributeError) as e:
                return "./"
            return os.path.abspath(os.path.realpath(os.path.dirname(class_file)))

    def add_shared_instructions(self, instructions: str):
        if not instructions:
            return

        if self._shared_instructions is None:
            self._shared_instructions = instructions
        else:
            self.instructions = self.instructions.replace(self._shared_instructions, "")
            self.instructions = self.instructions.strip().strip("\n")
            self._shared_instructions = instructions

        self.instructions = self._shared_instructions + "\n\n" + self.instructions

    # --- Cleanup Methods ---
    def delete(self):
        """Deletes assistant, all vector stores, and all files associated with the agent."""
        self._delete_assistant()
        self._delete_files()
        self._delete_settings()

    def _delete_files(self):
        if not self.tool_resources:
            return

        file_ids = []
        if self.tool_resources.get("code_interpreter"):
            file_ids = self.tool_resources["code_interpreter"].get("file_ids", [])

        if self.tool_resources.get("file_search"):
            file_search_vector_store_ids = self.tool_resources["file_search"].get(
                "vector_store_ids", []
            )
            for vector_store_id in file_search_vector_store_ids:
                files = self.client.vector_stores.files.list(
                    vector_store_id=vector_store_id, limit=100
                )
                for file in files:
                    file_ids.append(file.id)

                self.client.vector_stores.delete(vector_store_id)

        for file_id in file_ids:
            self.client.files.delete(file_id)

    def _delete_assistant(self):
        self.client.beta.assistants.delete(self.id)
        self._delete_settings()

    def _delete_settings(self):
        path = self.get_settings_path()
        # check if settings.json exists
        if os.path.isfile(path):
            settings = []
            with open(path, "r") as f:
                settings = json.load(f)
                for i, assistant_settings in enumerate(settings):
                    if assistant_settings["id"] == self.id:
                        settings.pop(i)
                        break
            with open(path, "w") as f:
                json.dump(settings, f, indent=4)



================================================
FILE: agency_swarm/agents/BrowsingAgent/__init__.py
================================================
from .BrowsingAgent import BrowsingAgent



================================================
FILE: agency_swarm/agents/BrowsingAgent/BrowsingAgent.py
================================================
import base64
import re

from typing_extensions import override

from agency_swarm.agents import Agent
from agency_swarm.tools.oai import FileSearch


class BrowsingAgent(Agent):
    SCREENSHOT_FILE_NAME = "screenshot.jpg"

    def __init__(self, selenium_config=None, **kwargs):
        from .tools.util.selenium import set_selenium_config

        super().__init__(
            name="BrowsingAgent",
            description="This agent is designed to navigate and search web effectively.",
            instructions="./instructions.md",
            files_folder="./files",
            schemas_folder="./schemas",
            tools=[],
            tools_folder="./tools",
            temperature=0,
            max_prompt_tokens=16000,
            model="gpt-4o",
            validation_attempts=25,
            **kwargs,
        )
        if selenium_config is not None:
            set_selenium_config(selenium_config)

        self.prev_message = ""

    @override
    def response_validator(self, message):
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.select import Select

        from .tools.util import (
            highlight_elements_with_labels,
            remove_highlight_and_labels,
        )
        from .tools.util.selenium import get_web_driver, set_web_driver

        # Filter out everything in square brackets
        filtered_message = re.sub(r"\[.*?\]", "", message).strip()

        if filtered_message and self.prev_message == filtered_message:
            raise ValueError(
                "Do not repeat yourself. If you are stuck, try a different approach or search in google for the page you are looking for directly."
            )

        self.prev_message = filtered_message

        if "[send screenshot]" in message.lower():
            wd = get_web_driver()
            remove_highlight_and_labels(wd)
            self.take_screenshot()
            response_text = "Here is the screenshot of the current web page:"

        elif "[highlight clickable elements]" in message.lower():
            wd = get_web_driver()
            highlight_elements_with_labels(
                wd,
                'a, button, div[onclick], div[role="button"], div[tabindex], '
                'span[onclick], span[role="button"], span[tabindex]',
            )
            self._shared_state.set(
                "elements_highlighted",
                'a, button, div[onclick], div[role="button"], div[tabindex], '
                'span[onclick], span[role="button"], span[tabindex]',
            )

            self.take_screenshot()

            all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

            all_element_texts = [element.text for element in all_elements]

            element_texts_json = {}
            for i, element_text in enumerate(all_element_texts):
                element_texts_json[str(i + 1)] = self.remove_unicode(element_text)

            element_texts_json = {k: v for k, v in element_texts_json.items() if v}

            element_texts_formatted = ", ".join(
                [f"{k}: {v}" for k, v in element_texts_json.items()]
            )

            response_text = (
                "Here is the screenshot of the current web page with highlighted clickable elements. \n\n"
                "Texts of the elements are: " + element_texts_formatted + ".\n\n"
                "Elements without text are not shown, but are available on screenshot. \n"
                "Please make sure to analyze the screenshot to find the clickable element you need to click on."
            )

        elif "[highlight text fields]" in message.lower():
            wd = get_web_driver()
            highlight_elements_with_labels(wd, "input, textarea")
            self._shared_state.set("elements_highlighted", "input, textarea")

            self.take_screenshot()

            all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

            all_element_texts = [element.text for element in all_elements]

            element_texts_json = {}
            for i, element_text in enumerate(all_element_texts):
                element_texts_json[str(i + 1)] = self.remove_unicode(element_text)

            element_texts_formatted = ", ".join(
                [f"{k}: {v}" for k, v in element_texts_json.items()]
            )

            response_text = (
                "Here is the screenshot of the current web page with highlighted text fields: \n"
                "Texts of the elements are: " + element_texts_formatted + ".\n"
                "Please make sure to analyze the screenshot to find the text field you need to fill."
            )

        elif "[highlight dropdowns]" in message.lower():
            wd = get_web_driver()
            highlight_elements_with_labels(wd, "select")
            self._shared_state.set("elements_highlighted", "select")

            self.take_screenshot()

            all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

            all_selector_values = {}

            i = 0
            for element in all_elements:
                select = Select(element)
                options = select.options
                selector_values = {}
                for j, option in enumerate(options):
                    selector_values[str(j)] = option.text
                    if j > 10:
                        break
                all_selector_values[str(i + 1)] = selector_values

            all_selector_values = {k: v for k, v in all_selector_values.items() if v}
            all_selector_values_formatted = ", ".join(
                [f"{k}: {v}" for k, v in all_selector_values.items()]
            )

            response_text = (
                "Here is the screenshot with highlighted dropdowns. \n"
                "Selector values are: " + all_selector_values_formatted + ".\n"
                "Please make sure to analyze the screenshot to find the dropdown you need to select."
            )

        else:
            return message

        set_web_driver(wd)
        content = self.create_response_content(response_text)
        raise ValueError(content)

    def take_screenshot(self):
        from .tools.util import get_b64_screenshot
        from .tools.util.selenium import get_web_driver

        wd = get_web_driver()
        screenshot = get_b64_screenshot(wd)
        screenshot_data = base64.b64decode(screenshot)
        with open(self.SCREENSHOT_FILE_NAME, "wb") as screenshot_file:
            screenshot_file.write(screenshot_data)

    def create_response_content(self, response_text):
        with open(self.SCREENSHOT_FILE_NAME, "rb") as file:
            file_id = self.client.files.create(
                file=file,
                purpose="vision",
            ).id

        content = [
            {"type": "text", "text": response_text},
            {"type": "image_file", "image_file": {"file_id": file_id}},
        ]
        return content

    # Function to check for Unicode escape sequences
    def remove_unicode(self, data):
        return re.sub(r"[^\x00-\x7F]+", "", data)



================================================
FILE: agency_swarm/agents/BrowsingAgent/instructions.md
================================================
# Browsing Agent Instructions

As an advanced browsing agent, you are equipped with specialized tools to navigate and search the web effectively. Your primary objective is to fulfill the user's requests by efficiently utilizing these tools.

### Primary Instructions:

1. **Avoid Guessing URLs**: Never attempt to guess the direct URL. Always perform a Google search if applicable, or return to your previous search results.
2. **Navigating to New Pages**: Always use the `ClickElement` tool to open links when navigating to a new web page from the current source. Do not guess the direct URL.
3. **Single Page Interaction**: You can only open and interact with one web page at a time. The previous web page will be closed when you open a new one. To navigate back, use the `GoBack` tool.
4. **Requesting Screenshots**: Before using tools that interact with the web page, ask the user to send you the appropriate screenshot using one of the commands below.

### Commands to Request Screenshots:

- **'[send screenshot]'**: Sends the current browsing window as an image. Use this command if the user asks what is on the page.
- **'[highlight clickable elements]'**: Highlights all clickable elements on the current web page. This must be done before using the `ClickElement` tool.
- **'[highlight text fields]'**: Highlights all text fields on the current web page. This must be done before using the `SendKeys` tool.
- **'[highlight dropdowns]'**: Highlights all dropdowns on the current web page. This must be done before using the `SelectDropdown` tool.

### Important Reminders:

- Only open and interact with one web page at a time. Do not attempt to read or click on multiple links simultaneously. Complete your interactions with the current web page before proceeding to a different source.



================================================
FILE: agency_swarm/agents/BrowsingAgent/requirements.txt
================================================
selenium
webdriver-manager
selenium_stealth



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/__init__.py
================================================
from .ClickElement import ClickElement
from .ExportFile import ExportFile
from .GoBack import GoBack
from .ReadURL import ReadURL
from .Scroll import Scroll
from .SelectDropdown import SelectDropdown
from .SendKeys import SendKeys
from .SolveCaptcha import SolveCaptcha
from .WebPageSummarizer import WebPageSummarizer



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/ClickElement.py
================================================
import time

from pydantic import Field
from selenium.webdriver.common.by import By

from agency_swarm.tools import BaseTool

from .util import get_web_driver, set_web_driver
from .util.highlights import remove_highlight_and_labels


class ClickElement(BaseTool):
    """
    This tool clicks on an element on the current web page based on its number.

    Before using this tool make sure to highlight clickable elements on the page by outputting '[highlight clickable elements]' message.
    """

    element_number: int = Field(
        ...,
        description="The number of the element to click on. The element numbers are displayed on the page after highlighting elements.",
    )

    def run(self):
        wd = get_web_driver()

        if "button" not in self._shared_state.get("elements_highlighted", ""):
            raise ValueError(
                "Please highlight clickable elements on the page first by outputting '[highlight clickable elements]' message. You must output just the message without calling the tool first, so the user can respond with the screenshot."
            )

        all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

        # iterate through all elements with a number in the text
        try:
            element_text = all_elements[self.element_number - 1].text
            element_text = element_text.strip() if element_text else ""
            # Subtract 1 because sequence numbers start at 1, but list indices start at 0
            try:
                all_elements[self.element_number - 1].click()
            except Exception as e:
                if "element click intercepted" in str(e).lower():
                    wd.execute_script(
                        "arguments[0].click();", all_elements[self.element_number - 1]
                    )
                else:
                    raise e

            time.sleep(3)

            result = f"Clicked on element {self.element_number}. Text on clicked element: '{element_text}'. Current URL is {wd.current_url} To further analyze the page, output '[send screenshot]' command."
        except IndexError:
            result = "Element number is invalid. Please try again with a valid element number."
        except Exception as e:
            result = str(e)

        wd = remove_highlight_and_labels(wd)

        wd.execute_script("document.body.style.zoom='1.5'")

        set_web_driver(wd)

        self._shared_state.set("elements_highlighted", "")

        return result



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/ExportFile.py
================================================
import base64

from agency_swarm.tools import BaseTool

from .util import get_web_driver


class ExportFile(BaseTool):
    """This tool converts the current full web page into a file and returns its file_id. You can then send this file id back to the user for further processing."""

    def run(self):
        wd = get_web_driver()
        from agency_swarm import get_openai_client

        client = get_openai_client()

        # Define the parameters for the PDF
        params = {
            "landscape": False,
            "displayHeaderFooter": False,
            "printBackground": True,
            "preferCSSPageSize": True,
        }

        # Execute the command to print to PDF
        result = wd.execute_cdp_cmd("Page.printToPDF", params)
        pdf = result["data"]

        pdf_bytes = base64.b64decode(pdf)

        # Save the PDF to a file
        with open("exported_file.pdf", "wb") as f:
            f.write(pdf_bytes)

        file_id = client.files.create(
            file=open("exported_file.pdf", "rb"),
            purpose="assistants",
        ).id

        self._shared_state.set("file_id", file_id)

        return (
            "Success. File exported with id: `"
            + file_id
            + "` You can now send this file id back to the user."
        )


if __name__ == "__main__":
    wd = get_web_driver()
    wd.get("https://www.google.com")
    tool = ExportFile()
    tool.run()



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/GoBack.py
================================================
import time

from agency_swarm.tools import BaseTool

from .util.selenium import get_web_driver, set_web_driver


class GoBack(BaseTool):
    """W
    This tool allows you to go back 1 page in the browser history. Use it in case of a mistake or if a page shows you unexpected content.
    """

    def run(self):
        wd = get_web_driver()

        wd.back()

        time.sleep(3)

        set_web_driver(wd)

        return "Success. Went back 1 page. Current URL is: " + wd.current_url



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/ReadURL.py
================================================
import time

from pydantic import Field

from agency_swarm.tools import BaseTool

from .util.selenium import get_web_driver, set_web_driver


class ReadURL(BaseTool):
    """
    This tool reads a single URL and opens it in your current browser window. For each new source, either navigate directly to a URL that you believe contains the answer to the user's question or perform a Google search (e.g., 'https://google.com/search?q=search') if necessary.

    If you are unsure of the direct URL, do not guess. Instead, use the ClickElement tool to click on links that might contain the desired information on the current web page.

    Note: This tool only supports opening one URL at a time. The previous URL will be closed when you open a new one.
    """

    chain_of_thought: str = Field(
        ...,
        description="Think step-by-step about where you need to navigate next to find the necessary information.",
        exclude=True,
    )
    url: str = Field(
        ...,
        description="URL of the webpage.",
        examples=["https://google.com/search?q=search"],
    )

    class ToolConfig:
        one_call_at_a_time: bool = True

    def run(self):
        wd = get_web_driver()

        wd.get(self.url)

        time.sleep(2)

        set_web_driver(wd)

        self._shared_state.set("elements_highlighted", "")

        return (
            "Current URL is: "
            + wd.current_url
            + "\n"
            + "Please output '[send screenshot]' next to analyze the current web page or '[highlight clickable elements]' for further navigation."
        )


if __name__ == "__main__":
    tool = ReadURL(url="https://google.com")
    print(tool.run())



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/Scroll.py
================================================
from typing import Literal

from pydantic import Field

from agency_swarm.tools import BaseTool

from .util.selenium import get_web_driver, set_web_driver


class Scroll(BaseTool):
    """
    This tool allows you to scroll the current web page up or down by 1 screen height.
    """

    direction: Literal["up", "down"] = Field(..., description="Direction to scroll.")

    def run(self):
        wd = get_web_driver()

        height = wd.get_window_size()["height"]

        # Get the zoom level
        zoom_level = wd.execute_script("return document.body.style.zoom || '1';")
        zoom_level = (
            float(zoom_level.strip("%")) / 100
            if "%" in zoom_level
            else float(zoom_level)
        )

        # Adjust height by zoom level
        adjusted_height = height / zoom_level

        current_scroll_position = wd.execute_script("return window.pageYOffset;")
        total_scroll_height = wd.execute_script("return document.body.scrollHeight;")

        result = ""

        if self.direction == "up":
            if current_scroll_position == 0:
                # Reached the top of the page
                result = "Reached the top of the page. Cannot scroll up any further.\n"
            else:
                wd.execute_script(f"window.scrollBy(0, -{adjusted_height});")
                result = "Scrolled up by 1 screen height. Make sure to output '[send screenshot]' command to analyze the page after scrolling."

        elif self.direction == "down":
            if current_scroll_position + adjusted_height >= total_scroll_height:
                # Reached the bottom of the page
                result = (
                    "Reached the bottom of the page. Cannot scroll down any further.\n"
                )
            else:
                wd.execute_script(f"window.scrollBy(0, {adjusted_height});")
                result = "Scrolled down by 1 screen height. Make sure to output '[send screenshot]' command to analyze the page after scrolling."

        set_web_driver(wd)

        return result



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/SelectDropdown.py
================================================
from typing import Dict

from pydantic import Field, model_validator
from selenium.webdriver.common.by import By
from selenium.webdriver.support.select import Select

from agency_swarm.tools import BaseTool

from .util import get_web_driver, set_web_driver
from .util.highlights import remove_highlight_and_labels


class SelectDropdown(BaseTool):
    """
    This tool selects an option in a dropdown on the current web page based on the description of that element and which option to select.

    Before using this tool make sure to highlight dropdown elements on the page by outputting '[highlight dropdowns]' message.
    """

    key_value_pairs: Dict[str, str] = Field(
        ...,
        description="A dictionary where the key is the sequence number of the dropdown element and the value is the index of the option to select.",
        examples=[{"1": 0, "2": 1}, {"3": 2}],
    )

    @model_validator(mode="before")
    @classmethod
    def check_key_value_pairs(cls, data):
        if not data.get("key_value_pairs"):
            raise ValueError(
                "key_value_pairs is required. Example format: "
                "key_value_pairs={'1': 0, '2': 1}"
            )
        return data

    def run(self):
        wd = get_web_driver()

        if "select" not in self._shared_state.get("elements_highlighted", ""):
            raise ValueError(
                "Please highlight dropdown elements on the page first by outputting '[highlight dropdowns]' message. You must output just the message without calling the tool first, so the user can respond with the screenshot."
            )

        all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

        try:
            for key, value in self.key_value_pairs.items():
                key = int(key)
                element = all_elements[key - 1]

                select = Select(element)

                # Select the first option (index 0)
                select.select_by_index(int(value))
            result = f"Success. Option is selected in the dropdown. To further analyze the page, output '[send screenshot]' command."
        except Exception as e:
            result = str(e)

        remove_highlight_and_labels(wd)

        set_web_driver(wd)

        return result



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/SendKeys.py
================================================
import time
from typing import Dict

from pydantic import Field, model_validator
from selenium.webdriver import Keys
from selenium.webdriver.common.by import By

from agency_swarm.tools import BaseTool

from .util import get_web_driver, set_web_driver
from .util.highlights import remove_highlight_and_labels


class SendKeys(BaseTool):
    """
    This tool sends keys into input fields on the current webpage based on the description of that element and what needs to be typed. It then clicks "Enter" on the last element to submit the form. You do not need to tell it to press "Enter"; it will do that automatically.

    Before using this tool make sure to highlight the input elements on the page by outputting '[highlight text fields]' message.
    """

    elements_and_texts: Dict[int, str] = Field(
        ...,
        description="A dictionary where the key is the element number and the value is the text to be typed.",
        examples=[
            {52: "johndoe@gmail.com", 53: "password123"},
            {3: "John Doe", 4: "123 Main St"},
        ],
    )

    @model_validator(mode="before")
    @classmethod
    def check_elements_and_texts(cls, data):
        if not data.get("elements_and_texts"):
            raise ValueError(
                "elements_and_texts is required. Example format: "
                "elements_and_texts={1: 'John Doe', 2: '123 Main St'}"
            )
        return data

    def run(self):
        wd = get_web_driver()
        if "input" not in self._shared_state.get("elements_highlighted", ""):
            raise ValueError(
                "Please highlight input elements on the page first by outputting '[highlight text fields]' message. You must output just the message without calling the tool first, so the user can respond with the screenshot."
            )

        all_elements = wd.find_elements(By.CSS_SELECTOR, ".highlighted-element")

        i = 0
        try:
            for key, value in self.elements_and_texts.items():
                key = int(key)
                element = all_elements[key - 1]

                try:
                    element.click()
                    element.send_keys(Keys.CONTROL + "a")  # Select all text in input
                    element.send_keys(Keys.DELETE)
                    element.clear()
                except Exception as e:
                    pass
                element.send_keys(value)
                # send enter key to the last element
                if i == len(self.elements_and_texts) - 1:
                    element.send_keys(Keys.RETURN)
                    time.sleep(3)
                i += 1
            result = f"Sent input to element and pressed Enter. Current URL is {wd.current_url} To further analyze the page, output '[send screenshot]' command."
        except Exception as e:
            result = str(e)

        remove_highlight_and_labels(wd)

        set_web_driver(wd)

        return result



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/SolveCaptcha.py
================================================
import base64
import time

from selenium.webdriver.common.by import By
from selenium.webdriver.support.expected_conditions import (
    frame_to_be_available_and_switch_to_it,
    presence_of_element_located,
)
from selenium.webdriver.support.wait import WebDriverWait

from agency_swarm.tools import BaseTool
from agency_swarm.util import get_openai_client

from .util import get_b64_screenshot, remove_highlight_and_labels
from .util.selenium import get_web_driver


class SolveCaptcha(BaseTool):
    """
    This tool asks a human to solve captcha on the current webpage. Make sure that captcha is visible before running it.
    """

    def run(self):
        wd = get_web_driver()

        try:
            WebDriverWait(wd, 10).until(
                frame_to_be_available_and_switch_to_it(
                    (By.XPATH, "//iframe[@title='reCAPTCHA']")
                )
            )

            element = WebDriverWait(wd, 3).until(
                presence_of_element_located((By.ID, "recaptcha-anchor"))
            )
        except Exception as e:
            return "Could not find captcha checkbox"

        try:
            # Scroll the element into view
            wd.execute_script("arguments[0].scrollIntoView(true);", element)
            time.sleep(1)  # Give some time for the scrolling to complete

            # Click the element using JavaScript
            wd.execute_script("arguments[0].click();", element)
        except Exception as e:
            return f"Could not click captcha checkbox: {str(e)}"

        try:
            # Now check if the reCAPTCHA is checked
            WebDriverWait(wd, 3).until(
                lambda d: d.find_element(
                    By.CLASS_NAME, "recaptcha-checkbox"
                ).get_attribute("aria-checked")
                == "true"
            )

            return "Success"
        except Exception as e:
            pass

        wd.switch_to.default_content()

        client = get_openai_client()

        WebDriverWait(wd, 10).until(
            frame_to_be_available_and_switch_to_it(
                (
                    By.XPATH,
                    "//iframe[@title='recaptcha challenge expires in two minutes']",
                )
            )
        )

        time.sleep(2)

        attempts = 0
        while attempts < 5:
            tiles = wd.find_elements(By.CLASS_NAME, "rc-imageselect-tile")

            # filter out tiles with rc-imageselect-dynamic-selected class
            tiles = [
                tile
                for tile in tiles
                if not tile.get_attribute("class").endswith(
                    "rc-imageselect-dynamic-selected"
                )
            ]

            image_content = []
            i = 0
            for tile in tiles:
                i += 1
                screenshot = get_b64_screenshot(wd, tile)

                image_content.append(
                    {
                        "type": "text",
                        "text": f"Image {i}:",
                    }
                )
                image_content.append(
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{screenshot}",
                            "detail": "high",
                        },
                    },
                )
            # highlight all titles with rc-imageselect-tile class but not with rc-imageselect-dynamic-selected
            # wd = highlight_elements_with_labels(wd, 'td.rc-imageselect-tile:not(.rc-imageselect-dynamic-selected)')

            # screenshot = get_b64_screenshot(wd, wd.find_element(By.ID, "rc-imageselect"))

            task_text = (
                wd.find_element(By.CLASS_NAME, "rc-imageselect-instructions")
                .text.strip()
                .replace("\n", " ")
            )

            continuous_task = "once there are none left" in task_text.lower()

            task_text = task_text.replace("Click verify", "Output 0")
            task_text = task_text.replace("click skip", "Output 0")
            task_text = task_text.replace("once", "if")
            task_text = task_text.replace("none left", "none")
            task_text = task_text.replace("all", "only")
            task_text = task_text.replace("squares", "images")

            additional_info = ""
            if len(tiles) > 9:
                additional_info = (
                    "Keep in mind that all images are a part of a bigger image "
                    "from left to right, and top to bottom. The grid is 4x4. "
                )

            messages = [
                {
                    "role": "system",
                    "content": f"""You are an advanced AI designed to support users with visual impairments.
                    User will provide you with {i} images numbered from 1 to {i}. Your task is to output
                    the numbers of the images that contain the requested object, or at least some part of the requested
                    object. {additional_info}If there are no individual images that satisfy this condition, output 0.
                    """.replace("\n", ""),
                },
                {
                    "role": "user",
                    "content": [
                        *image_content,
                        {
                            "type": "text",
                            "text": f"{task_text}. Only output numbers separated by commas and nothing else. "
                            f"Output 0 if there are none.",
                        },
                    ],
                },
            ]

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                max_tokens=1024,
                temperature=0.0,
            )

            message = response.choices[0].message
            message_text = message.content

            # check if 0 is in the message
            if "0" in message_text and "10" not in message_text:
                # Find the button by its ID
                verify_button = wd.find_element(By.ID, "recaptcha-verify-button")

                verify_button_text = verify_button.text

                # Click the button
                wd.execute_script("arguments[0].click();", verify_button)

                time.sleep(1)

                try:
                    if self.verify_checkbox(wd):
                        return "Success. Captcha solved."
                except Exception as e:
                    print("Not checked")
                    pass

            else:
                numbers = [
                    int(s.strip())
                    for s in message_text.split(",")
                    if s.strip().isdigit()
                ]

                # Click the tiles based on the provided numbers
                for number in numbers:
                    wd.execute_script("arguments[0].click();", tiles[number - 1])
                    time.sleep(0.5)

                time.sleep(3)

                if not continuous_task:
                    # Find the button by its ID
                    verify_button = wd.find_element(By.ID, "recaptcha-verify-button")

                    verify_button_text = verify_button.text

                    # Click the button
                    wd.execute_script("arguments[0].click();", verify_button)

                    try:
                        if self.verify_checkbox(wd):
                            return "Success. Captcha solved."
                    except Exception as e:
                        pass
                else:
                    continue

            if "verify" in verify_button_text.lower():
                attempts += 1

        wd = remove_highlight_and_labels(wd)

        wd.switch_to.default_content()

        # close captcha
        try:
            element = WebDriverWait(wd, 3).until(
                presence_of_element_located((By.XPATH, "//iframe[@title='reCAPTCHA']"))
            )

            wd.execute_script(
                f"document.elementFromPoint({element.location['x']}, {element.location['y']-10}).click();"
            )
        except Exception as e:
            print(e)
            pass

        return "Could not solve captcha."

    def verify_checkbox(self, wd):
        wd.switch_to.default_content()

        try:
            WebDriverWait(wd, 10).until(
                frame_to_be_available_and_switch_to_it(
                    (By.XPATH, "//iframe[@title='reCAPTCHA']")
                )
            )

            WebDriverWait(wd, 5).until(
                lambda d: d.find_element(
                    By.CLASS_NAME, "recaptcha-checkbox"
                ).get_attribute("aria-checked")
                == "true"
            )

            return True
        except Exception as e:
            wd.switch_to.default_content()

            WebDriverWait(wd, 10).until(
                frame_to_be_available_and_switch_to_it(
                    (
                        By.XPATH,
                        "//iframe[@title='recaptcha challenge expires in two minutes']",
                    )
                )
            )

        return False



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/WebPageSummarizer.py
================================================
from selenium.webdriver.common.by import By

from agency_swarm.tools import BaseTool

from .util import get_web_driver, set_web_driver


class WebPageSummarizer(BaseTool):
    """
    This tool summarizes the content of the current web page, extracting the main points and providing a concise summary.
    """

    def run(self):
        from agency_swarm import get_openai_client

        wd = get_web_driver()
        client = get_openai_client()

        content = wd.find_element(By.TAG_NAME, "body").text

        # only use the first 10000 characters
        content = " ".join(content.split()[:10000])

        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "Your task is to summarize the content of the provided webpage. The summary should be concise and informative, capturing the main points and takeaways of the page.",
                },
                {
                    "role": "user",
                    "content": "Summarize the content of the following webpage:\n\n"
                    + content,
                },
            ],
            temperature=0.0,
        )

        return completion.choices[0].message.content


if __name__ == "__main__":
    wd = get_web_driver()
    wd.get("https://en.wikipedia.org/wiki/Python_(programming_language)")
    set_web_driver(wd)
    tool = WebPageSummarizer()
    print(tool.run())



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/util/__init__.py
================================================
from .get_b64_screenshot import get_b64_screenshot
from .highlights import highlight_elements_with_labels, remove_highlight_and_labels
from .selenium import get_web_driver, set_web_driver



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/util/get_b64_screenshot.py
================================================
def get_b64_screenshot(wd, element=None):
    if element:
        screenshot_b64 = element.screenshot_as_base64
    else:
        screenshot_b64 = wd.get_screenshot_as_base64()

    return screenshot_b64



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/util/highlights.py
================================================
def highlight_elements_with_labels(driver, selector):
    """
    This function highlights clickable elements like buttons, links, and certain divs and spans
    that match the given CSS selector on the webpage with a red border and ensures that labels are visible and positioned
    correctly within the viewport.

    :param driver: Instance of Selenium WebDriver.
    :param selector: CSS selector for the elements to be highlighted.
    """
    script = f"""
        // Helper function to check if an element is visible
        function isElementVisible(element) {{
            var rect = element.getBoundingClientRect();
            if (rect.width <= 0 || rect.height <= 0 ||
                rect.top >= (window.innerHeight || document.documentElement.clientHeight) ||
                rect.bottom <= 0 ||
                rect.left >= (window.innerWidth || document.documentElement.clientWidth) ||
                rect.right <= 0) {{
                return false;
            }}
            // Check if any parent element is hidden, which would hide this element as well
            var parent = element;
            while (parent) {{
                var style = window.getComputedStyle(parent);
                if (style.display === 'none' || style.visibility === 'hidden') {{
                    return false;
                }}
                parent = parent.parentElement;
            }}
            return true;
        }}

        // Remove previous labels and styles if they exist
        document.querySelectorAll('.highlight-label').forEach(function(label) {{
            label.remove();
        }});
        document.querySelectorAll('.highlighted-element').forEach(function(element) {{
            element.classList.remove('highlighted-element');
            element.removeAttribute('data-highlighted');
        }});

        // Inject custom style for highlighting elements
        var styleElement = document.getElementById('highlight-style');
        if (!styleElement) {{
            styleElement = document.createElement('style');
            styleElement.id = 'highlight-style';
            document.head.appendChild(styleElement);
        }}
        styleElement.textContent = `
            .highlighted-element {{
                border: 2px solid red !important;
                position: relative;
                box-sizing: border-box;
            }}
            .highlight-label {{
                position: absolute;
                z-index: 2147483647;
                background: yellow;
                color: black;
                font-size: 25px;
                padding: 3px 5px;
                border: 1px solid black;
                border-radius: 3px;
                white-space: nowrap;
                box-shadow: 0px 0px 2px #000;
                top: -25px;
                left: 0;
                display: none;
            }}
        `;

        // Function to create and append a label to the body
        function createAndAdjustLabel(element, index) {{
            if (!isElementVisible(element)) return;

            element.classList.add('highlighted-element');
            var label = document.createElement('div');
            label.className = 'highlight-label';
            label.textContent = index.toString();
            label.style.display = 'block'; // Make the label visible

            // Calculate label position
            var rect = element.getBoundingClientRect();
            var top = rect.top + window.scrollY - 25; // Position label above the element
            var left = rect.left + window.scrollX;

            label.style.top = top + 'px';
            label.style.left = left + 'px';

            document.body.appendChild(label); // Append the label to the body
        }}

        // Select all clickable elements and apply the styles
        var allElements = document.querySelectorAll('{selector}');
        var index = 1;
        allElements.forEach(function(element) {{
            // Check if the element is not already highlighted and is visible
            if (!element.dataset.highlighted && isElementVisible(element)) {{
                element.dataset.highlighted = 'true';
                createAndAdjustLabel(element, index++);
            }}
        }});
        """

    driver.execute_script(script)

    return driver


def remove_highlight_and_labels(driver):
    """
    This function removes all red borders and labels from the webpage elements,
    reversing the changes made by the highlight functions using Selenium WebDriver.

    :param driver: Instance of Selenium WebDriver.
    """
    selector = (
        'a, button, input, textarea, div[onclick], div[role="button"], div[tabindex], span[onclick], '
        'span[role="button"], span[tabindex]'
    )
    script = f"""
        // Remove all labels
        document.querySelectorAll('.highlight-label').forEach(function(label) {{
            label.remove();
        }});

        // Remove the added style for red borders
        var highlightStyle = document.getElementById('highlight-style');
        if (highlightStyle) {{
            highlightStyle.remove();
        }}

        // Remove inline styles added by highlighting function
        document.querySelectorAll('{selector}').forEach(function(element) {{
            element.style.border = '';
        }});
        """

    driver.execute_script(script)

    return driver



================================================
FILE: agency_swarm/agents/BrowsingAgent/tools/util/selenium.py
================================================
import os

wd = None

selenium_config = {
    "chrome_profile_path": None,
    "headless": True,
    "full_page_screenshot": True,
}


def get_web_driver():
    print("Initializing WebDriver...")
    try:
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service as ChromeService

        print("Selenium imported successfully.")
    except ImportError:
        print("Selenium not installed. Please install it with pip install selenium")
        raise ImportError

    try:
        from webdriver_manager.chrome import ChromeDriverManager

        print("webdriver_manager imported successfully.")
    except ImportError:
        print(
            "webdriver_manager not installed. Please install it with pip install webdriver-manager"
        )
        raise ImportError

    try:
        from selenium_stealth import stealth

        print("selenium_stealth imported successfully.")
    except ImportError:
        print(
            "selenium_stealth not installed. Please install it with pip install selenium-stealth"
        )
        raise ImportError

    global wd, selenium_config

    if wd:
        print("Returning existing WebDriver instance.")
        return wd

    chrome_profile_path = selenium_config.get("chrome_profile_path", None)
    profile_directory = None
    user_data_dir = None
    if isinstance(chrome_profile_path, str) and os.path.exists(chrome_profile_path):
        profile_directory = (
            os.path.split(chrome_profile_path)[-1].strip("\\").rstrip("/")
        )
        user_data_dir = os.path.split(chrome_profile_path)[0].strip("\\").rstrip("/")
        print(f"Using Chrome profile: {profile_directory}")
        print(f"Using Chrome user data dir: {user_data_dir}")
        print(f"Using Chrome profile path: {chrome_profile_path}")

    chrome_options = webdriver.ChromeOptions()
    print("ChromeOptions initialized.")

    chrome_driver_path = "/usr/bin/chromedriver"
    if not os.path.exists(chrome_driver_path):
        print(
            "ChromeDriver not found at /usr/bin/chromedriver. Installing using webdriver_manager."
        )
        chrome_driver_path = ChromeDriverManager().install()
    else:
        print(f"ChromeDriver found at {chrome_driver_path}.")

    if selenium_config.get("headless", False):
        chrome_options.add_argument("--headless")
        print("Headless mode enabled.")
    if selenium_config.get("full_page_screenshot", False):
        chrome_options.add_argument("--start-maximized")
        print("Full page screenshot mode enabled.")
    else:
        chrome_options.add_argument("--window-size=1920,1080")
        print("Window size set to 1920,1080.")

    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--remote-debugging-port=9222")
    chrome_options.add_argument("--disable-extensions")
    chrome_options.add_argument("--disable-popup-blocking")
    chrome_options.add_argument("--ignore-certificate-errors")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_argument("--disable-web-security")
    chrome_options.add_argument("--allow-running-insecure-content")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    print("Chrome options configured.")

    if user_data_dir and profile_directory:
        chrome_options.add_argument(f"user-data-dir={user_data_dir}")
        chrome_options.add_argument(f"profile-directory={profile_directory}")
        print(
            f"Using user data dir: {user_data_dir} and profile directory: {profile_directory}"
        )

    try:
        wd = webdriver.Chrome(
            service=ChromeService(chrome_driver_path), options=chrome_options
        )
        print("WebDriver initialized successfully.")
        if wd.capabilities["chrome"]["userDataDir"]:
            print(f"Profile path in use: {wd.capabilities['chrome']['userDataDir']}")
    except Exception as e:
        print(f"Error initializing WebDriver: {e}")
        raise e

    if not selenium_config.get("chrome_profile_path", None):
        stealth(
            wd,
            languages=["en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True,
        )
        print("Stealth mode configured.")

    wd.implicitly_wait(3)
    print("Implicit wait set to 3 seconds.")

    return wd


def set_web_driver(new_wd):
    # remove all popups
    js_script = """
    var popUpSelectors = ['modal', 'popup', 'overlay', 'dialog']; // Add more selectors that are commonly used for pop-ups
    popUpSelectors.forEach(function(selector) {
        var elements = document.querySelectorAll(selector);
        elements.forEach(function(element) {
            // You can choose to hide or remove; here we're removing the element
            element.parentNode.removeChild(element);
        });
    });
    """

    new_wd.execute_script(js_script)

    # Close LinkedIn specific popups
    if "linkedin.com" in new_wd.current_url:
        linkedin_js_script = """
        var linkedinSelectors = ['div.msg-overlay-list-bubble', 'div.ml4.msg-overlay-list-bubble__tablet-height'];
        linkedinSelectors.forEach(function(selector) {
            var elements = document.querySelectorAll(selector);
            elements.forEach(function(element) {
                element.parentNode.removeChild(element);
            });
        });
        """
        new_wd.execute_script(linkedin_js_script)

    new_wd.execute_script("document.body.style.zoom='1.2'")

    global wd
    wd = new_wd


def set_selenium_config(config):
    global selenium_config
    selenium_config = config



================================================
FILE: agency_swarm/agents/Devid/__init__.py
================================================
from .Devid import Devid



================================================
FILE: agency_swarm/agents/Devid/Devid.py
================================================
import re

from typing_extensions import override

from agency_swarm.agents import Agent
from agency_swarm.tools import FileSearch
from agency_swarm.util.validators import llm_validator


class Devid(Agent):
    def __init__(self):
        super().__init__(
            name="Devid",
            description="Devid is an AI software engineer capable of performing advanced coding tasks.",
            instructions="./instructions.md",
            files_folder="./files",
            schemas_folder="./schemas",
            tools=[FileSearch],
            tools_folder="./tools",
            validation_attempts=1,
            temperature=0,
            max_prompt_tokens=25000,
        )

    @override
    def response_validator(self, message):
        pattern = r"(```)((.*\n){5,})(```)"

        if re.search(pattern, message):
            # take only first 100 characters
            raise ValueError(
                "You returned code snippet. Please never return code snippets to me. "
                "Use the FileWriter tool to write the code locally. Then, test it if possible. Continue."
            )

        llm_validator(
            statement="Verify whether the update from the AI Developer Agent confirms the task's "
            "successful completion. If the task remains unfinished, provide guidance "
            "within the 'reason' argument on the next steps the agent should take. For "
            "instance, if the agent encountered an error, advise the inclusion of debug "
            "statements for another attempt. Should the agent outline potential "
            "solutions or further actions, direct the agent to execute those plans. "
            "Message does not have to contain code snippets. Just confirmation.",
            client=self.client,
        )(message)

        return message



================================================
FILE: agency_swarm/agents/Devid/instructions.md
================================================
# Devid Operational Guide

As an AI software developer known as Devid, your role involves reading, writing, and modifying files to fulfill tasks derived from user requests.

**Operational Environment**:
- You have direct access to the internet, system executions, or environment variables.
- Interaction with the local file system to read, write, and modify files is permitted.
- Python is installed in your environment, enabling the execution of Python scripts and code snippets.
- Node.js and npm are also installed, allowing for the execution of Node.js scripts and code snippets.
- Installation of additional third-party libraries is within your capabilities.
- Execution of commands in the terminal to compile and run code is possible.

## Primary Instructions:

1. Begin by fully understanding the task at hand. Use the `myfiles_browser` tool to access and review any files uploaded by the user. If initial access to files fails, retry the operation until successful. Continue browsing the files until you have gathered sufficient information to proceed. Skip this step if no files were provided.
2. Verify your current directory's path and contents with `ListDir` and `CheckCurrentDir`. If necessary, navigate to the correct directory using the `DirectoryNavigator` tool or create a new directory for the task.
3. Utilize the `FileWriter` for creating or modifying files. To read a file, employ the `FileReader` tool. Always modify local files when executing tasks and avoid sending code snippets to the user. Work on one file at a time and refrain from creating or modifying multiple files simultaneously. Complete each file with `FileWriter` before proceeding to the next, integrating these files into the dependencies of the main file.
4. Execute your written code with the `CommandExecutor` by running the appropriate terminal commands. Iteratively debug and test to achieve the desired outcome. Seek clarification from the user only after all internal resolution efforts have been exhausted. To install additional libraries, execute the necessary terminal commands.
5. Repeat the above steps for each task.

**Important Note**: Your capabilities include accessing and interacting with local files, online resources, and the terminal. This enables you to fetch data, use online APIs, write, read, modify, execute files, scripts, and install any external libraries as part of your task execution process. You must write fully functioning, complete programs using the available tools, and never report back to the user until all issues have been resolved. Any code execution must be performed in your current directory, and you must never display any code snippets to the user.



================================================
FILE: agency_swarm/agents/Devid/tools/__init__.py
================================================



================================================
FILE: agency_swarm/agents/Devid/tools/ChangeFile.py
================================================
import os
from enum import Enum
from typing import List, Literal, Optional

from pydantic import BaseModel, Field, field_validator, model_validator

from agency_swarm import BaseTool


class LineChange(BaseModel):
    """
    Line changes to be made.
    """

    line_number: int = Field(
        ..., description="Line number to change.", examples=[1, 2, 3]
    )
    new_line: Optional[str] = Field(
        None,
        description="New line to replace the old line. Not required only for delete mode.",
        examples=["This is a new line"],
    )
    mode: Literal["replace", "insert", "delete"] = Field(
        "replace",
        description='Mode to use for the line change. "replace" replaces the line with the new line. '
        '"insert" inserts the new line at the specified line number, moving the previous line down.'
        ' "delete" deletes the specified line number.',
    )

    @model_validator(mode="after")
    def validate_new_line(self):
        mode, new_line = self.mode, self.new_line
        if mode == "delete" and new_line is not None:
            raise ValueError("new_line should not be specified for delete mode.")
        elif mode in ["replace", "insert"] and new_line is None:
            raise ValueError(
                "new_line should be specified for replace and insert modes."
            )
        return self


class ChangeFile(BaseTool):
    """
    This tool changes specified lines in a file. Returns the new file contents with line numbers at the start of each line.
    """

    chain_of_thought: str = Field(
        ...,
        description="Please think step-by-step about the required changes to the file in order to construct a fully functioning and correct program according to the requirements.",
        exclude=True,
    )
    file_path: str = Field(
        ...,
        description="Path to the file with extension.",
        examples=["./file.txt", "./file.json", "../../file.py"],
    )
    changes: List[LineChange] = Field(
        ...,
        description="Line changes to be made to the file.",
        examples=[
            {"line_number": 1, "new_line": "This is a new line", "mode": "replace"}
        ],
    )

    def run(self):
        # read file
        with open(self.file_path, "r") as f:
            file_contents = f.readlines()

            # Process changes in a way that accounts for modifications affecting line numbers
            for change in sorted(
                self.changes, key=lambda x: x.line_number, reverse=True
            ):
                try:
                    if change.mode == "replace" and 0 < change.line_number <= len(
                        file_contents
                    ):
                        file_contents[change.line_number - 1] = change.new_line + "\n"
                    elif change.mode == "insert":
                        file_contents.insert(
                            change.line_number - 1, change.new_line + "\n"
                        )
                    elif change.mode == "delete" and 0 < change.line_number <= len(
                        file_contents
                    ):
                        file_contents.pop(change.line_number - 1)
                except IndexError:
                    return f"Error: Line number {change.line_number} is out of the file's range."

        # write file
        with open(self.file_path, "w") as f:
            f.writelines(file_contents)

        with open(self.file_path, "r") as f:
            file_contents = f.readlines()

        # return file contents with line numbers
        return "\n".join([f"{i + 1}. {line}" for i, line in enumerate(file_contents)])

    # use field validation to ensure that the file path is valid
    @field_validator("file_path", mode="after")
    @classmethod
    def validate_file_path(cls, v: str):
        if not os.path.exists(v):
            raise ValueError("File path does not exist.")

        return v



================================================
FILE: agency_swarm/agents/Devid/tools/CheckCurrentDir.py
================================================
from pydantic import Field

from agency_swarm import BaseTool


class CheckCurrentDir(BaseTool):
    """
    This tool checks the current directory path.
    """

    chain_of_thought: str = Field(
        ...,
        description="Please think step-by-step about what you need to do next, after checking current directory to solve the task.",
        exclude=True,
    )

    class ToolConfig:
        one_call_at_a_time: bool = True

    def run(self):
        import os

        return os.getcwd()



================================================
FILE: agency_swarm/agents/Devid/tools/CommandExecutor.py
================================================
import shlex
import subprocess

from dotenv import find_dotenv, load_dotenv
from pydantic import Field

from agency_swarm.tools import BaseTool


class CommandExecutor(BaseTool):
    """
    Executes a specified command in the terminal and captures the output.

    This tool runs a given command in the system's default shell and returns the stdout and stderr.
    """

    command: str = Field(..., description="The command to execute in the terminal.")

    def run(self):
        """
        Executes the command and captures its output.

        Returns:
            A dictionary containing the standard output (stdout), standard error (stderr),
            and the exit code of the command.
        """
        load_dotenv(find_dotenv() or None)
        # Ensure the command is safely split for subprocess
        command_parts = shlex.split(self.command)

        # Execute the command and capture the output
        result = subprocess.run(command_parts, capture_output=True, text=True)

        # check if the command failed
        if result.returncode != 0 or result.stderr:
            return (
                f"stdout: {result.stdout}\nstderr: {result.stderr}\nexit code: {result.returncode}\n\n"
                f"Please add error handling and continue debugging until the command runs successfully."
            )

        return f"stdout: {result.stdout}\nstderr: {result.stderr}\nexit code: {result.returncode}"


if __name__ == "__main__":
    tool = CommandExecutor(command="ls -l")
    print(tool.run())



================================================
FILE: agency_swarm/agents/Devid/tools/DirectoryNavigator.py
================================================
import os

from pydantic import Field, field_validator, model_validator

from agency_swarm.tools import BaseTool


class DirectoryNavigator(BaseTool):
    """Allows you to navigate directories. Do not use this tool more than once at a time.
    You must finish all tasks in the current directory before navigating into new directory."""

    path: str = Field(..., description="The path of the directory to navigate to.")
    create: bool = Field(
        False,
        description="If True, the directory will be created if it does not exist.",
    )

    class ToolConfig:
        one_call_at_a_time: bool = True

    def run(self):
        try:
            os.chdir(self.path)
            return f"Successfully changed directory to: {self.path}"
        except Exception as e:
            return f"Error changing directory: {e}"

    @field_validator("create", mode="before")
    @classmethod
    def validate_create(cls, v):
        if not isinstance(v, bool):
            if v.lower() == "true":
                return True
            elif v.lower() == "false":
                return False
        return v

    @model_validator(mode="after")
    def validate_path(self):
        if not os.path.isdir(self.path):
            if "/mnt/data" in self.path:
                raise ValueError(
                    "You tried to access an openai file directory with a local directory reader tool. "
                    + "Please use the `myfiles_browser` tool to access openai files instead. "
                    + "Your local files are most likely located in your current directory."
                )

            if self.create:
                os.makedirs(self.path)
            else:
                raise ValueError(
                    f"The path {self.path} does not exist. Please provide a valid directory path. "
                    + "If you want to create the directory, set the `create` parameter to True."
                )

        return self



================================================
FILE: agency_swarm/agents/Devid/tools/FileMover.py
================================================
import os
import shutil

from pydantic import Field

from agency_swarm.tools import BaseTool


class FileMover(BaseTool):
    """
    FileMover is a tool designed to move files from a source path to a destination path. If the destination directory does not exist, it will be created.
    """

    source_path: str = Field(
        ...,
        description="The full path of the file to move, including the file name and extension.",
    )
    destination_path: str = Field(
        ...,
        description="The destination path where the file should be moved, including the new file name and extension if changing.",
    )

    def run(self):
        """
        Executes the file moving operation from the source path to the destination path.
        It checks if the destination directory exists and creates it if necessary, then moves the file.
        """
        if not os.path.exists(self.source_path):
            return f"Source file does not exist at {self.source_path}"

        # Ensure the destination directory exists
        destination_dir = os.path.dirname(self.destination_path)
        if not os.path.exists(destination_dir):
            os.makedirs(destination_dir)

        # Move the file
        shutil.move(self.source_path, self.destination_path)

        return f"File moved successfully from {self.source_path} to {self.destination_path}"



================================================
FILE: agency_swarm/agents/Devid/tools/FileReader.py
================================================
from pydantic import Field, field_validator

from agency_swarm.tools import BaseTool


class FileReader(BaseTool):
    """This tool reads a file and returns the contents along with line numbers on the left."""

    file_path: str = Field(
        ...,
        description="Path to the file to read with extension.",
        examples=["./file.txt", "./file.json", "../../file.py"],
    )

    def run(self):
        # read file
        with open(self.file_path, "r") as f:
            file_contents = f.readlines()

        # return file contents
        return "\n".join([f"{i + 1}. {line}" for i, line in enumerate(file_contents)])

    @field_validator("file_path", mode="after")
    @classmethod
    def validate_file_path(cls, v):
        if "file-" in v:
            raise ValueError(
                "You tried to access an openai file with a wrong file reader tool. "
                "Please use the `myfiles_browser` tool to access openai files instead."
                "This tool is only for reading local files."
            )
        return v



================================================
FILE: agency_swarm/agents/Devid/tools/FileWriter.py
================================================
import os
import re
from typing import List, Literal, Optional

from pydantic import Field, field_validator

from agency_swarm import get_openai_client
from agency_swarm.tools import BaseTool
from agency_swarm.util.validators import llm_validator

from .util import format_file_deps

history = [
    {
        "role": "system",
        "content": "As a top-tier software engineer focused on developing programs incrementally, you are entrusted with the creation or modification of files based on user requirements. It's imperative to operate under the assumption that all necessary dependencies are pre-installed and accessible, and the file in question will be deployed in an appropriate environment. Furthermore, it is presumed that all other modules or files upon which this file relies are accurate and error-free. Your output should be encapsulated within a code block, without specifying the programming language. Prior to embarking on the coding process, you must outline a methodical, step-by-step plan to precisely fulfill the requirements â€” no more, no less. It is crucial to ensure that the final code block is a complete file, without any truncation. This file should embody a flawless, fully operational program, inclusive of all requisite imports and functions, devoid of any placeholders, unless specified otherwise by the user.",
    },
]


class FileWriter(BaseTool):
    """This tools allows you to write new files or modify existing files according to specified requirements. In 'write' mode, it creates a new file or overwrites an existing one. In 'modify' mode, it modifies an existing file according to the provided requirements.
    Note: This tool does not have access to other files within the project. You must provide all necessary details to ensure that the generated file can be used in conjunction with other files in this project."""

    file_path: str = Field(
        ...,
        description="The path of the file to write or modify. Will create directories if they don't exist.",
    )
    requirements: str = Field(
        ...,
        description="The comprehensive requirements explaining how the file should be written or modified. This should be a detailed description of what the file should contain, including example inputs, desired behaviour and ideal outputs. It must not contain any code or implementation details.",
    )
    details: str = Field(
        None,
        description="Additional details like error messages, or class, function, and variable names from other files that this file depends on.",
    )
    documentation: Optional[str] = Field(
        None,
        description="Relevant documentation extracted with the myfiles_browser tool. You must pass all the relevant code from the documentation, as this tool does not have access to those files.",
    )
    mode: Literal["write", "modify"] = Field(
        ...,
        description="The mode of operation for the tool. 'write' is used to create a new file or overwrite an existing one. 'modify' is used to modify an existing file.",
    )
    file_dependencies: List[str] = Field(
        [],
        description="Paths to other files that the file being written depends on.",
        examples=[
            "/path/to/dependency1.py",
            "/path/to/dependency2.css",
            "/path/to/dependency3.js",
        ],
    )
    library_dependencies: List[str] = Field(
        [],
        description="Any library dependencies required for the file to be written.",
        examples=["numpy", "pandas"],
    )

    class ToolConfig:
        one_call_at_a_time = True

    def run(self):
        client = get_openai_client()

        file_dependencies = format_file_deps(self.file_dependencies)

        library_dependencies = ", ".join(self.library_dependencies)

        filename = os.path.basename(self.file_path)

        if self.mode == "write":
            message = f"Please write {filename} file that meets the following requirements: '{self.requirements}'.\n"
        else:
            message = f"Please rewrite the {filename} file according to the following requirements: '{self.requirements}'.\n Only output the file content, without any other text."

        if file_dependencies:
            message += f"\nHere are the dependencies from other project files: {file_dependencies}."
        if library_dependencies:
            message += f"\nUse the following libraries: {library_dependencies}"
        if self.details:
            message += f"\nAdditional Details: {self.details}"
        if self.documentation:
            message += f"\nDocumentation: {self.documentation}"

        if self.mode == "modify":
            message += f"\nThe existing file content is as follows:"

            try:
                with open(self.file_path, "r") as file:
                    file_content = file.read()
                    message += f"\n\n```{file_content}```"
            except Exception as e:
                return f"Error reading {self.file_path}: {e}"

        history.append({"role": "user", "content": message})

        messages = history.copy()

        # use the last 5 messages
        messages = messages[-5:]

        # add system message upfront
        messages.insert(0, history[0])

        n = 0
        error_message = ""
        while n < 3:
            if self.mode == "modify":
                resp = client.chat.completions.create(
                    messages=messages,
                    model="gpt-4o",
                    temperature=0,
                    prediction={"type": "content", "content": file_content},
                )
            else:
                resp = client.chat.completions.create(
                    messages=messages,
                    model="gpt-4o",
                    temperature=0,
                )

            content = resp.choices[0].message.content

            messages.append({"role": "assistant", "content": content})

            pattern = r"```(?:[a-zA-Z]+\n)?(.*?)```"
            match = re.findall(pattern, content, re.DOTALL)
            if match:
                code = match[-1].strip()
                try:
                    self.validate_content(code)

                    history.append({"role": "assistant", "content": content})

                    break
                except Exception as e:
                    print(f"Error: {e}. Trying again.")
                    error_message = str(e)
                    messages.append(
                        {"role": "user", "content": f"Error: {e}. Please try again."}
                    )
            else:
                messages.append(
                    {
                        "role": "user",
                        "content": f"Error: Could not find the code block in the response. Please try again.",
                    }
                )

            n += 1

        if n == 3 or not code:
            history.append({"role": "assistant", "content": content})
            history.append({"role": "user", "content": error_message})
            return "Error: Could not generate a valid file: " + error_message

        try:
            # create directories if they don't exist
            dir_path = os.path.dirname(self.file_path)
            if dir_path != "" and not os.path.exists(dir_path):
                os.makedirs(dir_path, exist_ok=True)

            with open(self.file_path, "w") as file:
                file.write(code)
            return f"Successfully wrote to file: {self.file_path}. Please make sure to now test the program. Below is the content of the file:\n\n```{content}```\n\nPlease now verify the integrity of the file and test it."
        except Exception as e:
            return f"Error writing to file: {e}"

    @field_validator("file_dependencies", mode="after")
    @classmethod
    def validate_file_dependencies(cls, v):
        for file in v:
            if not os.path.exists(file):
                raise ValueError(f"File dependency '{file}' does not exist.")
        return v

    def validate_content(self, v):
        client = get_openai_client()

        llm_validator(
            statement="Check if the code is bug-free. Code should be considered in isolation, with the understanding that it is part of a larger, fully developed program that strictly adheres to these standards of completeness and correctness. All files, elements, components, functions, or modules referenced within this snippet are assumed to exist in other parts of the project and are also devoid of any errors, ensuring a cohesive and error-free integration across the entire software solution. Certain placeholders may be present.",
            client=client,
            model="gpt-4o",
            temperature=0,
            allow_override=False,
        )(v)

        return v

    @field_validator("requirements", mode="after")
    @classmethod
    def validate_requirements(cls, v):
        if "placeholder" in v:
            raise ValueError(
                "Requirements contain placeholders. "
                "Please never user placeholders. Instead, implement only the code that you are confident about."
            )

        # check if code is included in requirements
        pattern = r"(```)((.*\n){5,})(```)"
        if re.search(pattern, v):
            raise ValueError(
                "Requirements contain a code snippet. Please never include code snippets in requirements. "
                "Requirements must be a description of the complete file to be written. You can include specific class, function, and variable names, but not the actual code."
            )

        return v

    @field_validator("details", mode="after")
    @classmethod
    def validate_details(cls, v):
        if len(v) == 0:
            raise ValueError(
                "Details are required. Remember: this tool does not have access to other files. Please provide additional details like relevant documentation, error messages, or class, function, and variable names from other files that this file depends on."
            )
        return v

    @field_validator("documentation", mode="after")
    @classmethod
    def validate_documentation(cls, v):
        # check if documentation contains code
        pattern = r"(```)((.*\n){5,})(```)"
        pattern2 = r"(`)(.*)(`)"
        if not (re.search(pattern, v) or re.search(pattern2, v)):
            raise ValueError(
                "Documentation does not contain a code snippet. Please provide relevant documentation extracted with the myfiles_browser tool. You must pass all the relevant code snippets information, as this tool does not have access to those files."
            )


if __name__ == "__main__":
    # Test case for 'write' mode
    tool_write = FileWriter(
        requirements="Write a program that takes a list of integers as input and returns the sum of all the integers in the list.",
        mode="write",
        file_path="test_write.py",
    )
    print(tool_write.run())

    # Test case for 'modify' mode
    tool_modify = FileWriter(
        requirements="Modify the program to also return the product of all the integers in the list.",
        mode="modify",
        file_path="test_write.py",
    )
    print(tool_modify.run())



================================================
FILE: agency_swarm/agents/Devid/tools/ListDir.py
================================================
import os

from pydantic import Field, field_validator

from agency_swarm import BaseTool


class ListDir(BaseTool):
    """
    This tool returns the tree structure of the directory.
    """

    dir_path: str = Field(
        ...,
        description="Path of the directory to read.",
        examples=["./", "./test", "../../"],
    )

    def run(self):
        tree = []

        def list_directory_tree(path, indent=""):
            """Recursively list the contents of a directory in a tree-like format."""
            if not os.path.isdir(path):
                raise ValueError(f"The path {path} is not a valid directory")

            items = os.listdir(path)
            # exclude common hidden files and directories
            exclude = [
                ".git",
                ".idea",
                "__pycache__",
                "node_modules",
                ".venv",
                ".gitignore",
                ".gitkeep",
                ".DS_Store",
                ".vscode",
                ".next",
                "dist",
                "build",
                "out",
                "venv",
                "env",
                "logs",
                "data",
            ]

            items = [item for item in items if item not in exclude]

            for i, item in enumerate(items):
                item_path = os.path.join(path, item)
                if i < len(items) - 1:
                    tree.append(indent + "â”œâ”€â”€ " + item)
                    if os.path.isdir(item_path):
                        list_directory_tree(item_path, indent + "â”‚   ")
                else:
                    tree.append(indent + "â””â”€â”€ " + item)
                    if os.path.isdir(item_path):
                        list_directory_tree(item_path, indent + "    ")

        list_directory_tree(self.dir_path)

        return "\n".join(tree)

    @field_validator("dir_path", mode="after")
    @classmethod
    def validate_dir_path(cls, v):
        if "file-" in v:
            raise ValueError(
                "You tried to access an openai file with a local directory reader tool. "
                "Please use the `myfiles_browser` tool to access openai directories instead."
            )

        if not os.path.isdir(v):
            if "/mnt/data" in v:
                raise ValueError(
                    "You tried to access an openai file directory with a local directory reader tool. "
                    "Please use the `myfiles_browser` tool to access openai files instead. "
                    "You can work in your local directory by using the `FileReader` tool."
                )

            raise ValueError(f"The path {v} is not a valid directory")
        return v



================================================
FILE: agency_swarm/agents/Devid/tools/util/__init__.py
================================================
from .format_file_deps import format_file_deps



================================================
FILE: agency_swarm/agents/Devid/tools/util/format_file_deps.py
================================================
from typing import List, Literal

from pydantic import BaseModel, Field

from agency_swarm import get_openai_client


def format_file_deps(v):
    client = get_openai_client()
    result = ""
    for file in v:
        # extract dependencies from the file using openai
        with open(file, "r") as f:
            content = f.read()

        class Dependency(BaseModel):
            type: Literal["class", "function", "import"] = Field(
                ..., description="The type of the dependency."
            )
            name: str = Field(
                ...,
                description="The name of the dependency, matching the import or definition.",
            )

        class Dependencies(BaseModel):
            dependencies: List[Dependency] = Field(
                [], description="The dependencies extracted from the file."
            )

            def append_dependencies(self):
                functions = [
                    dep.name for dep in self.dependencies if dep.type == "function"
                ]
                classes = [dep.name for dep in self.dependencies if dep.type == "class"]
                imports = [
                    dep.name for dep in self.dependencies if dep.type == "import"
                ]
                variables = [
                    dep.name for dep in self.dependencies if dep.type == "variable"
                ]
                nonlocal result
                result += f"File path: {file}\n"
                result += f"Functions: {functions}\nClasses: {classes}\nImports: {imports}\nVariables: {variables}\n\n"

        completion = client.beta.chat.completions.parse(
            messages=[
                {
                    "role": "system",
                    "content": "You are a world class dependency resolved. You must extract the dependencies from the file provided.",
                },
                {
                    "role": "user",
                    "content": f"Extract the dependencies from the file '{file}'.",
                },
            ],
            model="gpt-4o-mini",
            temperature=0,
            response_format=Dependencies,
        )

        if completion.choices[0].message.refusal:
            raise ValueError(completion.choices[0].message.refusal)

        model = completion.choices[0].message.parsed

        model.append_dependencies()

    return result



================================================
FILE: agency_swarm/integrations/fastapi.py
================================================
import os
from typing import List, Optional, Dict, Type
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager

from agency_swarm.agents import Agent
from agency_swarm.agency import Agency
from agency_swarm.tools import BaseTool

from dotenv import load_dotenv

load_dotenv()


def run_fastapi(
    agencies: Optional[List[Agency]] = None,
    tools: Optional[List[Type[BaseTool]]] = None,
    host: str = "0.0.0.0",
    port: int = 8000,
    app_token_env: str = "APP_TOKEN",
):
    """
    Launch a FastAPI server exposing endpoints for multiple agencies and tools.
    Each agency is deployed at /[agency-name]/get_completion and /[agency-name]/get_completion_stream.
    Each tool is deployed at /tool/[tool-name].
    """
    if (agencies is None or len(agencies) == 0) and (tools is None or len(tools) == 0):
        print("No endpoints to deploy. Please provide at least one agency or tool.")
        return

    try:
        import uvicorn
        from fastapi import FastAPI
        from fastapi.middleware.cors import CORSMiddleware
        from .fastapi_utils.request_models import add_agent_validator, BaseRequest
        from .fastapi_utils.endpoint_handlers import (
            make_completion_endpoint,
            make_stream_endpoint,
            make_tool_endpoint,
            exception_handler,
            get_verify_token,
        )
    except ImportError:
        print(
            "FastAPI deployment dependencies are missing. Please install agency-swarm[fastapi] package"
        )
        return

    app_token = os.getenv(app_token_env)
    if app_token is None or app_token == "":
        print(f"Warning: {app_token_env} is not set. Authentication will be disabled.")
    verify_token = get_verify_token(app_token)

    @asynccontextmanager
    async def lifespan(app):
        # Startup logic
        global _EXECUTOR
        from .fastapi_utils.endpoint_handlers import _MAX_WORKERS, _EXECUTOR
        if _EXECUTOR is None:
            print("Initializing ThreadPoolExecutor in FastAPI startup event")
            _EXECUTOR = ThreadPoolExecutor(max_workers=_MAX_WORKERS)
        else:
            print("ThreadPoolExecutor already initialized")
        try:
            yield
        finally:
            # Shutdown logic
            if _EXECUTOR is not None:
                print("Shutting down ThreadPoolExecutor in FastAPI shutdown event")
                _EXECUTOR.shutdown(wait=False, cancel_futures=True)
                _EXECUTOR = None
            else:
                print("No ThreadPoolExecutor to shut down")

    app = FastAPI(lifespan=lifespan)
    
    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    endpoints = []
    agency_names = []

    if agencies:
        for idx, agency in enumerate(agencies):
            agency_name = getattr(agency, "name", None)
            if agency_name is None:
                agency_name = "agency" if len(agencies) == 1 else f"agency_{idx+1}"
            agency_name = agency_name.replace(" ", "_")
            if agency_name in agency_names:
                raise ValueError(f"Agency name {agency_name} is already in use. Please provide a unique name in the agency's 'name' parameter.")
            agency_names.append(agency_name)

            # Store agent instances for easy lookup
            AGENT_INSTANCES: Dict[str, "Agent"] = {
                agent.name: agent for agent in agency.agents
            }

            class VerboseRequest(BaseRequest):
                verbose: bool = False

            AgencyRequest = add_agent_validator(VerboseRequest, AGENT_INSTANCES)
            AgencyRequestStreaming = add_agent_validator(BaseRequest, AGENT_INSTANCES)

            app.add_api_route(
                f"/{agency_name}/get_completion",
                make_completion_endpoint(AgencyRequest, agency, verify_token),
                methods=["POST"],
            )
            app.add_api_route(
                f"/{agency_name}/get_completion_stream",
                make_stream_endpoint(AgencyRequestStreaming, agency, verify_token),
                methods=["POST"],
            )
            endpoints.append(f"/{agency_name}/get_completion")
            endpoints.append(f"/{agency_name}/get_completion_stream")

    if tools:
        for tool in tools:
            tool_name = tool.__name__
            tool_handler = make_tool_endpoint(tool, verify_token)
            app.add_api_route(
                f"/tool/{tool_name}", tool_handler, methods=["POST"], name=tool_name
            )
            endpoints.append(f"/tool/{tool_name}")

    app.add_exception_handler(Exception, exception_handler)

    print(f"Starting FastAPI server at http://{host}:{port}")
    print("Created endpoints:\n" + "\n".join(endpoints))
    uvicorn.run(app, host=host, port=port)



================================================
FILE: agency_swarm/integrations/fastapi_utils/endpoint_handlers.py
================================================
import asyncio
import json
import os
from concurrent.futures import Future, ThreadPoolExecutor
from typing import Any, Optional

import anyio
from anyio import (
    EndOfStream,
    create_memory_object_stream,
    fail_after,
)
from fastapi import Depends, HTTPException, Request
from fastapi.responses import JSONResponse, StreamingResponse
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from openai.types.beta import AssistantStreamEvent

from agency_swarm.util.streaming import AgencyEventHandler

try:
    from typing import override  # py >= 3.12
except ImportError:  # pragma: no cover â€“ fallback path
    from typing_extensions import override  # type: ignore

_n_cpus = os.cpu_count() or 1
_MAX_WORKERS = max(1, int(os.getenv("STREAM_THREAD_POOL_SIZE", _n_cpus * 4)))
_EXECUTOR: Optional[ThreadPoolExecutor] = None

def get_executor() -> ThreadPoolExecutor:
    """Get the thread pool executor, ensuring it has been initialized."""
    global _EXECUTOR
    if _EXECUTOR is None:
        # Fallback initialization if not created by FastAPI lifecycle hooks
        print("WARNING: ThreadPoolExecutor not initialized by FastAPI lifecycle hooks. Creating now.")
        _EXECUTOR = ThreadPoolExecutor(max_workers=_MAX_WORKERS)
    return _EXECUTOR

def get_verify_token(app_token):
    auto_error = app_token is not None and app_token != ""
    security = HTTPBearer(auto_error=auto_error)
    async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
        if app_token is None or app_token == "":
            return None
        if not credentials or credentials.credentials != app_token:
            raise HTTPException(status_code=401, detail="Unauthorized")
        return credentials.credentials
    return verify_token

# Nonâ€‘streaming completion endpoint
def make_completion_endpoint(request_model, current_agency, verify_token):
    async def handler(request: request_model, token: str = Depends(verify_token)):
        def call_completion() -> Any:
            if request.threads:
                current_thread = get_threads(current_agency)
                if current_thread != request.threads:
                    override_threads(current_agency, request.threads)
            response = current_agency.get_completion(
                request.message,
                message_files=request.message_files,
                recipient_agent=request.recipient_agent,
                additional_instructions=request.additional_instructions,
                attachments=request.attachments,
                tool_choice=request.tool_choice,
                verbose=getattr(request, "verbose", False),
                response_format=request.response_format,
            )
            return response

        response = await anyio.to_thread.run_sync(call_completion, cancellable=True)
        return {"response": response, "threads": get_threads(current_agency)}

    return handler

# Streaming SSE endpoint
def make_stream_endpoint(request_model, current_agency, verify_token):
    """FastAPI SSE endpoint factory using AnyIO (handles backâ€‘pressure)."""

    async def handler(request: request_model, token: str = Depends(verify_token)):
        # Async queue bridging producer thread â†’ eventâ€‘loop
        send_ch, recv_ch = create_memory_object_stream(256)

        loop = asyncio.get_running_loop()  # capture once

        def _threadsafe_send(item):
            """Block the calling thread until the item is accepted."""
            try:
                asyncio.run_coroutine_threadsafe(send_ch.send(item), loop).result()
            except RuntimeError:
                # Eventâ€‘loop is closed (shutdown). Drop the message.
                pass

        class StreamEventHandler(AgencyEventHandler):
            @override
            def on_event(self, event: AssistantStreamEvent) -> None:
                _threadsafe_send(event.model_dump())

            @classmethod
            def on_all_streams_end(cls):
                _threadsafe_send("[DONE]")

            @classmethod
            def on_exception(cls, exc: Exception):
                _threadsafe_send({"error": str(exc)})

        def run_completion() -> None:
            try:
                if request.threads:
                    current_thread = get_threads(current_agency)
                    if current_thread != request.threads:
                        override_threads(current_agency, request.threads)
                current_agency.get_completion_stream(
                    request.message,
                    message_files=request.message_files,
                    recipient_agent=request.recipient_agent,
                    additional_instructions=request.additional_instructions,
                    attachments=request.attachments,
                    tool_choice=request.tool_choice,
                    response_format=request.response_format,
                    event_handler=StreamEventHandler,
                )
            except Exception as exc:
                _threadsafe_send({"error": str(exc)})
                raise

        worker: Future = get_executor().submit(run_completion)

        # ---------- Async generator consumed by StreamingResponse ----------
        async def generate_response():
            try:
                while True:
                    try:
                        with fail_after(30):
                            event = await recv_ch.receive()
                    except TimeoutError:
                        yield "data: " + json.dumps({"error": "Request timed out"}) + "\n\n"
                        break
                    except EndOfStream:
                        break

                    if event == "[DONE]":
                        break
                    if isinstance(event, dict) and "error" in event:
                        yield "data: " + json.dumps(event) + "\n\n"
                        break

                    yield "data: " + json.dumps(event) + "\n\n"
            except anyio.get_cancelled_exc_class():
                worker.cancel()  # cannot forcibly kill, but we stop reading
                raise
            finally:
                send_ch.close()  # unblock producer if still running

        return StreamingResponse(
            generate_response(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
            },
        )

    return handler

# Tool endpoint
def make_tool_endpoint(tool, verify_token):
    async def handler(request: Request, token: str = Depends(verify_token)):
        try:
            data = await request.json()
            tool_instance = tool(**data) if isinstance(tool, type) else tool
            return {"response": tool_instance.run()}
        except Exception as e:
            return JSONResponse(status_code=500, content={"Error": str(e)})
    return handler

async def exception_handler(request, exc):
    error_message = str(exc)
    if isinstance(exc, tuple):
        error_message = str(exc[1]) if len(exc) > 1 else str(exc[0])
    return JSONResponse(status_code=500, content={"error": error_message})

def override_threads(agency, threads: dict):
    try:
        _reset_agents_and_threads(agency)
        def load_threads(threads_dict: dict):
            return threads_dict
        def save_threads(threads_dict):
            pass
        if agency.threads_callbacks:
            agency.threads_callbacks['load'] = lambda: load_threads(threads)
        else:
            agency.threads_callbacks = {
                'load': lambda: load_threads(threads),
                'save': lambda threads: save_threads(threads)
            }
        agency._init_threads()
        agency._create_special_tools()
    except Exception as e:
        raise ValueError(f"Error overriding threads: {e}")
    
def get_threads(agency):
    loaded_thread_ids = {}
    for agent_name, threads in agency.agents_and_threads.items():
        if agent_name == "main_thread":
            continue
        loaded_thread_ids[agent_name] = {}
        for other_agent, thread in threads.items():
            loaded_thread_ids[agent_name][other_agent] = thread.id

    loaded_thread_ids["main_thread"] = agency.main_thread.id
    return loaded_thread_ids


def _reset_agents_and_threads(agency):
    """Helper function to return agents_and_threads to it's initial state (before init_threads)"""
    pre_loaded_dict = {}
    for sender_agent, recipients in agency.agents_and_threads.items():
        recipient_agents = {}
        if sender_agent == "main_thread" and not isinstance(recipients, dict):
            continue
        for recipient_agent in recipients.keys():
            recipient_agents[recipient_agent] = {
                "agent": sender_agent,
                "recipient_agent": recipient_agent
            }
        pre_loaded_dict[sender_agent] = recipient_agents
    agency.agents_and_threads = pre_loaded_dict



================================================
FILE: agency_swarm/integrations/fastapi_utils/request_models.py
================================================
from typing import List

from pydantic import BaseModel, Field, field_validator


class AttachmentTool(BaseModel):
    type: str


class Attachment(BaseModel):
    file_id: str
    tools: List[AttachmentTool]


class BaseRequest(BaseModel):
    message: str
    message_files: List[str] = None
    recipient_agent: str = None  # Will be automatically converted to the Agent instance
    additional_instructions: str = None
    attachments: List[Attachment] = []
    tool_choice: dict = None
    response_format: dict = None
    threads: dict = Field(
        None, # Not providing this parameter will keep the existing threads
        description="The structure should follow the pattern used in threads callbacks",
        examples=[
            {
                "CEOAgent": {
                    "WorkerAgent": "thread_asdAQWDadKHYTdi0uasndu8iub",
                    "HelperAgent": None, # Creates a new thread if None provided
                },
                "WorkerAgent": {"HelperAgent": "thread_opjknbnaf9198b1fv1089b3A"},
                "main_thread": "thread_Qiofn9HasdTYUCV6123v1f8v",
            },
            {
                "CEOAgent": {
                    "WorkerAgent": "thread_asdalndoasndi0uasndu8iub",
                    "HelperAgent": None, # Creates a new thread if None provided
                },
                # Providing a partial dict will reset threads of non-specified agents
                "main_thread": "thread_Qiofn9HasdTYUCV6123v1f8v",
            },
            {} # Providing empty dict will reset all threads and start a new chat
        ],
    )


def add_agent_validator(model, agent_instances):
    class ModifiedRequest(model):
        @field_validator("recipient_agent")
        def validate_recipient_agent(cls, v):
            if v is not None:
                if v not in agent_instances:
                    raise ValueError(f"Invalid agent name. Available agents: {list(agent_instances.keys())}")
                return agent_instances[v]
            return v
        
        @field_validator("threads")
        def validate_threads(cls, v):
            if v is not None:
                for agent, threads in v.items():
                    if agent not in agent_instances and agent != "main_thread":
                        raise ValueError(f"Invalid agent name. Available agents: {list(agent_instances.keys())+['main_thread']}")
                    if isinstance(threads, dict):
                        for other_agent, thread_id in threads.items():
                            print(f"other_agent: {other_agent}, thread_id: {thread_id}")
                            if other_agent not in agent_instances:
                                raise ValueError(
                                    f"Invalid agent name. Available agents: {list(agent_instances.keys())+['main_thread']}"
                                )
            return v

    return ModifiedRequest



================================================
FILE: agency_swarm/messages/__init__.py
================================================
from .message_output import MessageOutput



================================================
FILE: agency_swarm/messages/message_output.py
================================================
import hashlib
from typing import Literal

from openai.types.beta.threads.message import Message
from rich.console import Console, Group
from rich.live import Live
from rich.markdown import Markdown

console = Console()


class MessageOutput:
    def __init__(
        self,
        msg_type: Literal["function", "function_output", "text", "system"],
        sender_name: str,
        receiver_name: str,
        content,
        obj: Message | None = None,
    ):
        """Initialize a message object with sender, receiver, content and type.

        Args:
            msg_type (Literal["function", "function_output", "text", "system"]): Type of message.
            sender_name (str): Name of the sender.
            receiver_name (str): Name of the receiver.
            content: Content of the message.
            obj: Optional OpenAI object that is causing the message.
        """
        self.msg_type = msg_type
        self.sender_name = str(sender_name)
        self.receiver_name = str(receiver_name)
        self.content = str(content)
        self.obj = obj

    def hash_names_to_color(self):
        if self.msg_type == "function" or self.msg_type == "function_output":
            return "dim"

        if self.msg_type == "system":
            return "red"

        combined_str = self.sender_name + self.receiver_name
        encoded_str = combined_str.encode()
        hash_obj = hashlib.md5(encoded_str)
        hash_int = int(hash_obj.hexdigest(), 16)
        colors = [
            "green",
            "yellow",
            "blue",
            "magenta",
            "cyan",
            "bright_white",
        ]
        color_index = hash_int % len(colors)
        return colors[color_index]

    def cprint(self):
        console.rule()

        header_text = self.formatted_header
        md_content = Markdown(self.content)

        render_group = Group(header_text, md_content)

        console.print(render_group, end="")

    @property
    def formatted_header(self):
        return self.get_formatted_header()

    def get_formatted_header(self):
        if self.msg_type == "function":
            text = f"{self.sender_emoji} {self.sender_name} ðŸ› ï¸ Executing Function"
            return text

        if self.msg_type == "function_output":
            text = f"{self.sender_name} âš™ï¸ Function Output"
            return text

        text = f"{self.sender_emoji} {self.sender_name} ðŸ—£ï¸ @{self.receiver_name}"

        return text

    def get_formatted_content(self):
        header = self.get_formatted_header()
        content = f"\n{self.content}\n"
        return header + content

    @property
    def sender_emoji(self):
        return self.get_sender_emoji()

    def get_sender_emoji(self):
        if self.msg_type == "system":
            return "ðŸ¤–"

        sender_name = self.sender_name.lower()
        if self.msg_type == "function_output":
            sender_name = self.receiver_name.lower()

        if sender_name == "user":
            return "ðŸ‘¤"

        if sender_name == "ceo":
            return "ðŸ¤µ"

        # output emoji based on hash of sender name
        encoded_str = sender_name.encode()
        hash_obj = hashlib.md5(encoded_str)
        hash_int = int(hash_obj.hexdigest(), 16)
        emojis = [
            "ðŸ¶",
            "ðŸ±",
            "ðŸ­",
            "ðŸ¹",
            "ðŸ°",
            "ðŸ¦Š",
            "ðŸ»",
            "ðŸ¼",
            "ðŸ¨",
            "ðŸ¯",
            "ðŸ¦",
            "ðŸ®",
            "ðŸ·",
            "ðŸ¸",
            "ðŸµ",
            "ðŸ”",
            "ðŸ§",
            "ðŸ¦",
            "ðŸ¤",
        ]

        emoji_index = hash_int % len(emojis)

        return emojis[emoji_index]


class MessageOutputLive(MessageOutput):
    live_display = None

    def __init__(
        self,
        msg_type: Literal["function", "function_output", "text", "system"],
        sender_name: str,
        receiver_name: str,
        content,
    ):
        super().__init__(msg_type, sender_name, receiver_name, content)
        # Initialize Live display if not already done
        self.live_display = Live(vertical_overflow="visible")
        self.live_display.start()

        console.rule()

    def __del__(self):
        if self.live_display:
            self.live_display.stop()
            self.live_display = None

    def cprint_update(self, snapshot):
        """
        Update the display with new snapshot content.
        """
        self.content = (
            snapshot or "No content available"
        )  # Update content with the latest snapshot

        header_text = self.formatted_header
        try:
            md_content = Markdown(self.content)
        except Exception as e:
            # prevent url markdown error
            if "string index out of range" in str(e):
                return
            else:
                raise e

        # Creating a group of renderables for the live display
        render_group = Group(header_text, md_content)

        # Update the Live display
        self.live_display.update(render_group)



================================================
FILE: agency_swarm/threads/__init__.py
================================================
from .thread import Thread



================================================
FILE: agency_swarm/threads/thread.py
================================================
import asyncio
import inspect
import json
import logging
import os
import re
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Any, Generator, Type, Union

from openai import APIError, BadRequestError
from openai.types.beta import AssistantToolChoice
from openai.types.beta.threads.message import Attachment, Message
from openai.types.beta.threads.required_action_function_tool_call import (
    RequiredActionFunctionToolCall,
)
from openai.types.beta.threads.runs.tool_call import ToolCall

from agency_swarm.agents import Agent
from agency_swarm.messages import MessageOutput
from agency_swarm.tools import CodeInterpreter, FileSearch
from agency_swarm.user import User
from agency_swarm.util.oai import get_openai_client
from agency_swarm.util.streaming.agency_event_handler import AgencyEventHandler
from agency_swarm.util.tracking.tracking_manager import TrackingManager

logger = logging.getLogger(__name__)


class ToolNotFoundError(Exception):
    """Raised when a tool is not found in an agent's functions."""

    pass


class Thread:
    async_mode: str = None
    max_workers: int = 4

    @property
    def thread_url(self):
        return f"https://platform.openai.com/playground/assistants?assistant={self.recipient_agent.id}&mode=assistant&thread={self.id}"

    @property
    def thread(self):
        self.init_thread()

        if not self._thread:
            logger.debug(f"Retrieving thread {self.id}")
            self._thread = self.client.beta.threads.retrieve(self.id)

        return self._thread

    def __init__(self, agent: Union[Agent, User], recipient_agent: Agent):
        self.agent = agent
        self.recipient_agent = recipient_agent

        self.client = get_openai_client()

        self.id = None
        self._thread = None
        self._run = None
        self._stream = None

        self._num_run_retries = 0
        # names of recipient agents that were called in SendMessage tool
        # needed to prevent agents calling the same recipient agent multiple times
        self._called_recepients = []

        self.terminal_states = [
            "cancelled",
            "completed",
            "failed",
            "expired",
            "incomplete",
        ]

        self._tracking_manager = TrackingManager()

    def init_thread(self):
        self._called_recepients = []
        self._num_run_retries = 0

        if self.id:
            return

        self._thread = self.client.beta.threads.create()
        self.id = self._thread.id
        if self.recipient_agent.examples:
            for example in self.recipient_agent.examples:
                self.client.beta.threads.messages.create(
                    thread_id=self.id,
                    **example,
                )

    def get_completion_stream(
        self,
        message: str | list[dict] | None,
        event_handler: Type[AgencyEventHandler],
        message_files: list[str] | None = None,
        attachments: list[Attachment] | None = None,
        recipient_agent: Agent | None = None,
        additional_instructions: str | None = None,
        tool_choice: AssistantToolChoice | None = None,
        response_format: dict | None = None,
        parent_run_id: str | None = None,
    ) -> Generator[MessageOutput, None, str]:
        return self.get_completion(
            message,
            message_files,
            attachments,
            recipient_agent,
            additional_instructions,
            event_handler,
            tool_choice,
            yield_messages=False,
            response_format=response_format,
            parent_run_id=parent_run_id,
        )

    def get_completion(
        self,
        message: str | list[dict] | None,
        message_files: list[str] | None = None,
        attachments: list[Attachment] | None = None,
        recipient_agent: Agent | None = None,
        additional_instructions: str | None = None,
        event_handler: Type[AgencyEventHandler] | None = None,
        tool_choice: AssistantToolChoice | None = None,
        yield_messages: bool = False,
        response_format: dict | None = None,
        parent_run_id: str | None = None,
    ) -> Generator[MessageOutput, None, str]:
        """
        Primary entry point for sending messages to the recipient agent and handling
        the completion (including tool calls, validations, and re-tries).
        """

        # 1. Prepare basic thread and attachments
        self.init_thread()
        if not recipient_agent:
            recipient_agent = self.recipient_agent
        attachments = self._setup_attachments(
            attachments, message_files, recipient_agent
        )

        # 2. Optionally set the event handler's agent references
        if event_handler:
            event_handler.set_agent(self.agent)
            event_handler.set_recipient_agent(recipient_agent)

        # 3. Print debug info and send user message
        self._debug_print_sender_and_url(recipient_agent)
        message_obj = None
        if message:
            message_obj = self.create_message(
                message=message, role="user", attachments=attachments
            )
            if yield_messages:
                yield MessageOutput(
                    "text", self.agent.name, recipient_agent.name, message, message_obj
                )

        # 4. Create run (conversation block)
        self._create_run(
            recipient_agent,
            additional_instructions,
            event_handler,
            tool_choice,
            response_format=response_format,
        )
        final_output = None

        # 5. Fire run start callbacks
        self._tracking_manager.start_run(
            message,
            self.agent.name,
            recipient_agent.name,
            run_id=self._run.id,
            parent_run_id=parent_run_id,
            message_obj=message_obj,
            model=self._run.model,
            temperature=self._run.temperature,
        )

        # 6. Main try/except around the run loop
        final_output = yield from self._execute_main_loop(
            yield_messages=yield_messages,
            recipient_agent=recipient_agent,
            event_handler=event_handler,
            parent_run_id=parent_run_id,
            additional_instructions=additional_instructions,
            tool_choice=tool_choice,
            response_format=response_format,
        )

        if final_output is None:
            raise Exception("No output was generated from the execution loop")

        return final_output

    def _execute_main_loop(
        self,
        yield_messages: bool,
        recipient_agent: Agent,
        event_handler: Type[AgencyEventHandler] | None,
        parent_run_id: str | None,
        additional_instructions: str | None,
        tool_choice: AssistantToolChoice | None,
        response_format: dict | None,
    ) -> Generator[MessageOutput, None, str]:
        """
        Encapsulates the 'while True' run loop from get_completion to reduce
        cognitive load in the main method. Yields any MessageOutput events
        and returns the final output string.
        """
        error_attempts = 0
        validation_attempts = 0
        full_message = ""
        final_output = None

        while True:
            self._run_until_done()

            if self._run.status == "requires_action":
                maybe_output = yield from self._handle_run_requires_action(
                    recipient_agent,
                    event_handler,
                    yield_messages,
                    parent_run_id,
                    additional_instructions,
                )
                if maybe_output is not None:
                    final_output = maybe_output
                    break

            elif self._run.status == "failed":
                # If the run fails, try re-running on certain error messages
                full_message += self._get_last_message_text()
                retry_successful = self._try_run_failed_recovery(
                    error_attempts,
                    recipient_agent,
                    additional_instructions,
                    event_handler,
                    tool_choice,
                    response_format,
                    parent_run_id,
                )
                error_attempts += 1
                if not retry_successful:
                    raise Exception(
                        "OpenAI Run Failed. Error: ", self._run.last_error.message
                    )

            elif self._run.status == "incomplete":
                self._on_run_incomplete(parent_run_id)

            else:
                # final assistant message
                message_obj = self._get_last_assistant_message()
                last_message = message_obj.content[0].text.value
                full_message += last_message

                if yield_messages:
                    yield MessageOutput(
                        "text",
                        recipient_agent.name,
                        self.agent.name,
                        last_message,
                        message_obj,
                    )

                result = self._validate_assistant_response(
                    recipient_agent,
                    last_message,
                    validation_attempts,
                    yield_messages,
                    additional_instructions,
                    event_handler,
                    tool_choice,
                    response_format,
                )
                if result is not None:
                    # The function no longer yields, so `result` is a dict, not a generator
                    for mo in result.get("message_outputs", []):
                        yield mo  # yield the stored MessageOutput objects
                    validation_attempts = result["validation_attempts"]
                    if result["continue_loop"]:
                        continue

                if final_output is None:
                    final_output = last_message
                break

        return final_output

    def _create_run(
        self,
        recipient_agent: Agent,
        additional_instructions: str | None = None,
        event_handler: Type[AgencyEventHandler] | None = None,
        tool_choice: AssistantToolChoice | None = None,
        temperature: float | None = None,
        response_format: dict | None = None,
    ):
        # Always start from a clean slate
        self._ensure_no_active_run(action="cancel")
        try:
            if event_handler:
                with self.client.beta.threads.runs.stream(
                    thread_id=self.id,
                    event_handler=event_handler(),
                    assistant_id=recipient_agent.id,
                    additional_instructions=additional_instructions,
                    tool_choice=tool_choice,
                    max_prompt_tokens=recipient_agent.max_prompt_tokens,
                    max_completion_tokens=recipient_agent.max_completion_tokens,
                    truncation_strategy=recipient_agent.truncation_strategy,
                    temperature=temperature,
                    extra_body={
                        "parallel_tool_calls": recipient_agent.parallel_tool_calls
                    },
                    response_format=response_format,
                ) as stream:
                    stream.until_done()
                    self._run = stream.get_final_run()
            else:
                self._run = self.client.beta.threads.runs.create(
                    thread_id=self.id,
                    assistant_id=recipient_agent.id,
                    additional_instructions=additional_instructions,
                    tool_choice=tool_choice,
                    max_prompt_tokens=recipient_agent.max_prompt_tokens,
                    max_completion_tokens=recipient_agent.max_completion_tokens,
                    truncation_strategy=recipient_agent.truncation_strategy,
                    temperature=temperature,
                    parallel_tool_calls=recipient_agent.parallel_tool_calls,
                    response_format=response_format,
                )
                self._run = self.client.beta.threads.runs.poll(
                    thread_id=self.id,
                    run_id=self._run.id,
                )
        except APIError as e:
            match = re.search(
                r"Thread (\w+) already has an active run (\w+)", e.message
            )
            if match:
                self.cancel_run(
                    thread_id=match.groups()[0],
                    run_id=match.groups()[1],
                    check_status=False,
                )
                # Reattempt creating a new run after cancellation.
                return self._create_run(
                    recipient_agent,
                    additional_instructions,
                    event_handler,
                    tool_choice,
                    temperature=temperature,
                    response_format=response_format,
                )
            elif (
                "The server had an error processing your request" in e.message
                and self._num_run_retries < 3
            ):
                time.sleep(1)
                self._num_run_retries += 1
                return self._create_run(
                    recipient_agent,
                    additional_instructions,
                    event_handler,
                    tool_choice,
                    temperature=temperature,
                    response_format=response_format,
                )
            else:
                raise e

    def _run_until_done(self):
        while self._run.status in ["queued", "in_progress", "cancelling"]:
            time.sleep(0.5)
            self._run = self.client.beta.threads.runs.retrieve(
                thread_id=self.id, run_id=self._run.id
            )

    def submit_tool_outputs(self, tool_outputs, event_handler=None, poll=True):
        if not poll:
            self._run = self.client.beta.threads.runs.submit_tool_outputs(
                thread_id=self.id, run_id=self._run.id, tool_outputs=tool_outputs
            )
        else:
            if not event_handler:
                self._run = self.client.beta.threads.runs.submit_tool_outputs_and_poll(
                    thread_id=self.id, run_id=self._run.id, tool_outputs=tool_outputs
                )
            else:
                with self.client.beta.threads.runs.submit_tool_outputs_stream(
                    thread_id=self.id,
                    run_id=self._run.id,
                    tool_outputs=tool_outputs,
                    event_handler=event_handler(),
                ) as stream:
                    stream.until_done()
                    self._run = stream.get_final_run()

    def cancel_run(self, thread_id=None, run_id=None, check_status=True):
        if (
            check_status
            and (not self._run or self._run.status in self.terminal_states)
            and not run_id
        ):
            return

        try:
            actual_thread_id = thread_id or self.id
            actual_run_id = run_id or (self._run.id if self._run else None)

            if not actual_run_id:
                logger.warning(
                    f"Can't cancel without a run ID: thread_id={actual_thread_id}"
                )
                return

            self._run = self.client.beta.threads.runs.cancel(
                thread_id=actual_thread_id, run_id=actual_run_id
            )

            self._run = self.client.beta.threads.runs.poll(
                thread_id=actual_thread_id,
                run_id=actual_run_id,
                poll_interval_ms=500,
            )
            time.sleep(1)  # Give time for cancellation to propagate
        except BadRequestError as e:
            if "Cannot cancel run with status" in e.message:
                logger.warning(f"Could not cancel run: {e.message}. Assuming it's in terminal state.")
                self._run = self.client.beta.threads.runs.poll(
                    thread_id=actual_thread_id,
                    run_id=actual_run_id,
                    poll_interval_ms=500,
                )
                time.sleep(1)
            else:
                raise e

    def _get_last_message_text(self):
        messages = self.client.beta.threads.messages.list(thread_id=self.id, limit=1)

        if len(messages.data) == 0 or len(messages.data[0].content) == 0:
            return ""

        return messages.data[0].content[0].text.value

    def _get_last_assistant_message(self):
        messages = self.client.beta.threads.messages.list(thread_id=self.id, limit=1)

        if len(messages.data) == 0 or len(messages.data[0].content) == 0:
            raise Exception("No messages found in the thread")

        message = messages.data[0]

        if message.role == "assistant":
            return message

        raise Exception("No assistant message found in the thread")

    def create_message(
        self,
        message: str | list[dict],
        role: str = "user",
        attachments: list[Attachment] | None = None,
    ) -> Message:
        # Never post while a run is still alive
        self._ensure_no_active_run(action="wait")
        try:
            return self.client.beta.threads.messages.create(
                thread_id=self.id, role=role, content=message, attachments=attachments
            )
        except BadRequestError as e:
            regex = re.compile(
                r"Can't add messages to thread_([a-zA-Z0-9]+) while a run run_([a-zA-Z0-9]+) is active\."
            )
            match = regex.search(str(e))

            if match:
                thread_id, run_id = match.groups()
                thread_id = f"thread_{thread_id}"
                run_id = f"run_{run_id}"

                self.cancel_run(thread_id=thread_id, run_id=run_id)

                return self.client.beta.threads.messages.create(
                    thread_id=thread_id,
                    role=role,
                    content=message,
                    attachments=attachments,
                )
            else:
                raise e

    def execute_tool(
        self,
        tool_call: ToolCall,
        recipient_agent=None,
        event_handler=None,
        tool_outputs_and_names=None,
    ) -> tuple[str | Generator[MessageOutput, None, None], bool]:
        if not recipient_agent:
            recipient_agent = self.recipient_agent
        if tool_outputs_and_names is None:
            tool_outputs_and_names = []

        is_retriever = tool_call.type == "file_search"

        tool_name = tool_call.function.name
        funcs = recipient_agent.functions
        tool = next((func for func in funcs if func.__name__ == tool_name), None)

        try:
            # Track start of tool execution
            self._tracking_manager.track_tool_start(
                tool_call=tool_call,
                run=self._run,
                agent_name=self.agent.name,
                recipient_agent_name=recipient_agent.name,
                is_retriever=is_retriever,
            )

            # init tool
            args = tool_call.function.arguments
            args = json.loads(args) if args else {}
            tool_instance = tool(**args)

            # check if the tool is already called
            for existing_tool_name in [name for name, _ in tool_outputs_and_names]:
                if tool_name == existing_tool_name and (
                    hasattr(tool_instance, "ToolConfig")
                    and hasattr(tool_instance.ToolConfig, "one_call_at_a_time")
                    and tool_instance.ToolConfig.one_call_at_a_time
                ):
                    error_message = f"Error: Function {tool_name} is already called. You can only call this function once at a time. Please wait for the previous call to finish before calling it again."
                    raise RuntimeError(error_message)

            # for send message tools, don't allow calling the same recipient agent multiple times
            if tool_name.startswith("SendMessage"):
                if tool_instance.recipient.value in self._called_recepients:
                    error_message = f"Error: Agent {tool_instance.recipient.value} has already been called. You can only call each agent once at a time. Please wait for the previous call to finish before calling it again."
                    raise RuntimeError(error_message)

                self._called_recepients.append(tool_instance.recipient.value)

            tool_instance._caller_agent = recipient_agent
            tool_instance._event_handler = event_handler
            tool_instance._tool_call = tool_call

            output = tool_instance.run()
            return output, tool_instance.ToolConfig.output_as_result

        except Exception as e:
            error_message = f"Error: {e}"
            if "For further information visit" in error_message:
                error_message = error_message.split("For further information visit")[0]

            # Track error
            self._tracking_manager.track_tool_error(
                error=Exception(error_message),
                tool_call=tool_call,
                parent_run_id=self._run.id,
                is_retriever=is_retriever,
            )

            return error_message, False

    def _await_coroutines(self, tool_outputs):
        async_tool_calls = []
        for tool_output in tool_outputs:
            if inspect.iscoroutine(tool_output["output"]):
                async_tool_calls.append(tool_output)

        if async_tool_calls:
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    raise RuntimeError
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop = asyncio.get_event_loop()

            results = loop.run_until_complete(
                asyncio.gather(
                    *[call["output"] for call in async_tool_calls],
                    return_exceptions=True,  # Capture exceptions to set as individual results
                )
            )

            for tool_output, result in zip(async_tool_calls, results):
                tool_output["output"] = str(result)

        return tool_outputs

    def _get_sync_async_tool_calls(
        self, tool_calls: list[RequiredActionFunctionToolCall], recipient_agent: Agent
    ):
        async_tool_calls = []
        sync_tool_calls = []

        for tool_call in tool_calls:
            if tool_call.function.name.startswith("SendMessage"):
                sync_tool_calls.append(tool_call)
                continue

            tool = next(
                (
                    func
                    for func in recipient_agent.functions
                    if func.__name__ == tool_call.function.name
                ),
                None,
            )

            if tool is None:
                error_message = (
                    f"Tool {tool_call.function.name} not found in agent {recipient_agent.name}. "
                    "Cancelling run."
                )
                logger.error(error_message)
                self.cancel_run()
                raise ToolNotFoundError(error_message)

            if (
                hasattr(tool.ToolConfig, "async_mode") and tool.ToolConfig.async_mode
            ) or self.async_mode == "tools_threading":
                async_tool_calls.append(tool_call)
            else:
                sync_tool_calls.append(tool_call)

        return sync_tool_calls, async_tool_calls

    def get_messages(self, limit=None):
        all_messages = []
        after = None
        while True:
            response = self.client.beta.threads.messages.list(
                thread_id=self.id, limit=100, after=after
            )
            messages = response.data
            if not messages:
                break
            all_messages.extend(messages)
            # Set the 'after' cursor to the ID of the last message
            after = messages[-1].id

            if limit and len(all_messages) >= limit:
                break

        return all_messages

    def _handle_run_requires_action(
        self,
        recipient_agent: Agent,
        event_handler: Type[AgencyEventHandler] | None,
        yield_messages: bool,
        parent_run_id: str | None,
        additional_instructions: str,
    ) -> Union[str, None, Generator[MessageOutput, None, None]]:
        """
        Handle the 'requires_action' state within the main while-loop of get_completion.
        Returns either a final output string (if a tool call outputs as result),
        None (to continue processing), or a generator (if yield_messages is used).
        """
        self._called_recepients = []
        tool_calls = self._run.required_action.submit_tool_outputs.tool_calls
        tool_outputs_and_names: list[tuple[str, Any]] = []

        self._tracking_manager.track_agent_actions(
            tool_calls, self._run.id, parent_run_id
        )

        sync_tool_calls, async_tool_calls = self._get_sync_async_tool_calls(
            tool_calls, recipient_agent
        )

        def handle_output(
            tool_call: ToolCall, output: str | Generator[Any, None, None]
        ) -> str | Generator[MessageOutput, None, None]:
            """
            Local helper to handle the output from each tool call.
            Yields messages if yield_messages is True.
            """
            final_output = None
            if inspect.isgenerator(output):
                try:
                    while True:
                        item = next(output)
                        if isinstance(item, MessageOutput) and yield_messages:
                            yield item
                except StopIteration as e:
                    final_output = e.value
            else:
                final_output = output
                if yield_messages:
                    yield MessageOutput(
                        "function_output",
                        tool_call.function.name,
                        recipient_agent.name,
                        output,
                        tool_call,
                    )

            for tool_output in tool_outputs_and_names:
                if tool_output[1]["tool_call_id"] == tool_call.id:
                    tool_output[1]["output"] = final_output

            self._tracking_manager.track_tool_end(
                output=final_output,
                tool_call=tool_call,
                parent_run_id=self._run.id,
                is_retriever=tool_call.type == "file_search",
            )
            return final_output

        final_output = None

        # If async tool calls are allowed, run them with a ThreadPoolExecutor
        if len(async_tool_calls) > 0 and self.async_mode == "tools_threading":
            max_workers = min(self.max_workers, os.cpu_count() or 1)
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = {}
                for tool_call in async_tool_calls:
                    if yield_messages:
                        yield MessageOutput(
                            "function",
                            recipient_agent.name,
                            self.agent.name,
                            str(tool_call.function),
                            tool_call,
                        )
                    futures[
                        executor.submit(
                            self.execute_tool,
                            tool_call,
                            recipient_agent,
                            event_handler,
                            tool_outputs_and_names,
                        )
                    ] = tool_call
                    tool_outputs_and_names.append(
                        (tool_call.function.name, {"tool_call_id": tool_call.id})
                    )

                for future in as_completed(futures):
                    tool_call = futures[future]
                    output, output_as_result = future.result()
                    gen = handle_output(tool_call, output)
                    if inspect.isgenerator(gen):
                        yield from gen
                        output = tool_outputs_and_names[-1][1]["output"]
                    else:
                        output = gen

                    if output_as_result:
                        self.cancel_run()
                        final_output = output
                        break
        else:
            # execute sync tool calls
            sync_tool_calls += async_tool_calls

        for tool_call in sync_tool_calls:
            if yield_messages:
                yield MessageOutput(
                    "function",
                    recipient_agent.name,
                    self.agent.name,
                    str(tool_call.function),
                    tool_call,
                )
            output, output_as_result = self.execute_tool(
                tool_call,
                recipient_agent,
                event_handler,
                tool_outputs_and_names,
            )
            tool_outputs_and_names.append(
                (
                    tool_call.function.name,
                    {"tool_call_id": tool_call.id, "output": output},
                )
            )
            gen = handle_output(tool_call, output)
            if inspect.isgenerator(gen):
                yield from gen
                output = tool_outputs_and_names[-1][1]["output"]
            else:
                output = gen

            if output_as_result:
                self.cancel_run()
                final_output = output
                break

        # If a tool call had "output_as_result", return immediately
        if final_output is not None:
            return final_output

        tool_outputs = [t for _, t in tool_outputs_and_names]
        tool_names = [n for n, _ in tool_outputs_and_names]

        tool_outputs = self._await_coroutines(tool_outputs)

        for to_ in tool_outputs:
            if not isinstance(to_["output"], str):
                to_["output"] = str(to_["output"])

        if event_handler:
            event_handler.set_agent(self.agent)
            event_handler.set_recipient_agent(recipient_agent)

        try:
            self.submit_tool_outputs(tool_outputs, event_handler)
        except BadRequestError as e:
            if 'Runs in status "expired"' in e.message or 'Runs in status "cancelled"' in e.message:
                self.create_message(
                    message="Previous request timed out. Please repeat the exact same tool calls in the exact same order with the same arguments.",
                    role="user",
                )
                self._create_run(
                    recipient_agent,
                    additional_instructions,
                    event_handler,
                    "required",
                    temperature=0,
                )
                self._run_until_done()

                if self._run.status != "requires_action":
                    raise Exception(
                        "Run Failed. Error: ",
                        self._run.last_error or self._run.incomplete_details,
                    )
                tool_calls = self._run.required_action.submit_tool_outputs.tool_calls
                if len(tool_calls) != len(tool_outputs):
                    # If the tool calls changed, mark them as an error
                    tool_outputs = []
                    for i, tool_call in enumerate(tool_calls):
                        tool_outputs.append(
                            {
                                "tool_call_id": tool_call.id,
                                "output": "Error: openai run timed out. You can try again one more time.",
                            }
                        )
                else:
                    # Re-map tool_outputs to the new tool_call IDs
                    for i, tool_name in enumerate(tool_names):
                        for tool_call in tool_calls[:]:
                            if tool_call.function.name == tool_name:
                                tool_outputs[i]["tool_call_id"] = tool_call.id
                                tool_calls.remove(tool_call)
                                break

                self.submit_tool_outputs(tool_outputs, event_handler)
            else:
                raise e

        # Return None so the outer loop continues
        return None

    # -----------------------------
    # Private helper methods
    # -----------------------------

    def _ensure_no_active_run(self, action: str = "wait") -> None:
        """
        Make sure the thread is in a safe state before any mutating call.

        Parameters
        ----------
        action : {"wait", "cancel"}
            "wait"   â€“ block until the current run reaches a terminal state.
            "cancel" â€“ actively cancel the run, then wait until the
                        cancellation is confirmed.
        """
        # First check local state
        if not self._run or self._run.status in self.terminal_states:
            # Local state looks good, verify through API
            has_active_run, run_id = self._check_for_active_runs()
            if not has_active_run:
                return  # Confirmed safe
            
            # We found an active run that our local state wasn't aware of
            # Update our local state
            if run_id:
                self._run = self.client.beta.threads.runs.retrieve(
                    thread_id=self.id, run_id=run_id
                )
        
        # Handle the active run
        if action == "cancel":
            self.cancel_run()  # poll() inside guarantees termination
        else:
            self._run_until_done()  # passive wait

        # Double-check with the API
        has_active_run, _ = self._check_for_active_runs()
        if has_active_run:
            raise RuntimeError(
                f"Run still active after _ensure_no_active_run "
                f"(status={self._run.status if self._run else 'unknown'})."
            )
        
    def _check_for_active_runs(self) -> tuple[bool, str | None]:
        """
        Check if there are any active runs for this thread.
        
        Returns:
            tuple: (has_active_run, run_id)
        """
        # List runs with a filter for non-terminal states
        runs = self.client.beta.threads.runs.list(thread_id=self.id, limit=1)
        
        for run in runs.data:
            if run.status not in self.terminal_states:
                return True, run.id
                
        return False, None

    def _setup_attachments(
        self,
        attachments: list[Attachment] | None,
        message_files: list[str] | None,
        recipient_agent: Agent,
    ) -> list[Attachment]:
        """Prepare attachments (file_ids, relevant tools) if provided."""
        if not attachments:
            attachments = []

        if message_files:
            recipient_tools = []

            if FileSearch in recipient_agent.tools:
                recipient_tools.append({"type": "file_search"})
            if CodeInterpreter in recipient_agent.tools:
                recipient_tools.append({"type": "code_interpreter"})

            for file_id in message_files:
                attachments.append(
                    Attachment(
                        file_id=file_id,
                        tools=recipient_tools or [{"type": "file_search"}],
                    )
                )

        return attachments

    def _debug_print_sender_and_url(self, recipient_agent):
        """Utility method to print debug info about the conversation.
        Determines the sender's name based on the agent type.
        """
        sender_name = "user" if isinstance(self.agent, User) else self.agent.name
        logger.info(
            f"THREAD:[ {sender_name} -> {recipient_agent.name} ]: URL {self.thread_url}"
        )

    def _try_run_failed_recovery(
        self,
        error_attempts: int,
        recipient_agent: Agent,
        additional_instructions: str | None,
        event_handler: Type[AgencyEventHandler] | None,
        tool_choice: AssistantToolChoice | None,
        response_format: dict | None,
        parent_run_id: str | None,
    ) -> bool:
        """Attempts to recover from run failures if they match common errors (up to 3 times)."""
        error_message = (
            self._run.last_error.message.lower() if self._run.last_error else ""
        )
        common_errors = [
            "something went wrong",
            "the server had an error processing your request",
            "rate limit reached",
        ]
        if error_attempts < 3 and any(e in error_message for e in common_errors):
            if error_attempts < 2:
                time.sleep(1 + error_attempts)
            else:
                # Make one last try with a 'Continue.' user prompt
                self.create_message(message="Continue.", role="user")

            self._create_run(
                recipient_agent,
                additional_instructions,
                event_handler,
                tool_choice,
                response_format=response_format,
            )
            return True
        else:
            # chain error
            self._tracking_manager.track_chain_error(
                error=Exception(f"OpenAI Run Failed. Error: {error_message}"),
                run_id=self._run.id,
                parent_run_id=parent_run_id,
            )
            return False

    def _on_run_incomplete(self, parent_run_id: str | None):
        """Handle incomplete runs by firing chain error callbacks and raising an exception."""
        self._tracking_manager.track_chain_error(
            error=Exception(
                "OpenAI Run Incomplete. Details: " + str(self._run.incomplete_details)
            ),
            run_id=self._run.id,
            parent_run_id=parent_run_id,
        )
        raise Exception(
            "OpenAI Run Incomplete. Details: ", self._run.incomplete_details
        )

    def _validate_assistant_response(
        self,
        recipient_agent: Agent,
        last_message: str,
        validation_attempts: int,
        yield_messages: bool,
        additional_instructions: str | None,
        event_handler: Type[AgencyEventHandler] | None,
        tool_choice: AssistantToolChoice | None,
        response_format: dict | None,
    ):
        """
        If recipient_agent has a response validator, attempt to validate the last_message.
        If validation fails, send the validation prompt back to the agent and re-create run.

        Returns:
        - None if validation passes
        - A dict if validation fails, containing:
            {
            "validation_attempts": int,
            "continue_loop": bool,
            "message_outputs": List[MessageOutput]   (possibly empty if no messages to yield)
            }
        """
        if recipient_agent.response_validator:
            try:
                recipient_agent.response_validator(message=last_message)
            except Exception as e:
                # We only retry if below the maximum number of validation attempts
                if validation_attempts < recipient_agent.validation_attempts:
                    # Attempt to parse the exception as text
                    message_outputs = []
                    try:
                        evaluated_content = eval(str(e))
                        content = (
                            evaluated_content
                            if isinstance(evaluated_content, list)
                            else str(e)
                        )
                    except Exception as e2:
                        content = str(e2)

                    # Create the user message to inform the model about the validation error
                    message_obj = self.create_message(message=content, role="user")

                    # If we were streaming messages, store them to yield in the caller
                    if yield_messages and hasattr(message_obj.content[0], "text"):
                        message_outputs.append(
                            MessageOutput(
                                "text",
                                self.agent.name,
                                recipient_agent.name,
                                message_obj.content[0].text.value,
                                message_obj,
                            )
                        )

                    # Fire the event handler callbacks for the message
                    if event_handler:
                        handler = event_handler()
                        handler.on_message_created(message_obj)
                        handler.on_message_done(message_obj)

                    # Increment validations and recreate run
                    validation_attempts += 1
                    self._create_run(
                        recipient_agent,
                        additional_instructions,
                        event_handler,
                        tool_choice,
                        response_format=response_format,
                    )
                    # Return structured info for the caller
                    return {
                        "validation_attempts": validation_attempts,
                        "continue_loop": True,
                        "message_outputs": message_outputs,
                    }
        return None



================================================
FILE: agency_swarm/threads/thread_async.py
================================================
import threading
from typing import List, Optional, Union

from openai.types.beta import AssistantToolChoice

from agency_swarm.agents import Agent
from agency_swarm.threads import Thread
from agency_swarm.user import User


class ThreadAsync(Thread):
    def __init__(self, agent: Union[Agent, User], recipient_agent: Agent):
        super().__init__(agent, recipient_agent)
        self.pythread = None
        self.response = None
        self.async_mode = False

    def worker(
        self,
        message: str,
        message_files: List[str] = None,
        attachments: Optional[List[dict]] = None,
        recipient_agent=None,
        additional_instructions: str = None,
        tool_choice: AssistantToolChoice = None,
        parent_run_id: str | None = None,
    ):
        self.async_mode = False

        gen = self.get_completion(
            message=message,
            message_files=message_files,
            attachments=attachments,
            recipient_agent=recipient_agent,
            additional_instructions=additional_instructions,
            tool_choice=tool_choice,
            parent_run_id=parent_run_id,
        )

        while True:
            try:
                next(gen)
            except StopIteration as e:
                self.response = (
                    f"""{self.recipient_agent.name}'s Response: '{e.value}'"""
                )
                break

        return

    def get_completion_async(
        self,
        message: str,
        message_files: List[str] = None,
        attachments: Optional[List[dict]] = None,
        recipient_agent=None,
        additional_instructions: str = None,
        tool_choice: AssistantToolChoice = None,
        parent_run_id: str | None = None,
    ):
        if self.pythread and self.pythread.is_alive():
            return "System Notification: 'Agent is busy, so your message was not received. Please always use 'GetResponse' tool to check for status first, before using 'SendMessage' tool again for the same agent.'"
        elif self.pythread and not self.pythread.is_alive():
            self.pythread.join()
            self.pythread = None
            self.response = None

        run = self.get_last_run()

        if run and run.status in ["queued", "in_progress", "requires_action"]:
            return "System Notification: 'Agent is busy, so your message was not received. Please always use 'GetResponse' tool to check for status first, before using 'SendMessage' tool again for the same agent.'"

        self.pythread = threading.Thread(
            target=self.worker,
            args=(
                message,
                message_files,
                attachments,
                recipient_agent,
                additional_instructions,
                tool_choice,
                parent_run_id,
            ),
        )

        self.pythread.start()

        return "System Notification: 'Task has started. Please notify the user that they can tell you to check the status later. You can do this with the 'GetResponse' tool, after you have been instructed to do so. Don't mention the tool itself to the user. "

    def check_status(self, run=None):
        if not run:
            run = self.get_last_run()

        if not run:
            return "System Notification: 'Agent is ready to receive a message. Please send a message with the 'SendMessage' tool.'"

        # check run status
        if run.status in ["queued", "in_progress", "requires_action"]:
            return "System Notification: 'Task is not completed yet. Please tell the user to wait and try again later.'"

        if run.status == "failed":
            return f"System Notification: 'Agent run failed with error: {run.last_error.message}. You may send another message with the 'SendMessage' tool.'"

        messages = self.client.beta.threads.messages.list(
            thread_id=self.id,
            order="desc",
        )

        return f"""{self.recipient_agent.name}'s Response: '{messages.data[0].content[0].text.value}'"""

    def get_last_run(self):
        self.init_thread()

        runs = self.client.beta.threads.runs.list(
            thread_id=self.id,
            order="desc",
        )

        if len(runs.data) == 0:
            return None

        run = runs.data[0]

        return run



================================================
FILE: agency_swarm/tools/__init__.py
================================================
from .BaseTool import BaseTool
from .oai.CodeInterpreter import CodeInterpreter
from .oai.FileSearch import FileSearch
from .oai.Retrieval import Retrieval
from .ToolFactory import ToolFactory



================================================
FILE: agency_swarm/tools/BaseTool.py
================================================
from abc import ABC, abstractmethod
from typing import Any, ClassVar, Literal, Union

from docstring_parser import parse
from openai.types.beta.threads.runs.tool_call import ToolCall
from pydantic import BaseModel

from agency_swarm.util.shared_state import SharedState


class classproperty:
    def __init__(self, fget):
        self.fget = fget

    def __get__(self, instance, owner):
        return self.fget(owner)


class BaseTool(BaseModel, ABC):
    _shared_state: ClassVar[SharedState] = None
    _caller_agent: Any = None
    _event_handler: Any = None
    _tool_call: ToolCall = None
    openai_schema: ClassVar[dict[str, Any]]

    def __init__(self, **kwargs):
        if not self.__class__._shared_state:
            self.__class__._shared_state = SharedState()
        super().__init__(**kwargs)

        # Ensure all ToolConfig variables are initialized
        config_defaults = {
            "strict": False,
            "one_call_at_a_time": False,
            "output_as_result": False,
            "async_mode": None,
        }

        for key, value in config_defaults.items():
            if not hasattr(self.ToolConfig, key):
                setattr(self.ToolConfig, key, value)

    class ToolConfig:
        strict: bool = False
        one_call_at_a_time: bool = False
        # return the tool output as assistant message
        output_as_result: bool = False
        async_mode: Union[Literal["threading"], None] = None

    @classproperty
    def openai_schema(cls) -> dict[str, Any]:
        """
        Return the schema in the format of OpenAI's schema as jsonschema

        Note:
            It's important to add a docstring to describe how to best use this class; it will be included in the description attribute and be part of the prompt.

        Returns:
            model_json_schema (dict): A dictionary in the format of OpenAI's schema as jsonschema
        """
        schema = cls.model_json_schema()
        docstring = parse(cls.__doc__ or "")
        parameters = {
            k: v for k, v in schema.items() if k not in ("title", "description")
        }
        for param in docstring.params:
            if (name := param.arg_name) in parameters["properties"] and (
                description := param.description
            ):
                if "description" not in parameters["properties"][name]:
                    parameters["properties"][name]["description"] = description

        parameters["required"] = sorted(
            k for k, v in parameters["properties"].items() if "default" not in v
        )

        if "description" not in schema:
            if docstring.short_description:
                schema["description"] = docstring.short_description
            else:
                schema["description"] = (
                    f"Correctly extracted `{cls.__name__}` with all "
                    f"the required parameters with correct types"
                )

        schema = {
            "name": schema["title"],
            "description": schema["description"],
            "parameters": parameters,
        }

        strict = getattr(cls.ToolConfig, "strict", False)
        if strict:
            schema["strict"] = True
            schema["parameters"]["additionalProperties"] = False
            # iterate through defs and set additionalProperties to false
            if "$defs" in schema["parameters"]:
                for def_ in schema["parameters"]["$defs"].values():
                    def_["additionalProperties"] = False

        return schema

    @abstractmethod
    def run(self):
        pass



================================================
FILE: agency_swarm/tools/ToolFactory.py
================================================
import inspect
import json
import os
import sys
from datetime import date, datetime
from decimal import Decimal
from enum import Enum
import logging
from typing import Any, Callable, Dict, List, Literal, Optional, Set, Tuple, Type, Union

import httpx
import jsonref
from datamodel_code_generator import DataModelType, PythonVersion
from datamodel_code_generator.model import get_data_model_types
from datamodel_code_generator.parser.jsonschema import JsonSchemaParser

from .BaseTool import BaseTool

logger = logging.getLogger(__name__)
class ToolFactory:
    @staticmethod
    def from_langchain_tools(tools: List) -> List[Type[BaseTool]]:
        """
        Converts a list of langchain tools into a list of BaseTools.

        Parameters:
            tools: The langchain tools to convert.

        Returns:
            A list of BaseTools.
        """
        converted_tools = []
        for tool in tools:
            converted_tools.append(ToolFactory.from_langchain_tool(tool))

        return converted_tools

    @staticmethod
    def from_langchain_tool(tool) -> Type[BaseTool]:
        """
        Converts a langchain tool into a BaseTool.

        Parameters:
            tool: The langchain tool to convert.

        Returns:
            A BaseTool.
        """
        try:
            from langchain_community.tools import format_tool_to_openai_function
        except ImportError:
            raise ImportError("You must install langchain to use this method.")

        if inspect.isclass(tool):
            tool = tool()

        def callback(self):
            tool_input = self.model_dump()
            try:
                return tool.run(tool_input)
            except TypeError:
                if len(tool_input) == 1:
                    return tool.run(list(tool_input.values())[0])
                else:
                    raise TypeError(
                        f"Error parsing input for tool '{tool.__class__.__name__}' Please open an issue "
                        f"on github."
                    )

        return ToolFactory.from_openai_schema(
            format_tool_to_openai_function(tool), callback
        )

    @staticmethod
    def from_openai_schema(schema: Dict[str, Any], callback: Any) -> Type[BaseTool]:
        """
        Converts an OpenAI schema into a BaseTool.

        Parameters:
            schema: The OpenAI schema to convert.
            callback: The function to run when the tool is called.

        Returns:
            A BaseTool.
        """
        data_model_types = get_data_model_types(
            DataModelType.PydanticV2BaseModel,
            target_python_version=PythonVersion.PY_310,
        )

        parser = JsonSchemaParser(
            json.dumps(schema["parameters"]),
            data_model_type=data_model_types.data_model,
            data_model_root_type=data_model_types.root_model,
            data_model_field_type=data_model_types.field_model,
            data_type_manager_type=data_model_types.data_type_manager,
            dump_resolve_reference_action=data_model_types.dump_resolve_reference_action,
            use_schema_description=True,
            validation=False,
            class_name="Model",
            strip_default_none=schema.get("strict", False), # default parameters are not supported in strict mode
            # custom_template_dir=Path('/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/tools/data_schema_templates')
        )

        result = parser.parse()

        # Prepend necessary imports to the generated code string
        imports_str = "from typing import List, Dict, Any, Optional, Union, Set, Tuple, Literal\nfrom enum import Enum\n"
        result = imports_str + result

        # --- FIX: Remove problematic __future__ import added by generator --- #
        result = result.replace("from __future__ import annotations\n", "")
        # --- END FIX --- #

        # Rebuild the model to ensure it's fully defined
        result += "\n\nModel.model_rebuild(force=True)"

        # Execute the result to extract the model
        exec_globals = {
            # We might not strictly need all these in globals anymore if they are imported in the string,
            # but keeping them shouldn't hurt.
            "List": List,
            "Dict": Dict,
            "Type": Type,
            "Union": Union,
            "Optional": Optional,
            "datetime": datetime,
            "date": date,
            "Set": Set,
            "Tuple": Tuple,
            "Any": Any,
            "Callable": Callable,
            "Decimal": Decimal,
            "Literal": Literal,
            "Enum": Enum,
        }

        exec(result, exec_globals)
        model = exec_globals.get("Model")

        if not model:
            raise ValueError(f"Could not extract model from schema {schema['name']}")

        # --- FIX: Explicitly rebuild the generated model --- #
        try:
            model.model_rebuild(force=True)
        except Exception as e:
            print(f"Warning: Could not rebuild model {schema['name']} after exec: {e}")
        # --- END FIX --- #

        class ToolConfig:
            strict: bool = schema.get("strict", False)

        tool = type(
            schema["name"],
            (BaseTool, model),
            {
                "__doc__": schema.get("description", ""),
                "run": callback,
            },
        )

        tool.ToolConfig = ToolConfig

        return tool

    @staticmethod
    def from_openapi_schema(
        schema: Union[str, dict],
        headers: Dict[str, str] = None,
        params: Dict[str, Any] = None,
        strict: bool = False,
    ) -> List[Type[BaseTool]]:
        """
        Converts an OpenAPI schema into a list of BaseTools.

        Parameters:
            schema: The OpenAPI schema to convert.
            headers: The headers to use for requests.
            params: The parameters to use for requests.
            strict: Whether to use strict OpenAI mode.
        Returns:
            A list of BaseTools.
        """
        if isinstance(schema, dict):
            openapi_spec = schema
            openapi_spec = jsonref.JsonRef.replace_refs(openapi_spec)
        else:
            openapi_spec = jsonref.loads(schema)
        tools = []
        headers = headers or {}
        headers = {k: v for k, v in headers.items() if v is not None}

        for path, methods in openapi_spec["paths"].items():
            for method, spec_with_ref in methods.items():
                # Use the callback factory to create a unique callback for each path/method
                # This ensures each callback captures the correct path value
                callback = ToolFactory._create_callback_for_path(
                    path, method, openapi_spec, params, headers
                )

                # 1. Resolve JSON references.
                spec = jsonref.replace_refs(spec_with_ref)

                # 2. Extract a name for the functions.
                function_name = spec.get("operationId")

                # 3. Extract a description and parameters.
                desc = spec.get("description") or spec.get("summary", "")

                schema = {"type": "object", "properties": {}}

                req_body = (
                    spec.get("requestBody", {})
                    .get("content", {})
                    .get("application/json", {})
                    .get("schema")
                )
                if req_body:
                    schema["properties"]["requestBody"] = req_body

                spec_params = spec.get("parameters", [])
                if spec_params:
                    param_properties = {}
                    required_params = []
                    for param in spec_params:
                        if "schema" not in param and "type" in param:
                            param["schema"] = {"type": param["type"]}
                        param_properties[param["name"]] = param["schema"]
                        if "description" in param:
                            param_properties[param["name"]]["description"] = param[
                                "description"
                            ]
                        if "required" in param and param["required"]:
                            required_params.append(param["name"])
                        if "example" in param:
                            param_properties[param["name"]]["example"] = param[
                                "example"
                            ]
                        if "examples" in param:
                            param_properties[param["name"]]["examples"] = param[
                                "examples"
                            ]

                    schema["properties"]["parameters"] = {
                        "type": "object",
                        "properties": param_properties,
                        "required": required_params,
                    }

                function = {
                    "name": function_name,
                    "description": desc,
                    "parameters": schema,
                    "strict": strict,
                }

                tools.append(ToolFactory.from_openai_schema(function, callback))

        return tools

    @staticmethod
    def _create_callback_for_path(path, method, openapi_spec, params, headers):
        """
        Creates a callback function for a specific path and method.
        This is a factory function that captures the current values of path and method.

        Parameters:
            path: The path to create the callback for.
            method: The HTTP method to use.
            openapi_spec: The OpenAPI specification.
            params: Additional parameters to include in the request.
            headers: Headers to include in the request.

        Returns:
            An async callback function that makes the appropriate HTTP request.
        """

        async def callback(self):
            url = openapi_spec["servers"][0]["url"] + path
            parameters = self.model_dump().get("parameters", {})
            # replace all parameters in url
            for param, value in parameters.items():
                if "{" + str(param) + "}" in url:
                    url = url.replace(f"{{{param}}}", str(value))
                    parameters[param] = None
            url = url.rstrip("/")
            parameters = {k: v for k, v in parameters.items() if v is not None}
            parameters = {**parameters, **params} if params else parameters
            async with httpx.AsyncClient(
                timeout=90
            ) as client:  # Set custom read timeout to 10 seconds
                if method == "get":
                    response = await client.get(url, params=parameters, headers=headers)
                elif method == "post":
                    response = await client.post(
                        url,
                        params=parameters,
                        json=self.model_dump().get("requestBody", None),
                        headers=headers,
                    )
                elif method == "put":
                    response = await client.put(
                        url,
                        params=parameters,
                        json=self.model_dump().get("requestBody", None),
                        headers=headers,
                    )
                elif method == "delete":
                    response = await client.delete(
                        url,
                        params=parameters,
                        json=self.model_dump().get("requestBody", None),
                        headers=headers,
                    )
                return response.json()

        return callback

    @staticmethod
    def from_file(file_path: str) -> Type[BaseTool]:
        """Dynamically imports a BaseTool class from a Python file within a package structure.

        Parameters:
            file_path: The file path to the Python file containing the BaseTool class.

        Returns:
            The imported BaseTool class.
        """
        file_path = os.path.relpath(file_path)
        # Normalize the file path to be absolute and extract components
        directory, file_name = os.path.split(file_path)
        import_path = os.path.splitext(file_path)[0].replace(os.sep, ".")
        class_name = os.path.splitext(file_name)[0]

        exec_globals = globals()

        # importing from agency_swarm package
        if "agency_swarm" in import_path:
            import_path = import_path.lstrip(".")
            exec(f"from {import_path} import {class_name}", exec_globals)
        # importing from current working directory
        else:
            current_working_directory = os.getcwd()
            sys.path.append(current_working_directory)
            exec(f"from {import_path} import {class_name}", exec_globals)

        imported_class = exec_globals.get(class_name)
        if not imported_class:
            raise ImportError(f"Could not import {class_name} from {import_path}")

        # Check if the imported class is a subclass of BaseTool
        if not issubclass(imported_class, BaseTool):
            raise TypeError(f"Class {class_name} must be a subclass of BaseTool")

        return imported_class

    @staticmethod
    def from_mcp(server):
        tool_definitions = server.list_tools()
        tools = []

        if tool_definitions == []:
            raise Exception(f"No tools found in MCP server: {server.name}")

        for definition in tool_definitions:
            # Handle both dictionary and object formats
            if isinstance(definition, dict):
                name = definition.get("name")
                description = definition.get("description", "")
                parameters = definition.get("inputSchema", {})
            else:
                # Access attributes from object
                name = getattr(definition, "name", "")
                description = getattr(definition, "description", "")
                parameters = getattr(definition, "inputSchema", {})
                # The returned object might have the parameters as a property or a method
                if callable(parameters):
                    parameters = parameters()
            # Check if any parameter has a default value
            has_default_values = False
            if isinstance(parameters, dict) and "properties" in parameters:
                for param_props in parameters["properties"].values():
                    if "default" in param_props:
                        has_default_values = True
                        break
            # If any parameter has a default value, set strict to False
            if has_default_values and server.strict:
                logger.warning("Non-supported tool parameter found, disabling strict mode.")
                server.strict = False

            # Create a factory function to properly capture the tool name
            def create_callback(tool_name):
                async def callback(self, **kwargs):

                    # Extract arguments from the model_dump, excluding any internal attributes
                    args = {
                        k: v
                        for k, v in self.model_dump().items()
                        if not k.startswith("_") and k != "self"
                    }

                    # Call the tool with just the arguments, not the whole model
                    try:
                        result = server.call_tool(tool_name, args)
                        logger.info(f"Tool {tool_name} output: {result}")
                    except Exception as e:
                        logger.error(f"Tool call failed: {type(e).__name__}: {e!r}")
                        return f"Tool call failed: {type(e).__name__}: {e!r}"

                    if hasattr(result, "content") and result.content:
                        # Extract text from the first content item if it exists
                        if len(result.content) > 0 and hasattr(
                            result.content[0], "text"
                        ):
                            return result.content[0].text
                        # Try to convert the content to a string
                        return str(result.content)
                    # Fallback: try to get the result attribute or convert the entire object to string
                    if hasattr(result, "result"):
                        return result.result

                    return str(result)

                return callback

            callback = create_callback(name)

            tool = ToolFactory.from_openai_schema(
                {
                    "name": name,
                    "description": description,
                    "parameters": parameters,
                    "strict": server.strict
                },
                callback,
            )
            tools.append(tool)

        return tools

    @staticmethod
    def get_openapi_schema(
        tools: List[Type[BaseTool]],
        url: str,
        title="Agent Tools",
        description="A collection of tools.",
    ) -> str:
        """
        Generates an OpenAPI schema from a list of BaseTools.

        Parameters:
            tools: BaseTools to generate the schema from.
            url: The base URL for the schema.
            title: The title of the schema.
            description: The description of the schema.

        Returns:
            A JSON string representing the OpenAPI schema with all the tools combined as separate endpoints.
        """
        schema = {
            "openapi": "3.1.0",
            "info": {"title": title, "description": description, "version": "v1.0.0"},
            "servers": [
                {
                    "url": url,
                }
            ],
            "paths": {},
            "components": {
                "schemas": {},
                "securitySchemes": {"apiKey": {"type": "apiKey"}},
            },
        }

        for tool in tools:
            if not issubclass(tool, BaseTool):
                continue

            openai_schema = tool.openai_schema
            defs = {}
            if "$defs" in openai_schema["parameters"]:
                defs = openai_schema["parameters"]["$defs"]
                del openai_schema["parameters"]["$defs"]

            schema["paths"]["/" + openai_schema["name"]] = {
                "post": {
                    "description": openai_schema["description"],
                    "operationId": openai_schema["name"],
                    "x-openai-isConsequential": False,
                    "parameters": [],
                    "requestBody": {
                        "content": {
                            "application/json": {"schema": openai_schema["parameters"]}
                        }
                    },
                }
            }

            schema["components"]["schemas"].update(defs)

        schema = json.dumps(schema, indent=2).replace(
            "#/$defs/", "#/components/schemas/"
        )

        return schema



================================================
FILE: agency_swarm/tools/mcp/__init__.py
================================================
from .server import (
    MCPServer,
    MCPServerSse,
    MCPServerStdio,
)

__all__ = [
    "MCPServer",
    "MCPServerSse",
    "MCPServerStdio",
]



================================================
FILE: agency_swarm/tools/mcp/server.py
================================================
import os
import abc
import time
import asyncio
import logging
import tempfile
from contextlib import AbstractAsyncContextManager, AsyncExitStack
from pathlib import Path
from typing import Any, Literal

from anyio.streams.memory import MemoryObjectReceiveStream, MemoryObjectSendStream
from mcp import ClientSession, StdioServerParameters, stdio_client
from mcp import Tool as MCPTool
from mcp.client.sse import sse_client
from mcp.types import CallToolResult, JSONRPCMessage
from typing_extensions import NotRequired, TypedDict
import threading
from concurrent.futures import Future


logger = logging.getLogger(__name__)


class AgentsException(Exception):
    """Base class for all exceptions in the Agents SDK."""


class UserError(AgentsException):
    """Exception raised when the user makes an error using the SDK."""

    message: str

    def __init__(self, message: str):
        self.message = message


class MCPServer(abc.ABC):
    """Base class for Model Context Protocol servers."""

    @abc.abstractmethod
    async def connect(self):
        """Connect to the server. For example, this might mean spawning a subprocess or
        opening a network connection. The server is expected to remain connected until
        `cleanup()` is called.
        """
        pass

    @property
    @abc.abstractmethod
    def name(self) -> str:
        """A readable name for the server."""
        pass

    @property
    @abc.abstractmethod
    def strict(self) -> bool:
        """Use strict mode for the OpenAI's structured outputs."""
        pass

    @abc.abstractmethod
    async def cleanup(self):
        """Cleanup the server. For example, this might mean closing a subprocess or
        closing a network connection.
        """
        pass

    @abc.abstractmethod
    async def list_tools(self) -> list[MCPTool]:
        """List the tools available on the server."""
        pass

    @abc.abstractmethod
    async def call_tool(
        self, tool_name: str, arguments: dict[str, Any] | None
    ) -> CallToolResult:
        """Invoke a tool on the server."""
        pass


class _MCPServerWithClientSession(MCPServer, abc.ABC):
    """Base class for MCP servers that use a `ClientSession` to communicate with the server."""

    def __init__(self, cache_tools_list: bool, strict: bool = False, allowed_tools: list[str] | None = None):
        """
        Args:
            cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be
            cached and only fetched from the server once. If `False`, the tools list will be
            fetched from the server on each call to `list_tools()`. The cache can be invalidated
            by calling `invalidate_tools_cache()`. You should set this to `True` if you know the
            server will not change its tools list, because it can drastically improve latency
            (by avoiding a round-trip to the server every time).
            strict: Whether to use strict mode when converting MCP tools to OpenAI tools.
            allowed_tools: Optional list of tool names to allow. Restricts the tools selection to the provided list.
        """
        self.session: ClientSession | None = None
        self.exit_stack: AsyncExitStack = AsyncExitStack()
        self._cleanup_lock: asyncio.Lock = asyncio.Lock()
        self.cache_tools_list = cache_tools_list
        self._strict = strict
        self._allowed_tools = allowed_tools
        # The cache is always dirty at startup, so that we fetch tools at least once
        self._cache_dirty = True
        self._tools_list: list[MCPTool] | None = None
        self._sync_manager = None
        self._thread = threading.Thread(target=self._run_loop, daemon=True)
        self._loop = asyncio.new_event_loop()
        self._queue = asyncio.Queue()
        self._shutdown_event = threading.Event()
        self._ready_event = threading.Event()
        self._startup_exception = None  # Store startup exception for detailed error reporting
        self._thread.start()

    def _run_loop(self):
        asyncio.set_event_loop(self._loop)
        self._loop.run_until_complete(self._main())

    async def _main(self):
        """
        Main event loop for the background thread managing async MCP server operations.

        Handles initial connection, dispatches synchronous method calls (connect, list_tools, call_tool, cleanup) to their async counterparts, maintains proper cleanup and shutdown.
        """
        await self._connect_async()
        self._ready_event.set()
        try:
            while True:
                item = await self._queue.get()
                if item == "SHUTDOWN":
                    break
                method, args, result_future = item
                try:
                    coro = getattr(self, f"_{method}_async")(*args)
                    result = await coro
                    result_future.set_result(result)
                except Exception as e:
                    result_future.set_exception(e)
        finally:
            await self._cleanup_async()
            self._shutdown_event.set()

    @staticmethod
    def extract_error_from_log(log_file_path: str, errlog_handle=None) -> str | None:
        """
        Read and return the contents of the given log file, or an empty string if not found or empty.
        Deletes the file after reading. Closes the file handle if provided.
        """
        if errlog_handle is not None and not errlog_handle.closed:
            errlog_handle.close()
        if not os.path.exists(log_file_path):
            return None
        with open(log_file_path, 'r', encoding='utf-8') as f:
            contents = f.read()
        # Try to delete the file, retrying if necessary
        start = time.time()
        while True:
            try:
                os.remove(log_file_path)
                break
            except PermissionError as e:
                if time.time() - start > 5.0:
                    logger.warning(f"Failed to delete log file after 5 seconds: {log_file_path}")
                    break
                time.sleep(0.2)
        return contents

    def _call_in_loop(self, method, *args, timeout=120):
        # Add a timeout to prevent indefinite hangs
        if not self._ready_event.wait(timeout=timeout):
            errlog = getattr(self, '_errlog_buffer', None)
            if errlog:
                error_message = self.extract_error_from_log(errlog.name, errlog)
                if error_message and error_message.strip()!='':
                    raise RuntimeError(error_message)
                else:
                    raise RuntimeError("Failed to connect to the server. Please check if the server is running and accessible.")
            else:
                # SSE servers do not support error logging, print generic message
                raise RuntimeError("Failed to connect to the server. Please check if the server is running and accessible.")
                
        result_future = Future()
        self._loop.call_soon_threadsafe(self._queue.put_nowait, (method, args, result_future))
        return result_future.result()  # blocks until result is ready

    # Synchronous public methods
    def connect(self):
        return self._call_in_loop("connect", timeout=10)

    def list_tools(self):
        return self._call_in_loop("list_tools", timeout=10)

    def call_tool(self, tool_name, arguments, timeout=120):
        return self._call_in_loop("call_tool", tool_name, arguments, timeout=timeout)

    def cleanup(self):
        self._loop.call_soon_threadsafe(self._queue.put_nowait, "SHUTDOWN")
        self._shutdown_event.wait()
        self._loop.call_soon_threadsafe(self._loop.stop)
        self._thread.join()
        if (errlog := getattr(self, '_errlog_buffer', None)) is not None:
            self.extract_error_from_log(errlog.name, errlog) # Delete the error log file

    # Async implementations
    async def _connect_async(self):
        try:
            transport = await self.exit_stack.enter_async_context(self.create_streams())
            read, write = transport
            session = await self.exit_stack.enter_async_context(
                ClientSession(read, write)
            )
            await session.initialize()
            self.session = session
        except Exception as e:
            logger.error(f"Error initializing MCP server: {e}")
            await self.cleanup()
            raise

    async def _list_tools_async(self) -> list[MCPTool]:
        if not self.session:
            raise UserError(
                "Server not initialized. Make sure you call `connect()` first."
            )
        # Return from cache if caching is enabled, we have tools, and the cache is not dirty
        if self.cache_tools_list and not self._cache_dirty and self._tools_list:
            tools = self._tools_list
        else:
            # Reset the cache dirty to False
            self._cache_dirty = False
            # Fetch the tools from the server
            self._tools_list = (await self.session.list_tools()).tools
            tools = self._tools_list
        # Filter tools if allowed_tools is set
        if self._allowed_tools is not None:
            tools = [tool for tool in tools if getattr(tool, 'name', None) in self._allowed_tools]
        return tools

    async def _call_tool_async(self, tool_name: str, arguments: dict[str, Any] | None) -> CallToolResult:
        if not self.session:
            raise UserError(
                "Server not initialized. Make sure you call `connect()` first."
            )

        return await self.session.call_tool(tool_name, arguments)

    async def _cleanup_async(self):
        async with self._cleanup_lock:
            try:
                await self.exit_stack.aclose()
                self.session = None
            except Exception as e:
                logger.error(f"Error cleaning up server: {e}")

    @property
    def strict(self) -> bool:
        """Whether to use strict mode when converting MCP tools to OpenAI tools."""
        return self._strict

    @strict.setter
    def strict(self, value: bool):
        self._strict = value

    @property
    def allowed_tools(self) -> list[str] | None:
        return self._allowed_tools

    @allowed_tools.setter
    def allowed_tools(self, value: list[str] | None):
        self._allowed_tools = value

    @abc.abstractmethod
    def create_streams(
        self,
    ) -> AbstractAsyncContextManager[
        tuple[
            MemoryObjectReceiveStream[JSONRPCMessage | Exception],
            MemoryObjectSendStream[JSONRPCMessage],
        ]
    ]:
        """Create the streams for the server."""
        pass

    def invalidate_tools_cache(self):
        """Invalidate the tools cache."""
        self._cache_dirty = True


class MCPServerStdioParams(TypedDict):
    """Mirrors `mcp.client.stdio.StdioServerParameters`, but lets you pass params without another
    import.
    """

    command: str
    """The executable to run to start the server. For example, `python` or `node`."""

    args: NotRequired[list[str]]
    """Command line args to pass to the `command` executable. For example, `['foo.py']` or
    `['server.js', '--port', '8080']`."""

    env: NotRequired[dict[str, str]]
    """The environment variables to set for the server. ."""

    cwd: NotRequired[str | Path]
    """The working directory to use when spawning the process."""

    encoding: NotRequired[str]
    """The text encoding used when sending/receiving messages to the server. Defaults to `utf-8`."""

    encoding_error_handler: NotRequired[Literal["strict", "ignore", "replace"]]
    """The text encoding error handler. Defaults to `strict`.

    See https://docs.python.org/3/library/codecs.html#codec-base-classes for
    explanations of possible values.
    """

    strict: NotRequired[bool]
    """Whether to use strict mode when converting MCP tools to OpenAI tools. Defaults to `False`."""


class MCPServerStdio(_MCPServerWithClientSession):
    """MCP server implementation that uses the stdio transport. See the [spec]
    (https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/#stdio) for
    details.
    """

    def __init__(
        self,
        params: MCPServerStdioParams,
        cache_tools_list: bool = False,
        name: str | None = None,
        strict: bool = False,
        allowed_tools: list[str] | None = None,
    ):
        """Create a new MCP server based on the stdio transport.

        Args:
            params: The params that configure the server. This includes the command to run to
                start the server, the args to pass to the command, the environment variables to
                set for the server, the working directory to use when spawning the process, and
                the text encoding used when sending/receiving messages to the server.
            cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be
                cached and only fetched from the server once. If `False`, the tools list will be
                fetched from the server on each call to `list_tools()`. The cache can be
                invalidated by calling `invalidate_tools_cache()`. You should set this to `True`
                if you know the server will not change its tools list, because it can drastically
                improve latency (by avoiding a round-trip to the server every time).
            name: A readable name for the server. If not provided, we'll create one from the
                command.
            strict: Use strict mode for the OpenAI's structured outputs. Defaults to `False`.
            allowed_tools: Optional list of tool names to allow. Restricts the tools selection to the provided list.
        """
        # For backwards compatibility, if strict is not provided, check if it's in the params
        if not strict:
            if "strict" in params:
                print("Strict parameter is deprecated. Use the strict argument instead.")
            strict = params.pop("strict", False)
        
        self.params = StdioServerParameters(
            command=params["command"],
            args=params.get("args", []),
            env=params.get("env"),
            cwd=params.get("cwd"),
            encoding=params.get("encoding", "utf-8"),
            encoding_error_handler=params.get("encoding_error_handler", "strict"),
        )
        self._name = name or f"stdio: {self.params.command}"
        # Save error log in the local directory
        self._errlog_buffer = tempfile.NamedTemporaryFile(
            mode="w+", encoding="utf-8", delete=False, suffix=f"_{self._name}_stderr.log"
        )
        super().__init__(cache_tools_list, strict=strict, allowed_tools=allowed_tools)

    def create_streams(
        self,
    ) -> AbstractAsyncContextManager[
        tuple[
            MemoryObjectReceiveStream[JSONRPCMessage | Exception],
            MemoryObjectSendStream[JSONRPCMessage],
        ]
    ]:
        """Create the streams for the server."""
        # Pass the error log buffer to stdio_client
        return stdio_client(self.params, errlog=self._errlog_buffer)

    @property
    def name(self) -> str:
        """A readable name for the server."""
        return self._name


class MCPServerSseParams(TypedDict):
    """Mirrors the params in`mcp.client.sse.sse_client`."""

    url: str
    """The URL of the server."""

    headers: NotRequired[dict[str, str]]
    """The headers to send to the server."""

    timeout: NotRequired[float]
    """The timeout for the HTTP request. Defaults to 5 seconds."""

    sse_read_timeout: NotRequired[float]
    """The timeout for the SSE connection, in seconds. Defaults to 5 minutes."""

    strict: NotRequired[bool]
    """Whether to use strict mode when converting MCP tools to OpenAI tools. Defaults to `False`."""


class MCPServerSse(_MCPServerWithClientSession):
    """MCP server implementation that uses the HTTP with SSE transport. See the [spec]
    (https://spec.modelcontextprotocol.io/specification/2024-11-05/basic/transports/#http-with-sse)
    for details.
    """

    def __init__(
        self,
        params: MCPServerSseParams,
        cache_tools_list: bool = False,
        name: str | None = None,
        strict: bool = False,
        allowed_tools: list[str] | None = None,
    ):
        """Create a new MCP server based on the HTTP with SSE transport.

        Args:
            params: The params that configure the server. This includes the URL of the server,
                the headers to send to the server, the timeout for the HTTP request, and the
                timeout for the SSE connection.

            cache_tools_list: Whether to cache the tools list. If `True`, the tools list will be
                cached and only fetched from the server once. If `False`, the tools list will be
                fetched from the server on each call to `list_tools()`. The cache can be
                invalidated by calling `invalidate_tools_cache()`. You should set this to `True`
                if you know the server will not change its tools list, because it can drastically
                improve latency (by avoiding a round-trip to the server every time).

            name: A readable name for the server. If not provided, we'll create one from the
                URL.
            strict: Use strict mode for the OpenAI's structured outputs. Defaults to `False`.
            allowed_tools: Optional list of tool names to allow. Restricts the tools selection to the provided list.
        """
        # For backwards compatibility, if strict is not provided, check if it's in the params
        if not strict:
            if "strict" in params:
                print("Strict parameter is deprecated. Use the strict argument instead.")
            strict = params.pop("strict", False)

        self.params = params
        self._name = name or f"sse: {self.params['url']}"
        super().__init__(cache_tools_list, strict=strict, allowed_tools=allowed_tools)

    def create_streams(
        self,
    ) -> AbstractAsyncContextManager[
        tuple[
            MemoryObjectReceiveStream[JSONRPCMessage | Exception],
            MemoryObjectSendStream[JSONRPCMessage],
        ]
    ]:
        """Create the streams for the server."""
        return sse_client(
            url=self.params["url"],
            headers=self.params.get("headers", None),
            timeout=self.params.get("timeout", 5),
            sse_read_timeout=self.params.get("sse_read_timeout", 60 * 5),
        )

    @property
    def name(self) -> str:
        """A readable name for the server."""
        return self._name


================================================
FILE: agency_swarm/tools/oai/__init__.py
================================================
from .CodeInterpreter import CodeInterpreter
from .FileSearch import FileSearch
from .Retrieval import Retrieval



================================================
FILE: agency_swarm/tools/oai/CodeInterpreter.py
================================================
from pydantic import BaseModel


class CodeInterpreter(BaseModel):
    type: str = "code_interpreter"



================================================
FILE: agency_swarm/tools/oai/FileSearch.py
================================================
from typing import Any
from openai.types.beta.file_search_tool import FileSearch as OpenAIFileSearch
from openai.types.beta.file_search_tool import FileSearchTool
from pydantic import ValidationError


class FileSearchConfig(OpenAIFileSearch):
    pass


class FileSearch(FileSearchTool):
    def __init__(self, **data: Any) -> None:
        try:
            super().__init__(**data)
        except ValidationError:
            # sometimes openai API sends a different schema
            super().__init__(type="file_search")

    type: str = "file_search"



================================================
FILE: agency_swarm/tools/oai/Retrieval.py
================================================
from pydantic import BaseModel


class Retrieval(BaseModel):
    type: str = "file_search"



================================================
FILE: agency_swarm/tools/send_message/__init__.py
================================================
from .SendMessage import SendMessage
from .SendMessageAsyncThreading import SendMessageAsyncThreading
from .SendMessageBase import SendMessageBase
from .SendMessageQuick import SendMessageQuick
from .SendMessageSwarm import SendMessageSwarm



================================================
FILE: agency_swarm/tools/send_message/SendMessage.py
================================================
from typing import List, Optional

from pydantic import Field, model_validator

from .SendMessageBase import SendMessageBase


class SendMessage(SendMessageBase):
    """Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message to the same recipient agent at the same time."""

    my_primary_instructions: str = Field(
        ...,
        description=(
            "Please repeat your primary instructions step-by-step, including both completed "
            "and the following next steps that you need to perform. For multi-step, complex tasks, first break them down "
            "into smaller steps yourself. Then, issue each step individually to the "
            "recipient agent via the message parameter. Each identified step should be "
            "sent in a separate message. Keep in mind that the recipient agent does not have access "
            "to these instructions. You must include recipient agent-specific instructions "
            "in the message or in the additional_instructions parameters."
        ),
    )
    message: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information from the conversation needed to complete the task.",
    )
    message_files: Optional[List[str]] = Field(
        default=None,
        description="A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
        examples=["file-1234", "file-5678"],
    )
    additional_instructions: Optional[str] = Field(
        default=None,
        description="Additional context or instructions from the conversation needed by the recipient agent to complete the task.",
    )

    @model_validator(mode="after")
    def validate_files(self):
        # prevent hallucinations with agents sending file IDs into incorrect fields
        if "file-" in self.message or (
            self.additional_instructions and "file-" in self.additional_instructions
        ):
            if not self.message_files:
                raise ValueError(
                    "You must include file IDs in message_files parameter."
                )
        return self

    def run(self):
        return self._get_completion(
            message=self.message,
            message_files=self.message_files,
            additional_instructions=self.additional_instructions,
        )



================================================
FILE: agency_swarm/tools/send_message/SendMessageAsyncThreading.py
================================================
from .SendMessage import SendMessage


class SendMessageAsyncThreading(SendMessage):
    """Use this tool for asynchronous communication with other agents within your agency. Initiate tasks by messaging, and check status and responses later with the 'GetResponse' tool. Relay responses to the user, who instructs on status checks. Continue until task completion."""

    class ToolConfig:
        async_mode = "threading"



================================================
FILE: agency_swarm/tools/send_message/SendMessageBase.py
================================================
from abc import ABC
from typing import ClassVar, Union

from pydantic import Field, field_validator

from agency_swarm.agents.agent import Agent
from agency_swarm.threads.thread import Thread
from agency_swarm.threads.thread_async import ThreadAsync
from agency_swarm.tools import BaseTool


class SendMessageBase(BaseTool, ABC):
    recipient: str = Field(
        ...,
        description="Recipient agent that you want to send the message to. This field will be overriden inside the agency class.",
    )

    _agents_and_threads: ClassVar = None

    @field_validator("additional_instructions", mode="before", check_fields=False)
    @classmethod
    def validate_additional_instructions(cls, value):
        # previously the parameter was a list, now it's a string
        # add compatibility for old code
        if isinstance(value, list):
            return "\n".join(value)
        return value

    def _get_thread(self) -> Thread | ThreadAsync:
        return self._agents_and_threads[self._caller_agent.name][self.recipient.value]

    def _get_main_thread(self) -> Thread | ThreadAsync:
        return self._agents_and_threads["main_thread"]

    def _get_recipient_agent(self) -> Agent:
        return self._agents_and_threads[self._caller_agent.name][
            self.recipient.value
        ].recipient_agent

    def _get_completion(self, message: Union[str, None] = None, **kwargs):
        thread = self._get_thread()

        if self.ToolConfig.async_mode == "threading":
            return thread.get_completion_async(
                message=message,
                parent_run_id=self._tool_call.id,
                **kwargs,
            )
        else:
            return thread.get_completion(
                message=message,
                event_handler=self._event_handler,
                yield_messages=not self._event_handler,
                parent_run_id=self._tool_call.id,
                **kwargs,
            )



================================================
FILE: agency_swarm/tools/send_message/SendMessageQuick.py
================================================
from pydantic import Field

from .SendMessageBase import SendMessageBase


class SendMessageQuick(SendMessageBase):
    """Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message to the same recipient agent at the same time."""

    message: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to inlcude all the relevant information from the conversation needed to complete the task.",
    )

    def run(self):
        return self._get_completion(message=self.message)



================================================
FILE: agency_swarm/tools/send_message/SendMessageSwarm.py
================================================
import logging
from typing import Generator, Union

from openai import BadRequestError

from agency_swarm.messages.message_output import MessageOutput

from .SendMessage import SendMessageBase


class SendMessageSwarm(SendMessageBase):
    """Use this tool to route messages to other agents within your agency. After using this tool, you will be switched to the recipient agent. This tool can only be used once per message. Do not use any other tools together with this tool."""

    class ToolConfig:
        # set output as result because the communication will be finished after this tool is called
        output_as_result: bool = True
        one_call_at_a_time: bool = True

    def run(self) -> Union[str, Generator[MessageOutput, None, None]]:
        logging.debug("SendMessageSwarm.run: Starting execution")

        # get main thread
        thread = self._get_main_thread()
        logging.debug(f"SendMessageSwarm.run: Got main thread: {thread}")

        # get recipient agent
        recipient_agent = self._get_recipient_agent()
        logging.debug(
            f"SendMessageSwarm.run: Got recipient agent: {recipient_agent.name}"
        )

        # submit tool output
        try:
            logging.debug("SendMessageSwarm.run: Submitting tool output")
            thread.submit_tool_outputs(
                tool_outputs=[
                    {
                        "tool_call_id": self._tool_call.id,
                        "output": "The request has been routed. You are now a "
                        + recipient_agent.name
                        + " agent. Please assist the user further with their request.",
                    }
                ],
                poll=False,
            )
            logging.debug("SendMessageSwarm.run: Tool output submitted successfully")
        except BadRequestError as e:
            logging.error(
                f"SendMessageSwarm.run: BadRequestError while submitting tool output: {e}"
            )
            raise Exception(
                "You can only call this tool by itself. Do not use any other tools together with this tool."
            )

        try:
            # cancel run
            logging.debug("SendMessageSwarm.run: Canceling current run")
            thread.cancel_run()
            logging.debug("SendMessageSwarm.run: Run canceled successfully")

            # change recipient agent in thread
            logging.debug(
                f"SendMessageSwarm.run: Changing recipient agent to {recipient_agent.name}"
            )
            thread.recipient_agent = recipient_agent

            # change recipient agent in gradio dropdown
            if self._event_handler:
                logging.debug("SendMessageSwarm.run: Updating event handler")
                if hasattr(self._event_handler, "change_recipient_agent"):
                    self._event_handler.change_recipient_agent(self.recipient.value)
                    logging.debug("SendMessageSwarm.run: Event handler updated")

            # continue conversation with the new recipient agent
            logging.debug(
                "SendMessageSwarm.run: Getting completion from new recipient agent"
            )
            message = thread.get_completion(
                message=None,
                recipient_agent=recipient_agent,
                event_handler=self._event_handler,
                yield_messages=not self._event_handler,
                parent_run_id=self._tool_call.id,
            )

            # Log only if message is a string (not a generator)
            if isinstance(message, str):
                logging.debug(
                    f"SendMessageSwarm.run: Got completion response: {message[:100]}..."
                )

            return message or ""
        except Exception as e:
            # we need to catch errors because tool outputs are already submitted
            logging.error(f"SendMessageSwarm.run: Error during execution: {e}")
            print("Error in SendMessageSwarm: ", e)
            return str(e)



================================================
FILE: agency_swarm/user/__init__.py
================================================
from .user import User



================================================
FILE: agency_swarm/user/user.py
================================================
class User:
    name: str = "User"

    def __init__(self, name: str = None):
        # later, we can add more attributes to the user like bio, etc
        pass



================================================
FILE: agency_swarm/util/__init__.py
================================================
from .cli.create_agent_template import create_agent_template
from .cli.import_agent import import_agent
from .files import get_file_purpose, get_tools
from .oai import get_openai_client, set_openai_client, set_openai_key
from .tracking import get_callback_handler, init_tracking, stop_tracking
from .validators import llm_validator

__all__ = [
    "create_agent_template",
    "import_agent",
    "get_file_purpose",
    "get_tools",
    "get_openai_client",
    "set_openai_client",
    "set_openai_key",
    "init_tracking",
    "get_callback_handler",
    "llm_validator",
    "stop_tracking",
]



================================================
FILE: agency_swarm/util/errors.py
================================================
class RefusalError(Exception):
    pass



================================================
FILE: agency_swarm/util/files.py
================================================
import mimetypes

# Register the MIME type for .xlsx files
mimetypes.add_type(
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", ".xlsx"
)
mimetypes.add_type(
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document", ".docx"
)
mimetypes.add_type(
    "application/vnd.openxmlformats-officedocument.presentationml.presentation", ".pptx"
)

image_types = ["image/jpeg", "image/jpg", "image/png", "image/webp", "image/gif"]

code_interpreter_types = [
    "application/csv",
    "image/jpeg",
    "image/gif",
    "image/png",
    "application/x-tar",
    "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    "application/xml",
    "text/xml",
    "application/zip",
    "text/csv",
]

dual_types = [
    "text/x-c",
    "text/x-csharp",
    "text/x-c++",
    "application/msword",
    "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
    "text/html",
    "text/x-java",
    "application/json",
    "text/markdown",
    "application/pdf",
    "text/x-php",
    "application/vnd.openxmlformats-officedocument.presentationml.presentation",
    "text/x-python",
    "text/x-script.python",
    "text/x-ruby",
    "text/x-tex",
    "text/plain",
    "text/css",
    "text/javascript",
    "application/x-sh",
    "application/typescript",
]


def get_file_purpose(file_path):
    mime_type, _ = mimetypes.guess_type(file_path)
    if not mime_type:
        raise ValueError(f"Could not determine type for file: {file_path}")
    if mime_type in image_types:
        return "vision"
    if mime_type in code_interpreter_types or mime_type in dual_types:
        return "assistants"
    raise ValueError(f"Unsupported file type: {mime_type}")


def get_tools(file_path):
    """Returns the tools for the given file path"""
    mime_type, _ = mimetypes.guess_type(file_path)
    if not mime_type:
        raise ValueError(f"Could not determine type for file: {file_path}")
    if mime_type in code_interpreter_types:
        return [{"type": "code_interpreter"}]
    elif mime_type in dual_types:
        return [{"type": "code_interpreter"}, {"type": "file_search"}]
    else:
        raise ValueError(f"Unsupported file type: {mime_type}")



================================================
FILE: agency_swarm/util/oai.py
================================================
import os
import threading

import httpx
import openai
from dotenv import load_dotenv

load_dotenv()

_lock = threading.Lock()
client = None


def get_openai_client():
    global client
    with _lock:
        if client is None:
            # Check if the API key is set
            api_key = openai.api_key or os.getenv("OPENAI_API_KEY")
            if api_key is None:
                raise ValueError(
                    "OpenAI API key is not set. Please set it using set_openai_key."
                )

            client = openai.OpenAI(
                api_key=api_key,
                timeout=httpx.Timeout(60.0, read=40, connect=5.0),
                max_retries=10,
                default_headers={"OpenAI-Beta": "assistants=v2"},
            )
    return client


def set_openai_client(new_client):
    global client
    with _lock:
        client = new_client


def set_openai_key(key: str):
    if not key:
        raise ValueError("Invalid API key. The API key cannot be empty.")

    openai.api_key = key

    global client
    with _lock:
        client = None



================================================
FILE: agency_swarm/util/openapi.py
================================================
import json


def validate_openapi_spec(spec: str):
    spec = json.loads(spec)

    # Validate that 'paths' is present in the spec
    if "paths" not in spec:
        raise ValueError("The spec must contain 'paths'.")

    for path, path_item in spec["paths"].items():
        # Ensure each path item is a dictionary
        if not isinstance(path_item, dict):
            raise ValueError(f"Path item for '{path}' must be a dictionary.")

        for operation in path_item.values():
            # Basic validation for each operation
            if "operationId" not in operation:
                raise ValueError("Each operation must contain an 'operationId'.")
            if "description" not in operation:
                raise ValueError("Each operation must contain a 'description'.")

    # Perform any additional basic validation as needed

    # If the function reaches this point, the spec has passed basic validation
    return spec



================================================
FILE: agency_swarm/util/schema.py
================================================
def dereference_schema(schema):
    defs = schema.get("parameters", {}).get("$defs", {})

    def resolve_refs(node):
        if isinstance(node, dict):
            if "$ref" in node:
                ref_path = node["$ref"]
                ref_path_parts = ref_path.split("/")
                ref = defs.get(ref_path_parts[-1], {})
                return ref
            else:
                return {k: resolve_refs(v) for k, v in node.items()}
        elif isinstance(node, list):
            return [resolve_refs(element) for element in node]
        else:
            return node

    return resolve_refs(schema)


def reference_schema(schema):
    # Enhanced function to only extract nested properties into $defs

    def find_and_extract_defs(node, defs, parent_key=None, path_prefix="#/$defs/"):
        if isinstance(node, dict):
            # Extract nested properties into $defs
            if (
                parent_key == "properties"
                and "properties" in node
                and isinstance(node["properties"], dict)
            ):
                def_name = node.get("title", None)
                if def_name:
                    defs[def_name] = node
                    return {"$ref": path_prefix + def_name}

            # Recursively process the dictionary
            return {
                k: find_and_extract_defs(v, defs, parent_key=k) for k, v in node.items()
            }
        elif isinstance(node, list):
            # Recursively process the list
            return [
                find_and_extract_defs(element, defs, parent_key) for element in node
            ]
        else:
            return node

    defs = {}
    # Extract definitions and update the schema
    new_schema = {k: find_and_extract_defs(v, defs) for k, v in schema.items()}
    if defs:
        new_schema["parameters"] = new_schema.get("parameters", {})
        new_schema["parameters"]["$defs"] = defs
    return new_schema



================================================
FILE: agency_swarm/util/shared_state.py
================================================
class SharedState:
    def __init__(self):
        self.data = {}

    def set(self, key, value):
        if not isinstance(key, str):
            raise ValueError("Key must be a string")
        self.data[key] = value

    def get(self, key, default=None):
        if not isinstance(key, str):
            raise ValueError("Key must be a string")
        return self.data.get(key, default)

    def print_data(self):
        for key, value in self.data.items():
            print(f"{key}: {value}")



================================================
FILE: agency_swarm/util/validators.py
================================================
from typing import Callable

from openai import OpenAI
from pydantic import BaseModel, Field

from agency_swarm.constants import DEFAULT_MODEL_MINI
from agency_swarm.util.oai import get_openai_client


class Validator(BaseModel):
    """
    Validate if an attribute is correct and if not,
    return a new value with an error message
    """

    reason: str = Field(
        ...,
        description="Step-by-step reasoning why the attribute could be valid or not with a conclussion at the end.",
    )
    is_valid: bool = Field(
        ..., description="Whether the attribute is valid based on the requirements."
    )
    fixed_value: str = Field(
        ...,
        description="If the attribute is not valid, suggest a new value for the attribute. Otherwise, leave it empty.",
    )


def llm_validator(
    statement: str,
    client: OpenAI = None,
    allow_override: bool = False,
    model: str = DEFAULT_MODEL_MINI,
    temperature: float = 0,
) -> Callable[[str], str]:
    """
    Create a validator that uses the LLM to validate an attribute

    ## Usage

    ```python
    from agency_swarm import llm_validator
    from pydantic import Field, field_validator

    class User(BaseTool):
        name: str = Annotated[str, llm_validator("The name must be a full name all lowercase")
        age: int = Field(description="The age of the person")

    try:
        user = User(name="Jason Liu", age=20)
    except ValidationError as e:
        print(e)
    ```

    ```
    1 validation error for User
    name
        The name is valid but not all lowercase (type=value_error.llm_validator)
    ```

    Note that there, the error message is written by the LLM, and the error type is `value_error.llm_validator`.

    Parameters:
        statement (str): The statement to validate
        model (str): The LLM to use for validation. Must be compatible with structured outputs. (default: "gpt-4o-mini")
        temperature (float): The temperature to use for the LLM (default: 0)
        openai_client (OpenAI): The OpenAI client to use (default: None)
    """
    if client is None:
        client = get_openai_client()

    def llm(v: str) -> str:
        resp = client.beta.chat.completions.parse(
            response_format=Validator,
            messages=[
                {
                    "role": "system",
                    "content": "You are a world class validation model, capable to determine if the following value is valid or not for a given statement. Before providing a response, you must think step by step about the validation.",
                },
                {
                    "role": "user",
                    "content": f"Does `{v}` follow the rules: {statement}",
                },
            ],
            model=model,
            temperature=temperature,
        )

        if resp.choices[0].message.refusal:
            raise ValueError(resp.choices[0].message.refusal)

        resp = resp.choices[0].message.parsed

        # If the response is  not valid, return the reason, this could be used in
        # the future to generate a better response, via reasking mechanism.
        assert resp.is_valid, resp.reason

        if allow_override and not resp.is_valid and resp.fixed_value is not None:
            # If the value is not valid, but we allow override, return the fixed value
            return resp.fixed_value
        return v

    return llm



================================================
FILE: agency_swarm/util/cli/__init__.py
================================================
from .create_agent_template import create_agent_template
from .import_agent import import_agent



================================================
FILE: agency_swarm/util/cli/create_agent_template.py
================================================
import os


def create_agent_template(
    agent_name=None,
    agent_description=None,
    path="./",
    instructions=None,
    code_interpreter=False,
    use_txt=False,
    include_example_tool=True,
):
    if not agent_name:
        agent_name = input("Enter agent name: ")
    if not agent_description:
        agent_description = input("Enter agent description: ")

    class_name = agent_name.replace(" ", "").strip()

    # create folder
    path = os.path.join(path, class_name) + "/"
    if os.path.isdir(path):
        raise Exception("Folder already exists.")
    os.mkdir(path)

    # create agent file
    with open(path + class_name + ".py", "w") as f:
        f.write(
            agent_template.format(
                class_name=class_name,
                agent_name=agent_name,
                agent_description=agent_description,
                ext="md" if not use_txt else "txt",
                code_interpreter="CodeInterpreter" if code_interpreter else "",
                code_interpreter_import="from agency_swarm.tools import CodeInterpreter"
                if code_interpreter
                else "",
            )
        )

    with open(path + "__init__.py", "w") as f:
        f.write(f"from .{class_name} import {class_name}")

    # create instructions file
    instructions_path = "instructions.md" if not use_txt else "instructions.txt"
    with open(path + instructions_path, "w") as f:
        if instructions:
            f.write(instructions)
        else:
            f.write(f"# {agent_name} Instructions\n\n")

    # create files folder
    os.mkdir(path + "files")
    os.mkdir(path + "schemas")
    os.mkdir(path + "tools")

    # with open(path + "tools/" + "__init__.py", "w") as f:
    #     f.write("")

    if include_example_tool:
        with open(path + "tools/" + "ExampleTool.py", "w") as f:
            f.write(example_tool_template)

    print("Agent folder created successfully.")
    print(f"Import it with: from {class_name} import {class_name}")


agent_template = """from agency_swarm.agents import Agent
{code_interpreter_import}

class {class_name}(Agent):
    def __init__(self):
        super().__init__(
            name="{agent_name}",
            description="{agent_description}",
            instructions="./instructions.{ext}",
            files_folder="./files",
            schemas_folder="./schemas",
            tools=[{code_interpreter}],
            tools_folder="./tools",
            temperature=0.3,
            max_prompt_tokens=25000,
        )

    def response_validator(self, message):
        return message
"""

example_tool_template = """from agency_swarm.tools import BaseTool
from pydantic import Field
import os

account_id = "MY_ACCOUNT_ID"
api_key = os.getenv("MY_API_KEY") # or access_token = os.getenv("MY_ACCESS_TOKEN")

class ExampleTool(BaseTool):
    \"\"\"
    A brief description of what the custom tool does.
    The docstring should clearly explain the tool's purpose and functionality.
    It will be used by the agent to determine when to use this tool.
    \"\"\"

    # Define the fields with descriptions using Pydantic Field
    example_field: str = Field(
        ..., description="Description of the example field, explaining its purpose and usage for the Agent."
    )

    def run(self):
        \"\"\"
        The implementation of the run method, where the tool's main functionality is executed.
        This method should utilize the fields defined above to perform the task.
        Docstring is not required for this method and will not be used by the agent.
        \"\"\"
        # Your custom tool logic goes here
        # do_something(self.example_field, api_key, account_id)

        # Return the result of the tool's operation as a string
        return "Result of ExampleTool operation"
"""



================================================
FILE: agency_swarm/util/cli/import_agent.py
================================================
import os
import shutil
from importlib import resources  # For Python 3.9+ use importlib.resources


def import_agent(agent_name, destination):
    """
    Copies the specified agent files from the package to a specified destination directory,
    preserving the folder structure.
    """
    package = "agency_swarm.agents"

    # Construct the destination path for the agent
    agent_destination = os.path.join(destination, agent_name)
    if not os.path.exists(agent_destination):
        os.makedirs(agent_destination, exist_ok=True)

    try:
        # Using importlib.resources.files to get a reference to the directory
        agent_folder = resources.files(package) / agent_name

        # Copy each item in the directory to the destination
        for item in agent_folder.iterdir():
            source_path = item
            destination_path = os.path.join(agent_destination, item.name)

            if item.is_dir():
                shutil.copytree(source_path, destination_path, dirs_exist_ok=True)
            else:
                shutil.copy2(source_path, destination_path)

        print(f"Agent '{agent_name}' copied to: {agent_destination}")
    except Exception as e:
        print(
            f"Error importing agent '{agent_name}'. Most likely the agent name is wrong. Error: {e}"
        )



================================================
FILE: agency_swarm/util/helpers/__init__.py
================================================
from .get_available_agent_descriptions import get_available_agent_descriptions
from .list_available_agents import list_available_agents
from .sync_async import run_async_sync



================================================
FILE: agency_swarm/util/helpers/get_available_agent_descriptions.py
================================================
import importlib
import re
from pathlib import Path

from .list_available_agents import list_available_agents


def extract_description_from_file(file_path):
    """
    Extracts the agent's description from its Python file.
    """
    description_pattern = re.compile(
        r'\s*description\s*=\s*["\'](.*?)["\'],', re.DOTALL
    )
    with open(file_path, "r", encoding="utf-8") as file:
        content = file.read()
    match = description_pattern.search(content)
    if match:
        description = " ".join(match.group(1).split())
        return description
    return "Description not found."


def get_available_agent_descriptions():
    descriptions = {}

    # Dynamically get the path of the agency_swarm.agents module
    spec = importlib.util.find_spec("agency_swarm.agents")
    if spec is None or spec.origin is None:
        raise ImportError("Could not locate 'agency_swarm.agents' module.")
    agents_path = Path(spec.origin).parent

    agents = list_available_agents()
    for agent_name in agents:
        agent_file_path = agents_path / agent_name / f"{agent_name}.py"

        # Check if the agent file exists before trying to extract the description
        if agent_file_path.exists():
            descriptions[agent_name] = extract_description_from_file(agent_file_path)
        else:
            print(f"Could not find the file for agent '{agent_name}'.")

    agent_descriptions = "Available agents:\n\n"
    for name, desc in descriptions.items():
        agent_descriptions += f"'{name}': {desc}\n"

    return agent_descriptions



================================================
FILE: agency_swarm/util/helpers/list_available_agents.py
================================================
import os
from importlib import resources


def list_available_agents(package="agency_swarm.agents"):
    """
    Lists available agents within the specified package directory.

    :param package: The package containing the agents directory.
    :return: A list of available agent names (subdirectories).
    """
    available_agents = []

    # Use resources.files to access the package directory
    try:
        # For Python 3.9 and newer
        package_dir = resources.files(package)
    except AttributeError:
        # Fallback for Python 3.7 and 3.8 where resources.files is not available
        # This requires the importlib_resources backport
        from importlib_resources import files as package_files

        package_dir = package_files(package)

    # List the contents of the agents directory
    if package_dir.is_dir():
        for entry in package_dir.iterdir():
            if entry.is_dir() and not entry.name.startswith((".", "_")):
                available_agents.append(entry.name)

    return available_agents



================================================
FILE: agency_swarm/util/helpers/sync_async.py
================================================
import asyncio

def run_async_sync(async_fn, *args, **kwargs):
    """
    Runs an async function synchronously, handling event loop logic.
    This is useful for wrapping async code in a sync interface.
    """
    try:
        loop = asyncio.get_running_loop()
        if loop.is_running():
            # If already in an event loop, create a new task and run it
            # This will block the current thread until the task is done
            # but is not ideal for nested event loops. For most agent use cases,
            # we assume sync context, so fallback to asyncio.run otherwise.
            return asyncio.run(async_fn(*args, **kwargs))
        else:
            return asyncio.run(async_fn(*args, **kwargs))
    except RuntimeError:
        # No event loop, safe to use asyncio.run
        return asyncio.run(async_fn(*args, **kwargs)) 


================================================
FILE: agency_swarm/util/streaming/__init__.py
================================================
from .agency_event_handler import AgencyEventHandler
from .gradio_event_handler import create_gradio_handler
from .term_event_handler import create_term_handler

__all__ = [
    "AgencyEventHandler",
    "create_gradio_handler",
    "create_term_handler",
]



================================================
FILE: agency_swarm/util/streaming/agency_event_handler.py
================================================
from abc import ABC

from openai.lib.streaming import AssistantEventHandler


class AgencyEventHandler(AssistantEventHandler, ABC):
    agent_name = None
    recipient_agent_name = None
    agent = None
    recipient_agent = None

    @classmethod
    def on_all_streams_end(cls):
        """Fires when streams for all agents have ended, as there can be multiple if you're agents are communicating
        with each other or using tools."""
        pass

    @classmethod
    def set_agent(cls, value):
        cls.agent = value
        cls.agent_name = value.name if value else None

    @classmethod
    def set_recipient_agent(cls, value):
        cls.recipient_agent = value
        cls.recipient_agent_name = value.name if value else None



================================================
FILE: agency_swarm/util/streaming/gradio_event_handler.py
================================================
import queue
from typing import Type

from openai.types.beta.threads import Message
from openai.types.beta.threads.runs.run_step import RunStep
from openai.types.beta.threads.runs.tool_call import (
    CodeInterpreterToolCall,
    FileSearchToolCall,
    FunctionToolCall,
    ToolCall,
)
from typing_extensions import override

from agency_swarm.messages import MessageOutput
from agency_swarm.util.streaming import AgencyEventHandler


def create_gradio_handler(chatbot_queue: queue.Queue) -> Type[AgencyEventHandler]:
    """
    Factory function that creates a new GradioEventHandler class with proper dependencies.
    This ensures thread safety by creating a new class with its own class-level attributes.

    Args:
        chatbot_queue: The chatbot queue to be associated with the handler

    Returns:
        Type[GradioEventHandler]: A new GradioEventHandler class with proper dependencies
    """

    class GradioHandler(AgencyEventHandler):
        _chatbot_queue = chatbot_queue
        _message_output = None

        @classmethod
        def change_recipient_agent(cls, recipient_agent_name):
            cls._chatbot_queue.put("[change_recipient_agent]")
            cls._chatbot_queue.put(recipient_agent_name)

        @override
        def on_message_created(self, message: Message) -> None:
            if message.role == "user":
                full_content = ""
                for content in message.content:
                    if content.type == "image_file":
                        full_content += f"ðŸ–¼ï¸ Image File: {content.image_file.file_id}\n"
                        continue

                    if content.type == "image_url":
                        full_content += f"\n{content.image_url.url}\n"
                        continue

                    if content.type == "text":
                        full_content += content.text.value + "\n"

                self._message_output = MessageOutput(
                    "text",
                    self.agent_name,
                    self.recipient_agent_name,
                    full_content,
                )

            else:
                self._message_output = MessageOutput(
                    "text", self.recipient_agent_name, self.agent_name, ""
                )

            self._chatbot_queue.put("[new_message]")
            self._chatbot_queue.put(self._message_output.get_formatted_content())

        @override
        def on_text_delta(self, delta, snapshot):
            self._chatbot_queue.put(delta.value)

        @override
        def on_tool_call_created(self, tool_call: ToolCall):
            if isinstance(tool_call, dict):
                if "type" not in tool_call:
                    tool_call["type"] = "function"

                if tool_call["type"] == "function":
                    tool_call = FunctionToolCall(**tool_call)
                elif tool_call["type"] == "code_interpreter":
                    tool_call = CodeInterpreterToolCall(**tool_call)
                elif (
                    tool_call["type"] == "file_search"
                    or tool_call["type"] == "retrieval"
                ):
                    tool_call = FileSearchToolCall(**tool_call)
                else:
                    raise ValueError("Invalid tool call type: " + tool_call["type"])

            # TODO: add support for code interpreter and retrieval tools
            if tool_call.type == "function":
                self._chatbot_queue.put("[new_message]")
                self._message_output = MessageOutput(
                    "function",
                    self.recipient_agent_name,
                    self.agent_name,
                    str(tool_call.function),
                )
                self._chatbot_queue.put(
                    self._message_output.get_formatted_header() + "\n"
                )

        @override
        def on_tool_call_done(self, snapshot: ToolCall):
            if isinstance(snapshot, dict):
                if "type" not in snapshot:
                    snapshot["type"] = "function"

                if snapshot["type"] == "function":
                    snapshot = FunctionToolCall(**snapshot)
                elif snapshot["type"] == "code_interpreter":
                    snapshot = CodeInterpreterToolCall(**snapshot)
                elif snapshot["type"] == "file_search":
                    snapshot = FileSearchToolCall(**snapshot)
                else:
                    raise ValueError("Invalid tool call type: " + snapshot["type"])

            self._message_output = None

            # TODO: add support for code interpreter and retrieval tools
            if snapshot.type != "function":
                return

            self._chatbot_queue.put(str(snapshot.function))

            if snapshot.function.name == "SendMessage":
                try:
                    args = eval(snapshot.function.arguments)
                    recipient = args["recipient"]
                    self._message_output = MessageOutput(
                        "text",
                        self.recipient_agent_name,
                        recipient,
                        args["message"],
                    )

                    self._chatbot_queue.put("[new_message]")
                    self._chatbot_queue.put(
                        self._message_output.get_formatted_content()
                    )
                except Exception as e:
                    pass

            self._message_output = None

        @override
        def on_run_step_done(self, run_step: RunStep) -> None:
            super().on_run_step_done(run_step)

            if run_step.type == "tool_calls":
                for tool_call in run_step.step_details.tool_calls:
                    if tool_call.type != "function":
                        continue

                    if tool_call.function.name == "SendMessage":
                        continue

                    self._message_output = None
                    self._chatbot_queue.put("[new_message]")

                    self._message_output = MessageOutput(
                        "function_output",
                        tool_call.function.name,
                        self.recipient_agent_name,
                        tool_call.function.output,
                    )

                    self._chatbot_queue.put(
                        self._message_output.get_formatted_header() + "\n"
                    )
                    self._chatbot_queue.put(tool_call.function.output)

        @override
        @classmethod
        def on_all_streams_end(cls):
            cls._message_output = None
            cls._chatbot_queue.put("[end]")

    return GradioHandler



================================================
FILE: agency_swarm/util/streaming/term_event_handler.py
================================================
from typing import Type

from openai.types.beta.threads import Message
from openai.types.beta.threads.runs import RunStep
from openai.types.beta.threads.runs.tool_call import (
    CodeInterpreterToolCall,
    FileSearchToolCall,
    FunctionToolCall,
)
from typing_extensions import override

from agency_swarm.messages.message_output import MessageOutputLive
from agency_swarm.util.streaming.agency_event_handler import AgencyEventHandler


def create_term_handler(agency=None) -> Type[AgencyEventHandler]:
    """
    Factory function that creates a new TermEventHandler class with proper dependencies.
    This ensures thread safety by creating a new class with its own class-level attributes.

    Args:
        agency: The agency instance to be associated with the handler

    Returns:
        Type[TermEventHandler]: A new TermEventHandler class with proper dependencies
    """

    class TermEventHandler(AgencyEventHandler):
        _message_output = None
        _agency = agency

        @override
        def on_message_created(self, message: Message) -> None:
            if message.role == "user":
                self._message_output = MessageOutputLive(
                    "text", self.agent_name, self.recipient_agent_name, ""
                )
                self._message_output.cprint_update(message.content[0].text.value)
            else:
                self._message_output = MessageOutputLive(
                    "text", self.recipient_agent_name, self.agent_name, ""
                )

        @override
        def on_message_done(self, message: Message) -> None:
            self._message_output = None

        @override
        def on_text_delta(self, delta, snapshot):
            self._message_output.cprint_update(snapshot.value)

        @override
        def on_tool_call_created(self, tool_call):
            if isinstance(tool_call, dict):
                if "type" not in tool_call:
                    tool_call["type"] = "function"

                if tool_call["type"] == "function":
                    tool_call = FunctionToolCall(**tool_call)
                elif tool_call["type"] == "code_interpreter":
                    tool_call = CodeInterpreterToolCall(**tool_call)
                elif (
                    tool_call["type"] == "file_search"
                    or tool_call["type"] == "retrieval"
                ):
                    tool_call = FileSearchToolCall(**tool_call)
                else:
                    raise ValueError("Invalid tool call type: " + tool_call["type"])

            # TODO: add support for code interpreter and retrieval tools

            if tool_call.type == "function":
                self._message_output = MessageOutputLive(
                    "function",
                    self.recipient_agent_name,
                    self.agent_name,
                    str(tool_call.function),
                )

        @override
        def on_tool_call_delta(self, delta, snapshot):
            if isinstance(snapshot, dict):
                if "type" not in snapshot:
                    snapshot["type"] = "function"

                if snapshot["type"] == "function":
                    snapshot = FunctionToolCall(**snapshot)
                elif snapshot["type"] == "code_interpreter":
                    snapshot = CodeInterpreterToolCall(**snapshot)
                elif snapshot["type"] == "file_search":
                    snapshot = FileSearchToolCall(**snapshot)
                else:
                    raise ValueError("Invalid tool call type: " + snapshot["type"])

            self._message_output.cprint_update(str(snapshot.function))

        @override
        def on_tool_call_done(self, snapshot):
            self._message_output = None

            # TODO: add support for code interpreter and retrieval tools
            if snapshot.type != "function":
                return

            if snapshot.function.name == "SendMessage" and not (
                hasattr(
                    self._agency.send_message_tool_class.ToolConfig,
                    "output_as_result",
                )
                and self._agency.send_message_tool_class.ToolConfig.output_as_result
            ):
                try:
                    args = eval(snapshot.function.arguments)
                    recipient = args["recipient"]
                    self._message_output = MessageOutputLive(
                        "text", self.recipient_agent_name, recipient, ""
                    )

                    self._message_output.cprint_update(args["message"])
                except Exception as e:
                    pass

            self._message_output = None

        @override
        def on_run_step_done(self, run_step: RunStep) -> None:
            super().on_run_step_done(run_step)

            if run_step.type == "tool_calls":
                for tool_call in run_step.step_details.tool_calls:
                    if tool_call.type != "function":
                        continue

                    if tool_call.function.name == "SendMessage":
                        continue

                    self._message_output = None
                    self._message_output = MessageOutputLive(
                        "function_output",
                        tool_call.function.name,
                        self.recipient_agent_name,
                        tool_call.function.output,
                    )
                    self._message_output.cprint_update(tool_call.function.output)

                self._message_output = None

        @override
        def on_end(self):
            self._message_output = None

    return TermEventHandler



================================================
FILE: agency_swarm/util/tracking/__init__.py
================================================
import logging
import threading
from typing import Any, Dict, Literal, Optional

# Dictionary to store handlers keyed by tracker name.
_callback_handlers: Dict[str, Any] = {}
_lock = threading.Lock()

logger = logging.getLogger(__name__)

SUPPORTED_TRACKERS = ["agentops", "langfuse", "local"]
SUPPORTED_TRACKERS_TYPE = Literal["agentops", "langfuse", "local"]


class MultiCallbackHandler:
    """A handler that delegates method calls to multiple underlying handlers."""

    def __init__(self, handlers: Dict[str, Any]):
        self.handlers = handlers

    def __bool__(self):
        """Return True if there are handlers, False otherwise."""
        return bool(self.handlers)

    def __getattr__(self, name):
        def method(*args, **kwargs):
            for tracker_name, handler in self.handlers.items():
                try:
                    if hasattr(handler, name):
                        handler_method = getattr(handler, name)
                        if callable(handler_method):
                            handler_method(*args, **kwargs)
                except Exception as e:
                    logger.exception(
                        f"Error in {tracker_name} handler method '{name}': {e}"
                    )
            return None

        return method


def get_callback_handler() -> MultiCallbackHandler:
    """Return a callback handler that delegates to all registered handlers."""
    with _lock:
        return MultiCallbackHandler(_callback_handlers)


def init_tracking(tracker_name: SUPPORTED_TRACKERS_TYPE, **kwargs):
    """
    Initialize a tracking system and register its callback handler.

    Args:
        tracker_name: The name of the tracker to initialize.
        **kwargs: Additional keyword arguments passed to the handler constructor.

    Raises:
        ValueError: If the provided tracker name is not supported.
    """
    if tracker_name not in SUPPORTED_TRACKERS:
        raise ValueError(f"Invalid tracker name: {tracker_name}")

    logger.debug(f"Initializing tracking for {tracker_name}")

    from .langchain_types import use_langchain_types

    use_langchain_types()

    if tracker_name == "local":
        from .local_callback_handler import LocalCallbackHandler

        handler_class = LocalCallbackHandler

    elif tracker_name == "agentops":
        from agentops.integration.callbacks.langchain import (
            LangchainCallbackHandler,
        )

        handler_class = LangchainCallbackHandler

    elif tracker_name == "langfuse":
        from langfuse.callback import CallbackHandler

        handler_class = CallbackHandler

    # Register the handler instance with its tracker name.
    with _lock:
        _callback_handlers[tracker_name] = handler_class(**kwargs)
        logger.debug(f"Successfully initialized {tracker_name} tracking")


def stop_tracking(tracker_name: Optional[str] = None):
    """
    Clear tracking handlers.

    Args:
        tracker_name: The specific tracker to clear, or None to clear all registered trackers.
    """
    with _lock:
        if tracker_name is None:
            logger.debug("Stopping all tracking handlers")
            _callback_handlers.clear()
        elif tracker_name in _callback_handlers:
            logger.debug(f"Stopping tracking for {tracker_name}")
            del _callback_handlers[tracker_name]


__all__ = [
    "init_tracking",
    "get_callback_handler",
    "stop_tracking",
]



================================================
FILE: agency_swarm/util/tracking/langchain_types.py
================================================
from typing import TYPE_CHECKING, Any, Dict, Generic, TypeVar, Union

from pydantic import BaseModel, Field

if TYPE_CHECKING:
    from langchain.schema import AgentAction as LangchainAgentAction
    from langchain.schema import AgentFinish as LangchainAgentFinish
    from langchain.schema import HumanMessage as LangchainHumanMessage


# Create base classes that match langchain's structure
class BaseAgentAction(BaseModel):
    tool: str
    tool_input: Union[str, Dict[str, Any]] = Field(default_factory=dict)
    log: str = ""


class BaseAgentFinish(BaseModel):
    return_values: Dict[str, Any] = Field(default_factory=dict)
    log: str = ""


class BaseHumanMessage(BaseModel):
    content: str = ""


T = TypeVar("T")


class Proxy(Generic[T]):
    def __init__(self, default_impl: T):
        self._impl: T = default_impl

    def __call__(self, *args: Any, **kwargs: Any) -> Any:
        return self._impl(*args, **kwargs)

    def set_implementation(self, impl: T) -> None:
        self._impl = impl


# Initialize with our base implementations
AgentAction = Proxy[Union[BaseAgentAction, "LangchainAgentAction"]](BaseAgentAction)
AgentFinish = Proxy[Union[BaseAgentFinish, "LangchainAgentFinish"]](BaseAgentFinish)
HumanMessage = Proxy[Union[BaseHumanMessage, "LangchainHumanMessage"]](BaseHumanMessage)


def use_langchain_types() -> None:
    """Switch to using langchain types after langchain is imported"""
    global AgentAction, AgentFinish, HumanMessage
    from langchain.schema import AgentAction as LangchainAgentAction
    from langchain.schema import AgentFinish as LangchainAgentFinish
    from langchain.schema import HumanMessage as LangchainHumanMessage

    AgentAction.set_implementation(LangchainAgentAction)
    AgentFinish.set_implementation(LangchainAgentFinish)
    HumanMessage.set_implementation(LangchainHumanMessage)



================================================
FILE: agency_swarm/util/tracking/local_callback_handler.py
================================================
import json
import logging
import sqlite3
import threading
from typing import Any, Dict, List, Optional, Sequence, Union
from uuid import UUID

import tiktoken
from langchain.schema import AgentAction, AgentFinish, BaseMessage, Document, LLMResult

from agency_swarm.constants import DEFAULT_MODEL

logger = logging.getLogger(__name__)


class LocalCallbackHandler:
    """
    A local callback handler that logs every event into a single 'events' table,
    creating a new row for each callback. This table can later be queried or exported
    for analysis of usage, latencies, error rates, etc.
    """

    TABLE_COLUMNS = {
        "event_id": "INTEGER PRIMARY KEY AUTOINCREMENT",
        "run_id": "TEXT",
        "parent_run_id": "TEXT",
        "event_time": "TIMESTAMP DEFAULT CURRENT_TIMESTAMP",
        "callback_type": "TEXT",
        "serialized": "TEXT",
        "inputs": "TEXT",
        "outputs": "TEXT",
        "error": "TEXT",
        "metadata": "TEXT",
        "prompts": "TEXT",
        "file_search_query": "TEXT",
        "documents": "TEXT",
        "prompt_tokens": "INTEGER",
        "completion_tokens": "INTEGER",
        "tags": "TEXT",
    }

    def __init__(self, db_path: str = "usage.db"):
        self.db_path = db_path
        self.lock = threading.Lock()
        self._closed = False
        self._connect()

    def _connect(self) -> None:
        """Connect to database and create tables if needed."""
        try:
            self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
            self._create_tables()
        except sqlite3.Error as e:
            logger.error(f"Database error during connect: {e}")
            raise

    def _create_tables(self) -> None:
        """Create 'events' table if it does not exist."""
        columns_sql = ", ".join(
            f"{col} {type_}" for col, type_ in self.TABLE_COLUMNS.items()
        )
        with self.conn:
            self.conn.execute(f"""
                CREATE TABLE IF NOT EXISTS events (
                    {columns_sql}
                )
            """)

    def _insert_event(
        self,
        callback_type: str,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        serialized: Optional[dict] = None,
        inputs: Optional[Any] = None,
        outputs: Optional[Any] = None,
        error: Optional[str] = None,
        metadata: Optional[dict] = None,
        prompts: Optional[List[str]] = None,
        file_search_query: Optional[str] = None,
        documents: Optional[Any] = None,
        prompt_tokens: Optional[int] = None,
        completion_tokens: Optional[int] = None,
        tags: Optional[List[str]] = None,
    ) -> None:
        """
        Insert a new event row for the given callback. Each event is logged separately.
        """
        sql = """
            INSERT INTO events (
                run_id, parent_run_id, callback_type,
                serialized, inputs, outputs, error, metadata, prompts,
                file_search_query, documents, prompt_tokens, completion_tokens, tags
            )
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

        def _json_dumps(value):
            if isinstance(value, str):
                return value
            return json.dumps(value) if value is not None else None

        params = (
            str(run_id),
            str(parent_run_id) if parent_run_id else None,
            callback_type,
            _json_dumps(serialized),
            _json_dumps(inputs),
            _json_dumps(outputs),
            error,
            _json_dumps(metadata),
            _json_dumps(prompts),
            file_search_query,
            _json_dumps(documents),
            prompt_tokens,
            completion_tokens,
            _json_dumps(tags),
        )

        try:
            with self.conn:
                self.conn.execute(sql, params)
        except sqlite3.Error as e:
            logger.error(f"Database error inserting event: {e}")
            raise

    def _count_tokens(self, text: str, model: str = DEFAULT_MODEL) -> int:
        """Count tokens in a given text for a particular model."""
        if not text:
            return 0
        try:
            encoding = tiktoken.encoding_for_model(model)
            return len(encoding.encode(text))
        except Exception as e:
            logger.error(f"Error counting tokens: {e}")
            return 0

    def _count_message_tokens(
        self, messages: List[Dict[str, Any]], model: str = DEFAULT_MODEL
    ) -> int:
        """Count tokens in a list of message dicts (e.g. role/content pairs)."""
        total_tokens = 0
        try:
            encoding = tiktoken.encoding_for_model(model)
            for msg in messages:
                content = msg.get("content", "")
                if content:
                    total_tokens += len(encoding.encode(str(content)))
        except Exception as e:
            logger.error(f"Error counting message tokens: {e}")
        return total_tokens

    #
    # Public Callback Methods
    #

    def on_chain_start(
        self,
        serialized: Optional[Dict[str, Any]],
        inputs: Dict[str, Any],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        self._insert_event(
            callback_type="chain_start",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=serialized,
            inputs=inputs,
            tags=tags,
            metadata=metadata,
        )

    def on_chain_end(
        self,
        outputs: Dict[str, Any],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        # Attempt to count tokens in "response" if present
        response_text = outputs.get("response", "")
        completion_tokens = self._count_tokens(response_text)

        self._insert_event(
            callback_type="chain_end",
            run_id=run_id,
            parent_run_id=parent_run_id,
            outputs=outputs,
            completion_tokens=completion_tokens,
        )

    def on_chain_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        **kwargs: Any,
    ) -> None:
        self._insert_event(
            callback_type="chain_error",
            run_id=run_id,
            parent_run_id=parent_run_id,
            error=str(error),
            tags=tags,
        )

    def on_llm_start(
        self,
        serialized: Optional[Dict[str, Any]],
        prompts: List[str],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        model = kwargs.get("invocation_params", {}).get("model", DEFAULT_MODEL)
        prompt_tokens = sum(self._count_tokens(p, model) for p in prompts)

        self._insert_event(
            callback_type="llm_start",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=serialized,
            prompts=prompts,
            tags=tags,
            metadata=metadata,
            prompt_tokens=prompt_tokens,
        )

    def on_llm_new_token(
        self,
        token: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        """
        This method could also do an insert if you want to track each streamed token.
        But that can result in a large volume of data. By default, we'll just log a debug msg.
        """
        logger.debug(
            f"[streaming] new token: {token}, run_id: {run_id}, parent_run_id: {parent_run_id}"
        )

    def on_llm_end(
        self,
        response: LLMResult,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        completion_tokens = 0
        model = kwargs.get("model", DEFAULT_MODEL)
        for generation in response.generations:
            for g in generation:
                completion_tokens += self._count_tokens(g.text, model=model)

        self._insert_event(
            callback_type="llm_end",
            run_id=run_id,
            parent_run_id=parent_run_id,
            outputs=response.model_dump(),
            completion_tokens=completion_tokens,
        )

    def on_llm_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        self._insert_event(
            callback_type="llm_error",
            run_id=run_id,
            parent_run_id=parent_run_id,
            error=str(error),
        )

    def on_chat_model_start(
        self,
        serialized: Optional[Dict[str, Any]],
        messages: List[List[BaseMessage]],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        # Flatten messages into dicts for token counting
        msg_data = [[m.model_dump() for m in turn] for turn in messages]
        model = kwargs.get("invocation_params", {}).get("model", DEFAULT_MODEL)
        prompt_tokens = sum(
            self._count_message_tokens(turn, model) for turn in msg_data
        )

        self._insert_event(
            callback_type="chat_model_start",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=serialized,
            inputs=msg_data,
            tags=tags,
            metadata=metadata,
            prompt_tokens=prompt_tokens,
        )

    def on_tool_start(
        self,
        serialized: Optional[Dict[str, Any]],
        input_str: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        prompt_tokens = self._count_tokens(str(input_str))
        self._insert_event(
            callback_type="tool_start",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=serialized,
            inputs=input_str,
            tags=tags,
            metadata=metadata,
            prompt_tokens=prompt_tokens,
        )

    def on_tool_end(
        self,
        output: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        completion_tokens = self._count_tokens(str(output))
        self._insert_event(
            callback_type="tool_end",
            run_id=run_id,
            parent_run_id=parent_run_id,
            outputs=output,
            completion_tokens=completion_tokens,
        )

    def on_tool_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        error_str = str(error)
        completion_tokens = self._count_tokens(error_str)
        self._insert_event(
            callback_type="tool_error",
            run_id=run_id,
            parent_run_id=parent_run_id,
            error=error_str,
            completion_tokens=completion_tokens,
        )

    def on_agent_action(
        self,
        action: AgentAction,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        data = {
            "tool": action.tool,
            "tool_input": action.tool_input,
        }
        self._insert_event(
            callback_type="agent_action",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=data,
            completion_tokens=0,
        )

    def on_agent_finish(
        self,
        finish: AgentFinish,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        # If "response" is the main textual result
        response_text = finish.return_values.get("response", "")
        completion_tokens = self._count_tokens(response_text)

        self._insert_event(
            callback_type="agent_finish",
            run_id=run_id,
            parent_run_id=parent_run_id,
            outputs=finish.return_values,
            completion_tokens=completion_tokens,
        )

    def on_retriever_start(
        self,
        serialized: Optional[Dict[str, Any]],
        query: str,
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        tags: Optional[List[str]] = None,
        metadata: Optional[Dict[str, Any]] = None,
        **kwargs: Any,
    ) -> Any:
        self._insert_event(
            callback_type="retriever_start",
            run_id=run_id,
            parent_run_id=parent_run_id,
            serialized=serialized,
            file_search_query=query,
            tags=tags,
            metadata=metadata,
        )

    def on_retriever_end(
        self,
        documents: Sequence[Document],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        docs_json = [doc.model_dump() for doc in documents]

        self._insert_event(
            callback_type="retriever_end",
            run_id=run_id,
            parent_run_id=parent_run_id,
            documents=docs_json,
        )

    def on_retriever_error(
        self,
        error: Union[Exception, KeyboardInterrupt],
        *,
        run_id: UUID,
        parent_run_id: Optional[UUID] = None,
        **kwargs: Any,
    ) -> Any:
        self._insert_event(
            callback_type="retriever_error",
            run_id=run_id,
            parent_run_id=parent_run_id,
            error=str(error),
        )

    def __del__(self):
        with self.lock:
            if not self._closed:
                self.conn.close()
                self._closed = True



================================================
FILE: agency_swarm/util/tracking/tracking_manager.py
================================================
import json
from typing import Any
from uuid import uuid4

from openai.types.beta.threads.message import Message
from openai.types.beta.threads.run import RequiredActionFunctionToolCall, Run
from openai.types.beta.threads.runs.tool_call import ToolCall

from agency_swarm.messages.message_output import MessageOutput
from agency_swarm.util.tracking import get_callback_handler
from agency_swarm.util.tracking.langchain_types import AgentAction


class TrackingManager:
    def __init__(self):
        self.callback_handler = get_callback_handler()

    def track_tool_start(
        self,
        tool_call: ToolCall,
        run: Run,
        agent_name: str,
        recipient_agent_name: str,
        is_retriever: bool = False,
    ) -> None:
        """Track the start of a tool/retriever execution."""
        if not self.callback_handler:
            return

        metadata = {
            "agent_name": agent_name,
            "recipient_agent_name": recipient_agent_name,
            "run_status": run.status,
            "ls_model_name": run.model,
        }

        if is_retriever:
            self.callback_handler.on_retriever_start(
                serialized={"name": tool_call.function.name},
                query=tool_call.function.arguments,
                run_id=tool_call.id,
                parent_run_id=run.id,
                metadata=metadata,
            )
        else:
            self.callback_handler.on_tool_start(
                serialized={"name": tool_call.function.name},
                input_str=tool_call.function.arguments,
                run_id=tool_call.id,
                parent_run_id=run.id,
                metadata=metadata,
            )

    def track_tool_end(
        self,
        output: Any,
        tool_call: ToolCall,
        parent_run_id: str,
        is_retriever: bool = False,
    ) -> None:
        """Track the successful completion of a tool/retriever execution."""
        if not self.callback_handler:
            return

        if is_retriever:
            self.callback_handler.on_retriever_end(
                documents=output if isinstance(output, list) else [],
                run_id=tool_call.id,
                parent_run_id=parent_run_id,
            )
        else:
            self.callback_handler.on_tool_end(
                output=str(output),
                run_id=tool_call.id,
                parent_run_id=parent_run_id,
            )

    def track_tool_error(
        self,
        error: Exception,
        tool_call: ToolCall,
        parent_run_id: str,
        is_retriever: bool = False,
    ) -> None:
        """Track an error during tool/retriever execution."""
        if not self.callback_handler:
            return

        if is_retriever:
            self.callback_handler.on_retriever_error(
                error=error,
                run_id=tool_call.id,
                parent_run_id=parent_run_id,
            )
        else:
            self.callback_handler.on_tool_error(
                error=error,
                run_id=tool_call.id,
                parent_run_id=parent_run_id,
            )

    def track_agent_actions(
        self,
        tool_calls: list[RequiredActionFunctionToolCall],
        run_id: str,
        parent_run_id: str | None = None,
    ) -> None:
        """Send agent_action before each tool call."""
        if not self.callback_handler:
            return

        for tc in tool_calls:
            args = json.loads(tc.function.arguments) if tc.function.arguments else {}
            action = AgentAction(
                tool=tc.function.name,
                tool_input=args,
                log="",
            )
            self.callback_handler.on_agent_action(
                action=action,
                run_id=run_id,
                parent_run_id=parent_run_id,
            )

    def track_chain_error(
        self, error: Exception, run_id: str, parent_run_id: str | None = None
    ) -> None:
        """Track chain errors."""
        if not self.callback_handler:
            return

        self.callback_handler.on_chain_error(
            error=error,
            run_id=run_id,
            parent_run_id=parent_run_id,
        )

    def start_chain(self, message: str, chain_name: str) -> str:
        """Start tracking for a top-level chain (e.g. Agency.get_completion).
        Returns the run_id if tracking is enabled, None otherwise."""
        run_id = f"chain_{uuid4()}"
        if not self.callback_handler:
            return

        self.callback_handler.on_chain_start(
            serialized={"name": chain_name, "id": [run_id]},
            inputs={"message": message},
            run_id=run_id,
            metadata={"agency_class": "Agency"},
        )

        return run_id

    def end_chain(
        self, final_output: Any, run_id: str, parent_run_id: str | None = None
    ) -> None:
        """End tracking for a top-level chain."""
        if not self.callback_handler:
            return

        self.callback_handler.on_chain_end(
            outputs={"response": final_output},
            run_id=run_id,
            parent_run_id=parent_run_id,
        )

    def start_run(
        self,
        message: str | list[dict] | None,
        sender_agent: str,
        recipient_agent: str,
        model: str,
        run_id: str,
        parent_run_id: str | None,
        message_obj: Message | None = None,
        temperature: float | None = None,
    ) -> None:
        """Track the start of a run."""
        if not self.callback_handler:
            return

        prompts = [str(m) for m in message] if isinstance(message, list) else [message]

        metadata = {
            "agent_name": sender_agent,
            "recipient_agent_name": recipient_agent,
            "run_status": "running",
            "ls_model_name": model,
            "message_obj": message_obj.model_dump() if message_obj else {},
        }
        invocation_params = {
            "_type": "openai",
            "model": model,
            "temperature": temperature,
        }

        self.callback_handler.on_llm_start(
            serialized={
                "name": f"Thread: {sender_agent} -> {recipient_agent}",
                "id": [run_id],
            },
            prompts=prompts,
            run_id=run_id,
            parent_run_id=parent_run_id,
            metadata=metadata,
            invocation_params=invocation_params,
        )

    def end_run(
        self,
        message_output: MessageOutput,
        run_id: str,
        parent_run_id: str | None = None,
    ) -> None:
        """Track the end of a run with a message output."""
        if not self.callback_handler:
            return

        from langchain_core.outputs import Generation, LLMResult

        generation = Generation(text=message_output.content)

        result = LLMResult(generations=[[generation]])

        metadata = {
            "message_obj": message_output.obj.model_dump() if message_output.obj else {}
        }

        self.callback_handler.on_llm_end(
            response=result,
            run_id=run_id,
            parent_run_id=parent_run_id,
            metadata=metadata,
        )



================================================
FILE: docs/analise_docs.py
================================================
import os
import re
import textstat
import pandas as pd


def process_inline_code(code):
    # Replace dot access with whitespace if detected
    if re.search(r'\w+\.\w+', code):
        code = code.replace('.', ' ')
    # Replace square brackets with whitespace
    if '[' in code or ']' in code:
        code = code.replace('[', ' ').replace(']', ' ')
    return code


def clean_markdown(text):
    # Remove code blocks (triple backticks)
    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)

    # Process inline code: Replace inline code blocks with their processed plaintext
    def inline_code_replacer(match):
        code_content = match.group(1)
        processed = process_inline_code(code_content)
        return processed  # Inline code is replaced with its processed content

    text = re.sub(r'`([^`]+)`', inline_code_replacer, text)

    # Replace markdown links with their placeholder value (the text inside the square brackets)
    text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)

    # Optionally, remove or simplify other markdown formatting:
    # Remove headers (leading '#' characters) and emphasis markers
    text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)
    text = re.sub(r'[*_~]', '', text)

    return text



def compute_readability(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    # Clean markdown formatting for better readability analysis
    plain_text = clean_markdown(content)

    scores = {
        "File": file_path,
        "Flesch-Kincaid": textstat.flesch_kincaid_grade(plain_text),
        "SMOG Index": textstat.smog_index(plain_text),
        "ARI Index":textstat.automated_readability_index(plain_text),
        "Coleman-Liau":textstat.coleman_liau_index(plain_text),
    }
    return scores


def analyze_docs(root_directory):
    results = []
    for root, _, files in os.walk(root_directory):
        for file in files:
            if file.endswith('.mdx') or file.endswith('.md'):
                file_path = os.path.join(root, file)
                file_path = file_path.replace("\\","/")
                try:
                    scores = compute_readability(file_path)
                    results.append(scores)
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
    return results


# Replace 'docs_directory' with the path to your documentation
docs_directory = r'.'
readability_results = analyze_docs(docs_directory)

# Convert results to a DataFrame for a clean report
df = pd.DataFrame(readability_results)
print(df)

# Define the threshold
threshold = 15

# Filter the DataFrame where any of the readability scores is above the threshold
filtered_df = df[
    (df["Flesch-Kincaid"] > threshold) |
    (df["SMOG Index"] > threshold)|
    (df["ARI Index"] > threshold)|
    (df["Coleman-Liau"] > threshold)
]

# Extract the list of file names
pages_above_threshold = filtered_df["File"].tolist()
print("Pages with at least one readability score above", threshold, ":", pages_above_threshold)


# Optionally, save the report to CSV for further analysis
df.to_csv('readability_report.csv', index=False)

"""Explainer of results: 
Each test shows how many years of education a person needs to be able to effectively read through the text.
Flesch-Kincaid and SMOG Index are popular linguistic benchmarks applicable for most texts
ARI Index and Coleman-Liau are recommended for technical texts.
Generally is it considered that the lower the number is the easier the text is to approach.
When analysing the results just look for outliers.
"""


================================================
FILE: docs/docs.json
================================================
{
    "$schema": "https://mintlify.com/docs.json",
    "theme": "maple",
    "name": "Agency Swarm",
    "colors": {
        "primary": "#fcd53b",
        "light": "#fcd53b",
        "dark": "#B76E00"
    },
    "favicon": "/images/favicon.svg",
    "navigation": {
        "tabs": [{
                "tab": "Framework",
                "global": {
                    "anchors": [{
                            "anchor": "Discord Community",
                            "href": "https://discord.gg/cw2xBaWfFM",
                            "icon": "discourse"
                        },
                        {
                            "anchor": "Changelog",
                            "href": "https://github.com/VRSEN/agency-swarm/releases",
                            "icon": "timeline"
                        }
                    ]
                },
                "groups": [{
                        "group": "Welcome",
                        "pages": [
                            "welcome/overview",
                            "welcome/ai-agency-vs-other-frameworks",
                            {
                                "group": "Get Started",
                                "icon": "rocket",
                                "pages": [
                                    "welcome/installation",
                                    "welcome/getting-started/from-scratch",
                                    "welcome/getting-started/genesis-agency",
                                    "welcome/getting-started/cursor-ide"
                                ]
                            }
                        ]
                    },
                    {
                        "group": "Core Framework",
                        "pages": [{
                                "group": "Tools",
                                "icon": "wrench",
                                "pages": [
                                    "core-framework/tools/overview",
                                    {
                                        "group": "Custom Tools",
                                        "icon": "hammer",
                                        "pages": [
                                            "core-framework/tools/custom-tools/step-by-step-guide",
                                            "core-framework/tools/custom-tools/pydantic-is-all-you-need",
                                            "core-framework/tools/custom-tools/best-practices",
                                            "core-framework/tools/custom-tools/configuration"
                                        ]
                                    },
                                    "core-framework/tools/openapi-schemas",
                                    "core-framework/tools/mcp-integration"
                                ]
                            },
                            {
                                "group": "Agents",
                                "icon": "user",
                                "pages": [
                                    "core-framework/agents/overview",
                                    "core-framework/agents/built-in-tools",
                                    "core-framework/agents/advanced-configuration"
                                ]
                            },
                            {
                                "group": "Agencies",
                                "icon": "sitemap",
                                "pages": [
                                    "core-framework/agencies/overview",
                                    "core-framework/agencies/communication-flows",
                                    "core-framework/agencies/agency-parameters",
                                    "core-framework/agencies/running-agency"
                                ]
                            },
                            "core-framework/state-management"
                        ]
                    },
                    {
                        "group": "Additional Features",
                        "pages": [
                            "additional-features/asynchronous-execution",
                            "additional-features/shared-state",
                            "additional-features/few-shot-examples",
                            "additional-features/output-validation",
                            "additional-features/streaming",
                            "additional-features/fastapi-integration",
                            {
                                "group": "Custom Communication Flows",
                                "icon": "comments",
                                "pages": [
                                    "additional-features/custom-communication-flows/overview",
                                    "additional-features/custom-communication-flows/common-use-cases"
                                ]
                            },
                            "additional-features/azure-openai",
                            "additional-features/open-source-models",
                            "additional-features/deployment-to-production",
                            "additional-features/observability"
                        ]
                    },
                    {
                        "group": "References",
                        "pages": [
                            "references/api"
                        ]
                    },
                    {
                        "group": "Contributing",
                        "pages": [
                            "contributing/contributing"
                        ]
                    },
                    {
                        "group": "FAQ",
                        "pages": [
                            "faq"
                        ]
                    }
                ]
            },
            {
                "tab": "Platform",
                "global": {
                    "anchors": [{
                            "anchor": "Agencii Platform",
                            "href": "https://agencii.ai/signup/",
                            "icon": "globe"
                        },
                        {
                            "anchor": "Skool Community",
                            "href": "https://www.skool.com/agency-ai/about",
                            "icon": "users"
                        }
                    ]
                },
                "groups": [{
                        "group": "General",
                        "icon": "globe",
                        "pages": [
                            "platform/overview"
                        ]
                    },
                    {
                        "group": "Integrations",
                        "icon": "plug",
                        "pages": [
                            "platform/integrations/slack-integration",
                            "platform/integrations/whatsapp-integration",
                            "platform/integrations/zapier-integration",
                            "platform/integrations/web-api"
                        ]
                    },
                    {
                        "group": "Additional Features",
                        "pages": [
                            "platform/additional-instructions"
                        ]
                    }
                ],
                "openapi": {
                    "source": "/openapi.json",
                    "directory": "platform/integrations/api"
                }
            },
            {
                "tab": "Extras",
                "groups": [{
                        "group": "Extras",
                        "pages": [
                            "extras/extras"
                        ]
                    },
                    {
                        "group": "Tutorials",
                        "pages": [
                            "tutorials/tutorials"
                        ]
                    }
                ]
            }
        ]
    },
    "logo": {
        "light": "/images/logo-light.svg",
        "dark": "/images/logo-dark.svg",
        "href": "https://agency-swarm.ai"
    },
    "appearance": {
        "default": "dark",
        "strict": false
    },
    "background": {
        "color": {
            "dark": "#0C102D"
        }
    },
    "navbar": {
        "primary": {
            "type": "github",
            "href": "https://github.com/VRSEN/agency-swarm"
        }
    },
    "search": {
        "prompt": "Search Agency Swarm docs"
    },
    "seo": {
        "indexing": "navigable"
    },
    "footer": {
        "socials": {
            "website": "https://vrsen.ai",
            "x": "https://x.com/__vrsen__",
            "github": "https://github.com/VRSEN/agency-swarm",
            "youtube": "https://youtube.com/@vrsen"
        }
    }
}


================================================
FILE: docs/faq.mdx
================================================
---
title: "FAQ"
description: "Find answers to common questions about Agency Swarm."
icon: "question"
---

<AccordionGroup defaultOpen={true}>


<Accordion title="How do I set my OpenAI API key in my project?" icon="key">
Set your API key in your code:
```python
from agency_swarm import set_openai_key
set_openai_key("YOUR_API_KEY")
```
Or use a `.env` file:
```env
OPENAI_API_KEY=sk-1234...
```
Then load it with:
```python
from dotenv import load_dotenv
load_dotenv()
```
</Accordion>


<Accordion title="What's the difference between using .cursorrules (with Cursor IDE) and 'agency-swarm genesis'?" icon="scale-unbalanced">
There are two ways to create agents with AI:

1. [**Genesis Agency**:](/welcome/getting-started/genesis-agency) A simple command-line tool that helps you create basic agent structures. Great for getting started or simple use cases. Just run `agency-swarm genesis` and follow the prompts.

2. [**Cursor AI Code Editor**](/welcome/getting-started/cursor-ide): Use the `.cursorrules` file in Cursor IDE to create agents. This is the best option for both beginners and experienced developers since it gives you more control over the agent creation process.
</Accordion>


<Accordion title="Can I use open source models with Agency Swarm?" icon="code-fork">
Yesâ€”you can use open source models for simple, nonâ€“mission-critical tasks (usually one or two tools per agent). See [Open Source Models](/additional-features/open-source-models) for more information. Keep in mind that many open source models currently struggle with function calling.
</Accordion>


<Accordion title="How do I save and continue conversations?" icon="messages">
To persist threads between application restarts, implement thread callbacks that save and load thread IDs from a local file. For example, define your callback functions:
```python
import os
import json

def load_threads(chat_id):
    if os.path.exists(f"{chat_id}_threads.json"):
        with open(f"{chat_id}_threads.json", "r") as file:
            return json.load(file)
    return []

def save_threads(new_threads, chat_id):
    with open(f"{chat_id}_threads.json", "w") as file:
        json.dump(new_threads, file)
```

Then, pass these callbacks during your agency initialization to resume conversations:
```python
from agency_swarm.agency.genesis import GenesisAgency

agency = GenesisAgency(
    ...
    threads_callbacks={
        'load': lambda: load_threads(chat_id),
        'save': lambda new_threads: save_threads(new_threads, chat_id)
    }
)
```

This setup preserves your conversation context between runs.
</Accordion>


<Accordion title="How do I manage multiple users with Agency Swarm?" icon="users">
To support multiple users/chats, you need to load and save thread IDs in your database accordingly. Each chat/user should have unique thread IDs. Ensure to check out our [Deployment to Production](/additional-features/deployment-to-production) guide for more information.
</Accordion>


<Accordion title="How can I transfer data between tools and agents?" icon="upload">
There are two ways to transfer data between tools and agents:
1. Use shared state inside your tools. Read more: [Shared State](/additional-features/shared-state)
2. Create a tool (or modify an existing one) that uploads files to storage and outputs the file ID. This file ID can then be used by other tools or agents.
</Accordion>


<Accordion title="Why is the CodeInterpreter tool automatically added?" icon="code">
When file types like `.json`, `.docx`, or `.pptx` are uploaded, CodeInterpreter is auto-added to process them. To change the agent's behavior, update its instructions or create a custom file-handling tool.
</Accordion>


<Accordion title="How can I serve an Agency as an API using FastAPI?" icon="book">
Embed your agency within a FastAPI endpoint. For example:
```python
@app.post("/chat")
async def chat(user_request: UserRequest):
    chat_id = user_request.chat_id or str(uuid4())
    agency = Agency([...],
        threads_callbacks={
            'load': lambda: load_threads(chat_id),
            'save': lambda new_threads: save_threads(new_threads, chat_id)
        })
    response = agency.get_completion(user_request.message)
    return {"chat_id": chat_id, "response": response}
```
</Accordion>


<Accordion title="How do I deploy my agency to production?" icon="rocket">
Build a dedicated API backend (FastAPI is recommended) that manages authentication and persists thread state using callbacks. For more details, refer to our [Deployment to Production](/additional-features/deployment-to-production) guide.
</Accordion>

</AccordionGroup>


## Getting Support

<CardGroup cols={2}>
  <Card title="Community Support" icon="discord" href="https://discord.gg/cw2xBaWfFM">
    Join our Discord community for quick help and discussions.
  </Card>
  <Card title="Professional Services" icon="briefcase" href="https://agents.vrsen.ai/">
    Get professional help with our Agents-as-a-Service subscription.
  </Card>
</CardGroup>



================================================
FILE: docs/mintlify.cursorrules
================================================
Mintlify Docs Cheatsheet

# General

Start each page with a metadata block:

```mdx
---
title: "Page Title"
description: "Brief description of the page"
icon: "icon-name"
---
```

# Getting Started

## Global Settings (`mint.json`)

Your Mintlify site requires a `mint.json` file containing core configurations.

### Key Properties

#### Styling

- **name** (`string`, required): Your company or project name.
- **logo** (`string` or `Logo`, optional): Path to logo image(s).
  - For example:
    ```json
    "logo": "/path/to/logo.svg"
    ```
  - For light/dark modes:
    ```json
    "logo": {
      "light": "/path/to/light-logo.svg",
      "dark": "/path/to/dark-logo.svg",
      "url": "/"
    }
    ```
- **favicon** (`string`, optional): Path to your favicon image.
- **colors** (`Colors`, optional): Hex color codes for your theme.
- **theme** (`"venus"` | `"quill"` | `"prism"`, optional): Preset theme configurations.
- **layout** (`"topnav"` | `"sidenav"` | `"solidSidenav"`, optional): Global layout style.
- **background** (`Background`, optional): Decorative background settings.
- **font** (`FontDetailsType` or `{ headings?: FontDetailsType, body?: FontDetailsType }`, optional): Custom fonts.
- **modeToggle** (`ModeToggle`, optional): Customize the dark mode toggle.
- **sidebar** (`Sidebar`, optional): Customize sidebar components.
- **topbar** (`Topbar`, optional): Styling for the topbar.
- **search** (`Search`, optional): Configure the search bar location.
- **rounded** (`"default"` | `"sharp"`, optional): Style of rounded edges in the UI.
- **codeBlock** (`CodeBlock`, optional): Style code blocks in the documentation.

#### Structure

- **navigation** (`Navigation[]`, required): Define your site's navigation structure.
  ```json
  "navigation": [
    {
      "group": "Getting Started",
      "pages": ["quickstart"]
    }
  ]
  ```
- **topbarLinks** (`TopbarLink[]`, optional): Links to include in the topbar.
  ```json
  "topbarLinks": [
    {
      "name": "Community",
      "url": "https://mintlify.com/community"
    }
  ]
  ```
- **topbarCtaButton** (`Call to Action`, optional): Configuration for the topbar CTA button.
  ```json
  "topbarCTA": {
    "name": "Get Started",
    "url": "https://mintlify.com/get-started"
  }
  ```
- **versions** (`string[]`, optional): Doc versions for localization or versioning.
- **anchors** (`Anchor[]`, optional): Anchors for quick links to sections or external URLs.
- **topAnchor** (`Anchor`, optional): Override the default top anchor.
- **tabs** (`Tabs[]`, optional): Navigational tabs.
  ```json
  "tabs": [
    {
      "name": "API References",
      "url": "api-references"
    },
    {
      "name": "Content",
      "url": "content"
    }
  ],
  "primaryTab": {
    "name": "Home"
  }
  ```
- **footer** (`FooterSocials`, `FooterLinksColumn[]`, optional): Configure footer socials and links.
- **feedback** (`Feedback`, optional): Enable feedback buttons.

#### API Configurations

- **api** (`API`, optional): API settings configuration.
- **openapi** (`string` | `string[]`, optional): Paths or URLs to your OpenAPI files.
  ```json
  "openapi": "https://example.com/openapi.json"
  ```
  Or multiple OpenAPI files:
  ```json
  "openapi": [
    "https://example.com/openapi1.json",
    "./path/to/openapi2.json"
  ]
  ```
- **integrations** (`Integrations`, optional): Third-party integrations (excluding analytics).
- **analytics** (`Analytics`, optional): Third-party analytics integrations.

#### Redirects

- **redirects** (`Redirect[]`, optional): Configure URL redirects.
  ```json
  "redirects": [
    {
      "source": "/old-path",
      "destination": "/new-path"
    }
  ]
  ```

#### SEO

- **seo** (`SEO`, optional): Search Engine Optimization settings.
  - **indexHiddenPages** (`boolean`, default `false`): Index pages not included in navigation.
  ```json
  "seo": {
    "indexHiddenPages": true
  }
  ```

---

# Writing Content

## Page Titles and Metadata

Begin each MDX page with metadata:

```mdx
---
title: "Page Title"
description: "Brief description of the page"
icon: "icon-name"
---
```

### Additional Metadata Options

- **sidebarTitle**: Display a different title in the sidebar.
  ```mdx
  ---
  title: "Long Page Title"
  sidebarTitle: "Short Title"
  ---
  ```
- **icon** and **iconType**: Include icons for sidebar items.
  ```mdx
  ---
  title: "Code Block"
  icon: "rectangle-code"
  iconType: "solid"
  ---
  ```
- **mode**: Customize page layout.
  - `"default"`: Standard layout with table of contents.
  - `"wide"`: Hide the table of contents.
  - `"custom"`: Minimalist layout with only the top bar.
  ```mdx
  ---
  mode: "wide"
  ---
  ```
- **url**: Create external links in the sidebar.
  ```mdx
  ---
  title: "External Resource"
  url: "https://www.example.com"
  ---
  ```

## Content Formatting

### Headers

Structure your content with headers:

```markdown
## Title (H2)
### Subtitle (H3)
```

### Text Formatting

- **Bold**: `**text**` â†’ **text**
- *Italic*: `_text_` â†’ _text_
- ~~Strikethrough~~: `~text~` â†’ ~~text~~

### Links

- **External**: `[Link Text](https://example.com)`
- **Internal**: `[Link Text](/path/to/page)`

### Images

- **Markdown Syntax**:
  ```markdown
  ![Alt Text](/path/image.jpg)
  ```
- **Disable Zoom**:
  ```html
  <img src="/path/image.jpg" noZoom />
  ```
- **Linking Images**:
  ```html
  <a href="https://website.com" target="_blank">
    <img src="/path/image.jpg" />
  </a>
  ```

### Code Blocks

- **Inline Code**: `` `code` ``
- **Fenced Code Blocks**:
  ```language
  // Code here
  ```
- **Named Code Blocks**:
  ```javascript Example.js
  // JavaScript code
  ```
- **Line Highlighting**:
  ```javascript {1,3-5}
  // Code with specific lines highlighted
  ```
- **Code Groups**:
  ```mdx
  <CodeGroup>
    ```python example.py
    # Python code
    ```
    ```javascript example.js
    // JavaScript code
    ```
  </CodeGroup>
  ```

---

# Components

## Accordion

Create collapsible sections:

```mdx
<Accordion title="Section Title">
  Content inside the accordion.
</Accordion>
```

- **Props**:
  - `title` (string): Title displayed on the accordion.
  - `defaultOpen` (boolean): If `true`, accordion is open by default.

## Tabs

Switch between different content sections:

```mdx
<Tabs>
  <Tab title="First Tab">
    Content for the first tab.
  </Tab>
  <Tab title="Second Tab">
    Content for the second tab.
  </Tab>
</Tabs>
```

## Cards

Highlight key points or links:

```mdx
<Card title="Card Title" icon="icon-name" href="/link">
  Card content goes here.
</Card>
```

- **Props**:
  - `title` (string): Title of the card.
  - `icon` (string): Font Awesome icon name (examples: address-book, at, clipboard-user, code, database, eye, file-code, file-csv, file-lines, file-pdf, file-word, file-xml, fire-flame, folder-tree, folders, gear-code, github, globe-pointer, globe-stand, google, image, magnifying-glass-location, markdown, people-group, rocket-launch, screen-users, screwdriver-wrench, signal-stream, spider-web, terminal, toolbox, wrench, youtube).
  - `href` (string): URL to navigate when card is clicked.
  - `horizontal` (boolean): Display card in horizontal layout.
  - `img` (string): Path to an image displayed on the card.

## Steps

Display step-by-step instructions:

```mdx
<Steps>
  <Step title="Step One">
    Instructions for step one.
  </Step>
  <Step title="Step Two">
    Instructions for step two.
  </Step>
</Steps>
```

## Tooltips

Show additional information on hover:

```mdx
<Tooltip tip="Tooltip text">Hover over this text</Tooltip>
```

---

# API Components

## ParamField

Define API parameters:

```mdx
<ParamField param="user_id" type="string" required>
  The unique identifier of the user.
</ParamField>
```

- **Props**:
  - `param` (string): Parameter name.
  - `type` (string): Data type.
  - `required` (boolean): Indicates if parameter is required.
  - `default` (string): Default value.
  - `placeholder` (string): Placeholder text.
  - `deprecated` (boolean): Indicates if parameter is deprecated.

## ResponseField

Define API response fields:

```mdx
<ResponseField name="status" type="string" required>
  Status of the response.
</ResponseField>
```

- **Props**:
  - `name` (string): Field name.
  - `type` (string): Data type.
  - `required` (boolean): Indicates if field is required.
  - `default` (string): Default value.

## Expandable

Toggle the display of nested fields:

```mdx
<Expandable title="User Object">
  <ResponseField name="id" type="string">User ID</ResponseField>
  <ResponseField name="email" type="string">User Email</ResponseField>
</Expandable>
```

---

# Sidebar Code Examples

Use `<RequestExample>` and `<ResponseExample>` to display code in the sidebar.

```mdx
<RequestExample>
  ```javascript Example Request
  fetch('https://api.example.com/users')
    .then(response => response.json())
    .then(data => console.log(data));
  ```
</RequestExample>

<ResponseExample>
  ```json
  {
    "users": [
      { "id": "1", "name": "Alice" },
      { "id": "2", "name": "Bob" }
    ]
  }
  ```
</ResponseExample>
```

---

# Diagrams

## Mermaid Diagrams

Create diagrams using Mermaid syntax:

```markdown
```mermaid
graph TD
  A[Start] --> B[Process]
  B --> C[End]
```
```

---

This cheatsheet provides practical guidance for using Mintlify to create documentation sites with various components and configurations.



================================================
FILE: docs/openapi.json
================================================
{
  "openapi": "3.0.3",
  "info": {
    "title": "Agencii Platform API",
    "version": "1.0.0",
    "description": "Reference documentation for the Agencii Platform API. Provides endpoints allowing you to run your agents on custom backends or on other unsupported channels. âš¡ Live Postman Example: https://www.postman.com/vrsen-ai/agencii-api/overview"
  },
  "servers": [
    {
      "url": "https://agency-swarm-app-japboyzddq-uc.a.run.app",
      "description": "Production server"
    }
  ],
  "components": {
    "securitySchemes": {
      "BearerAuth": {
        "type": "http",
        "scheme": "bearer",
        "bearerFormat": "JWT",
        "description": "Platform token required for authentication. Find or create one inside Profile Icon > API Keys. Example: Bearer sk-agencii-..."
      }
    },
    "schemas": {
      "Attachment": {
        "type": "object",
        "description": "Object representing a file attachment.",
        "properties": {
          "file_id": { "type": "string", "description": "The unique identifier for the file. Example: file-0SY0lLXWCSSBIOb2gu8UolxH" },
          "tools": {
            "type": "array",
            "items": { "$ref": "#/components/schemas/Tool" },
            "description": "An array of tool objects specifying tools to be used with the file. Example: [{ \"type\": \"file_search\" }]"
          }
        },
        "required": ["file_id", "tools"]
      },
      "Tool": {
        "type": "object",
        "description": "Object representing a tool to be used.",
        "properties": {
          "type": { "type": "string", "description": "The type of tool to be used. Example: file_search" }
        },
        "required": ["type"]
      },
      "GetCompletionRequest": {
        "type": "object",
        "description": "Request body for the /get_completion endpoint.",
        "properties": {
          "message": { "type": "string", "description": "The message content to be processed by the agent. Example: \"Hey! How are you?\"" },
          "apiIntegrationId": { "type": "string", "description": "The unique identifier for the API integration being used. Example: \"dpCD7snQ0tCWrdtp6UhZ\"" },
          "chatId": { "type": "string", "description": "The unique identifier for the chat session. If provided, continues the chat with the previous context. Example: \"plOQeH3hW7UKiACqEdAx\"", "nullable": true },
          "attachments": {
            "type": "array",
            "items": { "$ref": "#/components/schemas/Attachment" },
            "description": "An array of attachment objects to include files and specify tools for processing. Example: [{\"file_id\": \"file-123\", \"tools\": [{\"type\": \"file_search\"}]}]",
            "nullable": true
          },
          "additionalInstructions": { "type": "string", "description": "Appends additional instructions at the end of the agent's instructions for the run. Useful for modifying behavior per-run. Example: \"User name: John Smith\"", "nullable": true },
          "aliasChatId": { "type": "string", "description": "An alternative to chatId which allows using custom identifiers for persisting chats through third party integrations. Example: \"custom-identifier\"", "nullable": true }
        },
        "required": ["message", "apiIntegrationId"]
      },
      "GetCompletionResponse": {
        "type": "object",
        "description": "Response body for the /get_completion endpoint when textOnly mode is disabled.",
        "properties": {
          "chatId": { "type": "string", "description": "The unique identifier for the chat session. Example: \"FVfA971B3fnBH4S1OKlo\"" },
          "createdAt": { "type": "string", "format": "date-time", "description": "The timestamp when the response was created (ISO 8601 format). Example: \"2024-08-06T02:02:37.533913\"" },
          "threadId": { "type": "string", "description": "The unique identifier for the underlying thread. Example: \"thread_ruUj69CyW2STm8Zog0HXkvIJ\"" },
          "assistantId": { "type": "string", "description": "The unique identifier for the assistant that responded. Example: \"J3NQwdHxqm9jvWFpOwFk\"" },
          "name": { "type": "string", "description": "The name of the API integration used. Example: \"Test API Integration\"" },
          "message": { "$ref": "#/components/schemas/Message", "description": "The message object containing the agent's response details." },
          "numMessages": { "type": "integer", "description": "The total number of messages in the chat thread. Example: 2" },
          "aliasChatId": { "type": "string", "description": "Alternative chat identifier used for persisting chats through third party integrations. Example: \"r14ud3CyX21Tm8Zog0HKJkvZJ\"" }
        }
      },
      "Message": {
        "type": "object",
        "description": "Object representing a message within the chat.",
        "properties": {
          "id": { "type": "string", "description": "The unique identifier for the message. Example: \"msg_nH4zWgFW7dCUoNQ5msLJNBUd\"" },
          "content": { "type": "string", "description": "The content of the message. Example: \"The secret phrase is: **papaya tangerine**.\"" },
          "role": { "type": "string", "description": "The role of the message sender (e.g., 'assistant', 'user'). Example: \"assistant\"" },
          "type": { "type": "string", "description": "The type of message (e.g., 'text'). Example: \"text\"" },
          "createdAt": { "type": "string", "format": "date-time", "description": "The timestamp when the message was created (ISO 8601 format). Example: \"2024-08-06T02:02:37.533913\"" },
          "references": { "type": "array", "items": { "type": "string" }, "description": "An array of references associated with the message." },
          "fileIds": { "type": "array", "items": { "type": "string" }, "description": "An array of file IDs associated with the message. Example: [\"file-wRZy12uetHH9dVEpR6PhE92j\"]" },
          "assistantData": { "type": "object", "nullable": true, "description": "Additional assistant-related data." },
          "functions": { "type": "object", "nullable": true, "description": "Additional function-related data." }
        }
      },
      "CreateNewChatRequest": {
        "type": "object",
        "description": "Request body for the /create_new_chat endpoint.",
        "properties": {
          "apiIntegrationId": { "type": "string", "description": "The unique identifier of the API integration for which to create the chat. Example: \"dpCD7snQ0tCWrdtp6UhZ\"" }
        },
        "required": ["apiIntegrationId"]
      },
      "CreateNewChatResponse": {
        "type": "object",
        "description": "Response body for the /create_new_chat endpoint.",
        "properties": {
          "chatId": { "type": "string", "description": "The unique identifier for the newly created chat. Example: \"FVfA971B3fnBH4S1OKlo\"" }
        }
      },
      "ErrorResponse": {
        "type": "object",
        "description": "Standard error response format.",
        "properties": {
          "detail": { "type": "string", "description": "A detailed error message." }
        }
      }
    }
  },
  "security": [ { "BearerAuth": [] } ],
  "paths": {
    "/create_new_chat": {
      "post": {
        "summary": "Create new chat",
        "description": "Creates a new chat instance for a user based on a provided API integration. Requires a valid platform token in the headers for authentication. Ensure the apiIntegrationId corresponds to an existing integration.",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": { "$ref": "#/components/schemas/CreateNewChatRequest" }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Chat created successfully. Returns the unique chatId for the new chat.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/CreateNewChatResponse" }
              }
            }
          },
          "400": {
            "description": "Bad Request. Occurs if the request body is missing required fields or the JSON payload is malformed.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "Your JSON payload is missing required fields. Please consult the documentation." }
              }
            }
          },
          "401": {
            "description": "Unauthorized. Occurs if the Authorization header is missing or contains an invalid token.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "Invalid or missing authorization token." }
              }
            }
          },
          "500": {
            "description": "Internal Server Error. Occurs if there is an issue on the server side while processing the request.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "An unexpected error occurred while processing your request." }
              }
            }
          }
        },
        "security": [ { "BearerAuth": [] } ]
      }
    },
    "/get_completion": {
      "post": {
        "summary": "Get completion",
        "description": "Processes a message using the specified API integration and returns a completion from the agent. Requires a valid platform token. Ensure the apiIntegrationId is valid. Supports continuing existing chats via chatId or aliasChatId and attaching files with tools.",
        "requestBody": {
          "required": true,
          "content": {
            "application/json": {
              "schema": { "$ref": "#/components/schemas/GetCompletionRequest" }
            }
          }
        },
        "responses": {
          "200": {
            "description": "Successful response. The format varies depending on the `textOnly` mode configured for the API Integration. If `textOnly` is enabled, the response is plain text. Otherwise, it's application/json.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/GetCompletionResponse" }
              },
              "text/plain": {
                "schema": { "type": "string", "example": "This is a final message response from the bot." }
              }
            }
          },
          "400": {
            "description": "Bad Request. Occurs if the request body is missing required fields or the JSON payload is malformed.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "Your JSON payload is missing required fields. Please consult the documentation." }
              }
            }
          },
          "401": {
            "description": "Unauthorized. Occurs if the Authorization header is missing or contains an invalid token.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "Invalid or missing authorization token." }
              }
            }
          },
          "500": {
            "description": "Internal Server Error. Occurs if there is an issue on the server side while processing the request.",
            "content": {
              "application/json": {
                "schema": { "$ref": "#/components/schemas/ErrorResponse" },
                "example": { "detail": "An unexpected error occurred while processing your request." }
              }
            }
          }
        },
        "security": [ { "BearerAuth": [] } ]
      }
    }
  }
}



================================================
FILE: docs/.prettierrc
================================================
{
  "semi": true,
  "singleQuote": false,
  "tabWidth": 2,
  "printWidth": 120,
  "bracketSpacing": true,
  "arrowParens": "always",
  "trailingComma": "none"
}



================================================
FILE: docs/additional-features/asynchronous-execution.mdx
================================================
---
title: "Asynchronous Execution"
description: "Run your agents or tools asynchronously."
icon: "bolt"
---

Asynchronous execution allows you to run your agents or tools asynchronously in separate threads. This can be useful for shortening response times for certain I/O-bound tasks.

## Async Agents

To run each agent in a separate thread, you need to use a special `SendMessageAsyncThreading` tool class. See [Custom Communicaiton Flows](/additional-features/custom-communication-flows) for more information.

```python
from agency_swarm import SendMessageAsyncThreading
from agency_swarm import Agency

agency = Agency(agents=[ceo], send_message_tool_class=SendMessageAsyncThreading)
```

With this mode, the caller agent does not receive an immediate reply. Instead, it first gets a system notification confirming that the message has been sent to the recipient agent. Later, the calling agent can retrieve the actual response from the recipient.

## Async Tools

To run each tool in a separate thread, you need to adjust the ToolConfig class for each tool that you want to run asynchronously. See [Custom Tools Configuration](/core-framework/tools/custom-tools/configuration) for more information.

```python
from agency_swarm import BaseTool

class Tool(BaseTool):
    # ...

    class ToolConfig:
        async_mode = "threading"

    # ...
```

With this mode, the agent will still have to wait for the tool to finish before it can continue with the next step in the conversation. So, it only makes sense to use this mode with multiple tools for the same agent that are not dependent on each other.



================================================
FILE: docs/additional-features/azure-openai.mdx
================================================
---
title: "Azure OpenAI"
description: "Integrate Azure OpenAI with Agency Swarm to ensure secure data processing and enhanced privacy."
icon: "microsoft"
---

Many organizations prioritize data privacy and are cautious about sharing their data with any third-parties. By leveraging Azure OpenAI, you can ensure that your data is processed only within your own secure Azure environment, and not even shared with OpenAI itself.

<Info>
Running OpenAI models on Azure is the same as deploying your own open source model on any other cloud provider.
</Info>

## Prerequisites

Before you begin, ensure you have the following:

1. Create an Azure Account with an active subscription. [Create an account here](https://azure.microsoft.com/en-us/free/).
2. Get approved access to the OpenAI Service on Azure.
3. Create an Azure OpenAI resource in [one of the available regions](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#assistants-preview) and deploy a model to it.
4. Obtain the endpoint URL and API key for the OpenAI resource.

## Setting Up Azure OpenAI with Agency Swarm


<Steps>
<Step title="Configure the Azure OpenAI Client">
To use Azure OpenAI, you need to replace the default OpenAI client with the configured `AzureOpenAI` client:


```python
from openai import AzureOpenAI
from agency_swarm import set_openai_client
import os

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    api_version="2024-02-15-preview",
    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
    timeout=5,
    max_retries=5,
)

set_openai_client(client)
```


</Step>

<Step title="Update Agent Model Parameters">

Replace the `model` parameter inside each agent with your model deployment name from Azure.t:

```python
from agency_swarm import Agent

ceo = Agent(
    name="ceo",
    description="I am the CEO",
    model="azure-model-deployment-name"
)
```
<Note>
Model deployment name might be different from the stadard OpenAI model names. It is set by you when you deploy a model to Azure.
</Note>

</Step>

<Step title="Run Your Agency">

After configuring the client and updating the agents, you can run your agency as usual:

```python
from agency_swarm import Agency

agency = Agency([ceo])
agency.run_demo()
```
</Step>
</Steps>

## Example Notebook

For an example of using Azure OpenAI with Agency Swarm, refer to the [Azure OpenAI Notebook](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/azure.ipynb) in the notebooks folder.



================================================
FILE: docs/additional-features/deployment-to-production.mdx
================================================
---
title: "Deployment to Production"
description: "Step-by-step guide for deploying your agency in a production environment."
icon: "rocket-launch"
---
To deploy your agency to production, typically the process is as follows:
1. **Dynamically Load Conversation Threads**: Required to continue conversations from where they left off
2. **Dynamically Load Assistant Settings**: Needed to make changes to your agent's settings persist even after redeployment
3. **Deploy Agents and Tools on a Production Server**: Decide whether to deploy agents and tools together or separately

<Note>
  This guide assumes that you have already created an agency. If you haven't, check out the [Getting Started](/welcome/installation) guide.
</Note>

<Warning>
  Before deploying your agency, ensure you have thoroughly tested all tools and agents in isolation and in combination. Run the test cases in each tool file and verify the agency works end-to-end using the `run_demo()` or `demo_gradio` methods.
</Warning>

<Steps>

<Step title="Step 1: Dynamically Load Conversation Threads" icon="message-dots">

By default, every time you create a new `Agency()`, it starts a fresh conversation thread. However, in production environments, you typically need to pick up old conversations or handle multiple users at once.

<Info>
In Agency Swarm, threads are stored in a dictionary that contains all conversation thread IDs, including those between your agents.
</Info>

Loading threads from a database before processing a new request allows you to continue conversations from where they left off, even if you are using stateless backend.

<Info>
Callbacks are functions that are called by the framework automatically when Agency is initialized.
</Info>

Example threads callbacks:

```python
def load_threads(chat_id):
    # Load threads from your database using the chat_id
    threads = load_threads_from_db(chat_id)
    return threads

def save_threads(new_threads):
    # Save updated threads to your database
    save_threads_to_db(new_threads)

agency = Agency(
    ...
    threads_callbacks={
        'load': lambda: load_threads(chat_id),
        'save': lambda new_threads: save_threads(new_threads)
    },
)
```

</Step>

<Step title="Step 2: Dynamically Load Assistant Settings" icon="gear">

By default, agencies store assistant settings (such as name, description, instructions, tools, and model) in a local file defined in the `settings_path` parameter (`settings.json` by default). While this works well for development, in production environments, we recommend storing these settings in a database to persist changes between deployments.

<Info>
Settings is a list of dictionaries that contains settings of all agents. If a change is detected in the settings, the framework will automatically save the new settings to a local file and trigger the `save` callback.
</Info>

`settings_callbacks` are executed every time agent settings are loaded or saved. Just like `threads_callbacks`, you can use it to load or save agent configurations based on your identifier (e.g. user_id):

```python
def load_settings(user_id):
    # Load settings from your database using the user_id
    settings = load_settings_from_db(user_id)
    return settings

def save_settings(new_settings):
    # Save updated settings to your database
    save_settings_to_db(new_settings)

agency = Agency(
    ...
    settings_callbacks={
        'load': lambda: load_settings(user_id),
        'save': lambda new_settings: save_settings(new_settings)
    },
)
```

<Note>
Make sure you load and return settings and threads in the exact same format as they are saved.
</Note>

</Step>


<Step title="Step 3: Deploying Agents and Tools on a Production Server" icon="rocket-launch">

Depending on your needs, you can deploy your agents and tools together or separately:
1. **Agents Together with Tools**: This is the simplest method: your agents execute the tools directly, in the same environment.
2. **Tools as Separate API Endpoints**: This is the most scalable method: multiple agents can reuse the same tools, and you can scale the tools independently.

<Accordion title="Comparison Table" defaultOpen={true}>

| Feature               | Agents with Tools                     | Tools as Separate API Endpoints          |
|-----------------------|----------------------------------------|-------------------------------------------|
| **Setup Complexity**  | "One-click" deployment       | Additional setup required          |
| **Scalability**       | Combined agency scaling               | Independent tool/agent scaling           |
| **Tool Reusability**  | Limited to current agency             | Cross-project utilization                 |
| **Cost Efficiency**   | Predictable resource allocation       | Optimized resource scaling                |
| **Security**          | Internal tool access only             | API authentication required           |
| **Best For**          | Small to medium projects              | Large-scale or multi-project environments |

</Accordion>

<Tabs>

<Tab title="Option 1: Agents and Tools Together" defaultOpen={true}>

This is the simplest deployment method. You can use the official Railway template to get your agency up and running quickly.

Watch the video below for a detailed walkthrough:
<iframe width="560" height="315" src="https://www.youtube.com/embed/53_e3lmk6Mo?si=kASCTtxfa6ljqGNy&amp;start=806" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

<Card
  title="Railway Deployment Template"
  href="https://github.com/VRSEN/agency-swarm-api-railway-template"
  icon="train"
  iconType="duotone"
>
  Click here to open the template and follow the instructions provided.
</Card>

<Note>
  The template includes a Gradio interface and REST API endpoints with proper authentication.
</Note>

</Tab>

<Tab title="Option 2: Tools as Separate API Endpoints">

Instead of deploying agents and tools together, you can host your tools separately as serverless functions or custom APIs, then connect them to your agents using [OpenAPI schemas](/core-framework/tools/openapi-schemas). This approach is useful if you want to reuse tools across different projects or scale them independently. You can also use OpenAPI schemas to connect third-party tools to your agency.

You can use our Firebase template:
<Card
  title="Firebase Deployment Template"
  href="https://github.com/vrsen-ai-solutions/agency-swarm-tools-template"
  icon="fire"
  iconType="duotone"
>
  Click here to open the template and follow the instructions provided.
</Card>

<Note>
  When deploying tools separately, shared state between calls will not be preserved.
</Note>

</Tab>

</Tabs>

</Step>
</Steps>



================================================
FILE: docs/additional-features/fastapi-integration.mdx
================================================
---
title: "FastAPI Integration"
description: "Serving your agencies and tools as APIs with FastAPI."
icon: "server"
---

Agency Swarm supports serving your agencies and tools as production-ready HTTP APIs using [FastAPI](https://fastapi.tiangolo.com/). This enables you to interact with your agents and tools over HTTP, integrate with other services, or connect it to web frontends.

## Installation

FastAPI integration is an **optional installation**. To install all required dependencies, run:

```bash
pip install agency-swarm[fastapi]
```

## Setting Up FastAPI Endpoints

You can expose your agencies and tools as API endpoints using the `run_fastapi()` function.

### Example: Create an api endpoint for a single agency using instance method

```python
from agency_swarm.agency import Agency

agency = Agency([ceo], name="test_agency")

agency.run_fastapi()
```

Optionally, you can specify following parameters: 
- host (default: `"0.0.0.0"`)
- port (default: `8000`)
- app_token_env (default: `"APP_TOKEN"`) - Name of the env variable storing app token.

This will create 2 endpoints for the agency: 
- `/test_agency/get_completion`
- `/test_agency/get_completion_stream`

Both of these endpoints will accept following input parameters:
```python
message: str
message_files: List[str] = None
# Name of the agent, as defined within it's name attribute
recipient_agent: str = None
additional_instructions: str = None
attachments: List[Attachment] = []
tool_choice: dict = None
response_format: dict = None
# Only for the get_completion endpoint, will be ignored in the streaming endpoint
verbose: bool = False
```

Additionally, you will need to provide a bearer token in the authorization if you have `"APP_TOKEN"` specified (or a differently named variable if you provided app_token_env). If the token is **not specified** in the env variables, **authentication will be disabled**.

### Example: Serving Multiple Agencies and Tools
You can deploy multiple agencies **and** tools in a single function call by using run_fastapi function from the integrations directory

```python
from pydantic import Field

from agency_swarm.agency import Agency
from agency_swarm.tools import BaseTool
from agency_swarm.integrations.fastapi import run_fastapi


# Example tools
class ExampleTool(BaseTool):
  example_field: str = Field(..., description="Example input.")
  def run(self):
      return "Result of ExampleTool operation"

class TestTool(BaseTool):
  example_field: str = Field(..., description="Example input.")
  def run(self):
      return "Result of TestTool operation"

# Create agencies
agency1 = Agency([agent], name="test_agency_1")
agency2 = Agency([agent], name="test_agency_2")

run_fastapi(
    agencies=[agency_test_1, agency_test_2],
    tools=[ExampleTool, TestTool],
)
```

This will create 6 following endpoints: 
- `/test_agency_1/get_completion`
- `/test_agency_1/get_completion_stream`
- `/test_agency_2/get_completion`
- `/test_agency_2/get_completion_stream`
- `/tool/ExampleTool`
- `/tool/TestTool`

Inputs for the tool endpoints will follow their pydantic schemas respectively.

---

## API Usage Example

You can interact with your agents and tools using HTTP requests. Here's an example using Python's `requests` library:

```python
import requests

agency_url = "http://127.0.0.1:8000/test_agency_1/get_completion"
payload = {
    "message": "Hello",
}

headers = {
    "Authorization": "Bearer 123"  # Replace 'test-token' with your actual token if needed
}

agency_response = requests.post(url, json=payload, headers=headers)
print("Status code:", agency_response.status_code)
print("Response:", agency_response.json()) 

tool_url = "http://127.0.0.1:8000/tool/ExampleTool"
payload = {
    "example_field": "test",
}

tool_response = requests.post(url, json=payload, headers=headers)
print("Status code:", tool_response.status_code)
print("Response:", tool_response.json()) 
```

---

## Endpoint Structure

- **Agency Endpoints:**  
  Each agency is served at:
  - `/your_agency_name/get_completion` (POST)
  - `/your_agency_name/get_completion_stream` (POST, streaming responses)

- **Tool Endpoints:**  
  Each tool is served at:
  - `/tool/ToolClassName` (POST)

---


================================================
FILE: docs/additional-features/few-shot-examples.mdx
================================================
---
title: "Few-Shot Examples"
description: "Guide agent responses using few-shot prompting."
icon: "clone"
---

**Few-shot prompting** is a powerful technique where you provide a small number of sample interactions (typically 2 to 5) to guide your agent's behavior. This method helps the agent understand the desired output format and task requirements by learning from the given examples, thereby improving performance without writing extensive instructions.

## Crafting Effective Examples

- **Provide Task Demonstrations**: Use examples that clearly illustrate the tasks that your agents will perform.
- **Use Realistic Scenarios**: Include interactions that mirror actual conversations that your agent will handle.
- **Use Preferred Tone and Style**: Ensure the agent's replies in your examples match your desired brand voice.

## Defining Few-Shot Examples

In the **Agency Swarm** framework, few-shot examples are structured using the [OpenAI message object format](https://platform.openai.com/docs/api-reference/messages/createMessage), including the `role` and `content` fields.

**Example**: Technical Support Agent:

```python
examples = [
    {
        "role": "user",
        "content": "My device won't turn on.",
    },
    {
        "role": "assistant",
        "content": "I'm sorry to hear that. Let's try some troubleshooting steps. First, please press and hold the power button for at least 10 seconds.",
    },
    {
        "role": "user",
        "content": "I tried that, but it still won't turn on.",
    },
    {
        "role": "assistant",
        "content": "Thank you for trying that. Please connect your device to a charger and check if any lights appear. Let me know what you observe.",
    }
]
```

The optional fields `attachments` and `metadata` can be included if needed but are not required for basic examples.

## Using Few-Shot Examples

You can add few-shot examples to your agent either during initialization or afterward:

<Tabs>
    <Tab title="During Initialization">

    ```python
    from agency_swarm import Agent

    agent = Agent(
        name="CustomerSupportAgent",
        description="Assists customers with inquiries and provides detailed information.",
        examples=examples
    )
    ```

    </Tab>
    <Tab title="After Initialization">

    ```python
    agent = Agent(name="CustomerSupportAgent")
    agent.examples = examples
    ```

    </Tab>

</Tabs>

See more advanced features in [Agent Class](/core-framework/agents/advanced-configuration)



================================================
FILE: docs/additional-features/observability.mdx
================================================
---
title: "Observability"
description: "Track and analyze your agent performance and behavior by connecting with third party observability tools."
icon: "eyes"
---

Agency Swarm uses Langchain callbacks to connect with third party observability tools.

<Info>
  Although we strongly discourage using Langchain for agent development due to its numerous unnecessary abstractions, it currently has the widest support among third-party observability tools. For this reason, we have adopted its callback structure. However, no Langchain code is used within Agency Swarm.
</Info>

<Accordion title="Prerequisites" defaultOpen={true}>
  To get started with observability features, install the Langchain package:

  ```bash
  pip install langchain
  ```
</Accordion>

## Supported Observability Platforms

When it comes to choosing your observability platform, there are a few options. You can use one or multiple trackers simultaneously for comprehensive monitoring:

<CardGroup cols={2}>
  <Card title="Langfuse" icon="chart-line" href="#getting-started">
    Advanced tracing, metrics, and debugging tools
  </Card>
  <Card title="AgentOps" icon="gauge-high" href="#getting-started">
    Platform for managing and tracking your agents
  </Card>
  <Card title="Local Tracking" icon="database" href="#getting-started">
    Lightweight SQLite-based local tracking solution
  </Card>
  <Card title="Implementation" icon="code" href="#how-it-works">
    Technical details about tracking implementation
  </Card>
</CardGroup>

## Getting Started

We currently recommend [**Langfuse**](https://langfuse.com/) because it is fully open source, easy to use, and offers the most comprehensive set of features and support. You can also combine it with other trackers for enhanced observability.

![Langfuse dashboard](/images/observability-langfuse.png)

<Tabs>
  <Tab title="Langfuse">
    <Steps>
      <Step title="Install Package">
        ```bash
        pip install langfuse==2.60.5
        ```
      </Step>
      <Step title="Set Environment Variables">
        ```bash
        export LANGFUSE_SECRET_KEY=<your-secret-key>
        export LANGFUSE_PUBLIC_KEY=<your-public-key>
        ```
        <Tooltip tip="You can find these keys on the Langfuse dashboard">Keys are available on the Langfuse dashboard</Tooltip>
      </Step>
      <Step title="Initialize Tracking">
        ```python
        from agency_swarm import init_tracking

        # Initialize single tracker
        init_tracking("langfuse")

        # Or initialize multiple trackers
        init_tracking("langfuse")
        init_tracking("local")  # Add local tracking alongside Langfuse
        ```
        <Accordion title="Configuration (Optional)">
          You can pass additional configuration options:

          ```python
          # Using environment variables with additional options
          init_tracking("langfuse", debug=True, host="custom-host", user_id="user-123")

          # Direct API key passing (useful for multi-user applications)
          init_tracking("langfuse", public_key="your-public-key", secret_key="your-secret-key")
          ```
      </Accordion>
          For more information, see the [Langfuse Documentation](https://langfuse.com/docs/integrations/langchain/tracing#add-langfuse-to-your-langchain-application).
      </Step>

    </Steps>
  </Tab>

  <Tab title="AgentOps (Limited Support)">
    <Steps>
      <Step title="Install Dependencies">
        ```bash
        pip install agentops==0.4.6
        ```
      </Step>
      <Step title="Set API Key">
        Either add to your `.env` file:
        ```bash
        AGENTOPS_API_KEY=<YOUR API KEY>
        ```

        Or pass directly when initializing (for multi-user applications):
        ```python
        init_tracking("agentops", api_key="your-agentops-api-key")
        ```

        <Note>AgentOps integration has limited support - not all messages are shown in the chat view.</Note>
      </Step>
      <Step title="Run and Monitor">
        1. Run your agent
        2. Visit [app.agentops.ai/drilldown](https://app.agentops.ai/drilldown) to observe your agent
        3. After the run, AgentOps prints a clickable URL in the console that takes you directly to your session
      </Step>

    </Steps>
  </Tab>

  <Tab title="Local Tracking">
    Local SQLite implementation:
    <Steps>
      <Step title="Install Dependencies">
        ```bash
        pip install tiktoken
        ```
      </Step>
      <Step title="Initialize Tracking">
        ```python
        from agency_swarm import init_tracking
        init_tracking("local")
        ```

        A SQLite database will be created in the current directory.
      </Step>
      <Step title="Custom Database Path (Optional)">
        ```python
        init_tracking("local", db_path="path/to/your/database.db")
        ```
      </Step>

    </Steps>
  </Tab>
</Tabs>

## How It Works

Agency Swarm uses a simple but powerful tracking system that captures every interaction in your agent's lifecycle:

1. **Event Tracking**: Every message, tool call, and error is automatically tracked with unique IDs and timestamps.
2. **Hierarchical Structure**: Events are organized in a tree structure, showing how different parts of your agent interact.
3. **Multiple Platforms**: You can send this data to different platforms (Langfuse, AgentOps, or local SQLite) for analysis.

The tracking system is built on top of Langchain's callback interface, which means it can work with any observability tool that supports Langchain. This gives you flexibility while keeping the implementation simple.

### What Gets Tracked

The system automatically captures:
- **Messages**: Every conversation between users and agents
- **Tool Calls**: When agents use tools and their results
- **Errors**: Any issues that occur during execution
- **Performance**: Token usage, timing, and other metrics
- **Relationships**: How different parts of your agent interact

This data helps you understand your agent's behavior, debug issues, and optimize performance.

<Accordion title="Event Hierarchy" defaultOpen="true">
  ```
  Agency Chain
  â”œâ”€â”€ Messages
  â”‚   â”œâ”€â”€ User messages
  â”‚   â”œâ”€â”€ Assistant messages
  â”‚   â”œâ”€â”€ Function calls
  â”‚   â””â”€â”€ Function outputs
  â””â”€â”€ Errors
      â”œâ”€â”€ Chain errors (in agency.py)
      â”‚   â””â”€â”€ Generator errors
      â””â”€â”€ Tool errors (in thread.py)
          â”œâ”€â”€ Validation errors
          â”œâ”€â”€ Execution errors
          â””â”€â”€ Tool-specific errors
  ```
</Accordion>

<Accordion title="Key Components">
  <ResponseField name="TrackingManager" type="class">
    Central tracking coordinator
  </ResponseField>
  <ResponseField name="Langchain callbacks" type="interface">
    Standardized event tracking interface
  </ResponseField>
  <ResponseField name="LocalCallbackHandler" type="class">
    SQLite-based callback handler that logs events sequentially in a local database, using tiktoken for token counting
  </ResponseField>
</Accordion>

<Accordion title="Event Types">
  <Expandable title="Chain Events" defaultOpen="true">
    <ResponseField name="Agency runs" type="event">Start/end of agency runs</ResponseField>
    <ResponseField name="Relationships" type="metadata">Parent-child relationships</ResponseField>
    <ResponseField name="Errors" type="event">Error tracking</ResponseField>
  </Expandable>

  <Expandable title="Message Events">
    <ResponseField name="User/assistant messages" type="event">Communication between user and assistant</ResponseField>
    <ResponseField name="Tool calls" type="event">Function calls and outputs</ResponseField>
    <ResponseField name="Metadata" type="metadata">Run IDs and related information</ResponseField>
  </Expandable>

  <Expandable title="Tool Events">
    <ResponseField name="Execution" type="event">Tool execution start/end</ResponseField>
    <ResponseField name="Errors" type="event">Tool errors and validation</ResponseField>
    <ResponseField name="File operations" type="event">File search and retrieval</ResponseField>
  </Expandable>
</Accordion>

<Accordion title="Metadata Tracked">
  <ResponseField name="Run IDs" type="string">
    Unique identifiers for each run
  </ResponseField>
  <ResponseField name="Relationships" type="object">
    Parent-child relationships between runs
  </ResponseField>
  <ResponseField name="Agent info" type="object">
    Agent names and roles
  </ResponseField>
  <ResponseField name="Model info" type="object">
    Information about the models used
  </ResponseField>
  <ResponseField name="Timestamps" type="datetime">
    When events occurred
  </ResponseField>
  <ResponseField name="Token usage" type="object">
    Information about token consumption
  </ResponseField>
  <ResponseField name="Error details" type="object">
    Detailed error information when failures occur
  </ResponseField>
</Accordion>



================================================
FILE: docs/additional-features/open-source-models.mdx
================================================
---
title: "Open-Source Models"
description: "Utilize open-source models with Agency Swarm."
icon: "code-fork"
---

While OpenAI is generally recommended, there are situations where you might prefer open-source models. The following projects offer alternatives by mimicking the Assistants API:

## Supported Projects

<CardGroup>

<Card
  title="Astra Assistants API"
  icon="rocket"
  iconType="solid"
  href="https://github.com/datastax/astra-assistants-api"
>
  The best and the easiest option for running Open Source models. Supports Assistants API V2. See example
  [notebook](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/os_models_with_astra_assistants_api.ipynb) and [official examples](https://github.com/datastax/astra-assistants-api/tree/main/examples/python/agency-swarm).
</Card>

<Card title="Open Assistant API" icon="users" iconType="solid" href="https://github.com/MLT-OSS/open-assistant-api">
  Fully local, stable, and tested, but only supports Assistants V1. See example
  [here](https://github.com/VRSEN/agency-swarm-lab/tree/main/OpenSourceSwarm).
</Card>

<Card title="OpenOpenAI" icon="code" iconType="solid" href="https://github.com/transitive-bullshit/OpenOpenAI">
  Unverified.
</Card>

<Card title="LiteLLM" icon="code" iconType="solid" href="https://github.com/BerriAI/litellm/issues/2842">
  Assistants API Proxy in development.
</Card>

</CardGroup>

## Astra Assistants API

<Steps>

<Step title="1. Create an account on Astra Assistants API and obtain an API key." icon="user">
  Open the [Astra Assistants API](https://astra.datastax.com/signup) and create an account. Once you have an account,
  you can obtain an API key by clicking on the "Generate Token" button. ![Astra Assistants API
  Example](https://firebasestorage.googleapis.com/v0/b/vrsen-ai/o/public%2Fgithub%2FScreenshot%202024-07-01%20at%208.19.00%E2%80%AFAM.png?alt=media&token=b4f1a7ad-3b77-40fa-a5da-866a4f1410bd)
</Step>

<Step title="2. Add Astra DB Token to your .env file:" icon="file">
Copy the token from the file that starts with "AstraCS:" and paste it into your `.env` file.

```env
ASTRA_DB_APPLICATION_TOKEN=AstraCS:dsfkgn...
```

</Step>

<Step title="3. Add other model provider API keys to .env as well:" icon="key">
```env
PERPLEXITYAI_API_KEY=your_perplexityai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
TOGETHER_API_KEY=your_together_api_key
GROQ_API_KEY=your_groq_api_key
```
</Step>

<Step title="4. Install the Astra Assistants API and Gradio:" icon="download">
```bash
pip install astra-assistants-api gradio
```
</Step>

<Step title="5. Patch the OpenAI client:" icon="code">
```python
from openai import OpenAI
from astra_assistants import patch
from agency_swarm import set_openai_client
from dotenv import load_dotenv

load_dotenv()

client = patch(OpenAI())

set_openai_client(client)
```
</Step>

<Step title="6. Create an agent:" icon="user-plus">
Create an agent and replace the `model` parameter with the name of the model you want to use. With Astra Assistants, you can upload files as usual using `files_folder`.

```python
from agency_swarm import Agent

ceo = Agent(
    name="ceo",
    description="I am the CEO",
    model='ollama/llama3',
    # model = 'perplexity/llama-3-8b-instruct'
    # model = 'anthropic/claude-3-5-sonnet-20240620'
    # model = 'groq/mixtral-8x7b-32768'
    # model="gpt-4o",
    files_folder="path/to/your/files"
)
```

</Step>

<Step title="7. Create an agency:" icon="people-arrows">
You can add more agents as needed, just ensure all manager agents support function calling.

```python
from agency_swarm import Agency

agency = Agency([ceo])
```

</Step>

<Step title="8. Start Gradio:" icon="play">
To utilize your agency in Gradio, apply a specific non-streaming `demo_gradio` method from the [agency-swarm-lab](https://github.com/VRSEN/agency-swarm-lab/blob/main/OpenSourceSwarm/demo_gradio.py) repository:

```python
from agency_swarm import Agency
from .demo_gradio import demo_gradio

agency = Agency([ceo])

demo_gradio(agency)
```

</Step>

</Steps>

**For complete examples, see the [implementation notebook](https://github.com/VRSEN/agency-swarm/blob/main/notebooks/os_models_with_astra_assistants_api.ipynb) and [official Astra Assistants examples](https://github.com/datastax/astra-assistants-api/tree/main/examples/python/agency-swarm).**

## General Instructions

To use agency-swarm with any other projects that mimic the Assistants API, generally, you need to follow these steps:

<Steps>

<Step title="Install the previous version of agency-swarm as most projects are not yet compatible with streaming and Assistants V2:">
```bash
pip install agency-swarm==0.1.7
```
</Step>

<Step title="Switch out the OpenAI client:">
```python
import openai
from agency_swarm import set_openai_client

client = openai.OpenAI(api_key="your-api-key", base_url="http://127.0.0.1:8000/")

set_openai_client(client)
```
</Step>

<Step title="Set the model parameter:">
```python
from agency_swarm import Agent

ceo = Agent(
    name="ceo",
    description="I am the CEO",
    model='ollama/llama3'
)
```

</Step>

<Step title="Start Gradio:">
To utilize your agency in Gradio, apply a specific non-streaming `demo_gradio` method from the [agency-swarm-lab](https://github.com/VRSEN/agency-swarm-lab/blob/main/OpenSourceSwarm/demo_gradio.py) repository:

```python
from agency_swarm import Agency
from .demo_gradio import demo_gradio

agency = Agency([ceo])

demo_gradio(agency)
```

</Step>

<Step title="For backend integrations, simply use:">
```python
agency.get_completion("I am the CEO")
```
</Step>

</Steps>

## Limitations

<Warning>
Be aware of the limitations when using open-source models.
</Warning>

- **Function calling is not supported by most open-source models**: This limitation prevents the agent from communicating with other agents in the agency. Therefore, it must be positioned at the end of the agency chart and cannot utilize any tools.
- **RAG is typically limited**: Most open-source assistants API implementations have restricted Retrieval-Augmented Generation capabilities. It is recommended to develop a custom tool with your own vector database.
- **Code Interpreter is not supported**: The Code Interpreter feature is still under development for all open-source assistants API implementations.

## Future Plans

Updates will be provided as new open-source assistant API implementations stabilize.

If you successfully integrate other projects with agency-swarm, please share your experience through an issue or pull request.



================================================
FILE: docs/additional-features/output-validation.mdx
================================================
---
title: "Output Validation"
description: "Implementing validators for agents and tools."
icon: "shield-check"
---

Validating the outputs of agents and tools is crucial for building reliable and secure AI agents. Validators help ensure data integrity and handle LLM hallucinations.

## Validators

There are 4 different validators in Agency Swarm:

- Tool validators:
  - `field_validator`: Validate individual fields independently.
  - `model_validator`: Perform complex checks involving multiple fields.
- Agent validators:
  - `response_validator`: Validate the response before sending it to the user or other agents.
- Universal validators:
  - `llm_validator`: Validate outputs against specified natural language rules.

### Agent Response Validator

You can define a `response_validator` method inside your Agent class to validate responses before sending them to the user or other agents. This method should raise an error if the response is invalid, allowing the agent to handle the error and generate a corrected response.

**Example:**

```python
from agency_swarm import Agent

class CustomerSupportAgent(Agent):
    def response_validator(self, message: str) -> str:
        """Validate the response before sending it."""
        if "bad word" in message.lower():
            raise ValueError("Please avoid using inappropriate language.")
        return message
```

In this example, `CustomerSupportAgent` checks the response for the presence of "bad word" and raises a `ValueError` if it is found. The error is passed to the Agent to generate a corrected response.

### Tool Validators

When defining tools, you can use Pydantic validators to prevent invalid data from being passed to the tool by the calling agent.

There are 2 types of validators used specifically in tools: field-level and model-level validators. Here is the comparison table to help you understand the difference between them:

| Type   | Purpose                                                        | Usage                                                                                                                |
|------------------|----------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|
| **Field Validators** | Validate individual fields independently.                      | Use the `@field_validator` decorator on methods, specifying the field(s) to validate.                                |
| **Model Validators** | Validate the entire model, allowing checks involving multiple fields. | Use the `@model_validator` decorator on methods.                                                                   |

<Tabs>
<Tab title="Field Validators" defaultOpen={true}>
This example ensures that the `username` field does not contain spaces using a field validator:

```python
from pydantic import field_validator
from agency_swarm import BaseTool

class User(BaseTool):
    username: str

    @field_validator('username')
    @classmethod
    def validate_username(cls, value):
        if ' ' in value:
            raise ValueError('Username must not contain spaces.')
        return value
```
</Tab>

<Tab title="Model Validators">
This example, a model validator checks that `password` and `confirm_password` match, which requires access to multiple fields:
```python
from pydantic import model_validator
from agency_swarm import BaseTool

class User(BaseTool):
    password: str
    confirm_password: str

    @model_validator(mode='after')
    def check_passwords_match(self):
        if self.password != self.confirm_password:
            raise ValueError('Passwords do not match.')
        return self
```
</Tab>
</Tabs>

### LLM Validator

The `llm_validator` is a powerful way to validate outputs against specified natural language rules.

**Example:**

```python
from agency_swarm.tools.send_message import SendMessage
from agency_swarm.util.validators import llm_validator
from pydantic import model_validator

class SendMessageLLMValidation(SendMessage):
    @model_validator(mode='after')
    def validate_recipient(self):
        if self.recipient == "CustomerSupportAgent":
            llm_validator(
                statement="The message is related to customer support."
            )(self.message)
        return self
```

In this example, the `llm_validator` will throw an error if the message is not related to customer support. The caller agent will then have to fix the recipient or the message and send it again.

<Note>
Since `llm_validator` uses LLMs for validation, it may incur additional costs and latency due to extra API calls. Use it for fields that require complex validation beyond simple checks.
</Note>

By combining all the validators described above, you can create robust validation logic to ensure your agents and tools perform reliably.



================================================
FILE: docs/additional-features/shared-state.mdx
================================================
---
title: "Shared State"
description: "Leveraging shared state across tools and agents."
icon: "database"
---

`shared_state` is a centralized Python dictionary accessible by all tools and agents. It allows you to control execution flow, share data, and provide instructions to the agents based on certain conditions or actions performed by other agents.

<Note>
Shared state is only available when tools are deployed together with agents (see [Deployment to Production](/additional-features/deployment-to-production) guide). If tools are deployed as separate APIs, they won't share the same state, and you'll need to implement your own state management solution.
</Note>

## Understanding Shared State

Shared state is particularly useful when your agents interact with multiple tools that need to exchange information. Here's why:

- **Without Shared State**: Suppose `Tool A` collects data that `Tool B` needs. The agent must explicitly pass this data as a parameter to `Tool B`.

![Without Shared State](/images/shared-state-without.png)

- **With Shared State**: `Tool A` can store the required data in the shared state, and `Tool B` can get it without needing direct parameter passing. This approach reduces complexity and minimizes the risk of errors.

![With Shared State](/images/shared-state-with.png)

## Using Shared State

The two basic operations are:
- **Setting** a value in the shared state: `shared_state.set('key', value)`
- **Getting** a value from the shared state: `shared_state.get('key')`

You can use shared state in your tools and agents. Here's how:

<Tabs>

<Tab title="Within a Tool: Setting a value">
  To set a value in the shared state within a tool, use the `self._shared_state.set` inside your tool. For example, you can store the context retrieved from a database in the shared state:
    ```python
    class QueryDatabase(BaseTool):
        """
        Retrieves data from the database and stores it in the shared state.
        """
        question: str = Field(..., description="The query to execute.")

        def run(self):
            # Fetch data based on the question
            context = query_database(self.question)
            # Store the context in shared state
            self._shared_state.set('context', context)
            return "Context has been retrieved and stored successfully."
    ```
</Tab>

<Tab title="Within a Tool: Using the value">
  To get a value from the shared state within a tool, use `self._shared_state.get`. Continuing the previous example, you can ensure that the Agent has called the `QueryDatabase` tool before proceeding:
    ```python
    class AnswerQuestion(BaseTool):
        """
        Provides answers based on the context stored in shared state.
        """
        def run(self):
            # Access the stored context
            context = self._shared_state.get('context')
            if not context:
                return "Context is missing. Please call QueryDatabase tool first."
            # Generate an answer using the context
            answer = f"Answer derived from context: {context}"
            return answer
    ```
</Tab>

<Tab title="Within an Agent: Using the value">
  You can use the shared state within your agent's `response_validator` method to validate responses. For example, you can verify if the agent's response matches content stored in the shared state:
    ```python
    class MyAgent(Agent):
        """
        An agent that utilizes shared state to validate responses.
        """
        def response_validator(self, message: str) -> str:
            """Validate the response before returning it."""
            context = self.shared_state.get('context')
            if message not in context:
                raise ValueError(f"Invalid response: {message} is not in context: {context}")
            return message
    ```
</Tab>

</Tabs>



================================================
FILE: docs/additional-features/streaming.mdx
================================================
---
title: "Streaming"
description: "Implementing streaming in Agency Swarm."
icon: "ellipsis"
---

Streaming enables agents to return outputs immidiately, significantly improving user experience. Instead of waiting for the entire response to be generated, the user can see the response being generated in real-time.

## Streaming Responses

To stream the conversation between agents, you can use the `get_completion_stream` method with your own event handler. The process follows a similar pattern to the [official OpenAI documentation](https://platform.openai.com/docs/api-reference/assistants-streaming).

The only difference is that you must extend the `AgencyEventHandler` class, which has 2 additional properties: `agent_name` and `recipient_agent_name`, to get the names of the agents communicating with each other. (See the `on_text_created` below.)

```python
from typing_extensions import override
from agency_swarm import AgencyEventHandler

class EventHandler(AgencyEventHandler):
    @override
    def on_text_created(self, text) -> None:
        # Get the name of the agent that is sending the message
        print(f"\n{self.recipient_agent_name} @ {self.agent_name}  > ", end="", flush=True)

    @override
    def on_text_delta(self, delta, snapshot):
        print(delta.value, end="", flush=True)

    def on_tool_call_created(self, tool_call):
        print(f"\n{self.recipient_agent_name} > {tool_call.type}\n", flush=True)

    def on_tool_call_delta(self, delta, snapshot):
        if delta.type == 'code_interpreter':
            if delta.code_interpreter.input:
                print(delta.code_interpreter.input, end="", flush=True)
            if delta.code_interpreter.outputs:
                print(f"\n\noutput >", flush=True)
                for output in delta.code_interpreter.outputs:
                    if output.type == "logs":
                        print(f"\n{output.logs}", flush=True)

    @classmethod
    def on_all_streams_end(cls):
        print("\n\nAll streams have ended.")  # Conversation is over and message is returned to the user.

response = agency.get_completion_stream("I want you to build me a website", event_handler=EventHandler)
```

<Note>
  The `on_all_streams_end` class method is called when all streams have ended. This is particularly important since your
  event handler might be called multiple times and possibly by multiple agents, unlike in the official OpenAI
  documentation.
</Note>



================================================
FILE: docs/additional-features/custom-communication-flows/common-use-cases.mdx
================================================
---
title: "Common Use Cases"
description: "Explore common use cases for custom communication flows in Agency Swarm."
icon: "code"
---

In the following sections, we'll look at some common use cases for extending the `SendMessageBase` tool and how to implement them, so you can learn how to create your own SendMessage tools and use them in your own applications.

#### 1. Adjusting parameters and descriptions

The most basic use case is if you want to use your own parameter descriptions, such as if you want to change the docstring or the description of the `message` parameter. This can help you better customize how the agents communicate with each other and what information they relay.

Let's say that instead of sending messages, I want my agents to send tasks to each other. In this case, I can change the docstring and the `message` parameter to a `task` parameter to better fit the nature of my application.

```python
from pydantic import Field
from agency_swarm.tools.send_message import SendMessageBase

class SendMessageTask(SendMessageBase):
    """Use this tool to send tasks to other agents within your agency."""
    chain_of_thought: str = Field(
        ...,
        description="Please think step-by-step about how to solve your current task, provided by the user. Then, break down this task into smaller steps and issue each step individually to the recipient agent via the task parameter."
    )
    task: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to include all the relevant information needed to complete the task."
    )

    def run(self):
        return self._get_completion(message=self.task)
```

To remove the chain of thought, you can simply remove the `chain_of_thought` parameter.

#### 2. Adding custom validation logic

Now, let's say that I need to ensure that my message is sent to the correct recipient agent. (This is a very common hallucination in production.) In this case, I can add a custom validator to the `recipient` parameter, which is defined in the `SendMessageBase` class. Since I don't want to change any other parameters or descriptions, I can inherit the default `SendMessage` class and only add this new validation logic.

```python
from agency_swarm.tools.send_message import SendMessage
from pydantic import model_validator

class SendMessageValidation(SendMessage):
    @model_validator(mode='after')
    def validate_recipient(self):
        if "customer support" not in self.message.lower() and self.recipient == "CustomerSupportAgent":
            raise ValueError("Messages not related to customer support cannot be sent to the customer support agent.")
        return self
```

You can, of course, also use GPT for this:

```python
from agency_swarm.tools.send_message import SendMessage
from agency_swarm.util.validators import llm_validator
from pydantic import model_validator

class SendMessageLLMValidation(SendMessage):
    @model_validator(mode='after')
    def validate_recipient(self):
        if self.recipient == "CustomerSupportAgent":
            llm_validator(
                statement="The message is related to customer support."
            )(self.message)
        return self
```

In this example, the `llm_validator` will throw an error if the message is not related to customer support. The caller agent will then have to fix the recipient or the message and send it again! This is extremely useful when you have a lot of agents.

#### 3. Summarizing previous conversations with other agents and adding to context

Sometimes, when using default `SendMessage`, the agents might not relay all the necessary details to the recipient agent, especially when the previous conversation is too long. In this case, you can summarize the previous conversation with GPT and add it to the context, instead of the additional instructions. I will extend the `SendMessageQuick` class, which already contains the `message` parameter, as I don't need chain of thought or files in this case.

```python
from agency_swarm.tools.send_message import SendMessageQuick
from agency_swarm.util.oai import get_openai_client

class SendMessageSummary(SendMessageQuick):
    def run(self):
        client = get_openai_client()
        thread = self._get_main_thread() # get the main thread (conversation with the user)

        # get the previous messages
        previous_messages = thread.get_messages()
        previous_messages_str = "\n".join([f"{m.role}: {m.content[0].text.value}" for m in previous_messages])

        # summarize the previous conversation
        summary = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "You are a world-class summarizer. Please summarize the following conversation in a few sentences:"},
                {"role": "user", "content": previous_messages_str}
            ]
        )

        # send the message with the summary
        return self._get_completion(message=self.message, additional_instructions=f"\n\nPrevious conversation summary: '{summary.choices[0].message.content}'")
```

With this example, you can add your own custom logic to the `run` method. It does not have to be a summary; you can also use it to add any other information to the context. For example, you can even query a vector database or use an external API.

#### 4. Running each agent in a separate API call

If you are a PRO, and you have managed to deploy each agent in a separate API endpoint, instead of using `_get_completion()`, you can call your own API and let the agents communicate with each other over the internet.

```python
import requests
from agency_swarm.tools.send_message import SendMessage

class SendMessageAPI(SendMessage):
    def run(self):
        response = requests.post(
            "https://your-api-endpoint.com/send-message",
            json={"message": self.message, "recipient": self.recipient}
        )
        return response.json()["message"]
```

This is very powerful, as you can even allow your agents to collaborate with agents outside your system. More on this is coming soon!

<Tip title="Contributing">
  If you have any ideas for new communication flows, please either adjust this page in docs, or add your new send
  message tool in the `agency_swarm/tools/send_message` folder and open a PR!
</Tip>

**After implementing your own `SendMessage` tool**, simply pass it into the `send_message_tool_class` parameter when initializing the `Agency` class:

```python
agency = Agency(
    ...
    send_message_tool_class=SendMessageAPI
)
```

That's it! Now, your agents will use your own custom `SendMessageAPI` class for communication!



================================================
FILE: docs/additional-features/custom-communication-flows/overview.mdx
================================================
---
title: "Overview"
description: "Learn how to customize communication flows for your agency."
icon: "globe"
---

Multi-agent communication is the core functionality of any Multi-Agent System. Unlike in all other frameworks, Agency Swarm not only allows you to define communication flows in any way you want (uniform communication flows), but also to configure the underlying logic for this feature. This means that you can create entirely new types of communication or adjust it to your own needs. Below you will find a guide on how to do all this, along with some common examples.

## Pre-Made SendMessage Classes

Agency Swarm contains multiple commonly requested classes for communication flows. Currently, the following classes are available:

| Class Name                  | Description                                                                                                                                                                                                                               | When to Use                                                                                                    | Code Link                                                                                                            |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| `SendMessage` (default)     | This is the default class for sending messages to other agents. It uses synchronous communication with basic COT (Chain of Thought) prompting and allows agents to relay files and modify system instructions for each other.             | Suitable for most use cases. Balances speed and functionality.                                                 | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessage.py)               |
| `SendMessageQuick`          | A variant of the SendMessage class without Chain of Thought prompting, files, and additional instructions. It allows for faster communication without the overhead of COT.                                                                | Use for simpler use cases or when you want to save tokens and increase speed.                                  | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageQuick.py)          |
| `SendMessageAsyncThreading` | Similar to `SendMessage` but with `async_mode='threading'`. Each agent will execute asynchronously in a separate thread. In the meantime, the caller agent can continue the conversation with the user and check the results later.       | Use for asynchronous applications or when sub-agents take significant amounts of time to complete their tasks. | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageAsyncThreading.py) |
| `SendMessageSwarm`          | Instead of sending a message to another agent, it replaces the caller agent with the recipient agent, similar to [OpenAI's Swarm](https://github.com/openai/swarm). The recipient agent will then have access to the entire conversation. | When you need more granular control. It is not able to handle complex multi-step, multi-agent tasks.           | [link](https://github.com/VRSEN/agency-swarm/blob/main/agency_swarm/tools/send_message/SendMessageSwarm.py)          |

**To use any of the pre-made `SendMessage` classes**, simply put it in the `send_message_tool_class` parameter when initializing the `Agency` class:

```python
from agency_swarm.tools.send_message import SendMessageQuick

agency = Agency(
    ...
    send_message_tool_class=SendMessageQuick
)
```

That's it! Now, your agents will use your own custom `SendMessageQuick` class for communication.

## Creating Your Own Unique Communication Flows

To create your own communication flow, you will first need to extend the `SendMessageBase` class. This class extends the `BaseTool` class, like any other tools in Agency Swarm, and contains the most basic parameters required for communication, such as the `recipient_agent`.

### Default `SendMessage` Class

By default, Agency Swarm uses the following tool for communication:

```python
from pydantic import Field, field_validator, model_validator
from .SendMessageBase import SendMessageBase

class SendMessage(SendMessageBase):
    """Use this tool to facilitate direct, synchronous communication between specialized agents within your agency. When you send a message using this tool, you receive a response exclusively from the designated recipient agent. To continue the dialogue, invoke this tool again with the desired recipient agent and your follow-up message. Remember, communication here is synchronous; the recipient agent won't perform any tasks post-response. You are responsible for relaying the recipient agent's responses back to the user, as the user does not have direct access to these replies. Keep engaging with the tool for continuous interaction until the task is fully resolved. Do not send more than 1 message to the same recipient agent at the same time."""
    my_primary_instructions: str = Field(
        ...,
        description=(
            "Please repeat your primary instructions step-by-step, including both completed "
            "and the following next steps that you need to perform. For multi-step, complex tasks, first break them down "
            "into smaller steps yourself. Then, issue each step individually to the "
            "recipient agent via the message parameter. Each identified step should be "
            "sent in a separate message. Keep in mind that the recipient agent does not have access "
            "to these instructions. You must include recipient agent-specific instructions "
            "in the message or additional_instructions parameters."
        )
    )
    message: str = Field(
        ...,
        description="Specify the task required for the recipient agent to complete. Focus on clarifying what the task entails, rather than providing exact instructions. Make sure to include all the relevant information needed to complete the task."
    )
    message_files: list[str] | None = Field(
        default=None,
        description="A list of file IDs to be sent as attachments to this message. Only use this if you have the file ID that starts with 'file-'.",
        examples=["file-1234", "file-5678"]
    )
    additional_instructions: Optional[str] = Field(
        default=None,
        description="Additional context or instructions from the conversation needed by the recipient agent to complete the task."
    )

    @model_validator(mode='after')
    def validate_files(self):
        # prevent hallucinations with agents sending file IDs into incorrect fields
        if "file-" in self.message or (self.additional_instructions and "file-" in self.additional_instructions):
            if not self.message_files:
                raise ValueError("You must include file IDs in message_files parameter.")
        return self


    def run(self):
        return self._get_completion(message=self.message,
                                    message_files=self.message_files,
                                    additional_instructions=self.additional_instructions)
```

Let's break down the code.

In general, all `SendMessage` tools have the following components:

1. **The Docstring**: This is used to generate a description of the tool for the agent. This part should clearly describe how your multi-agent communication works, along with some additional guidelines on how to use it.
2. **Parameters**: Parameters like `message`, `message_files`, `additional_instructions` are used to provide the recipient agent with the necessary information.
3. **The `run` method**: This is where the communication logic is implemented. Most of the time, you just need to map your parameters to `self._get_completion()` the same way you would call it in the `agency.get_completion()` method.

When creating your own `SendMessage` tools, you can use the above components as a template.

### Common Use Cases

For detailed **Common Use Cases**, please refer to the [Common Use Cases](./common-use-cases) subpage.

## Conclusion

Agency Swarm has been designed to give you, the developer, full control over your systems. It is the only framework that does not hard-code any prompts, parameters, or even worse, agents for you. With this new feature, the last part of the system that you couldn't fully customize to your own needs is now gone!

So, we want to encourage you to keep experimenting and designing your own unique communication flows. While the examples above should serve as a good starting point, they do not even merely scratch the surface of what's possible here! We are looking forward to seeing what you will create. Please share it in our [Discord server](https://discord.gg/7HcABDpFPG) so we can all learn from each other.



================================================
FILE: docs/contributing/contributing.mdx
================================================
---
title: "Contributing to Agency Swarm"
description: "Learn how to contribute to Agency Swarm"
icon: "code-fork"
---

We welcome contributions to Agency Swarm! By contributing, you help improve the framework for everyone. Here's how you can get involved:

## Setting Up Your Development Environment

### Prerequisites

- Python 3.10 or higher
- Pip
- Git

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/VRSEN/agency-swarm.git
   cd agency-swarm
   ```
2. Create and activate a virtual environment (recommended):
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows use `.venv\Scripts\activate`
   ```
3. Install dependencies including development tools:
   ```bash
   pip install -e ".[dev]"
   ```

4. Install Pre-Commit Hooks:
   ```bash
   pip install pre-commit
   pre-commit install
   ```

## Running Tests

<Tip>
  Testing ensures that your contributions work as intended and do not break existing functionality.
</Tip>

<Steps titleSize="h3">

<Step title="Install Test Dependencies" icon="download" iconType="solid">
Ensure all test dependencies are installed.

```bash
pip install -e ".[dev]"
```

</Step>

<Step title="Run Tests" icon="play" iconType="solid">
Run the test suite using Pytest.

```bash
pytest
```

</Step>

<Step title="Check Test Coverage" icon="chart-bar" iconType="solid">
Check the test coverage to ensure comprehensive testing.

```bash
pytest --cov=agency_swarm tests/
```

</Step>

</Steps>

## Submitting Changes

<AccordionGroup>

  <Accordion title="Create Branch" icon="code-branch" iconType="solid">
    Create a branch for your work:
    ```bash
    git checkout -b feature/your-feature-name
    ```
  </Accordion>

  <Accordion title="Commit Changes" icon="git" iconType="solid">
    Commit your updates:
    ```bash
    git add .
    git commit -m "Add [feature]: Description"
    ```
  </Accordion>

  <Accordion title="Push Branch" icon="code-fork" iconType="solid">
    Push your branch:
    ```bash
    git push origin feature/your-feature-name
    ```
  </Accordion>

  <Accordion title="Open PR" icon="paper-plane" iconType="solid">
    Open a pull request on GitHub:
    ```markdown
    - Provide a concise title and description.
    - Reference related issues.
    ```
  </Accordion>

</AccordionGroup>

### Code Style and Linting

This project uses `ruff` for linting and code formatting. Configuration for this tool can be found in `pyproject.toml`.

Before committing your changes, please check and fix linting errors:

```bash
ruff check . --fix
```

It's recommended to install these tools in your development environment. If you followed the setup instructions, they should already be installed via:

```bash
pip install -e ".[dev]"
```



================================================
FILE: docs/core-framework/state-management.mdx
================================================
---
title: "State Management"
description: "Learn how Agency Swarm manages state across agents and sessions."
icon: "database"
---

Agency Swarm conveniently manages the state of your agents and threads, simplifying the assistant creation and management process on [OpenAI's Assistants API](https://platform.openai.com/docs/assistants/deep-dive).

## Agent State Management

In OpenAI Assistants API, all agents need to be updated before they can be used. Agency Swarm manages this by maintaining a local `settings.json` file, and the comparing local settings with the ones stored on OpenAI's servers. If there are any differences, the Assistants are updated on OpenAI's servers. This ensures that the agents are only created once, and are only updated when needed.

<img src="/images/state-management.png" alt="State Management" />

## Thread State Management

Additionally, OpenAI's Assistants API manages the conversation context through threads. A thread represents a persistent conversation between an assistant and a user, automatically handling the storage and truncation of messages to fit within the model's context window. This approach offloads the complexity of conversation state management to OpenAI, ensuring efficient and seamless context handling.

<CardGroup cols={2}>
  <Card title="Persistent Conversations" icon="messages">
    Maintains ongoing conversations without manual history management.
  </Card>
  <Card title="Automatic Context Management" icon="scissors">
    Handles message storage and truncation within token limits.
  </Card>
</CardGroup>

## Next Steps

- [Read all available agent parameters](/core-framework/agents/overview)
- [Learn how to manage your agents on a remote server](/additional-features/deployment-to-production)



================================================
FILE: docs/core-framework/agencies/agency-parameters.mdx
================================================
---
title: "Agency Parameters"
description: "Explanation of parameters in Agency class."
icon: "sliders"
---

## Shared Instructions (Agency Manifesto)

The `agency_manifesto.md` file contains instructions that will be shared among all agents in the agency.

Here is a template to help get you started:

```markdown
# Agency Manifesto

[Description of your agency]

## Mission Statement

[Your mission statement]

## Operating Environment

[Description of your operating environment]
```

To use the manifesto, simply specify the path to your manifesto in the `Agency` class.

```python
agency = Agency(
    agency_chart=[...],
    shared_instructions='agency_manifesto.md',
    ...
)
```

## Shared Files

Shared files allow you to share certain files among all agents in the agency. All your agents will than be able to use these files with `FileSearch` and `CodeInterpreter` tools.

To use shared files, simply put them in a folder and specify the folder path in a `shared_files` parameter.

```python
agency = Agency([ceo], shared_files='my_shared_files_folder')
```

## Default Parameters

Some parametrs in `Agency` class mimic those in `Agent` class.

**In case if the parameter is defined in both classes, the value from `Agent` class will be used.**

```python
agency = Agency([ceo], temperature=0.3, max_prompt_tokens=25000)
```

You can use the folloing parameters to set default values for the entire agency:

- `temperature`
- `top_p`
- `max_completion_tokens`
- `max_prompt_tokens`
- `truncation_strategy`

## Custom Settings Path

By default, Agency Swarm keeps the state of your agents in a special `settings.json` file. If you would like to use a different file path for settings, you can specify a `settings_path` parameter:

```python
agency = Agency([ceo], settings_path='my_settings.json')
```

If this file does not exist, it will be created, along with new Assistants on your OpenAI account.



================================================
FILE: docs/core-framework/agencies/communication-flows.mdx
================================================
---
title: "Communication Flows"
description: "Understanding communication flows in Agency Swarm."
icon: "comments"
---

Unlike all other frameworks, communication flows in Agency Swarm are **not hierarchical** or **sequential**. Instead, they are **uniform**, which means you can define them in any way you want.

## Defining Your Own Communication Flows

Communication flows in Agency Swarm are established from left to right inside the `agency_chart`. So, in the example below, the CEO can initiate communication and send tasks to the Developer and the Virtual Assistant, and it can respond back to him in the same thread, but the Developer or the VA cannot initiate a conversation and assign tasks to the CEO.

```python
from agency_swarm import Agency

agency = Agency([
    ceo, dev  # CEO and Developer will be the entry point for communication with the user
    [ceo, dev],  # CEO can initiate communication with Developer
    [ceo, va],   # CEO can initiate communication with Virtual Assistant
    [dev, va]    # Developer can initiate communication with Virtual Assistant
])
```

All agents added inside the top-level list of `agency_chart` (`ceo, dev`), can talk to the user.

To allow Developer to initiate communication with the CEO, you need to simply add it to the `agency_chart` list:

```python
agency = Agency([
    ceo, dev, [dev, ceo]  # Developer can initiate communication with the CEO
])
```

You can add as many levels of communication as you want.

## Under the Hood

Agency Swarm uses a special `SendMessage` to allow agents to communicate with each other. By adding agents to the second-level list, it simply adds a new recipient to the `SendMessage` function. If you'd like to modify the behavior of this tool, you can do so by creating your own [Custom Communication Flows](/additional-features/custom-communication-flows/overview) (**Advanced**).



================================================
FILE: docs/core-framework/agencies/overview.mdx
================================================
---
title: "Overview"
description: "Understanding agencies in Agency Swarm."
icon: "globe"
---

Agency in Agency Swarm is a collection of agents that can collaborate with one another.

## Benefits of Using an Agency

Utilizing an Agency consisting of multiple agents offers several benefits:

<CardGroup cols={3}>
<Card title="Fewer Hallucinations" icon="bug" iconType="solid">
  Agents within an agency can supervise each other, reducing mistakes and handling unexpected scenarios more effectively.
</Card>

<Card title="Complex Tasks" icon="diagram-project" iconType="solid">
  Adding more agents allows for longer sequences of actions, enabling the completion of more complex tasks before delivering results to the user.
</Card>

<Card title="Scalability" icon="arrow-up-right-dots" iconType="solid">
  Agencies allow you to scale your solutions seamlessly by adding more agents, as the complexity of your system grows.
</Card>
</CardGroup>

<Tip>
  Start with a minimal number of agents. Fine-tune them to ensure they function correctly before adding more.
  Introducing too many agents initially can make debugging and understanding interactions challenging.
</Tip>



## Agency Parameters

Overview of parameters in `Agency` class:

| Name | Parameter | Description |
|------|-----------|-------------|
| Agency Chart | `agency_chart` | A list that defines the hierarchy and interaction patterns between agents. It specifies:<br/>1. Individual agents that can interact with users<br/>2. Agent pairs that can communicate with each other<br/><br/>Example: `[agent1, [agent1, agent2]]`<br/>- `agent1` has user interaction permissions<br/>- `agent1` can communicate with `agent2` |
| Shared Instructions *(optional)* | `shared_instructions` | Path to a file containing instructions shared across all agents. Can be a relative path from the agency's folder or an absolute path. Default: empty string |
| Shared Files *(optional)* | `shared_files` | Path to a folder or list of folders containing files accessible by all agents. These files are added to each agent's files folder. Default: `None` |
| Async Mode *(optional)* | `async_mode` | Specifies the asynchronous processing mode. Options:<br/>- `"threading"`: All sub-agents run in separate threads<br/>- `"tools_threading"`: All tools run in separate threads, but agents do not<br/>Default: `None` |
| Settings Path *(optional)* | `settings_path` | Path to the JSON settings file for the agency. If file doesn't exist, it will be created. Default: `"./settings.json"` |
| Settings Callbacks *(optional)* | `settings_callbacks` | Dictionary containing functions to load and save settings. Must include both `"load"` and `"save"` functions. Both functions must be defined. Default: `None` |
| Threads Callbacks *(optional)* | `threads_callbacks` | Dictionary containing functions to load and save threads. Must include both `"load"` and `"save"` functions. Both functions must be defined. Default: `None` |
| Temperature *(optional)* | `temperature` | Controls response randomness (0.0 to 1.0). Agent-specific values override this. Lower values make responses more focused and deterministic. Default: `0.3` |
| Top P *(optional)* | `top_p` | Alternative to temperature for controlling response randomness (0.0 to 1.0). Agent-specific values override this. Default: `1.0` |
| Max Prompt Tokens *(optional)* | `max_prompt_tokens` | Maximum tokens allowed in the prompt for each agent. Agent-specific values override this. Default: `None` |
| Max Completion Tokens *(optional)* | `max_completion_tokens` | Maximum tokens allowed in the completion for each agent. Agent-specific values override this. Default: `None` |
| Truncation Strategy *(optional)* | `truncation_strategy` | Dictionary configuring how to handle token limits. Agent-specific values override this. See [OpenAI documentation](https://platform.openai.com/docs/api-reference/runs/createRun#runs-createrun-truncation_strategy) for details. Default: `None` |

## Example

Quick example of how to create an agency with 3 agents:

```python
from agency_swarm import Agency
from .ceo import CEO
from .developer import Developer
from .virtual_assistant import VirtualAssistant

ceo = CEO()
dev = Developer()
va = VirtualAssistant()

agency = Agency([
    ceo, dev  # CEO and Developer will be the entry point for communication with the user
    [ceo, dev],  # CEO can initiate communication with Developer
    [ceo, va],   # CEO can initiate communication with Virtual Assistant
    [dev, va]    # Developer can initiate communication with Virtual Assistant
])
```

## Next Steps

Make sure to learn more about [Communication Flows](/core-framework/agencies/communication-flows), [Agency Parameters](/core-framework/agencies/agency-parameters), and [Running an Agency](/core-framework/agencies/running-agency).



================================================
FILE: docs/core-framework/agencies/running-agency.mdx
================================================
---
title: "Running an Agency"
description: "How to run an Agency."
icon: "rocket"
---

When it comes to running your agency, you have 3 options:

1. **Gradio Interface**: The most convenient way to get started.
2. **Get Completion**: For backend or custom integrations.
3. **Terminal Version**: Best for quick debugging and testing.

## Gradio Interface

To open a convenient Gradio interface in your browser, use the `demo_gradio` method:

```python
agency.demo_gradio(height=700)
```

Simply follow the `localhost` link from the terminal to start using your agency.

## Get Completion

To get a response from your agency directly in code, use the `get_completion` method:

```python
response = agency.get_completion("I want you to build me a website",
                                 additional_instructions="This is an additional instruction for the task.",
                                 tool_choice={"type": "function", "function": {"name": "SendMessage"}},
                                 attachments=[],
                                 recipient_agent=dev,
                                 )
print(response)
```

**Parameters**:

- `message`: The message to send to the agency.
- `additional_instructions` (optional): Additional instructions that will be appended at the end of instructions for the recipient agent.
- `tool_choice` (optional): Force the recipient agent to use a specific tool.
- `attachments` (optional): A list of attachments to be sent with the message, following [OpenAI format](https://platform.openai.com/docs/api-reference/messages/createMessage#messages-createmessage-attachments).
- `recipient_agent` (optional): The agent to which the message should be sent.

### Image attachments

When using the `get_completion` method, you can also pass an array of message objects to use vision capabilities (if your llm model supports it):

```python
message_objects = [
    {
        "type": "text",
        "text": "What is presented on these pictures?"
    },
    {
        "type": "image_file",
        "image_file": {"file_id": file_id}
    },
    {
        "type": "image_url",
        "image_url": {"url": "https://example.com/image.png"}
    }
]

response = agency.get_completion(message=message_objects)
print(response)
```

## Terminal Version

To run the agency directly from your terminal, use the `run_demo` method:

```bash
agency.run_demo()
```
<Tip>
When using the terminal to run the agency, you can send messages directly to any top-level agent by using the "mentions" feature. To do this, start your message with the agent's name preceded by an @ symbol (for example, `@Developer I want you to build me a website`). This directs your message to the specified agent instead of the CEO. You can also press the tab key to autocomplete the agent's name.
</Tip>

---

## Deleting Agency

If you would like to delete the agency and all associated files, vector stores, and assistants on OpenAI, you can use the `delete` method:

```python
agency.delete()
```



================================================
FILE: docs/core-framework/agents/advanced-configuration.mdx
================================================
---
title: "Advanced Configuration"
description: "Learn advanced configuration options for your agents in Agency Swarm."
icon: "gears"
---

All parameters inside the `Agent` class, follow the same structure as [OpenAI's Assistants API](https://platform.openai.com/docs/api-reference/assistants). However, there are a few advanced parameters that require more explanation.

### Parallel Tool Calls

Whether to run tools in parallel or sequentially. By default, this parameter is set to `True`.

```python
from agency_swarm import Agent

agent = Agent(name='MyAgent', parallel_tool_calls=False)
```

### File Search Configuration

File search configuration for the agent, as described in the [OpenAI documentation](https://platform.openai.com/docs/api-reference/assistants/createAssistant#assistants-createassistant-tools).

```python
from agency_swarm import Agent

agent = Agent(
    name='MyAgent',
    file_search={
        'max_num_results': 25,
        'ranking_options': {
            "score_threshold": 0.5,
            "ranker": "auto"
        }
    }
)
```

Parameters:
- `max_num_results`: The maximum number of results the file search tool should output. The default is 20 for `gpt-4*` models and 5 for `gpt-3.5-turbo`. This number should be between 1 and 50 inclusive. Note that the file search tool may output fewer than `max_num_results` results.
- `ranking_options`: The ranking options for the file search. If not specified, the file search tool will use the `auto` ranker and a score_threshold of 0. See the [file search tool documentation](https://platform.openai.com/docs/assistants/tools/file-search#customizing-file-search-settings) for more information.

### Response Validator

This is a special function that allows you to validate the response before sending it to the user or another agent. This function should raise an error if the response is invalid. The agent will then see this error as the user message and try correct itself accordingly.

```python

from agency_swarm import Agent

class MyAgent(Agent):
    def response_validator(self, message: str) -> str:
        """This function is used to validate the response before sending it to the user or another agent."""
        if "bad word" in message:
            raise ValueError("Please don't use bad words.")

        return message
```

### Few-Shot Examples

Few-show examples help the agent to understand how to respond. The format for examples follows [message object format on OpenAI](https://platform.openai.com/docs/api-reference/messages/createMessage):

```python
from agency_swarm import Agent

examples=[
    {
        "role": "user",
        "content": "Hi!",
        "attachments": [],
        "metadata": {},
    },
    {
        "role": "assistant",
        "content": "Hi! I am the CEO. I am here to help you with your tasks. Please tell me what you need help with.",
        "attachments": [],
        "metadata": {},
    }
]

agent = Agent(
    name='MyAgent',
    examples=examples
)
```



================================================
FILE: docs/core-framework/agents/built-in-tools.mdx
================================================
---
title: "Built-in Tools"
description: "Learn how to use built-in tools in Agency Swarm."
icon: "wrench"
---

Each agent in Agency Swarm also with some built-in tools inherited from [OpenAI Assistants API](https://platform.openai.com/docs/api-reference/assistants/createAssistant#assistants-createassistant-tools).


## Code Interpreter

Code Interpreter allows agents to execute code within a remote Jupyter Notebook environment.

```python
from agency_swarm.tools import CodeInterpreter

agent = Agent(
    name="DataAnalyst",
    tools=[CodeInterpreter],
    # Other agent parameters
)
```

**When to use:**
- To perform data analysis and precise calculations.
- To handle structured files (CSV, Excel, etc.).
- To run standalone code snippets in a remote environment.

## File Search

File Search allows agents to search through their knowledge base to improve their responses. This tool uses a production-ready vector database provided by OpenAI.

```python
  from agency_swarm.tools import FileSearch

  agent = Agent(
      name="Researcher",
      tools=[FileSearch],
      # Optionally, you can specify your own vector store ID to use:
      tool_resources={
        "file_search": {
          "vector_store_ids": ["vs_abc123"],
        },
      },
      # More details can be found here: https://platform.openai.com/docs/api-reference/vector-stores/object
      # Other agent parameters
  )
  ```

**When to use:**
- To enrich your agent's knowledge about specific topics
- To reduce hallucinations by grounding agent responses in your documents
- To enable users to query their own documents



================================================
FILE: docs/core-framework/agents/overview.mdx
================================================
---
title: "Overview"
description: "Understanding Agents in Agency Swarm."
icon: "globe"
---

Agents are the core building blocks of the Agency Swarm framework. Each agent is specialized for a specific role and is designed to perform a specific set of processes within an agency.

## Key Characteristics of Agents

<CardGroup cols={3}>
  <Card
    title="Autonomous"
    icon="robot"
  >
    Agents can determine the next best actions by themselves.
  </Card>

  <Card
    title="Adaptive"
    icon="bolt"
  >
    Agents adapt their course of action based on real-time feedback.
  </Card>

  <Card
    title="Interactive"
    icon="wrench"
  >
    Agents can manipulate their environment by using tools.
  </Card>
</CardGroup>

## Agent Parameters

From a technical perspective, in Agency Swarm, agents are essentially wrappers for [OpenAI Assistants](https://platform.openai.com/docs/assistants/deep-dive#creating-assistants). The `Agent` class includes convenience methods to help you manage the state of your assistant, upload files, attach tools, and more:

| Name | Parameter | Description |
|------|-----------|-------------|
| ID *(optional)* | `id` | Loads the assistant from OpenAI assistant ID. Assistant will be created or loaded from settings if ID is not provided. Default: `None` |
| Name *(optional)* | `name` | Name of the agent. Default: Uses the class name |
| Description *(optional)* | `description` | A brief description of the agent's purpose. Default: `None` |
| Instructions *(optional)* | `instructions` | Path to a file containing specific instructions for the agent. Default: Empty string |
| Tools *(optional)* | `tools` | A list of tool classes that the agent can use (BaseTool, FileSearch, or CodeInterpreter). Default: `None` |
| Tool Resources *(optional)* | `tool_resources` | Resources used by the assistant's tools. For example, code_interpreter requires file IDs, while file_search requires vector store IDs. Default: `None` |
| Temperature *(optional)* | `temperature` | Controls randomness in the agent's responses. Lower values make responses more focused and deterministic. Default: `None` |
| Top P *(optional)* | `top_p` | Alternative to temperature for controlling response randomness. Default: `None` |
| Response Format *(optional)* | `response_format` | Specifies the format for agent responses. Can be a string, dict, or Pydantic BaseModel. Default: `"auto"` |
| Tools Folder *(optional)* | `tools_folder` | Path to a directory containing tools. Each tool must be in a separate file named after the tool class. Default: `None` |
| Files Folder *(optional)* | `files_folder` | Path or list of paths to directories containing files for the agent. Default: `None` |
| Schemas Folder *(optional)* | `schemas_folder` | Path or list of paths to directories containing OpenAPI schemas. Default: `None` |
| API Headers *(optional)* | `api_headers` | Headers for OpenAPI requests. Keys must match schema filenames. Default: Empty dict |
| API Params *(optional)* | `api_params` | Extra parameters for OpenAPI requests. Keys must match schema filenames. Default: Empty dict |
| Metadata *(optional)* | `metadata` | Additional metadata for the agent. Default: Empty dict |
| Model *(optional)* | `model` | The OpenAI model to use. Default: `"gpt-4o-2024-08-06"` |
| Validation Attempts *(optional)* | `validation_attempts` | Number of attempts to validate responses. Default: `1` |
| Max Prompt Tokens *(optional)* | `max_prompt_tokens` | Maximum tokens allowed in the prompt. Default: `None` |
| Max Completion Tokens *(optional)* | `max_completion_tokens` | Maximum tokens allowed in completions. Default: `None` |
| Truncation Strategy *(optional)* | `truncation_strategy` | Strategy for handling token limits. Default: `None` |
| Examples *(optional)* | `examples` | List of example messages for the agent. Default: `None` |
| File Search *(optional)* | `file_search` | Configuration for the file search tool. Default: `None` |
| Parallel Tool Calls *(optional)* | `parallel_tool_calls` | Whether to run tools in parallel. Default: `True` |
| Refresh From ID *(optional)* | `refresh_from_id` | Whether to load and update the agent from OpenAI when an ID is provided. Default: `True` |

<Warning>
**Warning**: The `file_ids` parameter is deprecated. Use the `tool_resources` parameter instead.
</Warning>

## Agent Template

It's recommended to create your agent in a seprate file. Your agent class should look like this:

```python
from agency_swarm import Agent

class AgentName(Agent):
    def __init__(self):
        super().__init__(
            name="agent_name",
            description="agent_description",
            instructions="./instructions.md",
            files_folder="./files",
            schemas_folder="./schemas",
            tools_folder="./tools",
            tools=[],
            temperature=0.3,
            max_prompt_tokens=25000,
            examples=[]
        )
```

You can add more parameters to the `__init__` method.

To initialize the agent:

```python
from AgentName import AgentName

agent = AgentName()
```



================================================
FILE: docs/core-framework/tools/mcp-integration.mdx
================================================
---
title: 'MCP Integration'
description: 'Connect your agents to external tools and data using the Model Context Protocol (MCP).'
icon: "plug"
---

Agency Swarm agents can interact with a wider range of tools and data sources beyond their built-in capabilities by using the **Model Context Protocol (MCP)**. MCP is an open standard ([view specification](https://github.com/modelcontextprotocol/modelcontextprotocol)) that allows agents to communicate with external services like local file systems, databases, or custom APIs, as long as those services implement the protocol.

Think of MCP as a universal translator that lets your agent talk to specialized external tools.

## Why use MCP?

*   **Access Local Resources:** Let agents read/write local files or run local commands.
*   **Connect to Custom Services:** Integrate with proprietary APIs or internal tools without writing specific Agency Swarm tool wrappers for each one, provided an MCP server exists.
*   **Leverage Existing MCP Tools:** Utilize third-party tools that already support MCP.

## Supported MCP Server Types

Agency Swarm provides helpers to connect to the two common MCP transport protocols. Choose the server type based on how your tool provider operates:

<Accordion title="MCPServerStdio: For Command-Line Tools" icon="terminal">
Use this if your tool server is a **command-line program or script**. Agency Swarm will start this program for you and communicate with it directly using its standard input/output.

*   **When to use:** Your tool is a local script, an executable, or requires running a specific command to be activated (like the standard MCP filesystem server).
</Accordion>

<Accordion title="MCPServerSse: For Web Service Tools" icon="globe-pointer">
Use this if your tool server is already **running as a web service** at a specific **HTTP URL**. Agency Swarm connects to this URL to access tools exposed via Server-Sent Events (SSE).

*   **When to use:** Your tool is provided by a web API, a microservice, or any server accessible via an HTTP endpoint that speaks MCP+SSE (like the Python server in the demo).
</Accordion>


## Connecting Agents to MCP Servers

To give an agent access to MCP tools, you define the server connections and pass them to the agent's `mcp_servers` list during initialization. Agency Swarm then automatically discovers the tools offered by the server and makes them available to the agent under the `name` you specified (e.g., `Filesystem_Server.list_files`).

Follow these steps:

<Accordion title="Step 1: Define Stdio Server Connection (e.g., Filesystem)">
This example shows how to configure `MCPServerStdio` to run the standard MCP filesystem tool using `npx`.

```python
from agency_swarm.tools.mcp import MCPServerStdio

filesystem_server = MCPServerStdio(
    # This name determines how the agent accesses the tools (e.g., Filesystem_Server.list_files)
    name="Filesystem_Server",
    params={
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", "."], # Run in current directory
    },
    # cache_tools_list and strict are direct arguments for Stdio
    cache_tools_list=False,
    strict=False,

    # You can restrict the agent to using specific tools from the server by providing allowed_tools list
    allowed_tools = ["tool_1_name", "tool_2_name"]
)
```
</Accordion>

<Accordion title="Step 2: Define SSE Server Connection (Optional)">
This example shows how to configure `MCPServerSse` to connect to a hypothetical web server running locally that provides tools via SSE.

```python
from agency_swarm.tools.mcp import MCPServerSse

# Assumes your SSE server is running at this URL
sse_server = MCPServerSse(
    name="My_Custom_SSE_Server", # Tools will be accessed like My_Custom_SSE_Server.some_tool
    params={
        "url": "http://localhost:8080/sse",
    },
    cache_tools_list=False,
    strict=False,

    # Not providing allowed_tools will attach all available tools to the agent
)
```
</Accordion>

<Accordion title="Step 3: Initialize Agent with Servers">
Pass the list of configured server connections to the `mcp_servers` parameter when creating your `Agent`.

```python
from agency_swarm import Agent

# Assuming filesystem_server and sse_server are defined as above
my_mcp_agent = Agent(
    name="MCPAgent",
    description="An agent that can use filesystem and custom SSE tools.",
    instructions="Use the Filesystem_Server tools to manage files or My_Custom_SSE_Server tools for custom tasks.",
    # Pass the list of configured servers here
    mcp_servers=[filesystem_server, sse_server],
    temperature=0,
)

# Agency Swarm automatically discovers tools from the connected servers.
# Example: my_mcp_agent.tools will now include tools like
# 'Filesystem_Server.read_file', 'My_Custom_SSE_Server.get_data', etc.
```
</Accordion>


## Runnable Demo

For a practical, runnable example using both `MCPServerStdio` and `MCPServerSse`, see the `demo_mcp.py` script located in the `tests/demos/` directory of the Agency Swarm repository.

*   **Remember:** The demo requires you to run the example SSE server ([server.py](https://github.com/VRSEN/agency-swarm/blob/main/tests/scripts/server.py)) in a separate terminal first.

## Key Takeaways

*   MCP connects agents to external tools/data via standard protocols (Stdio, SSE).
*   Use `MCPServerStdio` for command-line tool servers and `MCPServerSse` for URL-based tool servers.
*   Define server connections using the appropriate class, providing `name`, `params`, and optionally configuring `strict` and `cache_tools_list`.
*   Pass configured server instances to the `Agent`'s `mcp_servers` parameter during initialization.
*   The `name` you give a server connection becomes the prefix for its tools (e.g., `MyServerName.tool_name`).
*   External MCP servers (especially SSE ones) must be running separately for the agent to connect to them.



================================================
FILE: docs/core-framework/tools/openapi-schemas.mdx
================================================
---
title: "OpenAPI Schemas"
description: "Convert OpenAPI schemas into tools."
icon: "brackets-curly"
---

Agency allows you to easily convert OpenAPI schemas into tools so your agents can interact with any external APIs. For example, by adding the Google Calendar API schema, your agent will be able to create, update, delete, and retrieve events from Google Calendar.

<Tip>
It is still recommended to create custom tools and wrap each API call into a `BaseTool` class, even if you have the OpenAPI schema. OpenAPI schemas allow you to get started quickly, however, for production, you might want to add some custom data validation, error handling, data processing or even combine multiple API calls into a single tool.
</Tip>

## How to Find OpenAPI Schemas

The recommended way to create OpenAPI schemas is to use [Actions GPT](https://chatgpt.com/g/g-TYEliDU6A-actionsgpt). Simply ask it to create a schema for the API you want to use and which actions you want to perform.

**If your API is public and well known**, it should be able to create a schema for you on the first try, without any extra documentation.

```
Create a schema for the Google Calendar API and include the following actions: create, update, delete, and get events.
```

**If your API is public but not well known**, we recommend searching for the API documentation manually and then sending a link to your API into the prompt:

```
Create a schema for the following API: https://api.example.com/openapi.json and include the following actions: create, update, delete, and get events.
```

**If you your API is private**, you can attach your API documentation in a file:

```
Create a schema for the API documentation attached in the file. Include the following actions: create, update, delete, and get events.
```

## How to Use OpenAPI Schemas

Below are the two ways to use OpenAPI schemas in your agents:

#### Option 1: Using the `schemas_folder`

The first way to integrate OpenAPI schemas is by placing all your OpenAPI schema files in a folder, and then initializing your agent with the `schemas_folder` parameter. Agency Swarm will then automatically scan this folder and convert any OpenAPI schemas it finds into `BaseTool` instances.

```python
from agency_swarm import Agent

agent = Agent(
    name='MyAgent',
    schemas_folder='schemas',
    api_params={'api_schema.json': {'param1': 'value1'}},
    api_headers={'api_schema.json': {'Authorization': 'Bearer token'}}
)
```

In this example:

- `schemas_folder`: Directory where your OpenAPI schema files are stored.
- `api_params`: Extra parameters for specific schemas.
- `api_headers`: Custom headers for API calls, like authentication tokens.



#### Option 2: Using the ToolFactory Class

Alternatively, you can use the `ToolFactory` class to convert OpenAPI schemas from local files or URLs.

```python
from agency_swarm.tools import ToolFactory

tools = ToolFactory.from_openapi_schema(
    "<your OpenAPI schema here>",
    headers={'api_schema.json': {'Authorization': 'Bearer token'}},
    params={'api_schema.json': {'param1': 'value1'}},
    strict=False
)
```

<Accordion title="Converting from a Local Schema File">
```python
from agency_swarm.tools import ToolFactory

with open("schemas/api_schema.json") as f:
    tools = ToolFactory.from_openapi_schema(f.read())
```
</Accordion>

<Accordion title="Converting from a Remote Schema URL">
```python
from agency_swarm.tools import ToolFactory
import requests

response = requests.get("https://api.example.com/openapi.json")
tools = ToolFactory.from_openapi_schema(response.json())
```
</Accordion>

Argument descriptions:

- `schema`: The OpenAPI schema to convert.
- `headers`: Custom headers for API calls, like authentication tokens.
- `params`: Extra parameters for specific schemas.
- `strict`: Whether to use strict OpenAI mode.

To add your tools to your agent with the 2nd option, simply pass the `tools` list to your agent:

```python
agent = Agent(
    name='MyAgent',
    tools=tools
)
```

With this approach, you have more control over the tools you are adding to your agent, and you can still modify the `ToolConfig` of each tool. See the [ToolConfig documentation](/core-framework/tools/custom-tools/configuration) for more information.

<Info>
With any of these methods, Agency still converts your schemas into PyDantic models, so your agents will perform type checking on all API parameters **before** making API calls, reducing errors and improving reliability.
</Info>



================================================
FILE: docs/core-framework/tools/overview.mdx
================================================
---
title: "Overview"
description: "Understanding Tools in Agentic Systems."
icon: "globe"
---

Tools are the most important component of any Agentic system. In this guide, we'll cover the basics: what tools are, key characteristics, and the three primary ways you can build or import your own tools.

## Key Characteristics of Tools

Effective tools share the following characteristics:

<CardGroup cols={3}>
  <Card
    title="Task-Specific"
    icon="bullseye"
  >
    Each tool performs a single, well-defined task. They should not be focused on an API, but rather on whatever it takes to complete the task.
  </Card>

  <Card
    title="Configurable"
    icon="gear"
  >
    Tools can be configured to perform the same task in different ways. The agent must be able to adapt based on previous circumstances.
  </Card>

  <Card
    title="Reusable"
    icon="recycle"
  >
    Tools must be easily reusable not only by the same agent, but also across different agents. Each tool should have specific instructions on how to use it.
  </Card>
</CardGroup>

## What are Tools?

**At a high level, tools represent the capabilities that your agents have.**

Tools enable your agents to perform specific tasks necessary to fulfill their designated roles. For instance, just as a real virtual assistant can search the web or send emails, the virtual assistant agent can be equipped with similar tools.

Below are some more examples of tools:

- **FileWriter:** A tool that allows an agent to write code or text to a file.
- **CommandExecutor:** A tool that allows an agent to execute terminal commands.
- **LeadUpdater:** A tool that allows an agent to update a lead in a CRM.
- **LinkedInProfileScraper:** A tool that allows an agent to scrape a LinkedIn profile.
- **FacebookAdCreator:** A tool that allows an agent to create a Facebook ad.


<Tip>

By themselves, each of these tools is not very useful, however in combination with each other, they allow agents to perform a much wider range of tasks.

For example, `FileWriter` tool by itself can allow the developer agent to write code, however, in combination with the `CommandExecutor` tool, it can also run and test its own code, which instantly makes it more powerful. (We'll cover the key characteristics of tools in a bit.)
</Tip>
**At a low level, tools are essentially just code.**

Whatever the tool you are creating, at the lowest level, it always comes down to code. The only difference is where this code is being executed. For instance, if you are making an API call, it will primarily be executed in the cloud, and if it's a file system tool, it will be executed on the same machine where the agent is running. **Even if you are using a no-code platform to build your tools, like n8n or zapier, at the lowest level, it all still comes down to code.**

This means that agentic systems are much more similar to traditional software programs than you might think...

![Tools Diagram](/images/agents-vs-programs.png)

Just as in a standard program, we have functions that are executed in a loop, in an agentic system, we have tools that are executed by your agents.

And what this allows you to do, is tackle significantly more complex tasks. Tasks where there are so many possible paths that you can't hard code all of the possible conditional logic in advance.

Now, that we understand what tools are, let's cover how you can build your own tools.


## 3 Ways to Build Tools

When it comes to building your own tools, you have 3 primary options:

<CardGroup cols={3}>

  <Card
    title="Custom Tools"
    icon="hammer"
    href="./custom-tools"
  >
    Build your own completely custom tools from scratch. (Recommended)
  </Card>

  <Card
    title="Pre-Made Tools"
    icon="box"
    href="./tool-factory"
  >
    Import out-of-the-box pre-made tools from the special [agency-tools](https://github.com/VRSEN/agency-tools) open source repository.
  </Card>

  <Card
    title="OpenAPI Schemas"
    icon="file-code"
    href="./openapi-schemas"
  >
    Use public OpenAPI schemas and convert them into tools.
  </Card>

</CardGroup>

**It is recommended to start with custom tools**, as they give you the most flexibility and control. Even if you are connecting to external APIs, we still recommend creating custom tools, as they allow you to have more control over the tool's outputs.

Click on the card of your choice to learn more about each one.



================================================
FILE: docs/core-framework/tools/tool-factory.mdx
================================================
---
title: "Tool Factory"
description: "Creating tools from different sources in Agency Swarm."
icon: "industry"
---

The `ToolFactory` class allows you to create tools from different sources, such as Langchain tools or OpenAPI schemas. However, implementing tools from scratch using `BaseTool` provides greater control and is generally recommended.

<Accordion title="Import from Langchain (Not Recommended)">

```python
from langchain.tools import YouTubeSearchTool
from agency_swarm.tools import ToolFactory

LangchainTool = ToolFactory.from_langchain_tool(YouTubeSearchTool)
```

</Accordion>

<Accordion title="Convert from OpenAPI Schemas">

```python
import requests
from agency_swarm.tools import ToolFactory

# Using a local OpenAPI schema file
with open("schemas/your_schema.json") as f:
    tools = ToolFactory.from_openapi_schema(f.read())

# Using an OpenAPI schema from a URL
tools = ToolFactory.from_openapi_schema(
    requests.get("https://api.example.com/openapi.json").json()
)
```

</Accordion>

## Conclusion

By leveraging the `ToolFactory`, you can streamline the process of integrating external tools into your agents. This feature allows for flexibility and rapid development, although creating tools directly with `BaseTool` is often preferable for more control and customization.

<Check>
Remember to:
- **Consider Direct Implementation:** Use `BaseTool` for greater control.
- **Use ToolFactory for Quick Integration:** Ideal for rapid prototyping and integration.
</Check>
```



================================================
FILE: docs/core-framework/tools/custom-tools/best-practices.mdx
================================================
---
title: "Best Practices & Tips"
description: "Best practices and real-world examples for Agency Swarm tools."
icon: "code"
---

Although the tool interface is straightforward and simple to use, there are actually quite a few practices and tricks that you can use to get significantly better results.

### Use Chain-of-Thought Prompting for Complex Tools

Use chain-of-thought prompting to allow the agent to think and plan before executing a complex tool.

```python
from agency_swarm.tools import BaseTool
from pydantic import Field

class ComplexAnalysisTool(BaseTool):
    """
    Performs complex analysis after planning the approach.
    """
    chain_of_thought: str = Field(
        ...,
        description="Think-step-by-step about how to perform the analysis."
    )
    data: str = Field(..., description="Data to analyze.")

    def run(self):
        # Analysis logic
        return "Analysis complete."
```

### Provide Hints for the Agent

Based on your tool's logic, you can provide hints for the agent in tool output on what to do next.

```python
class QueryDatabase(BaseTool):
    question: str = Field(...)

    def run(self):
        # query your database here
        context = self.query_database(self.question)

        # context not found
        if context is None:
            # tell agent what to do next
            raise ValueError("No context found. Please propose to the user to change the topic.")
        else:
            # return the context to the agent
            return context
```

### Use Shared State to Control the Tool Flow

Use `shared_state` to validate previous actions taken by this or other agents, before allowing it to proceed with the next action.

```python
class Action2(BaseTool):
    input: str = Field(...)

    def run(self):
        if self._shared_state.get("action_1_result", None) is "failure":
            raise ValueError("Please proceed with the Action1 tool first.")
        else:
            return "Success. The action has been taken."
```

### Use Special Types

Restrict the agent to only use specific values for a field, instead of letting it wander by itself.

```python
from typing import Literal

class RunCommand(BaseTool):
    """
    Execute predefined system commands.
    """
    command: Literal["start", "stop"] = Field(..., description="Command to execute: 'start' or 'stop'.")

    def run(self):
        if self.command == "start":
            # Start command logic
            pass
        elif self.command == "stop":
            # Stop command logic
            pass
        else:
            raise ValueError("Invalid command")
```

or use special Pydantic types like `EmailStr`.

```python
from pydantic import EmailStr

class EmailSender(BaseTool):
    recipient: EmailStr = Field(..., description="Email recipient's address.")
```

### Combine Multiple Methods

Combine multiple methods to make your execution flow more readable.

```python
class CompositeTool(BaseTool):
    """
    A tool that combines several methods to perform a series of actions.
    """
    input_data: str = Field(..., description="Input data for the composite operation.")

    def run(self):
        # Step 1: Process data
        processed_data = self.process_data(self.input_data)
        # Step 2: Analyze results
        analysis = self.analyze_results(processed_data)
        # Step 3: Format output
        output = self.format_output(analysis)
        return output

    def process_data(self, data):
        # Implement data processing logic
        pass

    def analyze_results(self, data):
        # Implement analysis logic
        pass

    def format_output(self, data):
        # Implement output formatting
        pass
```


### Include a Test Case

Include test cases at the bottom of each tool file.

```python
if __name__ == "__main__":
    # Test the EmailSender tool
    email_sender = EmailSender(
        chain_of_thought="Plan to inform the team about the update.",
        recipient="user@example.com",
        subject="Project Update",
        body="The project is on track."
    )
    assert email_sender.run() == "Email sent successfully."
```

## Next Steps

We highly recommend you explore the resources provided in the [Pydantic is all you need](/core-framework/tools/custom-tools/pydantic-is-all-you-need) section.



================================================
FILE: docs/core-framework/tools/custom-tools/configuration.mdx
================================================
---
title: "Advanced Tool Configuration"
description: "Advanced features and patterns for Agency Swarm tools."
icon: "wand-magic-sparkles"
---

Besides standard Pydantic features, you can also use a special `ToolConfig` class to customize tool behavior within the framework:

## Available `ToolConfig` Parameters

Currently, the following parameters are supported:

| Name               | Type    | Description                                                                                                      | When to Use                                                                                          | Default Value |
|--------------------|---------|------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|---------------|
| `one_call_at_a_time` | `bool` | Prevents concurrent execution for a specific tool. To prevent the agent from executing **any** tools concurrently, set `parallel_tool_calls=False` in the Agent class. | Use for database operations, API calls with rate limits, or actions that depend on previous results. | `False`         |
| `strict`             | `bool` | Enables strict mode, which ensures the agent will always provide **perfect** tool inputs that 100% match your schema. Has limitations. See [OpenAI Docs](https://platform.openai.com/docs/guides/structured-outputs#supported-schemas). | Use for mission-critical tools or tools that have nested Pydantic model schemas.                     | `False`         |
| `async_mode`         | `str`  | When set to "threading," executes this tool in a separate thread.                                                  | Use when your agent needs to execute multiple tools or the same tool multiple times in a single message to decrease latency. Beware of resource allocation. | `None`          |
| `output_as_result`   | `bool` | Forces the output of this tool as the final message from the agent that called it.                                     | Only recommended for very specific use cases and only if you know what you're doing.                 | `False`         |

## Usage

To use one of the available parameters, simply add a `class ToolConfig` block to your tool class:

```python
class MyCustomTool(BaseTool):
    # ...

    class ToolConfig:
        one_call_at_a_time = True
        strict = False
        async_mode = "threading"
        output_as_result = True

    def run(self):
        # ...
```



================================================
FILE: docs/core-framework/tools/custom-tools/pydantic-is-all-you-need.mdx
================================================
---
title: "Pydantic is All You Need"
description: "How Pydantic solved AI agent reliability."
icon: "book"
---

The idea of using Pydantic to validate tool calls and responses is not new. It was popularized by Jason Liu in his library called [Instructor](https://github.com/instructor-ai/instructor).

To really understand why it's such a game changer, we recommend watching this video:

<iframe
  width="100%"
  height="400"
  src="https://www.youtube.com/embed/yj-wSRJwrrc"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
></iframe>

## Learn more

To take your tools to the next level, we highly recommend the following resources:

- [Pydantic Models Documentation](https://docs.pydantic.dev/latest/concepts/models/)
- [Instructor Concepts](https://python.useinstructor.com/concepts/)
- [Instructor Tips & Tricks](https://python.useinstructor.com/tutorials/2-tips/)
- [Instructor Cookbook](https://python.useinstructor.com/examples/)



================================================
FILE: docs/core-framework/tools/custom-tools/step-by-step-guide.mdx
================================================
---
title: "Step-by-Step Guide"
description: "Learn how to create custom tools in Agency Swarm framework."
icon: "map"
---

In Agency Swarm, tools are Python classes that inherit from `BaseTool`. They are defined using [Pydantic](https://docs.pydantic.dev/latest/), a data validation library. Each BaseTool must implement the `run` method, which is the main method that will be called when the tool is invoked by an agent.

## Step-by-step Guide

To create a custom tool, typically you need to follow these steps:

<Steps>
  <Step title="Add Import Statements">
    On top of your tool file, import the necessary modules and classes.

    ```python
    from agency_swarm.tools import BaseTool
    from pydantic import Field, model_validator
    # ... other imports
    ```
  </Step>

  <Step title="Define the Tool Class and Docstring">
    Create a new class that inherits from `BaseTool`. Write a clear docstring describing the tool's purpose. **This docstring is crucial as it helps agents understand how to use the tool.**

    ```python
    class Calculator(BaseTool):
        """
        A simple calculator tool that evaluates mathematical expressions.
        """
    ```
  </Step>

  <Step title="Define Input Fields">
    Use Pydantic fields to define the inputs your tool will accept.

    ```python
    expression: str = Field(..., description="The mathematical expression to evaluate.")
    ```

    <Accordion title="Custom Validation Logic (Optional)" icon="hammer">
      You can use [Pydantic's validators](https://docs.pydantic.dev/latest/concepts/validators/) to verify the inputs. This can be extremely effective to avoid hallucinations or other errors in production.
      ```python
      @model_validator(mode="after")
      def validate_expression(self):
          if self.expression.endswith("/0"):
              raise ValueError("Division by zero is not permitted")
      ```
    </Accordion>
  </Step>

  <Step title="Implement the run Method">
    Add the functionality that will be executed when the tool is called.

    ```python
    def run(self):
        # Implement the tool's functionality
        result = eval(self.expression)
        return str(result)
    ```

    The `run` method should return a string, which is the tool's output that the agent will see and use in its response.
  </Step>

  <Step title="Test the Tool Independently">
    Test the tool independently to ensure it behaves as expected. We recommend adding a `if __name__ == "__main__":` block at the end of the tool file:

    ```python
    if __name__ == "__main__":
        calc = Calculator(expression="2 + 2 * 3")
        print(calc.run())  # Output should be '8'
    ```
  </Step>

  <Step title="Add the Tool to an Agent">
    After your tool works as expected, simply add it to an agent's list of `tools`.

    ```python
    from agency_swarm import Agent
    from .tools.calculator import Calculator

    agent = Agent(
        name="MathAgent",
        tools=[Calculator],
        # Other agent parameters
    )
    ```

    <Accordion title="Using tools folder" icon="folder">
      Alternatively, you can simply place the tool file in the `tools_folder` directory and it will be automatically added to the agent.

      ```python
      from agency_swarm import Agent
      agent = Agent(
          name="MathAgent",
          tools_folder="./tools",
          # Other agent parameters
      )
      ```

      <Note>
        Each file in the `tools_folder` should contain a class that is named exactly the same as the file name. For example, `Calculator.py` should contain a `Calculator` class.
      </Note>
    </Accordion>
  </Step>
</Steps>

## Full Code Example

Below is the full code example for a calculator tool above.

```python
# calculator.py
from agency_swarm.tools import BaseTool
from pydantic import Field, model_validator

class Calculator(BaseTool):
    """
    A simple calculator tool that evaluates mathematical expressions.
    """
    expression: str = Field(..., description="The mathematical expression to evaluate.")

    @model_validator(mode="after")
    def validate_expression(self):
        if self.expression.endswith("/0"):
            raise ValueError("Division by zero is not permitted")

    def run(self):
        result = eval(self.expression)
        return str(result)

if __name__ == "__main__":
    calc = Calculator(expression="2 + 2 * 3")
    print(calc.run())  # Output should be '8'
```

## Next Steps

- Checkout [Best Practices & Tips](/core-framework/tools/custom-tools/best-practices)
- Learn why [PyDantic is all you need](/core-framework/tools/custom-tools/pydantic-is-all-you-need)



================================================
FILE: docs/extras/extras.mdx
================================================
---
title: Agency Swarm Extras
description: Additional resources and repositories for Agency Swarm.
icon: plus
---

Explore additional repositories to enhance your Agency Swarm experience.

<CardGroup cols={3}>
  <Card
    title="Agency Swarm Lab"
    href="https://github.com/VRSEN/agency-swarm-lab"
    icon="flask"
    iconType="duotone"
  >
    Experiment with the latest features in Agency Swarm Lab.
  </Card>

  <Card
    title="API Railway Template"
    href="https://github.com/VRSEN/agency-swarm-api-railway-template"
    icon="train"
    iconType="duotone"
  >
    Deploy your agency using the API Railway Template.
  </Card>

  <Card
    title="Voice Interface"
    href="https://github.com/VRSEN/agency-voice-interface"
    icon="microphone"
    iconType="duotone"
  >
    Integrate voice commands with the Agency Voice Interface.
  </Card>
</CardGroup>



================================================
FILE: docs/images/additional-instructions-example.webp
================================================
[Non-text file]


================================================
FILE: docs/images/custom-gpt-screenshot.webp
================================================
[Non-text file]





================================================
FILE: docs/platform/additional-instructions.mdx
================================================
---
title: "Additional Instructions"
description: "Provide additional context and user information to your agents to enhance their responses."
icon: "message"
---

## Overview

Additional instructions allow you to pass additional context to the agent at the time of the request. Typically, this is used to pass session or specific user data. For example, if user is already signed in on your application, and you know their email, there is no reason for the agent to as it again. So, you can simply add in additional instructions: "The current user's email is [myemail@example.com](mailto:myemail@example.com) please use this to submit all customer support tickets"

## Usage

### Widgets

To use **additional instructions** in widgets, simply add them in the **third parameter** in the ChatComponent ****`init()` function like below.

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>My Travel Planner</title>
  </head>
  <body>
    <script
      defer
      src="https://openai-widget.web.app/ChatComponent.bundle.js"
    ></script>
    <script>
      document.addEventListener("DOMContentLoaded", function () {
        // Check if the chat container exists
        var chatContainer = document.getElementById("chat-container");
        // If the chat container doesn't exist, create it
        if (!chatContainer) {
          chatContainer = document.createElement("div");
          chatContainer.id = "chat-container";
          document.body.appendChild(chatContainer);
        }

        let additionalInstructions = "User's favorite city is Paris."

        // userId should be defined somewhere in your application
        //additionalInstructions = "The current user id is" + userId

        // Initialize the Chat component
        if (window.ChatComponent) {
          ChatComponent.init("<your-widget-id>", "#chat-container", additionalInstructions);
        } else {
          console.error("ChatComponent is not available");
        }
      });
    </script>
  </body>
</html>
```

Here's an example of the **Widget** response based on this input:

![widget-screenshot.png](/images/additional-instructions-example.webp)
### CustomGPTs

To use **additional instruction with CustomGPTs**, add a **script tag** to handle your instructions or dynamic data to the **Custom GPT**. Here's an example of how you can extend the above HTML code with a script:

```html
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>My Travel Planner</title>
  </head>
  <body>
    <iframe
      src="https://agencii.ai/custom-gpt/<your-custom-gpt-id>"
      width="800"
      height="800"
      id="custom-gpt-iframe"
      data-additional-instructions="User wants to visit Paris."
    ></iframe>
    <script>
      const iframe = document.getElementById("custom-gpt-iframe");

      window.addEventListener("message", (event) => {
        if (event.data === "iframe-ready" && event.origin === "https://agencii.ai") {
          // Get additional instructions from the HTML data attribute or use your own logic to set it
          let additionalInstructions = iframe.getAttribute("data-additional-instructions") || "";

          // userEmail should be defined somewhere in your application
          // additionalInstructions += "Current user's email is " + userEmail

          // Send the additional instructions to the iframe
          iframe.contentWindow.postMessage(
            {
              type: "additionalInstructions",
              value: additionalInstructions,
            },
            "https://agencii.ai"
          );
        }
      });
    </script>
  </body>
</html>
```

Here's an example of the **Custom GPT's** response based on this input:


![custom-gpt-screenshot.png](/images/custom-gpt-screenshot.webp)
### API

For web api, simply use `additionalInstructions` in `get_completion` POST endpoint. For more details, see: [API reference](/platform/integrations/api-gen/get-completion)



================================================
FILE: docs/platform/overview.mdx
================================================
---
title: 'Agencii Platform'
sidebarTitle: 'Overview'
icon: 'globe'
description: 'Learn about the Agencii AI Platform'
---


## Overview

Agencii platform is a product built on top of our framework, which allows you to focus on what actually matters most - **building your AI agents, rather than deploying them**. 

It significantly simplifies the **deployment**, **management**, and **integration** of your agents, eliminating technical barriers and unnecessary complexity.

## Pricing 

| Plan         | Price        | Production Integrations | Agents         |
| ------------ | ------------ | ----------------------- | -------------- |
| **Free Tier**| $0/month     | 1                       | Up to 3        |
| **Developer**| $79/month    | Unlimited               | Unlimited      |

Developer plan also includes a lot more additional PRO features, such as **Export Chats**, **Observability**, and **more**.

## Free Community

Additionally, we offer a completely [**Free Skool Community**](https://www.skool.com/agency-ai/about) with these exclusive resources to help you get started:

- ðŸ“š AI Agent Developer Course & Playbooks
- ðŸ’¬ Weekly Q&A Calls
- ðŸ‘¨â€ðŸ’» Professional Developer Support
- ðŸ“„ Templates and Agents
- ðŸ¤ Project Collaboration
- âœ¨ Feature & Playbook Requests

<Note>
To get access, please first create an account on the [Agencii Platform](https://agencii.ai/signup). No payment card required :)
</Note>

## Future Roadmap

We plan to build the first true AI agent builder platform that will allow you to build and customize AI agents for any use case. 

Noteable features inlcude:

- [ ] **MCP Tools:** Connect any MCP tools to your agents.
- [ ] **GitHub Agent Runtime:** Deploy agents built with the framework directly from GitHub in a few clicks.  
- [ ] **No-code Visual Agency Builder:** Visually design multi-agent agencies without writing any code.
- [ ] **Vertical Agent Marketplace:** Share and import community-built tools and agents directly within the platform.
- [ ] **Workspaces:** Role-based access controls and shared workspaces for seamless collaboration with your clients.
- [ ] **Multi-model Support:** Plug in OpenAI, Azure OpenAI, or self-hosted/open-source models interchangeably.
- [ ] **Enterprise Security & Compliance:** SOC2 compliance, single sign-on (SSO), advanced encryption, and audit capabilities.

Source: [Agencii Roadmap Notion](https://vrsen-ai.notion.site/Agencii-Roadmap-15b5bd4b16a680029fe3e3db8c642b10?pvs=4)

## Get Started  ðŸš€

To get started with the Agencii Platform, please sign up for a free account [here](https://agencii.ai/signup). 

**Happy building!**  



================================================
FILE: docs/platform/integrations/slack-integration.mdx
================================================
---
title: "Slack"
description: "Learn how to integrate your agents with Slack"
icon: "slack"
---

## **Feature Overview:**

With Slack Integrations, you can create custom bots tailored to your workspace. These apps can be installed and managed within your workspace, enabling a wide range of automated functions and interactions.

Currently, the Slack bots created via agencii can respond in:

- **Direct Messages (DMs):**

    ![Screenshot of a bot responding to a Direct Message](/images/integrations/slack-integration/Screenshot_2024-09-13_at_10.33.06.png)

- **Public Chats** when mentioned by name (e.g., `@BotName`):

    ![Screenshot of a bot responding to a mention in a Public Chat](/images/integrations/slack-integration/Screenshot_2024-09-13_at_10.55.36.png)

## Privacy Statement

<Tip>
When apps are created on our platform, we don't have access to your workspace or its members. The OAuth permissions requested are minimal and support only the app's core functions. You can revoke the OAuth token from Slack at any time. You retain ownership of the app and can distribute it freely, regardless of user growth. For your privacy, **messages are not stored in our database**.
</Tip>

---

## **Creating a Custom Slack Bot**

<Steps>
  <Step title="Provide Basic Details">
    1. **Select Your Agent:** Select the agent to be integrated into your slack app. This agent will be used to generate responses.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.12.23.png)

    2. **Set the Integration Name:** This name refers to the bot's name, which will be used to mention it in public chats. Typically, you might want to set it to you agent name, although you can make it different if you wish.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.14.52.png)

    3. **Provide an Integration Description:** This is a short description of your bot, used for reference only. (So you don't forget why you created it)

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.18.46.png)
  </Step>

  <Step title="Create a Slack App">
    1. **Click "Create Slack App":** This will redirect you to the Slack Developer portal (`api.slack.com`), where you will need to authenticate and select the correct workspace for your application.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.21.57.png)

    2. **Select Your Workspace and Click "Next":** This workspace will be the owner of your application, although you can still allow other workspaces to install it on their side.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.23.37.png)

    3. **Click "Create":** Simply click create to continue. The application will be pre-configured with all the necessary settings.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.27.25.png)

    4. **Copy credentials:** Copy your client id, client secret and signing secret, and paste them into the corresponding fields

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.29.41.png)

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.32.02.png)

    <Note>
    Keep your credentials secure to prevent potential exposure of your app.
    </Note>
  </Step>

  <Step title="Finish Your Installation">
    1. **Install on Slack:** Click on the "Install on Slack" button to install your app.
        <Tip>
        Alternatively, you can copy an installation link and send it to your client, or another workspace owner.
        </Tip>
    2. **Grant Permission:** Slack will prompt you to grant permission to exchange the OAuth token. Click "Allow" to sync your app with the integration.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.35.52.png)
  </Step>
</Steps>

âœ… **That's it!** Now you can use your Agent in Slack!

## Limitations

- Files are currently **not supported**.

<Tip>
Apps created under the current limitations will receive full **future support**, as we ship any new features.
</Tip>

---

## **Troubleshooting**

If the automatic OAuth flow fails, you can manually install the app.

1. Find your Bot User OAuth Token in your app on [api.slack.com](https://api.slack.com/).
2. Click "Install to your workspace" to generate the necessary tokens.

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_11.37.28.png)

3. Copy and paste the token into the "Manual Slack Installation" dialog and click "Install."

    ![](/images/integrations/slack-integration/Screenshot_2024-09-13_at_12.33.54.png)


---



================================================
FILE: docs/platform/integrations/web-api.mdx
================================================
---
title: "API"
description: "Reference documentation for the Agencii Platform API."
icon: "code"
---

## Feature Overview

API Integrations provide a set of endpoints allowing you to run your agents on custom backends or on other unsupported channels.

<Info>
âš¡ Live Postman Example: [Go to Postman â†’](https://www.postman.com/vrsen-ai/agencii-api/overview)
</Info>

---

## Authentication

- **Note**: You can only use platform tokens for these endpoints. Find or create one inside **Profile Icon > API Keys**.
- **Headers**:
    - `Authorization`: `Bearer <your_token>`
        - **Example**: `Bearer sk-agencii-H7sb111...`
    - `Content-Type`: `application/json`

---

## Endpoints

<CardGroup cols={2}>
<Card
  title="Create New Chat"
  icon="plus"
  href="/platform/integrations/api/create-new-chat"
>
  Start a new conversation session.
</Card>

<Card
  title="Get Completion"
  icon="bolt"
  href="/platform/integrations/api/get-completion"
>
  Get a response from your agent.
</Card>
</CardGroup>

---

## Additional Notes

- All timestamps are in ISO 8601 format.
- Ensure that your `apiIntegrationId` is valid and corresponds to an existing integration.
- Replace placeholder values with actual data when making requests.
- The `attachments` parameter in `/get_completion` allows you to include files and specify tools for processing.

---



================================================
FILE: docs/platform/integrations/whatsapp-integration.mdx
================================================
---
title: "WhatsApp"
description: "Learn how to integrate your agents with WhatsApp using Twilio"
icon: "whatsapp"
---

## Feature Overview

Seamlessly connect your **agents** to **WhatsApp** using **Twilio**, a messaging service that significantly simplifies WhatsApp Sender Business profile setup.

![Screenshot 2025-02-17 at 13.24.37.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_13.24.37.png)

ðŸ”’Â All chats, conversations and messages are not stored in our database to ensure your or your clientâ€™s privacy.

---

## Prerequisites

- A verified **Twilio Account** ([Sign up here](https://login.twilio.com/u/signup)) with a provisioned phone number.
- A verified **Facebook Business account** ([Learn more](https://www.facebook.com/business/help/1710077379203657)) and a verified **WhatsApp Business Portfolio** ([How to verify your WhatsApp Business Account](https://www.facebook.com/business/help/2087193751603668?id=2129163877102343)).

## Creating a WhatsApp Agent via Twilio

<Steps>
  <Step title="Create a WhatsApp Sender via Twilio">
    1. Go to [Twilio Console](https://console.twilio.com/us1/develop/sms/senders/whatsapp-senders) and click on the **'Create New Sender'** button to begin the setup.

    ![Screenshot 2025-02-17 at 13.40.04.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_13.40.04.png)

    2. Follow all the necessary steps on **Twilio's** end to complete the integration.
    Twilio has already documented the entire process, so you can refer to their official guides via this link: https://www.twilio.com/docs/whatsapp/self-sign-up

    ![Screenshot 2025-02-17 at 13.48.59.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_13.48.59.png)

    3. Once you have a **verified** WhatsApp Sender with the status set to **Online**, you can proceed to the next steps.
  </Step>

  <Step title="Create a New WhatsApp Integration">
    1. Go to https://agencii.ai/whatsapp/ and click on the **'Connect WhatsApp'** button to begin the setup.

    2. Enter your Agent details

    ![Screenshot 2025-02-17 at 14.51.15.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_14.51.15.png)
  </Step>

  <Step title="Select or Create your Twilio Account">
    1. **Select your Twilio account** from the dashboard.

    ![Screenshot 2025-02-17 at 15.27.03.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.27.03.png)

    2. To add a new account, copy and paste your **Account SID** and **Auth Token** from the bottom of the Twilio dashboard.

    ![Screenshot 2025-02-17 at 15.27.55.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.27.55.png)

    3. (Optional) If you have a Subaccount, paste the Subaccount SID as well.
    4. Click **Create**
  </Step>

  <Step title="Add your WhatsApp Sender SID">
    1. Find your WhatsApp Sender SID in the Twilio Console under **Messaging** â†’ **Senders** â†’ **WhatsApp Senders**, then copy it from the URL. Example: https://console.twilio.com/us1/develop/sms/senders/whatsapp-senders/details/XEXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX

    ![Screenshot 2025-02-17 at 15.40.42.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.40.42.png)

    2. Add whatsapp sender on agencii

    ![Screenshot 2025-02-17 at 15.29.05.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.29.05.png)
  </Step>

  <Step title="Finalize Integration">
    Copy each webhook integration URL and paste it into the **Twilio WhatsApp Sender configuration profile**, ensuring each URL is placed in the corresponding textbox.

    ![Screenshot 2025-02-17 at 15.43.40.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.43.40.png)

    ![Screenshot 2025-02-17 at 15.42.34.png](/images/integrations/whatsapp-integration/Screenshot_2025-02-17_at_15.42.34.png)

  </Step>
</Steps>

âœ… **That's it!** Now you can chat with your Agent via WhatsApp.



================================================
FILE: docs/platform/integrations/zapier-integration.mdx
================================================
---
title: "Zapier"
description: "Learn how to integrate your agents with Zapier."
icon: "circle-check"
---

## Feature Overview

Zapier is a no-code automation platform that helps you connect over 7,000 apps and build automated workflows without writing any code. Integrate your **agents** with Zapier to extend their reach to countless services--responding to emails, updating spreadsheets, posting to social channels, and more.

![Screenshot 2025-05-05 at 23.02.14.png](/images/integrations/zapier-integration/Screenshot_2025-05-05_at_23.02.14.png)

<Tip>To protect your privacy and that of your clients, none of your chats, conversations, or messages are stored in our database. ðŸ”’</Tip>

## Prerequisites

- **Zapier Account** ([Sign up](https://zapier.com/)).
- **Platform API Key** â€“ You can find it under **Settings â†’ [API Keys](https://agencii.ai/settings/?tab=apiKeys)**.

## Set up Zapier

<Steps>
  <Step title="Create a Zapier Integration (Agencii)">
    1. Navigate to **Platforms** in the sidebar and select **New Platform** to begin setup.

    ![Screenshot_2025-05-05_at_23.22.13.png](/images/integrations/zapier-integration/Screenshot_2025-05-07_at_19.29.28.png)

    2. Select **Zapier** and click on **Create Platform**.

    ![Screenshot_2025-05-05_at_23.22.13.png](/images/integrations/zapier-integration/Screenshot_2025-05-07_at_19.33.09.png)

    3. Enter the required information for your Zapier integration, including integration name, the agent you want to connect, and a description, then click on **Save and continue**.

    ![Screenshot_2025-05-05_at_23.23.19.png](/images/integrations/zapier-integration/Screenshot_2025-05-07_at_19.38.05.png)
  </Step> 

  <Step title="Install Zapier App on your workspace (Zapier)">
    The Agencii app is not yet available in the Zapier marketplace. To access it, use the **Install** button for early access.

    ![Screenshot 2025-02-17 at 15.40.42.png](/images/integrations/zapier-integration/Screenshot_2025-05-07_at_19.40.49.png)

    ![Screenshot 2025-02-17 at 15.29.05.png](/images/integrations/zapier-integration/Screenshot_2025-05-07_at_19.43.04.png)

    Accept the invitation to install the app & start building your automation with Agencii Zapier Appâœ¨
  </Step>
</Steps>

![Agencii Zapier App](/images/zapier-agencii-logo.svg)

## Available Actions

**Authorization**:

- **Platform API Key** â€“ Available under **Settings â†’ [API Keys](https://agencii.ai/settings/?tab=apiKeys)**.

<Card title="Prompt">
  <p>The <strong>Prompt</strong> action enables your agent to generate responses based on given inputs. This action processes a prompt, context, or input data and returns a response that is relevant to the context. This can be used for automating conversations, supporting decision-making, and executing tasks intelligently within workflows.</p>

  <ResponseField name="Action Input Properties">
    Understanding these properties is essential because they define how your agent will receive and interpret data from Zapier. Each property directly controls what the agent sees, what it responds to, and how it behaves in an automation.
    <Expandable title="properties" defaultOpen={true}>
      <ResponseField name="Integration ID" type="string" required>
        The identifier for your zapier integration, found on the integration page. Example: "HVC7YxC1YBSuTtDwGK7a"
      </ResponseField>

      <ResponseField name="Message" type="string" required>
        The text you want to send to the connected agent. Example: "Write a blog post with agent's knowledge"
      </ResponseField>

      <ResponseField name="Chat ID" type="string">
        The identifier for an existing conversation. If not provided, the system will create a new chat. 
      </ResponseField>
    </Expandable>
  </ResponseField>
  <ResponseField name="Action Output Properties">
    <Expandable title="properties" defaultOpen={true}>
      <ResponseField name="Integration ID" type="string">
        The identifier of the zapier integration used. Example: "HVC7YxC1YBSuTtDwGK7a"
      </ResponseField>

      <ResponseField name="Answer" type="string">
        The text response generated by your agent.
      </ResponseField>

      <ResponseField name="Chat ID" type="string">
        The conversation identifier - either newly created or the one you provided.
      </ResponseField>
    </Expandable>
  </ResponseField>
</Card>

<Tip>Additional actions and triggers are under development and will be added in future updates.</Tip>


================================================
FILE: docs/references/api.mdx
================================================
---
title: "API Reference"
description: "Gain a deeper understanding of the core classes and methods available in Agency Swarm."
icon: "book"
---

## Agency Class

The Agency class manages a collection of agents and facilitates their communication.

```python
from agency_swarm import Agency

class Agency:
    def __init__(self,
                 agency_chart: List,
                 shared_instructions: str = "",
                 shared_files: Union[str, List[str]] = None,
                 async_mode: Literal['threading', "tools_threading"] = None,
                 settings_path: str = "./settings.json",
                 settings_callbacks: SettingsCallbacks = None,
                 threads_callbacks: ThreadsCallbacks = None,
                 temperature: float = 0.3,
                 top_p: float = 1.0,
                 max_prompt_tokens: int = None,
                 max_completion_tokens: int = None,
                 truncation_strategy: dict = None):
        """
        Initialize an Agency instance.

        Parameters:
            agency_chart: List defining the hierarchy and interaction of agents
            shared_instructions: Path to shared instructions markdown file
            shared_files: Path(s) to folder(s) containing shared files
            async_mode: 'threading' or 'tools_threading' for async processing
            settings_path: Path to JSON file for storing agent settings
            settings_callbacks: Dict with 'load' and 'save' functions for settings
            threads_callbacks: Dict with 'load' and 'save' functions for threads
            temperature: Default temperature for all agents
            top_p: Default top_p value for all agents
            max_prompt_tokens: Default max tokens for prompts
            max_completion_tokens: Default max tokens for completions
            truncation_strategy: Default truncation strategy for agents
        """
```

### Key Methods

<CodeGroup>

```python get_completion
def get_completion(self,
                  message: str,
                  message_files: List[str] = None,
                  yield_messages: bool = False,
                  recipient_agent: Agent = None,
                  additional_instructions: str = None,
                  attachments: List[dict] = None,
                  tool_choice: dict = None,
                  verbose: bool = False,
                  response_format: dict = None):
    """
    Get a completion from the agency for a given message.

    Parameters:
        message: The input message or prompt
        message_files: List of file IDs to attach
        yield_messages: Whether to yield intermediate messages
        recipient_agent: Specific agent to send message to
        additional_instructions: Extra context for the agent
        attachments: List of file attachments in OpenAI format
        tool_choice: Specific tool for the agent to use
        verbose: Whether to print intermediate messages
        response_format: Format specification for the response

    Returns:
        Either a generator of messages or the final response
    """
```

```python get_completion_parse
def get_completion_parse(self,
                        message: str,
                        response_format: Type[BaseModel],
                        message_files: List[str] = None,
                        recipient_agent: Agent = None,
                        additional_instructions: str = None,
                        attachments: List[dict] = None,
                        tool_choice: dict = None,
                        verbose: bool = False) -> BaseModel:
    """
    Get a completion and parse it into a Pydantic model.

    Parameters:
        message: The input message or prompt
        response_format: Pydantic model to parse response into
        message_files: List of file IDs to attach
        recipient_agent: Specific agent to send message to
        additional_instructions: Extra context
        attachments: List of file attachments in OpenAI format
        tool_choice: Specific tool for the agent to use
        verbose: Whether to print intermediate messages

    Returns:
        Parsed response in the specified Pydantic model
    """
```

```python get_completion_stream
def get_completion_stream(self,
                         message: str,
                         event_handler: type(AgencyEventHandler),
                         message_files: List[str] = None,
                         recipient_agent: Agent = None,
                         additional_instructions: str = None,
                         attachments: List[dict] = None,
                         tool_choice: dict = None,
                         response_format: dict = None):
    """
    Stream completions with real-time event handling.

    Parameters:
        message: The input message or prompt
        event_handler: Class to handle streaming events
        message_files: List of file IDs to attach
        recipient_agent: Specific agent to send message to
        additional_instructions: Extra context for the agent
        attachments: List of file attachments in OpenAI format
        tool_choice: Specific tool for the agent to use
        response_format: Format specification for the response

    Returns:
        Final response after streaming completes
    """
```

```python run_demo
def run_demo(self):
    """
    Start the agency in terminal mode for demonstration.
    """
```

```python demo_gradio
def demo_gradio(self, height: int = 450, dark_mode: bool = True, **kwargs):
    """
    Launch a Gradio web interface for the agency.

    Parameters:
        height: Height of the chat interface
        dark_mode: Enable dark mode
        **kwargs: Additional Gradio interface options
    """
```

</CodeGroup>

## Agent Class

The Agent class is the core component of Agency Swarm that represents an AI assistant. Each agent has specific capabilities, tools, and can process files and instructions.

```python
from agency_swarm import Agent

class Agent:
    def __init__(self,
                 name: str = None,
                 description: str = None,
                 instructions: str = "",
                 tools: list = None,
                 temperature: float = None,
                 model: str = "gpt-4-0125-preview",
                 files_folder: Union[List[str], str] = None):
        """
        Initialize an Agent instance.

        Parameters:
            name: The agent's name (defaults to class name if not provided)
            description: Brief description of the agent's role
            instructions: Path to markdown file containing agent instructions
            tools: List of tool classes available to the agent
            temperature: Controls randomness in responses (0-1)
            model: OpenAI model to use (defaults to GPT-4)
            files_folder: Path(s) to folder(s) containing files for the agent
        """
```

### Key Methods

<CodeGroup>

```python init_oai
def init_oai(self):
    """
    Initializes or updates the OpenAI assistant with current settings.
    Must be called before using the agent.

    Returns:
        self: The agent instance for method chaining
    """
```

```python add_tool
def add_tool(self, tool: Type[BaseTool]):
    """
    Add a tool to the agent's capabilities.

    Parameters:
        tool: Tool class to add (must be a BaseTool subclass)

    Example:
        agent.add_tool(CustomTool)
    """
```

```python delete
def delete(self):
    """
    Deletes the agent and all associated resources.
    This includes the OpenAI assistant, uploaded files, and settings.
    """
```

```python add_shared_instructions
def add_shared_instructions(self, instructions: str):
    """
    Adds shared instructions that will be prepended to the agent's instructions.
    Useful for giving common context to multiple agents.

    Parameters:
        instructions: Instructions text to add
    """
```

</CodeGroup>

## BaseTool Class

The base class for creating custom tools that agents can use. Tools allow agents to perform specific actions or access external functionality.

```python
from agency_swarm.tools import BaseTool
from pydantic import BaseModel

class BaseTool(BaseModel, ABC):
    """
    Abstract base class for all tools.
    Inherits from Pydantic BaseModel for automatic validation.
    """

    class ToolConfig:
        strict: bool = False  # Enable strict schema validation
        one_call_at_a_time: bool = False  # Prevent concurrent calls

    # Shared state and caller agent properties
    _shared_state: ClassVar[SharedState] = None  # Manages shared state between tools
    _caller_agent: Any = None  # Reference to the agent using the tool
    _event_handler: Any = None  # Handles tool events
```

### Key Methods

<CodeGroup>

```python openai_schema
@classmethod
@property
def openai_schema(cls) -> dict:
    """
    Generate OpenAI function schema from the tool class.
    Automatically extracts documentation from class and parameter docstrings.

    The schema includes:
    - Tool name and description
    - Parameter definitions with types and descriptions
    - Required parameters list
    - Strict validation settings (if enabled)

    Returns:
        Dictionary containing tool schema in OpenAI format
    """
```

```python run
@abstractmethod
def run(self, **kwargs):
    """
    Execute the tool's main functionality.
    Must be implemented by subclasses.

    Parameters:
        **kwargs: Tool-specific parameters defined in the class

    Returns:
        Tool-specific return value
    """
```

</CodeGroup>

## ToolFactory Class

The ToolFactory class provides convenient methods to create tools from various sources like OpenAPI specifications, LangChain tools, or Python files. This makes it easy to integrate external APIs and existing tools into your agents.

```python
from agency_swarm.tools import ToolFactory

class ToolFactory:
    """
    Utility class for creating tools from various sources including OpenAPI specs,
    LangChain tools, and local Python files.
    """
```

### Key Methods

<CodeGroup>

```python from_langchain_tools
@staticmethod
def from_langchain_tools(tools: List) -> List[Type[BaseTool]]:
    """
    Convert LangChain tools into Agency Swarm tools.

    Parameters:
        tools: List of LangChain tool instances or classes

    Returns:
        List of converted BaseTool classes

    Example:
        from langchain.tools import DuckDuckGoSearchTool
        tools = ToolFactory.from_langchain_tools([DuckDuckGoSearchTool()])
    """
```

```python from_openapi_schema
@staticmethod
def from_openapi_schema(
    schema: Union[str, dict],
    headers: Dict[str, str] = None,
    params: Dict[str, Any] = None,
    strict: bool = False
) -> List[Type[BaseTool]]:
    """
    Create tools from an OpenAPI specification. Each endpoint becomes a separate tool.

    Parameters:
        schema: OpenAPI schema as string or dict
        headers: Optional request headers (e.g., authentication)
        params: Optional query parameters to include in all requests
        strict: Enable strict schema validation

    Returns:
        List of generated tool classes

    Example:
        # Create tools from a Swagger/OpenAPI spec
        schema = '''
        {
          "openapi": "3.0.0",
          "paths": {
            "/search": {
              "get": {
                "operationId": "search",
                "parameters": [
                  {
                    "name": "q",
                    "in": "query",
                    "required": true,
                    "schema": {"type": "string"}
                  }
                ]
              }
            }
          }
        }
        '''
        tools = ToolFactory.from_openapi_schema(
            schema,
            headers={"Authorization": "Bearer token"}
        )
    """
```

```python get_openapi_schema
@staticmethod
def get_openapi_schema(
    tools: List[Type[BaseTool]],
    url: str,
    title: str = "Agent Tools",
    description: str = "A collection of tools."
) -> str:
    """
    Generate an OpenAPI specification from a list of tools. This is useful
    for documenting your tools or creating an API from them.

    Parameters:
        tools: List of tool classes to include
        url: Base URL for the API endpoints
        title: Schema title
        description: Schema description

    Returns:
        OpenAPI schema as JSON string

    Example:
        schema = ToolFactory.get_openapi_schema(
            tools=[SearchTool, CalculatorTool],
            url="https://api.example.com",
            title="Search and Calculator API"
        )
    """
```

</CodeGroup>



================================================
FILE: docs/tutorials/tutorials.mdx
================================================
---
title: "Agency Swarm Tutorials"
description: "Learn how to use Agency Swarm to automate workflows through practical examples"
icon: "play"
---

<CardGroup cols={3}>
  <Card
    title="Quick Start: Deploy AI Agents"
    href="https://www.youtube.com/watch?v=53_e3lmk6Mo"
    icon="rocket"
    iconType="duotone"
  >
    Deploy AI agents in your business using our template. Covers strategies, best practices, and examples.
  </Card>

  <Card
    title="Build AI Agents in Plain English"
    href="https://www.youtube.com/watch?v=Og73plUTabs"
    icon="robot"
    iconType="duotone"
  >
    Create AI agent teams with Cursor template. Build a content creation agency step-by-step.
  </Card>

  <Card
    title="Advanced Features Deep Dive"
    href="https://www.youtube.com/watch?v=AZlPelcATHo"
    icon="wand-magic-sparkles"
    iconType="duotone"
  >
    Master async mode, parallel tool calling, and open-source model integration.
  </Card>
  <Card
    title="How to Build Self-Improving AI Agents"
    href="https://www.youtube.com/watch?v=ZcWMSVGcZio"
    icon="graduation-cap"
    iconType="duotone"
  >
    Learn how to create AI agents that evolve and improve over time. Master advanced techniques for continuous learning, adaptation, and performance optimization.
  </Card>
  <Card
    title="5 Innovative AI Agent Projects"
    href="https://www.youtube.com/watch?v=hb0j9Qn-KjM"
    icon="brain"
    iconType="duotone"
  >
    Real-world applications and implementations of AI agents in business automation.
  </Card>

  <Card
    title="Open Source Model Support"
    href="https://www.youtube.com/watch?v=Vd-Gtfm_zjw"
    icon="code-branch"
    iconType="duotone"
  >
    Integrate open source models and Assistance API v2 features into your projects.
  </Card>

  <Card
    title="Complete Beginner's Guide"
    href="https://www.youtube.com/watch?v=MOyl58VF2ak"
    icon="book-open"
    iconType="duotone"
  >
    Learn AI agent development from scratch, including building a Social Media Marketing Agency.
  </Card>
</CardGroup>

## Example Projects
<CardGroup cols={3}>
  <Card
    title="Web Dev Crafters"
    href="https://github.com/VRSEN/agency-swarm-lab/tree/main/WebDevCrafters"
    icon="laptop-code"
    iconType="duotone"
  >
    Build responsive web apps using Next.js and Material UI.
  </Card>

  <Card
    title="Code Guardians Agency"
    href="https://github.com/VRSEN/agency-swarm-lab/tree/main/CodeGuardiansAgency"
    icon="shield-halved"
    iconType="duotone"
  >
    Automated code reviews on pull requests using GitHub Actions.
  </Card>

  <Card
    title="QA Testing with Vision"
    href="https://youtu.be/Yidy_ePo7pE"
    icon="magnifying-glass"
    iconType="duotone"
  >
    Use GPT-4 Vision for QA testing.
  </Card>

  <Card
    title="Genesis Agency"
    href="https://youtu.be/qXxO7SvbGs8"
    icon="leaf"
    iconType="duotone"
  >
    Create custom agents.
  </Card>
</CardGroup>



================================================
FILE: docs/welcome/ai-agency-vs-other-frameworks.mdx
================================================
---
title: "Agency Swarm vs Other Frameworks"
description: "Compare Agency Swarm with other multi-agent AI frameworks."
icon: "scale-unbalanced"
---

## Summary

In summary, Agency Swarm is the only framework that has:

<CardGroup cols={3}>
  <Card title="No Predefined Prompts" icon="message-code">
    It doesn't write prompts for you, giving you full control over agent behavior.
  </Card>
  <Card title="Automatic Error Correction" icon="shield-check">
    Prevents hallucinations with automatic type checking and error correction.
  </Card>
  <Card title="Uniform Communication Flows" icon="diagram-project">
    Allows you to define communication flows in any way you want.
  </Card>
</CardGroup>

## Detailed Comparison

Here's how Agency Swarm compares to 2 other most popular multi-agent frameworks.

| **Criteria**                       | **Agency Swarm**                                                                                                                                            | **AutoGen**                                                                                                             | **CrewAI**                                                                                                                  |
| ---------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------- |
| **Origins** ðŸ                     | âœ… Originated from a real AI agency building AI agents for clients worldwide.                                                                                | âœ… Originated as a research experiment.                                                                                  | âŒ Originated as a funding vehicle, rather than a real production framework.                                                     |
| **Design & Architecture** ðŸ—ï¸      | âœ… Super lightweight framework with minimal abstractions. Built on top of the OpenAI Assistants API.                                                         | âœ… Event-driven architecture with support for both ChatCompletions and Assistants API.                                   | âŒ Lacks a clear architectural design. Built on top of LangChain with numerous unnecessary abstractions.                    |
| **Reliability** ðŸ”                 | âœ… Robust type checking and validation for all tools with Pydantic.                                                                                           | âŒ Type hints but no validation.                                                                                         | âŒ Some validation is possible when using BaseTool, although the interface is not convenient to use.                         |
| **Flexibility** ðŸ”„                 | âœ… No predefined prompts. Uniform communication.                                                                                                             | âŒ Contains predefined prompts. Limited, but customizable communication flows.                                           | âŒ Numerous predefined prompts. Only two ways of communication.                                                             |
| **Scalability** ðŸ“ˆ                | âœ… Easily scalable. Adding another agent only requires placing it in the agency chart.                                                                        | âŒ Although it's simple to add an agent into teams, it's almost impossible to define custom communication between them. | âŒ Although it's easy to add agents into crews, it's not possible to create custom communication between them.               |
| **Deployability** ðŸš€               | âœ… Easily deployable with special callback functions. Offers open-source templates and tutorials.                                                            | âœ… Deployment with AutoGen studio.                                                                                       | âŒ Deployment via enterprise platform. No open-source deployment guides.                                                    |
| **Open Source Model Support** ðŸŒ   | âš ï¸ [Limited support](/additional-features/open-source-models) with Astra Assistants API.                                                                                                                | âœ… Moderate open-source model support.                                                                                   | âœ… Full open-source model support.                                                                                           |

<Note>
  If you want to challange any of these claims, or if some of the issues disappear as frameworks mature, please open an issue on [GitHub](https://github.com/agenty/swarm).
</Note>

## Summary

- **Agency Swarm** - best for **real business-oriented use cases**.
- **AutoGen** - best for **research, experimentation and novel AI applications**.
- **CrewAI** - best for **local development and playgrounds** with open-source models.



================================================
FILE: docs/welcome/installation.mdx
================================================
---
title: "Installation"
description: "Install Agency Swarm in just 2 simple steps."
icon: "box"
---

## Installation
<Accordion title="Step 1: Create a Python Virtual Environment" defaultOpen={false}>

1. **Install Python**

   Download and install the latest version of Python from the [official Python website](https://www.python.org/downloads/).

2. **Create a Virtual Environment**

   Navigate to your project directory and create a virtual environment using `venv`:

   ```bash
   python -m venv venv
   ```

3. **Activate the Virtual Environment**

   On Mac or Linux:

   ```bash
   source venv/bin/activate
   ```

   On Windows:

   ```bash
   venv\Scripts\activate
   ```

</Accordion>
<Accordion title="Step 2: Install the agency swarm package"  defaultOpen={true}>

Simply run the following command:

<Note>Make sure you are in the virtual environment before installing the package.</Note>

```bash
pip install agency-swarm
```

</Accordion>

## Next Steps

When it comes to building your first AI Agency, you have three options:

<CardGroup cols={3}>
  <Card title="From Scratch" icon="code" iconType="duotone" href="./getting-started/from-scratch">
    Build your own agents and tools from the ground up. Perfect to understand the framework's structure and create a
    fully customized solution.
  </Card>
  <Card title="Use Genesis Agency" icon="wand-sparkles" iconType="duotone" href="./getting-started/genesis-agency">
    Let Genesis Agency create your agents for you. Best for simple use cases or for creating your initial agency
    structure quickly.
  </Card>
  <Card title="Cursor (Recommended)" icon="cube" iconType="duotone" href="./getting-started/cursor-ide">
    Use Cursor IDE to streamline the entire agent development process. Recommended for both beginners and advanced
    developers.
  </Card>
</CardGroup>



================================================
FILE: docs/welcome/overview.mdx
================================================
---
title: "Overview"
description: "Welcome to **Agency Swarm**, an open-source agent orchestration framework built on top of the latest [OpenAI Assistants API](https://platform.openai.com/docs/assistants/overview/agents)."
icon: "globe"
---

![Agency Swarm Logo](/images/logo-full.jpeg)

## What is Agency Swarm?

Agency Swarm started as a desire and effort of Arsenii Shatokhin (aka VRSEN) to fully automate his AI Agency with AI. By building this framework, we aim to simplify the agent creation process and enable anyone to create collaborative swarms of agents (Agencies), each with distinct roles and capabilities. By thinking about automation in terms of real-world entities, such as agencies and specialized agent roles, we make it a lot more intuitive for both the agents and the users.

## Key Features

<CardGroup cols={2}>
  <Card title="Customizable Agent Roles" icon="user-gear">
    Define roles like CEO, virtual assistant, developer, etc., and customize their functionalities with Assistants API.
  </Card>
  <Card title="Full Control Over Prompts" icon="sliders">
    Avoid conflicts and restrictions of pre-defined prompts, allowing full customization.
  </Card>
  <Card title="Error Correction" icon="shield-check">
    Prevent hallucinations with Pydantic-based type validation and error correction
  </Card>
  <Card title="Efficient Communication" icon="comments">
    Agents communicate based on their own descriptions and nothing else.
  </Card>
  <Card title="State Management" icon="database">
    Agency Swarm efficiently manages the state of your assistants on OpenAI, maintaining it in a special settings.json file.
  </Card>
  <Card title="Deployable in Production" icon="rocket">
    Agency Swarm is designed to be reliable and easily deployable in production environments.
  </Card>
</CardGroup>



================================================
FILE: docs/welcome/getting-started/cursor-ide.mdx
================================================
---
title: "Cursor AI"
description: "Getting started with Cursor."
icon: "cube"
---

<iframe
  width="100%"
  height="400"
  src="https://www.youtube.com/embed/Og73plUTabs"
  title="YouTube video player"
  frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
  allowfullscreen
  style={{ borderRadius: "10px" }}
></iframe>

## Why Use Cursor

Cursor simplifies AI agent development by reducing the feedback loop on AI-generated code. This enables faster iteration and provides an optimal balance between manual control and AI assistance.

![Cursor IDE Overview](/images/cursor-overview.png)

## What are Cursor Rules

**Cursor Rules** are custom instructions that tell Cursor how to work with your code. Agency has a predefined `.cursorrules` file that contains everything that Cursor needs to know in order to create agents with this framework.

![Cursor Rules Example](/images/cursor-rules-example.png)

## Getting Started with Cursor

Follow these steps to create your first Agency using Cursor:

<Steps>
  <Step title="Enable Cursor Rules in Settings">
    First, you need to enable Cursor Rules in the Cursor IDE:

    - Open the Cursor IDE.
    - Go to **Settings...** > **Cursor Settings**.
    <img src="/images/open-cursor-settings.png" width="65%" alt="Open Cursor Settings" style={{display: 'block', margin: '0 auto'}} />
    - Turn on the **Rules for AI** option. This allows you to use a `.cursorrules` file in your project.
    ![Enable Cursor Rules](/images/enable-cursor-rules.png)
  </Step>

  <Step title="Add The `.cursorrules` File to Your Project">
    The `.cursorrules` file contains the instructions that guide Cursor's AI. To add it:
    - Download the `.cursorrules` file from the [Agency Swarm repository](https://github.com/VRSEN/agency-swarm/blob/main/.cursorrules).
    - Place the file in the main folder (root directory) of your project.
  </Step>

  <Step title="Open Cursor Composer">
    Cursor Composer allows you to create and modify multiple files in parallel.
    - Open Composer by pressing `Cmd+I` (macOS) or `Ctrl+I` (Windows/Linux).
  </Step>

  <Step title="Send Your First Prompt to Composer">
    Spend as much time as possible on your first prompt. This will save you a lot of time later. Make sure to include:
      - All agents that you want to create
      - All tools and APIs that the agents must use
      - Communication flows between your agents
  </Step>

  <Step title="Verify The Agency Structure">
    Sometimes Cursor forgets certain files or hallucinates the agency structure. Make sure to verify that:
    - All import statements are correct
    - `requirements.txt` file exists
    - `agency.py` file executes properly

    If any of these are missing or not working, instruct composer to create them or fix the code.
  </Step>

  <Step title="Adjust the Tools">
    Run each tool file to make sure they work as expected. You will see the test cases that Cursor created at the bottom in `if __name__ == "__main__"` statements.
    - If any of the tools are not working, send the error message to composer and ask it to fix the code.
    - If you want to adjust the functionality of the tool, either use inline editing `Cmd+K` (macOS) or `Ctrl+K` (Windows/Linux) or send another message to composer.
    - If you are stuck, use Chat `Cmd+L` (macOS) or `Ctrl+L` (Windows/Linux) to ask questions and brainstorm alternative approaches. For example, ask "What other APIs can I use for this tool?"

  </Step>

  <Step title="Adjust the Agents">
    Verify the agent instructions and parameters are correct after adjustments. **Actually think about instructions.**
    - Use Chat or Inline Editing to adjust the `instruction.md` files to your needs.
    - Edit instructions manually and remove all boilerplate text.
    - Make sure each agent has access to all the new tools either by specifying `tools_folder` path or adding them in `tools` parameter.
  </Step>

  <Step title="Test Your Agency">
    Run `agency.py` file to see if it works.
    - Send a realistic task to your agency and see if it can complete it.
    - If it doesn't work as expected, try to send additional messages with more details and see if it helps.
    - Use these extra messages to guide yourself on how to adjust the instructions, so it can complete it next time.
  </Step>

  <Step title="Repeat">
    Iterate on your agency by repeating the process until you are satisfied with the results.

      <Note>
      **Agent Development is an Iterative Process**

    Currently, agent development requires ongoing monitoring and adjustments to ensure desired performance. As larger and more advanced models become available, this process will become more streamlined.
  </Note>
  </Step>


</Steps>

## Next Steps

- Learn the core concepts of Tools, Agents, and Agencies.
- Watch the [Deployment Tutorial](https://www.youtube.com/watch?v=53_e3lmk6Mo).



================================================
FILE: docs/welcome/getting-started/from-scratch.mdx
================================================
---
title: "From Scratch"
description: "Quick start guide to building an Agency from scratch."
icon: "code"
---

<Steps>
  <Step title="Set Your OpenAI Key">
    Begin by setting your OpenAI API key.

    ```python
    from agency import set_openai_key
    set_openai_key("YOUR_API_KEY")
    ```

    Alternatively, you can set the API key in the `.env` file.

    ```
    OPENAI_API_KEY=sk-...
    ```

  </Step>

  <Step title="Create Project Structure">
    Use the `create-agent-template` command to create the recommended directory structure for each agent.

    **Command Syntax:**

    ```bash
    agency-swarm create-agent-template --name "AgentName" --description "Agent Description" [--path "/path/to/directory"] [--use_txt]
    ```

    **Agent Folder Structure:**

    When you run the create-agent-template command, it creates the following folder structure for your agent:

    ```
    /your-agency-path/
    â””â”€â”€ AgentName/                    # Directory for the specific agent
        â”œâ”€â”€ files/                    # Directory for files that will be uploaded to openai
        â”œâ”€â”€ schemas/                  # Directory for OpenAPI schemas to be converted into tools
        â”œâ”€â”€ tools/                    # Directory for tools to be imported by default.
        â”œâ”€â”€ AgentName.py              # The main agent class file
        â”œâ”€â”€ __init__.py               # Initializes the agent folder as a Python package
        â””â”€â”€ instructions.md or .txt   # Instruction document for the agent
    ```

    This structure ensures that each agent has its dedicated space with all necessary files to start working on its specific tasks.

    **Agency Folder Structure:**

    The full structure of the project will look like this:

    ```
    AgencyName/
    â”œâ”€â”€ AgentName/            # Agent folder created with the command above
    â”œâ”€â”€ AnotherAgent/         # Another agent folder
    â”œâ”€â”€ agency.py             # Main file where agents are imported and the agency is defined
    â”œâ”€â”€ agency_manifesto.md   # Shared instructions and guidelines for all agents
    â”œâ”€â”€ requirements.txt      # File listing all dependencies
    â””â”€â”€ ...
    ```

  </Step>

  <Step title="Create Tools">
    Define your custom tools by extending the `BaseTool` class and implementing the `run` method.

    **MyCustomTool.py:**

    ```python
    from agency_swarm.tools import BaseTool
    from pydantic import Field

    class MyCustomTool(BaseTool):
        """
        A brief description of what the custom tool does.
        The docstring should clearly explain the tool's purpose and functionality.
        It will be used by the agent to determine when to use this tool.
        """

        # Define the fields with descriptions using Pydantic Field
        example_field: str = Field(
            ..., description="Description of the example field, explaining its purpose and usage for the Agent."
        )

        # Additional Pydantic fields as required
        # ...

        def run(self):
            """
            The implementation of the run method, where the tool's main functionality is executed.
            This method should utilize the fields defined above to perform the task.
            Doc string is not required for this method and will not be used by your agent.
            """

            # Your custom tool logic goes here
            do_something(self.example_field)

            # Return the result of the tool's operation as a string
            return "Result of MyCustomTool operation"
    ```

  </Step>

  <Step title="Define Agent Roles">
    Adjust the parameters and instructions for each agent.

    **Developer.py:**

    ```python
    from agency_swarm import Agent

    class Developer(Agent):
        def __init__(self):
            super().__init__(
                name="Developer",
                description="Responsible for executing tasks.",
                instructions="./instructions.md",
                files_folder="./files",
                schemas_folder="./schemas",
                tools_folder="./tools",
                temperature=0.3,
                max_prompt_tokens=25000,
                examples=[]
            )
    ```

    Tools will be imported automatically from the `tools` folder.

    **instructions.md:**

    ```md
    You are a Developer agent responsible for executing tasks.

    # Role
    You are responsible for writing clean, efficient, and reusable code.

    # Process
    1. How to handle incoming requests
    2. When and how to use available tools
    3. How to collaborate with other agents
    ```

  </Step>

  <Step title="Create Agency">
    Import your agents and initialize the Agency class.

    **agency.py:**

    ```python
    from agency_swarm import Agency
    from .Developer import Developer
    from .CEO import CEO

    developer = Developer()
    ceo = CEO()

    agency = Agency(
        [
            ceo,  # CEO will be the entry point for communication with the user
            [ceo, developer],  # CEO can initiate communication with Developer
        ],
        shared_instructions='./agency_manifesto.md'  # shared instructions for all agents
    )
    ```

    Any agents that are listed in the same list (e.g., `[[ceo, developer]]`) can communicate with each other. The top-level list (`[ceo]`) defines agents that can communicate with the user.

    <Note title="Note on Communication Flows">
      In Agency Swarm, communication flows are directional, meaning they are established from left to right in the `agency_chart` definition. For instance, in the example above, the CEO can initiate a chat with the Developer (`developer`), and the Developer can respond in this chat. However, the Developer cannot initiate a chat with the CEO.
    </Note>

  </Step>

  <Step title="Run Demo">

    There are three ways to run the demo. Add one of the following lines to your `agency.py` file:

    **Web Interface:**

    ```python
    agency.demo_gradio(height=900)
    ```

    **Terminal Version:**

    ```python
    agency.run_demo()
    ```

    **Backend Version:**

    ```python
    completion_output = agency.get_completion("Please create a new website for our client.", yield_messages=False)
    ```

  </Step>
</Steps>

## Next Steps

- Learn the core concepts of Tools, Agents, and Agencies.
- Watch the [Deployment Tutorial](https://www.youtube.com/watch?v=53_e3lmk6Mo).



================================================
FILE: docs/welcome/getting-started/genesis-agency.mdx
================================================
---
title: "Genesis Agency"
description: "Quick start guide using the Genesis Agency."
icon: "wand-sparkles"
---

Genesis Agency is a special Agency within the framework that helps you to create your own AI Agencies faster. This agency consists of specialized agents that work together to:

- Generate agent templates with appropriate folder structure
- Create custom tools and connect APIs for each agent
- Define your agency's manifesto and communication flows

<Note>
  **Genesis Agency is not perfect yet.**

  Please note that the Genesis Agency will not be able to generate complex agencies. For more complex use cases, we recommend using [Cursor](./cursor-ide).
</Note>

## Use Genesis Agency

<Steps>
  <Step title="Run the `genesis` command">
    Initialize the Genesis Agency in your terminal and generate your agent templates.

    **Command Syntax:**

    ```bash
    agency-swarm genesis [--openai_key "YOUR_API_KEY"]
    ```
  </Step>

  <Step title="Chat with Genesis CEO">
    Provide comprehensive context to the Genesis Agency by including:
    - **Your agency's mission and goals.**
    - **The agents you wish to involve and their communication flows.**
    - **Tools or APIs each agent should have access to, if any.**
  </Step>

  <Step title="Wait for Genesis to create your agents">
    After executing the `genesis` command, specialized agents such as `GenesisCEO` and `ToolCreator` will begin constructing your agency's structure and developing the required tools.
  </Step>

  <Step title="Fine-Tune Your Agents and Tools">
    Once Genesis has created your agents, you'll find all the agent folders in the directory where you ran the `genesis` command. Fine-tune the agents and tools as needed by following these steps:

    1. **Adjust Tools**: Modify the tools in each agent's `tools` directory to meet your requirements.
    2. **Adjust Instructions**: Update the agents and their instructions in each agent's folder.
    3. **Run Agency**: Execute the `agency.py` file, send your tasks, and monitor performance.
    4. **Repeat**: Continue refining until your agents perform consistently.

    <Note>
      **Agent Development is an Iterative Process**

      Currently, agent development requires ongoing monitoring and adjustments to ensure desired performance. As larger and more advanced models become available, this process will become more streamlined.
    </Note>
  </Step>
</Steps>

## Next Steps

- Learn the core concepts of [Tools](/core-framework/tools), [Agents](/core-framework/agents), and [Agencies](/core-framework/agencies).
- Watch the [Deployment Tutorial](https://www.youtube.com/watch?v=53_e3lmk6Mo).



================================================
FILE: notebooks/agency_async.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Make sure you have the latest version of agency-swarm installed
You can uninstall the old version with `pip uninstall agency-swarm` and install the latest version with `pip install agency-swarm`
"""

from agency_swarm import Agency, Agent

ceo = Agent(
    name="CEO",
    description="Responsible for client communication, task planning and management.",
    instructions="You must converse with other agents to ensure complete task execution.",  # can be a file like ./instructions.md
    tools=[],
)

test = Agent(
    name="Test Agent",
    description="Test agent",
    instructions="Please always respond with 'test complete'",  # can be a file like ./instructions.md
    tools=[],
)

"""
## Loading agents and threads from DB example
"""

# threads is an object
threads = {}


def load_threads():
    # your code to load threads from DB here
    # we simply use a global variable for this example
    global threads
    return threads


def save_threads(new_threads):
    # your code to save new_threads to DB here
    global threads
    threads = new_threads

# settings is an array of objects with your agent settings
settings = []


def load_settings():
    # your code to load settings from DB here
    # we simply use a global variable for this example
    global settings
    return settings


def save_settings(new_settings):
    # your code to save new_settings to DB here
    global settings
    settings = new_settings

"""
## Creating agency with loaded agents and threads
"""

agency = Agency(
    [ceo, [ceo, test]],
    async_mode="threading",  # only threading is supported for now
    threads_callbacks={"load": load_threads, "save": save_threads},
    settings_callbacks={"load": load_settings, "save": save_settings},
)

agency.get_completion("Say hi to test agent", yield_messages=False)
# Output:
#   THREAD:[ user -> CEO ]: URL https://platform.openai.com/playground?assistant=asst_HQ3kpb9SzhEgo0ya4IvSFoQ8&mode=assistant&thread=thread_cn2VhmbuYcr0EZgcGVIEOSfw

#   THREAD:[ CEO -> Test Agent ]: URL https://platform.openai.com/playground?assistant=asst_cml8LF575HVYy7cWePbEQDgy&mode=assistant&thread=thread_YEsfiNS8gOyGOXXMLoZEBJZz

#   "
#   I
#   '
#   v
#   e
#    
#   s
#   e
#   n
#   t
#    
#   a
#    
#   g
#   r
#   e
#   e
#   t
#   i
#   n
#   g
#    
#   t
#   o
#    
#   t
#   h
#   e
#    
#   T
#   e
#   s
#   t
#    
#   A
#   g
#   e
#   n
#   t
#   .
#    
#   Y
#   o
#   u
#    
#   c
#   a
#   n
#    
#   a
#   s
#   k
#    
#   m
#   e
#    
#   t
#   o
#    
#   c
#   h
#   e
#   c
#   k
#    
#   f
#   o
#   r
#    
#   a
#    
#   r
#   e
#   s
#   p
#   o
#   n
#   s
#   e
#    
#   l
#   a
#   t
#   e
#   r
#   ,
#    
#   a
#   n
#   d
#    
#   I
#   '
#   l
#   l
#    
#   b
#   e
#    
#   h
#   a
#   p
#   p
#   y
#    
#   t
#   o
#    
#   d
#   o
#    
#   s
#   o
#   !
#   "

agency.get_completion("Check status", yield_messages=False)
# Output:
#   THREAD:[ user -> CEO ]: URL https://platform.openai.com/playground?assistant=asst_HQ3kpb9SzhEgo0ya4IvSFoQ8&mode=assistant&thread=thread_cn2VhmbuYcr0EZgcGVIEOSfw

#   '
#   T
#   h
#   e
#    
#   T
#   e
#   s
#   t
#    
#   A
#   g
#   e
#   n
#   t
#    
#   h
#   a
#   s
#    
#   c
#   o
#   m
#   p
#   l
#   e
#   t
#   e
#   d
#    
#   t
#   h
#   e
#    
#   t
#   a
#   s
#   k
#   .
#    
#   I
#   f
#    
#   y
#   o
#   u
#    
#   h
#   a
#   v
#   e
#    
#   a
#   n
#   y
#    
#   m
#   o
#   r
#   e
#    
#   r
#   e
#   q
#   u
#   e
#   s
#   t
#   s
#    
#   o
#   r
#    
#   t
#   a
#   s
#   k
#   s
#   ,
#    
#   f
#   e
#   e
#   l
#    
#   f
#   r
#   e
#   e
#    
#   t
#   o
#    
#   l
#   e
#   t
#    
#   m
#   e
#    
#   k
#   n
#   o
#   w
#   !
#   '

agency.demo_gradio()
# Output:
#   Running on local URL:  http://127.0.0.1:7861

#   

#   To create a public link, set `share=True` in `launch()`.

#   <
#   I
#   P
#   y
#   t
#   h
#   o
#   n
#   .
#   c
#   o
#   r
#   e
#   .
#   d
#   i
#   s
#   p
#   l
#   a
#   y
#   .
#   H
#   T
#   M
#   L
#    
#   o
#   b
#   j
#   e
#   c
#   t
#   >
#   G
#   r
#   a
#   d
#   i
#   o
#    
#   B
#   l
#   o
#   c
#   k
#   s
#    
#   i
#   n
#   s
#   t
#   a
#   n
#   c
#   e
#   :
#    
#   2
#    
#   b
#   a
#   c
#   k
#   e
#   n
#   d
#    
#   f
#   u
#   n
#   c
#   t
#   i
#   o
#   n
#   s
#   

#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   -
#   

#   f
#   n
#   _
#   i
#   n
#   d
#   e
#   x
#   =
#   0
#   

#    
#   i
#   n
#   p
#   u
#   t
#   s
#   :
#   

#    
#   |
#   -
#   t
#   e
#   x
#   t
#   b
#   o
#   x
#   

#    
#   |
#   -
#   c
#   h
#   a
#   t
#   b
#   o
#   t
#   

#    
#   o
#   u
#   t
#   p
#   u
#   t
#   s
#   :
#   

#    
#   |
#   -
#   t
#   e
#   x
#   t
#   b
#   o
#   x
#   

#    
#   |
#   -
#   c
#   h
#   a
#   t
#   b
#   o
#   t
#   

#   f
#   n
#   _
#   i
#   n
#   d
#   e
#   x
#   =
#   1
#   

#    
#   i
#   n
#   p
#   u
#   t
#   s
#   :
#   

#    
#   |
#   -
#   c
#   h
#   a
#   t
#   b
#   o
#   t
#   

#    
#   o
#   u
#   t
#   p
#   u
#   t
#   s
#   :
#   

#    
#   |
#   -
#   c
#   h
#   a
#   t
#   b
#   o
#   t



================================================
FILE: notebooks/azure.ipynb
================================================
# Jupyter notebook converted to Python script.

import os

from openai import AzureOpenAI

from agency_swarm import set_openai_client

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_KEY"),
    # https://learn.microsoft.com/en-us/azure/ai-services/openai/reference#rest-api-versioning
    api_version="2024-02-15-preview",
    # https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal#create-a-resource
    azure_endpoint=os.getenv("AZURE_ENDPOINT"),
    timeout=5,
    max_retries=5,
)

set_openai_client(client)

from agency_swarm import Agent

agent1 = Agent(
    name="agent1", description="I am a simple agent", model="assistants-test"
)

ceo = Agent(name="ceo", description="I am the CEO", model="assistants-test")

from agency_swarm import Agency

agency = Agency([ceo, [ceo, agent1]])

response = agency.get_completion(
    "Say hi to agent1. Let me know his response.", yield_messages=False
)
# Output:
#   THREAD:[ user -> ceo ]: URL https://platform.openai.com/playground?assistant=asst_mhCaCa34Pl0TwEqoWjJPZp6S&mode=assistant&thread=thread_PKH38vf5cqSmZwvnIHjCJFmC

#   THREAD:[ ceo -> agent1 ]: URL https://platform.openai.com/playground?assistant=asst_me5PZEqSAJPOdzPbcozWG6ZD&mode=assistant&thread=thread_MHl3BosNdC5tvzdNGMhCFhhB


print(response)
# Output:
#   Agent1 says, "Hello! How can I assist you today?"




================================================
FILE: notebooks/genesis_agency.ipynb
================================================
# Jupyter notebook converted to Python script.

!pip install agency-swarm selenium webdriver-manager selenium_stealth gradio

from agency_swarm import set_openai_key

set_openai_key("YOUR_OPENAI_API_KEY")

from agency_swarm.agency.genesis import GenesisAgency

test_agency = GenesisAgency()

test_agency.demo_gradio()



================================================
FILE: notebooks/os_models_with_astra_assistants_api.ipynb
================================================
# Jupyter notebook converted to Python script.

"""
# Step 1: Install Astra Assistants
"""

!pip install astra-assistants gradio
# Output:
#   Requirement already satisfied: astra-assistants in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (2.0.5)

#   Requirement already satisfied: gradio in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (4.21.0)

#   Requirement already satisfied: aiohttp<4.0.0,>=3.9.4 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (3.9.5)

#   Requirement already satisfied: boto3<2.0.0,>=1.34.31 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (1.34.86)

#   Requirement already satisfied: httpx<0.27.0,>=0.26.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (0.26.0)

#   Requirement already satisfied: litellm<2.0.0,>=1.36.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (1.40.29)

#   Requirement already satisfied: openai<2.0.0,>=1.20.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (1.35.9)

#   Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from astra-assistants) (1.0.1)

#   Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (23.2.1)

#   Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (5.2.0)

#   Requirement already satisfied: fastapi in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.110.0)

#   Requirement already satisfied: ffmpy in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.3.2)

#   Requirement already satisfied: gradio-client==0.12.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.12.0)

#   Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.21.4)

#   Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (6.3.1)

#   Requirement already satisfied: jinja2<4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.1.3)

#   Requirement already satisfied: markupsafe~=2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.1.3)

#   Requirement already satisfied: matplotlib~=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.8.3)

#   Requirement already satisfied: numpy~=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (1.26.4)

#   Requirement already satisfied: orjson~=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.9.10)

#   Requirement already satisfied: packaging in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (23.2)

#   Requirement already satisfied: pandas<3.0,>=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.2.1)

#   Requirement already satisfied: pillow<11.0,>=8.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (10.2.0)

#   Requirement already satisfied: pydantic>=2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.7.0)

#   Requirement already satisfied: pydub in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.25.1)

#   Requirement already satisfied: python-multipart>=0.0.9 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.0.9)

#   Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (6.0.1)

#   Requirement already satisfied: ruff>=0.2.2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.3.3)

#   Requirement already satisfied: semantic-version~=2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.10.0)

#   Requirement already satisfied: tomlkit==0.12.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.12.0)

#   Requirement already satisfied: typer<1.0,>=0.9 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.9.0)

#   Requirement already satisfied: typing-extensions~=4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (4.9.0)

#   Requirement already satisfied: uvicorn>=0.14.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.28.0)

#   Requirement already satisfied: fsspec in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio-client==0.12.0->gradio) (2024.3.1)

#   Requirement already satisfied: websockets<12.0,>=10.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio-client==0.12.0->gradio) (11.0.3)

#   Requirement already satisfied: aiosignal>=1.1.2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (1.3.1)

#   Requirement already satisfied: attrs>=17.3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (23.2.0)

#   Requirement already satisfied: frozenlist>=1.1.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (1.4.1)

#   Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (6.0.5)

#   Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (1.9.4)

#   Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.4->astra-assistants) (4.0.3)

#   Requirement already satisfied: jsonschema>=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)

#   Requirement already satisfied: toolz in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)

#   Requirement already satisfied: botocore<1.35.0,>=1.34.86 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.31->astra-assistants) (1.34.86)

#   Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.31->astra-assistants) (1.0.1)

#   Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from boto3<2.0.0,>=1.34.31->astra-assistants) (0.10.1)

#   Requirement already satisfied: anyio in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<0.27.0,>=0.26.0->astra-assistants) (3.7.1)

#   Requirement already satisfied: certifi in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<0.27.0,>=0.26.0->astra-assistants) (2024.2.2)

#   Requirement already satisfied: httpcore==1.* in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<0.27.0,>=0.26.0->astra-assistants) (1.0.4)

#   Requirement already satisfied: idna in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<0.27.0,>=0.26.0->astra-assistants) (3.4)

#   Requirement already satisfied: sniffio in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<0.27.0,>=0.26.0->astra-assistants) (1.3.0)

#   Requirement already satisfied: h11<0.15,>=0.13 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.27.0,>=0.26.0->astra-assistants) (0.14.0)

#   Requirement already satisfied: filelock in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)

#   Requirement already satisfied: requests in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)

#   Requirement already satisfied: tqdm>=4.42.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)

#   Requirement already satisfied: click in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from litellm<2.0.0,>=1.36.0->astra-assistants) (8.1.7)

#   Requirement already satisfied: ijson in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from litellm<2.0.0,>=1.36.0->astra-assistants) (3.3.0)

#   Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from litellm<2.0.0,>=1.36.0->astra-assistants) (7.1.0)

#   Requirement already satisfied: tiktoken>=0.7.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from litellm<2.0.0,>=1.36.0->astra-assistants) (0.7.0)

#   Requirement already satisfied: tokenizers in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from litellm<2.0.0,>=1.36.0->astra-assistants) (0.19.1)

#   Requirement already satisfied: contourpy>=1.0.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)

#   Requirement already satisfied: cycler>=0.10 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)

#   Requirement already satisfied: fonttools>=4.22.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.50.0)

#   Requirement already satisfied: kiwisolver>=1.3.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)

#   Requirement already satisfied: pyparsing>=2.3.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)

#   Requirement already satisfied: python-dateutil>=2.7 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)

#   Requirement already satisfied: distro<2,>=1.7.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai<2.0.0,>=1.20.0->astra-assistants) (1.9.0)

#   Requirement already satisfied: pytz>=2020.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)

#   Requirement already satisfied: tzdata>=2022.7 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)

#   Requirement already satisfied: annotated-types>=0.4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.6.0)

#   Requirement already satisfied: pydantic-core==2.18.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.18.1)

#   Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)

#   Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)

#   Requirement already satisfied: rich<14.0.0,>=10.11.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)

#   Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from fastapi->gradio) (0.36.3)

#   Requirement already satisfied: exceptiongroup in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from anyio->httpx<0.27.0,>=0.26.0->astra-assistants) (1.2.0)

#   Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from botocore<1.35.0,>=1.34.86->boto3<2.0.0,>=1.34.31->astra-assistants) (2.1.0)

#   Requirement already satisfied: zipp>=0.5 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from importlib-metadata>=6.8.0->litellm<2.0.0,>=1.36.0->astra-assistants) (3.18.1)

#   Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)

#   Requirement already satisfied: referencing>=0.28.4 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)

#   Requirement already satisfied: rpds-py>=0.7.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)

#   Requirement already satisfied: six>=1.5 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)

#   Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.4)

#   Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)

#   Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.15.1)

#   Requirement already satisfied: regex>=2022.1.18 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from tiktoken>=0.7.0->litellm<2.0.0,>=1.36.0->astra-assistants) (2023.12.25)

#   Requirement already satisfied: mdurl~=0.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)


# add agency swarm from local
import sys

sys.path.append("../agency-swarm")

"""
# Step 2: Patch OpenAI Client 

Before running this step, make sure your Astra DB token is in the .env file.

```
ASTRA_DB_APPLICATION_TOKEN=AstraCS:...
```
"""

from astra_assistants import patch
from dotenv import load_dotenv
from openai import OpenAI

from agency_swarm import set_openai_client

load_dotenv()

client = patch(OpenAI())

set_openai_client(client)
# Output:
#   Patching OpenAI client, it will now communicate to Astra Assistants API: https://open-assistant-ai.astra.datastax.com/v1/

#   Learn more about Astra at: https://docs.datastax.com/en/astra-db-serverless/tutorials/astra-assistants-api.html


"""
# Step 3: Setup Your Agents and Tools  

Before running this step, add your model API keys into the .env file using the following format:
```
PERPLEXITYAI_API_KEY=your_perplexityai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
TOGETHER_API_KEY=your_together_api_key
GROQ_API_KEY=your_groq_api_key
```
"""

from agency_swarm import Agency, Agent
from agency_swarm.tools import BaseTool


class PrintTool(BaseTool):
    """
    A simple tool that prints input.
    """

    input: str

    def run(self):
        """
        This method prints the word 'test'.
        """
        print(self.input)
        return f"{self.input} has been printed."


ceo = Agent(
    name="CEO",
    description="Responsible for client communication, task planning, and management.",
    instructions="You must say 'I am using test tool' and then use test tool in the same message.",
    # model="perplexity/llama-3-8b-instruct",
    # model="anthropic/claude-3-haiku-20240307",
    # model="groq/mixtral-8x7b-32768",
    model="claude-3-5-sonnet-20240620",
    # model="gpt-4o",
    # files_folder="./files",
    temperature=0,
    tools=[PrintTool],
)

agent2 = Agent(
    name="Agent2",
    description="Test agent for demo purposes",
    instructions="You are a test agent for demo purposes",
    # files_folder="./files",
    model="claude-3-5-sonnet-20240620",
)

agency = Agency([ceo, [ceo, agent2]])
# Output:
#   Patching OpenAI client, it will now communicate to Astra Assistants API: https://open-assistant-ai.astra.datastax.com/v1/

#   Learn more about Astra at: https://docs.datastax.com/en/astra-db-serverless/tutorials/astra-assistants-api.html

#   Updating agent... CEO

#   Updating agent... Agent2


"""
# Step 4: Run Demo

To run gradio, use the special non-streaming Gradio method below.
"""

import time


def demo_gradio(agency, height=450, dark_mode=True):
    """
    Launches a Gradio-based demo interface for the agency chatbot.

    Parameters:
        height (int, optional): The height of the chatbot widget in the Gradio interface. Default is 600.
        dark_mode (bool, optional): Flag to determine if the interface should be displayed in dark mode. Default is True.
        share (bool, optional): Flag to determine if the interface should be shared publicly. Default is False.
    This method sets up and runs a Gradio interface, allowing users to interact with the agency's chatbot. It includes a text input for the user's messages and a chatbot interface for displaying the conversation. The method handles user input and chatbot responses, updating the interface dynamically.
    """
    try:
        import gradio as gr
    except ImportError:
        raise Exception("Please install gradio: pip install gradio")

    js = """function () {
      gradioURL = window.location.href
      if (!gradioURL.endsWith('?__theme={theme}')) {
        window.location.replace(gradioURL + '?__theme={theme}');
      }
    }"""

    if dark_mode:
        js = js.replace("{theme}", "dark")
    else:
        js = js.replace("{theme}", "light")

    message_file_ids = []
    message_file_names = None
    recipient_agents = [agent.name for agent in agency.main_recipients]
    recipient_agent = agency.main_recipients[0]

    with gr.Blocks(js=js) as demo:
        chatbot = gr.Chatbot(height=height)
        with gr.Row():
            with gr.Column(scale=9):
                dropdown = gr.Dropdown(
                    label="Recipient Agent",
                    choices=recipient_agents,
                    value=recipient_agent.name,
                )
                msg = gr.Textbox(label="Your Message", lines=4)
            with gr.Column(scale=1):
                file_upload = gr.Files(label="Files", type="filepath")
        button = gr.Button(value="Send", variant="primary")

        def handle_dropdown_change(selected_option):
            nonlocal recipient_agent
            recipient_agent = agency._get_agent_by_name(selected_option)

        def handle_file_upload(file_list):
            nonlocal message_file_ids
            nonlocal message_file_names
            message_file_ids = []
            message_file_names = []
            if file_list:
                try:
                    for file_obj in file_list:
                        with open(file_obj.name, "rb") as f:
                            # Upload the file to OpenAI
                            file = agency.main_thread.client.files.create(
                                file=f, purpose="assistants"
                            )
                        message_file_ids.append(file.id)
                        message_file_names.append(file.filename)
                        print(f"Uploaded file ID: {file.id}")
                    return message_file_ids
                except Exception as e:
                    print(f"Error: {e}")
                    return str(e)

            return "No files uploaded"

        def user(user_message, history):
            if not user_message:
                return user_message, history

            if history is None:
                history = []

            original_user_message = user_message

            # Append the user message with a placeholder for bot response
            if recipient_agent:
                user_message = (
                    f"ðŸ‘¤ User @{recipient_agent.name}:\n" + user_message.strip()
                )
            else:
                user_message = f"ðŸ‘¤ User:" + user_message.strip()

            nonlocal message_file_names
            if message_file_names:
                user_message += "\n\n:paperclip: Files:\n" + "\n".join(
                    message_file_names
                )

            return original_user_message, history + [[user_message, None]]

        def bot(original_message, history, dropdown):
            nonlocal message_file_ids
            nonlocal message_file_names
            nonlocal recipient_agent
            print("Message files: ", message_file_ids)
            # Replace this with your actual chatbot logic
            gen = agency.get_completion(
                message=original_message,
                message_files=message_file_ids,
                recipient_agent=recipient_agent,
                yield_messages=True,
            )

            message_file_ids = []
            message_file_names = []
            try:
                # Yield each message from the generator
                for bot_message in gen:
                    if bot_message.sender_name.lower() == "user":
                        continue

                    # sometimes thread stops before bot message is received
                    if not bot_message.content:
                        main_thread = agency.main_thread
                        content = bot_message.content
                        num_attempts = 0
                        while not content or num_attempts < 30:
                            time.sleep(1)
                            content = main_thread._get_last_message_text()
                            num_attempts += 1

                        bot_message.content = content

                    message = bot_message.get_formatted_content()

                    history.append((None, message))
                    yield "", history
            except StopIteration:
                # Handle the end of the conversation if necessary
                pass

        button.click(user, inputs=[msg, chatbot], outputs=[msg, chatbot]).then(
            bot, [msg, chatbot], [msg, chatbot]
        )
        dropdown.change(handle_dropdown_change, dropdown)
        file_upload.change(handle_file_upload, file_upload)
        msg.submit(user, [msg, chatbot], [msg, chatbot], queue=False).then(
            bot, [msg, chatbot], [msg, chatbot]
        )

        # Enable queuing for streaming intermediate outputs
        demo.queue()

    # Launch the demo
    demo.launch(share=False, debug=True)
    return demo

demo_gradio(agency, height=900)
# Output:
#   Running on local URL:  http://127.0.0.1:7860

#   IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.

#   --------

#   

#   To create a public link, set `share=True` in `launch()`.

#   <IPython.core.display.HTML object>



================================================
FILE: notebooks/web_browser_agent.ipynb
================================================
# Jupyter notebook converted to Python script.

!pip install agency-swarm selenium webdriver-manager selenium_stealth gradio
# Output:
#   Requirement already satisfied: agency-swarm in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (0.2.2)

#   Requirement already satisfied: selenium in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (4.20.0)

#   Requirement already satisfied: webdriver-manager in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (4.0.1)

#   Requirement already satisfied: selenium_stealth in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (1.0.6)

#   Requirement already satisfied: gradio in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (4.21.0)

#   Requirement already satisfied: openai==1.27.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (1.27.0)

#   Requirement already satisfied: instructor==1.2.6 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (1.2.6)

#   Requirement already satisfied: deepdiff==6.7.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (6.7.1)

#   Requirement already satisfied: termcolor==2.3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (2.3.0)

#   Requirement already satisfied: python-dotenv==1.0.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (1.0.0)

#   Requirement already satisfied: rich==13.7.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (13.7.0)

#   Requirement already satisfied: jsonref==1.1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from agency-swarm) (1.1.0)

#   Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from deepdiff==6.7.1->agency-swarm) (4.1.0)

#   Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (3.9.3)

#   Requirement already satisfied: docstring-parser<0.17,>=0.16 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (0.16)

#   Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (2.7.0)

#   Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (2.18.1)

#   Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (8.2.3)

#   Requirement already satisfied: typer<1.0.0,>=0.9.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from instructor==1.2.6->agency-swarm) (0.9.0)

#   Requirement already satisfied: anyio<5,>=3.5.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (3.7.1)

#   Requirement already satisfied: distro<2,>=1.7.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (1.9.0)

#   Requirement already satisfied: httpx<1,>=0.23.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (0.26.0)

#   Requirement already satisfied: sniffio in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (1.3.0)

#   Requirement already satisfied: tqdm>4 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (4.66.2)

#   Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from openai==1.27.0->agency-swarm) (4.9.0)

#   Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from rich==13.7.0->agency-swarm) (3.0.0)

#   Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from rich==13.7.0->agency-swarm) (2.15.1)

#   Requirement already satisfied: urllib3<3,>=1.26 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.1.0)

#   Requirement already satisfied: trio~=0.17 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from selenium) (0.25.0)

#   Requirement already satisfied: trio-websocket~=0.9 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from selenium) (0.11.1)

#   Requirement already satisfied: certifi>=2021.10.8 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from selenium) (2024.2.2)

#   Requirement already satisfied: requests in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from webdriver-manager) (2.31.0)

#   Requirement already satisfied: packaging in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from webdriver-manager) (23.2)

#   Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (23.2.1)

#   Requirement already satisfied: altair<6.0,>=4.2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (5.2.0)

#   Requirement already satisfied: fastapi in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.110.0)

#   Requirement already satisfied: ffmpy in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.3.2)

#   Requirement already satisfied: gradio-client==0.12.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.12.0)

#   Requirement already satisfied: huggingface-hub>=0.19.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.21.4)

#   Requirement already satisfied: importlib-resources<7.0,>=1.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (6.3.1)

#   Requirement already satisfied: jinja2<4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.1.3)

#   Requirement already satisfied: markupsafe~=2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.1.3)

#   Requirement already satisfied: matplotlib~=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.8.3)

#   Requirement already satisfied: numpy~=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (1.26.4)

#   Requirement already satisfied: orjson~=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (3.9.10)

#   Requirement already satisfied: pandas<3.0,>=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.2.1)

#   Requirement already satisfied: pillow<11.0,>=8.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (10.2.0)

#   Requirement already satisfied: pydub in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.25.1)

#   Requirement already satisfied: python-multipart>=0.0.9 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.0.9)

#   Requirement already satisfied: pyyaml<7.0,>=5.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (6.0.1)

#   Requirement already satisfied: ruff>=0.2.2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.3.3)

#   Requirement already satisfied: semantic-version~=2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (2.10.0)

#   Requirement already satisfied: tomlkit==0.12.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.12.0)

#   Requirement already satisfied: uvicorn>=0.14.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio) (0.28.0)

#   Requirement already satisfied: fsspec in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio-client==0.12.0->gradio) (2024.3.1)

#   Requirement already satisfied: websockets<12.0,>=10.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from gradio-client==0.12.0->gradio) (11.0.3)

#   Requirement already satisfied: jsonschema>=3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)

#   Requirement already satisfied: toolz in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)

#   Requirement already satisfied: httpcore==1.* in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.27.0->agency-swarm) (1.0.4)

#   Requirement already satisfied: idna in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.27.0->agency-swarm) (3.4)

#   Requirement already satisfied: h11<0.15,>=0.13 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.27.0->agency-swarm) (0.14.0)

#   Requirement already satisfied: filelock in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)

#   Requirement already satisfied: contourpy>=1.0.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.2.0)

#   Requirement already satisfied: cycler>=0.10 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (0.12.1)

#   Requirement already satisfied: fonttools>=4.22.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (4.50.0)

#   Requirement already satisfied: kiwisolver>=1.3.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (1.4.5)

#   Requirement already satisfied: pyparsing>=2.3.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (3.1.2)

#   Requirement already satisfied: python-dateutil>=2.7 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from matplotlib~=3.0->gradio) (2.8.2)

#   Requirement already satisfied: pytz>=2020.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)

#   Requirement already satisfied: tzdata>=2022.7 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)

#   Requirement already satisfied: annotated-types>=0.4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.0->instructor==1.2.6->agency-swarm) (0.6.0)

#   Requirement already satisfied: attrs>=23.2.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.2.0)

#   Requirement already satisfied: sortedcontainers in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)

#   Requirement already satisfied: outcome in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)

#   Requirement already satisfied: exceptiongroup in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)

#   Requirement already satisfied: wsproto>=0.14 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)

#   Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer<1.0.0,>=0.9.0->instructor==1.2.6->agency-swarm) (8.1.7)

#   Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)

#   Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)

#   Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)

#   Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from fastapi->gradio) (0.36.3)

#   Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from requests->webdriver-manager) (2.0.4)

#   Requirement already satisfied: aiosignal>=1.1.2 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.2.6->agency-swarm) (1.3.1)

#   Requirement already satisfied: frozenlist>=1.1.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.2.6->agency-swarm) (1.4.1)

#   Requirement already satisfied: multidict<7.0,>=4.5 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.2.6->agency-swarm) (6.0.5)

#   Requirement already satisfied: yarl<2.0,>=1.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.2.6->agency-swarm) (1.9.4)

#   Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.9.1->instructor==1.2.6->agency-swarm) (4.0.3)

#   Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)

#   Requirement already satisfied: referencing>=0.28.4 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)

#   Requirement already satisfied: rpds-py>=0.7.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)

#   Requirement already satisfied: mdurl~=0.1 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich==13.7.0->agency-swarm) (0.1.2)

#   Requirement already satisfied: six>=1.5 in /Users/vrsen/anaconda3/envs/agency-swarm/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)


"""
# Basic Single Browsing Agent

**If you get an error, please quit chrome and re-run the cell.**

Also, make sure to reload the notebook or close demo each time you run it.
"""

import sys

sys.path.insert(0, "../")

# don't run this cell if you have already set the key in environment variables
from agency_swarm import set_openai_key

set_openai_key("YOUR_OPENAI_API_KEY")

from agency_swarm import Agency, Agent
from agency_swarm.agents import BrowsingAgent, Devid

selenium_config = {
    # your profile path
    # "chrome_profile_path": "/Users/vrsen/Library/Application Support/Google/Chrome Canary/Profile 1",
    "headless": False,
    "full_page_screenshot": False,
}

browsing_agent = BrowsingAgent(selenium_config=selenium_config)

agency = Agency([browsing_agent])

demo = agency.demo_gradio(height=700)  # reload the notebook each time you run this cell
# Output:
#   Files folder '/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/files' is not a directory. Skipping...

#   Schemas folder path is not a directory. Skipping...  /Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/schemas

#   Updating assistant... BrowsingAgent

#   Running on local URL:  http://127.0.0.1:7861

#   IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.

#   --------

#   

#   To create a public link, set `share=True` in `launch()`.

#   <IPython.core.display.HTML object>

demo.close()

"""
# Creating Your Own Browsing Swarm
In this example, we'll simply add a manager agent with some additional instructions so he can tell the browsing agent what to do next.
"""

import sys

sys.path.insert(0, "../")

# don't run this cell if you have already set the key in environment variables
from agency_swarm import set_openai_key

set_openai_key("YOUR_OPENAI_API_KEY")

from agency_swarm import Agency, Agent
from agency_swarm.agents import BrowsingAgent

report_manager = Agent(
    name="Report Manager",
    description="The Report Manager Agent is responsible for supervising data collection from various weather websites and compiling reports as necessary.",
    instructions="As a Report Manager Agent, your role involves direct interaction and oversight of the BrowsingAgent's operations. Your primary duty is to guarantee that the user's task is comprehensively and accurately completed. Achieve this by methodically breaking down each task from the user into smaller steps required to complete it. Then, issue each step of the task as a distinct message to the BrowsingAgent. Make sure to always tell the browsing agent to go back to google search results before proceeding to the the next source. After the necessary data is collection, compile a report and send it to the user. Make sure to ask the browsing agent for direct links to the sources and include them into report. Try to trouble shoot any issues that may arise along the way with the other agents first, before reporting back to the user. Do not respond to the user until the report is complete or you have encountered an issue that you cannot resolve yourself.",
)

selenium_config = {
    # your profile path
    # "chrome_profile_path": "/Users/vrsen/Library/Application Support/Google/Chrome/Profile 1",
    "headless": False,
    "full_page_screenshot": False,
}

browsing_agent = BrowsingAgent(selenium_config=selenium_config)
# Output:
#   Files folder '/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/files' is not a directory. Skipping...

#   Schemas folder path is not a directory. Skipping...  /Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/schemas


agency = Agency(
    [report_manager, [report_manager, browsing_agent]],
    shared_instructions="You are a part of a data collection agency with the goal to find the most relevant information about people on the web. Your core value is autonomy and you are free to use any means necessary to achieve your goal. You do not stop until you have found the information you need or you have exhausted all possible means. You always to to compile a comprehensive report with as much information from the web pages as possible.",
)
# Output:
#   Updating assistant... Report Manager

#   Updating assistant... BrowsingAgent


"""
Reload the notebook each time you run the cell below
"""

demo = agency.demo_gradio(height=700)
# Output:
#   Running on local URL:  http://127.0.0.1:7860

#   IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.

#   --------

#   

#   To create a public link, set `share=True` in `launch()`.

#   <IPython.core.display.HTML object>
#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   THREAD:[ Report Manager -> BrowsingAgent ]: URL https://platform.openai.com/playground/assistants?assistant=asst_NDddvs0pmyGfwNAAjn6Cx7vj&mode=assistant&thread=thread_wzOAoIbsqcyCvI04WJ5I77A1

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   ChromeOptions initialized.

#   ChromeDriver not found at /usr/bin/chromedriver. Installing using webdriver_manager.

#   Window size set to 1920,1080.

#   Chrome options configured.

#   WebDriver initialized successfully.

#   Profile path in use: /var/folders/y3/_zvpts1x6_5gsh98xj0xp2rc0000gn/T/.org.chromium.Chromium.Q3mfXq

#   Stealth mode configured.

#   Implicit wait set to 3 seconds.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   THREAD:[ Report Manager -> BrowsingAgent ]: URL https://platform.openai.com/playground/assistants?assistant=asst_NDddvs0pmyGfwNAAjn6Cx7vj&mode=assistant&thread=thread_wzOAoIbsqcyCvI04WJ5I77A1

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   THREAD:[ Report Manager -> BrowsingAgent ]: URL https://platform.openai.com/playground/assistants?assistant=asst_NDddvs0pmyGfwNAAjn6Cx7vj&mode=assistant&thread=thread_wzOAoIbsqcyCvI04WJ5I77A1

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   THREAD:[ Report Manager -> BrowsingAgent ]: URL https://platform.openai.com/playground/assistants?assistant=asst_NDddvs0pmyGfwNAAjn6Cx7vj&mode=assistant&thread=thread_wzOAoIbsqcyCvI04WJ5I77A1

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Message files:  []

#   THREAD:[ user -> Report Manager ]: URL https://platform.openai.com/playground/assistants?assistant=asst_HRMYJ9tA8t6SszeUEuCEGGf3&mode=assistant&thread=thread_Gn13VtIwN5UuddUiKyygG7pT

#   THREAD:[ Report Manager -> BrowsingAgent ]: URL https://platform.openai.com/playground/assistants?assistant=asst_NDddvs0pmyGfwNAAjn6Cx7vj&mode=assistant&thread=thread_wzOAoIbsqcyCvI04WJ5I77A1

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.

#   Initializing WebDriver...

#   Selenium imported successfully.

#   webdriver_manager imported successfully.

#   selenium_stealth imported successfully.

#   Returning existing WebDriver instance.


"""
Compile a report on Arsenii Shatokhin from the top 3 sources on google
"""

demo.close()
# Output:
#   Closing server running on port: 7860


"""
Here are the instructions:
1. Tell browsing agent to to https://www.youtube.com/results?search_query=ai+channels&sp=EgIQAg%253D%253D, which is a search results page for all channels on ai
2. Click on channel link
3. Click on more link near the channel description
4. Check if channel has email address.
5. If it doesn't, go back to step 2 and repeat for top 5 channels
4. If it does, Click on view email address
5. Solve captcha if required 
6. Copy email 
7. Repeat from step 1 for top 5 channels
8. Send emails back to me
"""

"""
# Breaking Captchas
You can run this example with no additional configuration.

However, to add your own cookies, go to `chrome://version/` Then copy Profile path folder and paste it into Chrome Canary installation folder. You might also need to login with google first time the browser window opens. Don't forget to allow less secure apps: https://support.google.com/accounts/answer/6010255?hl=en
"""

import sys

sys.path.insert(0, "../")

# don't run this cell if you have already set the key in environment variables
from agency_swarm import set_openai_key

set_openai_key("YOUR_OPENAI_API_KEY")

from agency_swarm import Agency
from agency_swarm.agents import BrowsingAgent

browsing_agent = BrowsingAgent(
    selenium_config={
        # "chrome_profile_path": "/Users/vrsen/Library/Application Support/Google/Chrome Canary/Profile 5", # path to your canary chrome profile
        "headless": False,  # set to True if you don't want to see the browser
    }
)
# Output:
#   Files folder '/Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/files' is not a directory. Skipping...

#   Schemas folder path is not a directory. Skipping...  /Users/vrsen/Projects/agency-swarm/agency-swarm/agency_swarm/agents/BrowsingAgent/schemas


agency = Agency([browsing_agent], shared_instructions="")
# Output:
#   Updating assistant... BrowsingAgent


"""
### Task Instructions:

Go to https://www.google.com/recaptcha/api2/demo and use solve captcha tool
"""

# Reload the notebook each time you run this cell
# Additionally, do not change browser window size, or it will not work
agency.demo_gradio(height=600)
# Output:
#   Running on local URL:  http://127.0.0.1:7860

#   IMPORTANT: You are using gradio version 4.21.0, however version 4.29.0 is available, please upgrade.

#   --------

#   

#   To create a public link, set `share=True` in `launch()`.

#   <IPython.core.display.HTML object>
#   Gradio Blocks instance: 6 backend functions

#   -------------------------------------------

#   fn_index=0

#    inputs:

#    |-textbox

#    |-chatbot

#    outputs:

#    |-textbox

#    |-chatbot

#   fn_index=1

#    inputs:

#    |-textbox

#    |-chatbot

#    outputs:

#    |-textbox

#    |-chatbot

#   fn_index=2

#    inputs:

#    |-dropdown

#    outputs:

#   fn_index=3

#    inputs:

#    |-file

#    outputs:

#   fn_index=4

#    inputs:

#    |-textbox

#    |-chatbot

#    outputs:

#    |-textbox

#    |-chatbot

#   fn_index=5

#    inputs:

#    |-textbox

#    |-chatbot

#    outputs:

#    |-textbox

#    |-chatbot



================================================
FILE: tests/__init__.py
================================================



================================================
FILE: tests/test_agency.py
================================================
import inspect
import json
import os
import shutil
import sys
import time
import unittest

import httpx

sys.path.insert(0, "../agency-swarm")

from openai.types.beta.threads import Text
from openai.types.beta.threads.runs import ToolCall
from pydantic import BaseModel
from typing_extensions import override

from agency_swarm import (
    Agency,
    AgencyEventHandler,
    Agent,
    get_openai_client,
)
from agency_swarm.tools import BaseTool, FileSearch, ToolFactory
from agency_swarm.tools.send_message import SendMessageAsyncThreading
from agency_swarm.util import create_agent_template

os.environ["DEBUG_MODE"] = "True"


class AgencyTest(unittest.TestCase):
    TestTool = None
    agency = None
    agent2 = None
    agent1 = None
    ceo = None
    num_schemas = None
    num_files = None
    client = None

    # testing loading agents from db
    loaded_thread_ids = None
    loaded_agents_settings = None
    settings_callbacks = None
    threads_callbacks = None

    @classmethod
    def setUpClass(cls):
        cls.num_files = 0
        cls.num_schemas = 0
        cls.ceo = None
        cls.agent1 = None
        cls.agent2 = None
        cls.agency = None
        cls.client = get_openai_client()
        cls.client.timeout = 60.0

        # testing loading agents from db
        cls.loaded_thread_ids = {}
        cls.loaded_agents_settings = []

        def save_settings_callback(settings):
            cls.loaded_agents_settings = settings

        cls.settings_callbacks = {
            "load": lambda: cls.loaded_agents_settings,
            "save": save_settings_callback,
        }

        def save_thread_callback(agents_and_thread_ids):
            cls.loaded_thread_ids = agents_and_thread_ids

        cls.threads_callbacks = {
            "load": lambda: cls.loaded_thread_ids,
            "save": save_thread_callback,
        }

        if not os.path.exists("./test_agents"):
            os.mkdir("./test_agents")
        else:
            shutil.rmtree("./test_agents")
            os.mkdir("./test_agents")

        # create init file
        with open("./test_agents/__init__.py", "w") as f:
            f.write("")

        # create agent templates in test_agents
        create_agent_template(
            "CEO",
            "CEO Test Agent",
            path="./test_agents",
            instructions="Your task is to tell TestAgent1 to say test to another test agent. If the "
            "agent, does not respond or something goes wrong please say 'error' and "
            "nothing else. Otherwise say 'success' and nothing else.",
            include_example_tool=True,
        )
        create_agent_template(
            "TestAgent1",
            "Test Agent 1",
            path="./test_agents",
            instructions="Your task is to say test to another test agent using SendMessage tool. "
            "If the agent, does not "
            "respond or something goes wrong please say 'error' and nothing else. "
            "Otherwise say 'success' and nothing else.",
            code_interpreter=True,
            include_example_tool=False,
        )
        create_agent_template(
            "TestAgent2",
            "Test Agent 2",
            path="./test_agents",
            instructions="After using TestTool, please respond to the user that test was a success in JSON format. You can use the following format: {'test': 'success'}.",
            include_example_tool=False,
        )

        # Create files and schemas directories
        os.makedirs("./test_agents/TestAgent1/files", exist_ok=True)
        os.makedirs("./test_agents/TestAgent2/schemas", exist_ok=True)

        # copy files from data/files to test_agents/TestAgent1/files
        for file in os.listdir("./data/files"):
            shutil.copyfile("./data/files/" + file, "./test_agents/TestAgent1/files/" + file)
            cls.num_files += 1

        # copy schemas from data/schemas to test_agents/TestAgent2/schemas
        for file in os.listdir("./data/schemas"):
            shutil.copyfile("./data/schemas/" + file, "./test_agents/TestAgent2/schemas/" + file)
            cls.num_schemas += 1

        from tests.test_agents.CEO.CEO import CEO
        from tests.test_agents.TestAgent1.TestAgent1 import TestAgent1
        from tests.test_agents.TestAgent2.TestAgent2 import TestAgent2

        class TestTool(BaseTool):
            """
            A simple test tool that returns "Test Successful" to demonstrate the functionality of a custom tool within the Agency Swarm framework.
            """

            class ToolConfig:
                strict = True

            def run(self):
                """
                Executes the test tool's main functionality. In this case, it simply returns a success message.
                """
                self._shared_state.set("test_tool_used", True)

                return "Test Successful"

        cls.TestTool = TestTool

        cls.agent1 = TestAgent1()
        cls.agent1.add_tool(FileSearch)
        cls.agent1.truncation_strategy = {"type": "last_messages", "last_messages": 10}
        cls.agent1.file_search = {"max_num_results": 49}

        cls.agent2 = TestAgent2()
        cls.agent2.add_tool(cls.TestTool)

        cls.agent2.response_format = {
            "type": "json_object",
        }

        cls.agent2.model = "gpt-4o"

        cls.ceo = CEO()
        cls.ceo.examples = [
            {"role": "user", "content": "Hi!"},
            {
                "role": "assistant",
                "content": "Hi! I am the CEO. I am here to help you with your testing. Please tell me who to send message to.",
            },
        ]

        cls.ceo.max_completion_tokens = 100

    def test_01_init_agency(self):
        """it should initialize agency with agents"""
        self.__class__.agency = Agency(
            [
                self.__class__.ceo,
                [self.__class__.ceo, self.__class__.agent1],
                [self.__class__.agent1, self.__class__.agent2],
            ],
            shared_instructions="This is a shared instruction",
            settings_callbacks=self.__class__.settings_callbacks,
            threads_callbacks=self.__class__.threads_callbacks,
            temperature=0,
        )

        self.assertTrue(self.__class__.TestTool.openai_schema["strict"])

        self.check_all_agents_settings()

    def test_02_load_agent(self):
        """it should load existing assistant from settings"""
        from tests.test_agents.TestAgent1.TestAgent1 import TestAgent1

        agent3 = TestAgent1()
        agent3.add_shared_instructions(self.__class__.agency.shared_instructions)
        agent3.tools = self.__class__.agent1.tools
        agent3.top_p = self.__class__.agency.top_p
        agent3.file_search = self.__class__.agent1.file_search
        agent3.temperature = self.__class__.agent1.temperature
        agent3.model = self.__class__.agent1.model
        agent3 = agent3.init_oai()

        print("agent3", agent3.assistant.model_dump())
        print("agent1", self.__class__.agent1.assistant.model_dump())

        self.assertTrue(self.__class__.agent1.id == agent3.id)

        # check that assistant settings match
        self.assertTrue(agent3._check_parameters(self.__class__.agent1.assistant.model_dump()))

        self.check_agent_settings(agent3)

    def test_03_load_agent_id(self):
        """it should load existing assistant from id"""
        agent3 = Agent(id=self.__class__.agent1.id)
        agent3.tools = self.__class__.agent1.tools
        agent3.file_search = self.__class__.agent1.file_search
        agent3 = agent3.init_oai()

        print("agent3", agent3.assistant.model_dump())
        print("agent1", self.__class__.agent1.assistant.model_dump())

        self.assertTrue(self.__class__.agent1.id == agent3.id)

        # check that assistant settings match
        self.assertTrue(agent3._check_parameters(self.__class__.agent1.assistant.model_dump()))

        self.check_agent_settings(agent3)

    def test_04_agent_communication(self):
        """it should communicate between agents"""
        self.test_01_init_agency()
        print("TestAgent1 tools", self.__class__.agent1.tools)
        self.__class__.agent1.parallel_tool_calls = False
        message = self.__class__.agency.get_completion(
            "Please tell TestAgent1 to say test to TestAgent2.",
            tool_choice={"type": "function", "function": {"name": "SendMessage"}},
        )

        self.assertFalse(
            "error" in message.lower(),
            f"Error found in message: {message}. Thread url: {self.__class__.agency.main_thread.thread_url}",
        )

        self.assertTrue(self.__class__.agency.agents_and_threads["main_thread"].id)
        self.assertTrue(self.__class__.agency.agents_and_threads["CEO"]["TestAgent1"].id)
        self.assertTrue(self.__class__.agency.agents_and_threads["TestAgent1"]["TestAgent2"].id)

        for agent in self.__class__.agency.agents:
            self.assertTrue(agent.id in [settings["id"] for settings in self.__class__.loaded_agents_settings])

        # assistants v2 checks
        main_thread = self.__class__.agency.main_thread
        main_thread_id = main_thread.id

        thread_messages = self.__class__.client.beta.threads.messages.list(main_thread_id, limit=100, order="asc")

        self.assertTrue(len(thread_messages.data) == 4)

        self.assertTrue(thread_messages.data[0].content[0].text.value == "Hi!")

        run = main_thread._run
        self.assertTrue(run.max_prompt_tokens == self.__class__.ceo.max_prompt_tokens)
        self.assertTrue(run.max_completion_tokens == self.__class__.ceo.max_completion_tokens)
        self.assertTrue(run.tool_choice.type == "function")

        agent1_thread = self.__class__.agency.agents_and_threads[self.__class__.ceo.name][self.__class__.agent1.name]

        agent1_thread_id = agent1_thread.id

        agent1_thread_messages = self.__class__.client.beta.threads.messages.list(agent1_thread_id, limit=100)

        self.assertTrue(len(agent1_thread_messages.data) == 2)

        agent1_run = agent1_thread._run

        self.assertTrue(agent1_run.truncation_strategy.type == "last_messages")
        self.assertTrue(agent1_run.truncation_strategy.last_messages == 10)
        self.assertFalse(agent1_run.parallel_tool_calls)

        agent2_thread = self.__class__.agency.agents_and_threads[self.__class__.agent1.name][self.__class__.agent2.name]

        agent2_message = agent2_thread._get_last_message_text()

        try:
            json.loads(agent2_message)
        except json.JSONDecodeError as e:
            self.assertTrue(False)

    def test_05_agent_communication_stream(self):
        """it should communicate between agents using streaming"""
        print("TestAgent1 tools", self.__class__.agent1.tools)

        test_tool_used = False
        test_agent2_used = False
        num_on_all_streams_end_calls = 0

        class EventHandler(AgencyEventHandler):
            @override
            def on_text_created(self, text) -> None:
                # get the name of the agent that is sending the message
                if self.recipient_agent_name == "TestAgent2":
                    nonlocal test_agent2_used
                    test_agent2_used = True

            def on_tool_call_done(self, tool_call: ToolCall) -> None:
                if tool_call.function.name == "TestTool":
                    nonlocal test_tool_used
                    test_tool_used = True

            @override
            @classmethod
            def on_all_streams_end(cls):
                nonlocal num_on_all_streams_end_calls
                num_on_all_streams_end_calls += 1

        message = self.__class__.agency.get_completion_stream(
            "Please tell TestAgent1 to tell TestAgent2 to use TestTool.",
            event_handler=EventHandler,
            additional_instructions="\n\n**Your message to TestAgent1 should be exactly as follows:** "
            "'Please tell TestAgent2 to use TestTool.'",
            tool_choice={"type": "function", "function": {"name": "SendMessage"}},
        )

        # self.assertFalse('error' in message.lower())

        self.assertTrue(test_tool_used)
        self.assertTrue(test_agent2_used)
        self.assertTrue(num_on_all_streams_end_calls == 1)

        self.assertTrue(self.__class__.TestTool._shared_state.get("test_tool_used"))

        agent1_thread = self.__class__.agency.agents_and_threads[self.__class__.ceo.name][self.__class__.agent1.name]
        self.assertFalse(agent1_thread._run.parallel_tool_calls)

        self.assertTrue(self.__class__.agency.main_thread.id)
        self.assertTrue(self.__class__.agency.agents_and_threads["CEO"]["TestAgent1"].id)
        self.assertTrue(self.__class__.agency.agents_and_threads["TestAgent1"]["TestAgent2"].id)

        for agent in self.__class__.agency.agents:
            self.assertTrue(agent.id in [settings["id"] for settings in self.__class__.loaded_agents_settings])

    def test_06_load_from_db(self):
        """it should load agents from db"""
        # os.rename("settings.json", "settings2.json")

        previous_loaded_thread_ids = self.__class__.loaded_thread_ids.copy()
        previous_loaded_agents_settings = self.__class__.loaded_agents_settings.copy()

        from tests.test_agents.CEO.CEO import CEO
        from tests.test_agents.TestAgent1.TestAgent1 import TestAgent1
        from tests.test_agents.TestAgent2.TestAgent2 import TestAgent2

        agent1 = TestAgent1()
        agent1.add_tool(FileSearch)

        agent1.truncation_strategy = {"type": "last_messages", "last_messages": 10}

        agent1.file_search = {"max_num_results": 49}

        agent2 = TestAgent2()
        agent2.add_tool(self.__class__.TestTool)

        agent2.response_format = {
            "type": "json_object",
        }

        ceo = CEO()

        # check that agents are loaded
        agency = Agency(
            [ceo, [ceo, agent1], [agent1, agent2]],
            shared_instructions="This is a shared instruction",
            settings_path="./settings2.json",
            settings_callbacks=self.__class__.settings_callbacks,
            threads_callbacks=self.__class__.threads_callbacks,
            temperature=0,
        )

        # check that settings are the same
        self.assertTrue(len(agency.agents) == len(self.__class__.agency.agents))

        os.remove("settings.json")
        os.rename("settings2.json", "settings.json")

        self.check_all_agents_settings()

        # check that threads are the same
        print("previous_loaded_thread_ids", previous_loaded_thread_ids)
        print("self.__class__.loaded_thread_ids", self.__class__.loaded_thread_ids)
        # Start of Selection
        for agent, threads in self.__class__.agency.agents_and_threads.items():
            if agent == "main_thread":
                print("main_thread", threads)
                continue
            for other_agent, thread in threads.items():
                print(f"Thread ID between {agent} and {other_agent}: {thread.id}")
        self.assertTrue(
            self.__class__.agency.agents_and_threads["main_thread"].id
            == previous_loaded_thread_ids["main_thread"]
            == self.__class__.loaded_thread_ids["main_thread"]
        )
        self.assertTrue(
            self.__class__.agency.agents_and_threads["CEO"]["TestAgent1"].id
            == previous_loaded_thread_ids["CEO"]["TestAgent1"]
            == self.__class__.loaded_thread_ids["CEO"]["TestAgent1"]
        )
        self.assertTrue(
            self.__class__.agency.agents_and_threads["TestAgent1"]["TestAgent2"].id
            == previous_loaded_thread_ids["TestAgent1"]["TestAgent2"]
            == self.__class__.loaded_thread_ids["TestAgent1"]["TestAgent2"]
        )

        # check that agents are the same
        for agent in agency.agents:
            self.assertTrue(agent.id in [settings["id"] for settings in self.__class__.loaded_agents_settings])
            self.assertTrue(agent.id in [settings["id"] for settings in previous_loaded_agents_settings])

    def test_07_init_async_agency(self):
        """it should initialize async agency with agents"""
        # reset loaded thread ids
        self.__class__.loaded_thread_ids = {}

        # Set ids for all agents to None
        self.__class__.ceo.id = None
        self.__class__.agent1.id = None
        self.__class__.agent2.id = None

        self.__class__.agent1.file_search = {"max_num_results": 49}

        self.__class__.agency = Agency(
            [
                self.__class__.ceo,
                [self.__class__.ceo, self.__class__.agent1],
                [self.__class__.agent1, self.__class__.agent2],
            ],
            shared_instructions="",
            settings_callbacks=self.__class__.settings_callbacks,
            threads_callbacks=self.__class__.threads_callbacks,
            send_message_tool_class=SendMessageAsyncThreading,
            temperature=0,
        )

        self.check_all_agents_settings(True)

    def test_08_async_agent_communication(self):
        """it should communicate between agents asynchronously"""
        self.__class__.agency.get_completion(
            "Please tell TestAgent2 hello.",
            tool_choice={"type": "function", "function": {"name": "SendMessage"}},
            recipient_agent=self.__class__.agent1,
        )

        time.sleep(10)

        num_on_all_streams_end_calls = 0
        delta_value = ""
        full_text = ""

        class EventHandler(AgencyEventHandler):
            @override
            def on_text_delta(self, delta, snapshot):
                nonlocal delta_value
                delta_value += delta.value

            @override
            def on_text_done(self, text: Text) -> None:
                nonlocal full_text
                full_text += text.value

            @override
            @classmethod
            def on_all_streams_end(cls):
                nonlocal num_on_all_streams_end_calls
                num_on_all_streams_end_calls += 1

        message = self.__class__.agency.get_completion_stream(
            "Please check response. If output includes `TestAgent2's Response`, say 'success'. If the function output does not include `TestAgent2's Response`, or if you get a System Notification, or an error instead, say 'error'.",
            tool_choice={"type": "function", "function": {"name": "GetResponse"}},
            recipient_agent=self.__class__.agent1,
            event_handler=EventHandler,
        )

        self.assertTrue(num_on_all_streams_end_calls == 1)

        self.assertTrue(delta_value == full_text == message)

        self.assertTrue(EventHandler.agent_name == "User")
        self.assertTrue(EventHandler.recipient_agent_name == "TestAgent1")

        if "error" in message.lower():
            self.assertFalse("error" in message.lower(), self.__class__.agency.main_thread.thread_url)

        self.assertTrue(self.__class__.agency.main_thread.id)
        self.assertTrue(self.__class__.agency.agents_and_threads["TestAgent1"]["TestAgent2"].id)

        for agent in self.__class__.agency.agents:
            self.assertTrue(agent.id in [settings["id"] for settings in self.__class__.loaded_agents_settings])

    def test_09_async_tool_calls(self):
        """it should execute tools asynchronously"""

        class PrintTool(BaseTool):
            class ToolConfig:
                async_mode = "threading"

            def run(self, **kwargs):
                time.sleep(2)  # Simulate a delay
                return "Printed successfully."

        class AnotherPrintTool(BaseTool):
            class ToolConfig:
                async_mode = "threading"

            def run(self, **kwargs):
                time.sleep(2)  # Simulate a delay
                return "Another print successful."

        ceo = Agent(name="CEO", tools=[PrintTool, AnotherPrintTool])

        agency = Agency([ceo], temperature=0)

        result = agency.get_completion(
            "Use 2 print tools together at the same time and output the results exectly as they are. ",
            yield_messages=False,
        )

        self.assertIn("success", result.lower(), agency.main_thread.thread_url)
        self.assertIn("success", result.lower(), agency.main_thread.thread_url)

    def test_10_concurrent_API_calls(self):
        """it should execute API calls concurrently with asyncio"""

        # Create a mock client that will be used instead of httpx
        class MockClient:
            def __init__(self, **kwargs):
                self.timeout = kwargs.get("timeout", None)

            async def __aenter__(self):
                return self

            async def __aexit__(self, exc_type, exc_val, exc_tb):
                pass

            async def get(self, url, params=None, headers=None):
                # Verify that the domain parameter is correctly set in the URL
                if "print-headers-gntxktyfsq-uc.a.run.app" in url:

                    class MockResponse:
                        def json(self):
                            return {"headers": {"test": "success"}}

                        def raise_for_status(self):
                            pass

                    return MockResponse()
                raise ValueError(f"Invalid URL: {url}")

            async def aclose(self):
                pass

        # Patch httpx.AsyncClient with our mock
        original_client = httpx.AsyncClient
        httpx.AsyncClient = MockClient

        try:
            tools = []
            with open("./data/schemas/get-headers-params.json", "r") as f:
                tools = ToolFactory.from_openapi_schema(f.read(), {})

            ceo = Agent(
                name="CEO",
                tools=tools,
                instructions="""You are an agent that tests concurrent API calls. You must say 'success' if the output contains headers, and 'error' if it does not and **nothing else**.""",
            )

            agency = Agency([ceo], temperature=0)

            result = agency.get_completion(
                "Please call PrintHeaders tool TWICE at the same time in a single message with domain='print-headers' and query='test'. If any of the function outputs do not contain headers, please say 'error'."
            )

            self.assertTrue(result.lower().count("error") == 0, agency.main_thread.thread_url)
        finally:
            # Restore original client
            httpx.AsyncClient = original_client

    def test_11_structured_outputs(self):
        class MathReasoning(BaseModel):
            class Step(BaseModel):
                explanation: str
                output: str

            steps: list[Step]
            final_answer: str

        math_tutor_prompt = """
            You are a helpful math tutor. You will be provided with a math problem,
            and your goal will be to output a step by step solution, along with a final answer.
            For each step, just provide the output as an equation use the explanation field to detail the reasoning.
        """

        agent = Agent(
            name="MathTutor",
            response_format=MathReasoning,
            instructions=math_tutor_prompt,
        )

        agency = Agency([agent], temperature=0)

        result = agency.get_completion("how can I solve 8x + 7 = -23")

        # check if result is a MathReasoning object
        self.assertTrue(MathReasoning.model_validate_json(result))

        result = agency.get_completion_parse("how can I solve 3x + 2 = 14", response_format=MathReasoning)

        # check if result is a MathReasoning object
        self.assertTrue(isinstance(result, MathReasoning))

    # --- Helper methods ---

    def get_class_folder_path(self):
        return os.path.abspath(os.path.dirname(inspect.getfile(self.__class__)))

    def check_agent_settings(self, agent, async_mode=False):
        try:
            settings_path = agent.get_settings_path()
            self.assertTrue(os.path.exists(settings_path))
            with open(settings_path, "r") as f:
                settings = json.load(f)
                for assistant_settings in settings:
                    if assistant_settings["id"] == agent.id:
                        self.assertTrue(agent._check_parameters(assistant_settings, debug=True))

            assistant = agent.assistant
            self.assertTrue(assistant)
            self.assertTrue(agent._check_parameters(assistant.model_dump(), debug=True))
            if agent.name == "TestAgent1":
                num_tools = 3 if not async_mode else 4

                self.assertTrue(len(assistant.tool_resources.model_dump()["code_interpreter"]["file_ids"]) == 3)
                self.assertTrue(len(assistant.tool_resources.model_dump()["file_search"]["vector_store_ids"]) == 1)

                vector_store_id = assistant.tool_resources.model_dump()["file_search"]["vector_store_ids"][0]
                vector_store_files = agent.client.vector_stores.files.list(vector_store_id=vector_store_id)

                file_ids = [file.id for file in vector_store_files.data]

                # Add debug output
                print("Vector store files:", len(file_ids))

                self.assertTrue(len(file_ids) == 8)
                # check retrieval tools is there
                self.assertTrue(len(assistant.tools) == num_tools)
                self.assertTrue(len(agent.tools) == num_tools)
                self.assertTrue(assistant.tools[0].type == "code_interpreter")
                self.assertTrue(assistant.tools[1].type == "file_search")
                if not async_mode:
                    self.assertTrue(assistant.tools[1].file_search.max_num_results == 49)  # Updated line
                self.assertTrue(assistant.tools[2].type == "function")
                self.assertTrue(assistant.tools[2].function.name == "SendMessage")
                self.assertFalse(assistant.tools[2].function.strict)
                if async_mode:
                    self.assertTrue(assistant.tools[3].type == "function")
                    self.assertTrue(assistant.tools[3].function.name == "GetResponse")
                    self.assertFalse(assistant.tools[3].function.strict)

            elif agent.name == "TestAgent2":
                self.assertTrue(len(assistant.tools) == self.__class__.num_schemas + 1)
                for tool in assistant.tools:
                    self.assertTrue(tool.type == "function")
                    self.assertTrue(tool.function.name in [tool.__name__ for tool in agent.tools])
                test_tool = next(
                    (tool for tool in assistant.tools if tool.function.name == "TestTool"),
                    None,
                )
                self.assertTrue(test_tool.function.strict, test_tool)
            elif agent.name == "CEO":
                num_tools = 1 if not async_mode else 2
                self.assertFalse(assistant.tool_resources.code_interpreter)
                self.assertFalse(assistant.tool_resources.file_search)
                self.assertTrue(len(assistant.tools) == num_tools)
            else:
                pass
        except Exception as e:
            print("Error checking agent settings ", agent.name)
            raise e

    def check_all_agents_settings(self, async_mode=False):
        self.check_agent_settings(self.__class__.ceo, async_mode=async_mode)
        self.check_agent_settings(self.__class__.agent1, async_mode=async_mode)
        self.check_agent_settings(self.__class__.agent2, async_mode=async_mode)

    @classmethod
    def tearDownClass(cls):
        shutil.rmtree("./test_agents")
        # os.remove("./settings.json")
        if cls.agency:
            cls.agency.delete()


if __name__ == "__main__":
    unittest.main()



================================================
FILE: tests/test_communication.py
================================================
import time

import pytest
from pydantic import Field

from agency_swarm import Agency, Agent
from agency_swarm.tools import BaseTool
from agency_swarm.tools.send_message import SendMessageSwarm


@pytest.fixture
def test_agents():
    class PrintTool(BaseTool):
        """
        A simple tool that prints a message.
        """

        message: str = Field(..., description="The message to print.")

        def run(self):
            print(self.message)
            return f"Printed: {self.message}"

    ceo = Agent(
        name="CEO",
        description="Responsible for client communication, task planning and management.",
        instructions="""You are a CEO agent responsible for routing messages to other agents within your agency.
When a user asks to be connected to customer support or mentions needing help with an issue:
1. Use the SendMessageSwarm tool to immediately route them to the Customer Support agent
2. Do not engage in extended conversation - route them directly
3. Only respond with 'error' if you detect multiple routing requests at once""",
        tools=[PrintTool],
    )

    customer_support = Agent(
        name="Customer Support",
        description="Responsible for customer support.",
        instructions="You are a Customer Support agent. Answer customer questions and help with issues.",
        tools=[],
    )

    agency = Agency(
        [
            ceo,
            [ceo, customer_support],
            [customer_support, ceo],
        ],
        temperature=0,
        send_message_tool_class=SendMessageSwarm,
    )

    return ceo, customer_support, agency


def test_send_message_swarm(test_agents):
    _, customer_support, agency = test_agents
    start_time = time.time()
    timeout = 30  # 30 second timeout

    response = None
    while time.time() - start_time < timeout:
        try:
            response = agency.get_completion("Hello, I need customer support please.")
            break
        except Exception as e:
            time.sleep(1)
            continue

    assert response is not None, "Test timed out after 30 seconds"
    assert "error" not in response.lower(), agency.main_thread.thread_url

    response = agency.get_completion("Who are you?")
    assert "customer support" in response.lower(), agency.main_thread.thread_url

    main_thread = agency.main_thread

    # check if recipient agent is correct
    assert main_thread.recipient_agent == customer_support

    # check if all messages in the same thread (this is how Swarm works)
    assert (
        len(main_thread.get_messages()) >= 4
    )  # sometimes run does not cancel immediately, so there might be 5 messages


def test_send_message_double_recipient_error(test_agents):
    _, customer_support, _ = test_agents
    ceo = Agent(
        name="CEO",
        description="Responsible for client communication, task planning and management.",
        instructions="""You are an agent for testing. When asked to route requests AT THE SAME TIME:
            1. If you detect multiple simultaneous routing requests, respond with 'error'
            2. If you detect errors in all routing attempts, respond with 'fatal'
            3. Do not output anything else besides these exact words.""",
    )
    agency = Agency([ceo, [ceo, customer_support]], temperature=0)
    response = agency.get_completion(
        "Route me to customer support TWICE simultaneously (at the exact same time). This is a test of concurrent routing."
    )
    assert "error" in response.lower(), agency.main_thread.thread_url
    assert "fatal" not in response.lower(), agency.main_thread.thread_url



================================================
FILE: tests/test_mcp.py
================================================
import os
import signal
import platform
import subprocess
import sys
import time

import pytest
from dotenv import load_dotenv

from agency_swarm.agency import Agency
from agency_swarm.agents.agent import Agent
from agency_swarm.tools.mcp import MCPServerSse, MCPServerStdio

load_dotenv()

samples_dir = os.path.join(os.path.dirname(__file__), "data", "files")
server_file = os.path.join(os.path.dirname(__file__), "scripts", "server.py")


@pytest.fixture(scope="module", autouse=True)
def start_server():
    # Start the server as a subprocess
    process = subprocess.Popen([sys.executable, server_file])
    time.sleep(5)  # Give it time to start
    yield
    # Try sending SIGINT (Ctrl+C) for a cleaner shutdown
    if platform.system() == "Windows":
        process.terminate()
    else:
        process.send_signal(signal.SIGINT)
    try:
        process.wait(timeout=10)  # Wait up to 10 seconds
    except subprocess.TimeoutExpired:
        print("Server did not terminate gracefully, sending SIGTERM")
        process.terminate()
        try:
            process.wait(timeout=5)
        except subprocess.TimeoutExpired:
            print("Server did not terminate after SIGTERM, sending SIGKILL")
            process.kill()
            process.wait()


@pytest.fixture(scope="module")
def agency():
    filesystem_server = MCPServerStdio(
        name="Filesystem Server",
        params={
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", samples_dir],
        },
    )

    git_server = MCPServerStdio(
        name="Git Server",
        params={
            "command": "mcp-server-git",
        },
    )

    sse_server = MCPServerSse(
        name="SSE Python Server",
        params={"url": "http://localhost:8080/sse"},
        strict=True,
        allowed_tools=["get_secret_word"]
    )

    # Serialize agent initialization
    agents = []
    for name, server in [
        ("test1", filesystem_server),
        ("test2", git_server),
        ("test3", sse_server),
    ]:
        agent = Agent(
            name=name,
            description="test",
            instructions="test",
            mcp_servers=[server],
            temperature=0,
        )
        agents.append(agent)

    return Agency(agents)


# Might take a bit to process
def test_read_filesystem(agency):
    result = agency.get_completion(f"Use the list_directory tool to read the contents of {samples_dir} folder.", recipient_agent=agency.agents[0])
    print(result)
    assert "csv-test.csv" in result


def test_read_git_commit(agency):
    root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    result = agency.get_completion(f"Read the last commit of the {root_dir} folder. Provide result in the exact same format as you receive it.", recipient_agent=agency.agents[1])
    print(result)
    assert "Author" in result


def test_get_secret_word(agency):
    result = agency.get_completion("Get secret word using get_secret_word tool.", recipient_agent=agency.agents[2])
    print(result)
    assert "strawberry" in result.lower()


if __name__ == "__main__":
    import pytest

    pytest.main(["-v", __file__])



================================================
FILE: tests/test_tool_factory.py
================================================
import asyncio
import os
import shutil
import subprocess
import sys
import time
from enum import Enum
from typing import List, Optional

import httpx
import pytest
from langchain_community.tools import MoveFileTool, YouTubeSearchTool
from pydantic import BaseModel, ConfigDict, Field

from agency_swarm.tools import BaseTool, ToolFactory
from agency_swarm.tools.mcp import MCPServerSse, MCPServerStdio
from agency_swarm.util import get_openai_client
from agency_swarm.util.helpers.sync_async import run_async_sync


@pytest.fixture
def client():
    return get_openai_client()


def test_move_file_tool():
    tool = ToolFactory.from_langchain_tool(MoveFileTool())
    tool = tool(
        destination_path="Move a file from one folder to another",
        source_path="Move a file from one folder to another",
    )
    tool.run()


def test_complex_schema():
    class FriendDetail(BaseModel):
        """test 123"""

        model_config = ConfigDict(title="FriendDetail")

        id: int = Field(..., description="Unique identifier for each friend.")
        name: str = Field(..., description="Name of the friend.")
        age: Optional[int] = Field(25, description="Age of the friend.")
        email: Optional[str] = Field(None, description="Email address of the friend.")
        is_active: Optional[bool] = Field(
            None, description="Indicates if the friend is currently active."
        )

    class UserDetail(BaseModel):
        """Hey this is a test?"""

        model_config = ConfigDict(title="UserDetail")

        id: int = Field(..., description="Unique identifier for each user.")
        age: int
        name: str
        friends: List[FriendDetail] = Field(
            ...,
            description="List of friends, each represented by a FriendDetail model.",
        )

    class RelationshipType(str, Enum):
        FAMILY = "family"
        FRIEND = "friend"
        COLLEAGUE = "colleague"

    class UserRelationships(BaseTool):
        """Hey this is a test?"""

        model_config = ConfigDict(title="User Relationships")

        users: List[UserDetail] = Field(
            ...,
            description="Collection of users, correctly capturing the relationships among them.",
            title="Users",
        )
        relationship_type: RelationshipType = Field(
            ...,
            description="Type of relationship among users.",
            title="Relationship Type",
        )

    tool = ToolFactory.from_openai_schema(UserRelationships.openai_schema, lambda x: x)

    user_detail_instance = {
        "id": 1,
        "age": 20,
        "name": "John Doe",
        "friends": [{"id": 1, "name": "Jane Doe"}],
    }
    user_relationships_instance = {
        "users": [user_detail_instance],
        "relationship_type": "family",
    }

    tool = tool(**user_relationships_instance)

    user_relationships_schema = UserRelationships.openai_schema

    def remove_empty_fields(d):
        """
        Recursively remove all empty fields from a dictionary.
        """
        if not isinstance(d, dict):
            return d
        return {
            k: remove_empty_fields(v) for k, v in d.items() if v not in [{}, [], ""]
        }

    cleaned_schema = remove_empty_fields(user_relationships_schema)
    tool_schema = tool.openai_schema

    assert cleaned_schema == tool_schema


def test_youtube_search_tool():
    # requires pip install youtube_search to run
    ToolFactory.from_langchain_tool(YouTubeSearchTool)


def test_custom_tool():
    schema = {
        "name": "query_database",
        "description": "Use this funciton to query the database that provides insights about the interests of different family and household segments and describes various aspects of demographic data. It also contains advertising data, offering insights into various channels and platforms to provide a granular view of advertising performance. Use when you don't already have enough information to answer the user's question based on your previous responses.",
        "parameters": {
            "type": "object",
            "properties": {
                "query": {
                    "type": "string",
                    "description": "Query to the demographic database. Must be clearly stated in natural language.",
                },
            },
            "required": ["query"],
        },
        "strict": False,
    }

    tool = ToolFactory.from_openai_schema(schema, lambda x: x)

    schema["strict"] = True

    tool2 = ToolFactory.from_openai_schema(schema, lambda x: x)

    tool = tool(query="John Doe")

    assert not tool.openai_schema.get("strict", False)

    tool.run()

    assert tool2.openai_schema["strict"]


def test_get_weather_openapi():
    with open("./data/schemas/get-weather.json", "r") as f:
        tools = ToolFactory.from_openapi_schema(f.read(), {})

    assert not tools[0].openai_schema.get("strict", False)


@pytest.mark.asyncio
async def test_relevance_openapi_schema():
    with open("./data/schemas/relevance.json", "r") as f:
        # Create a mock client that will be used instead of httpx
        class MockClient:
            def __init__(self, **kwargs):
                self.timeout = kwargs.get("timeout", None)

            async def __aenter__(self):
                return self

            async def __aexit__(self, exc_type, exc_val, exc_tb):
                pass

            async def post(self, *args, **kwargs):
                class MockResponse:
                    def json(self):
                        return {"output": {"transformed": {"data": "test complete."}}}

                return MockResponse()

        # Patch httpx.AsyncClient with our mock
        original_client = httpx.AsyncClient
        httpx.AsyncClient = MockClient

        try:
            tools = ToolFactory.from_openapi_schema(
                f.read(), {"Authorization": "mock-key"}
            )

            output = await tools[0](requestBody={"text": "test"}).run()

            assert output["output"]["transformed"]["data"] == "test complete."
        finally:
            # Restore original client
            httpx.AsyncClient = original_client


@pytest.mark.asyncio
async def test_get_headers_openapi_schema():
    with open("./data/schemas/get-headers-params.json", "r") as f:
        tools = ToolFactory.from_openapi_schema(
            f.read(), {"Bearer": os.environ.get("GET_HEADERS_SCHEMA_API_KEY")}
        )

        output = await tools[0](
            parameters={"domain": "print-headers", "query": "test"}
        ).run()

        assert "headers" in output


def test_ga4_openapi_schema():
    with open("./data/schemas/ga4.json", "r") as f:
        tools = ToolFactory.from_openapi_schema(f.read(), {})

    assert len(tools) == 1
    assert tools[0].__name__ == "runReport"


def test_import_from_file():
    tool = ToolFactory.from_file("./data/tools/ExampleTool1.py")
    assert tool.__name__ == "ExampleTool1"
    assert tool(content="test").run() == "Tool output"


def test_mcp_filesystem():
    """Test the ToolFactory.from_mcp method with a filesystem MCP server"""
    # Skip if npx is not installed
    if not shutil.which("npx"):
        pytest.skip(
            "npx is not installed. Please install it with `npm install -g npx`."
        )

    # Get the sample files directory
    samples_dir = os.path.join(os.path.dirname(__file__), "data", "files")

    # Skip if the test file doesn't exist
    test_file = "favorite_books.txt"
    file_path = os.path.join(samples_dir, test_file)

    server_process = None
    try:
        # Create an MCP server for filesystem operations
        server = MCPServerStdio(
            params={
                "command": "npx",
                "args": ["-y", "@modelcontextprotocol/server-filesystem", samples_dir],
            }
        )

        # Store server process for cleanup
        if hasattr(server, "_process") and server._process:
            server_process = server._process

        # Get tools from the MCP server
        tools = ToolFactory.from_mcp(server)
        assert len(tools) > 0, "No tools were created from MCP server"

        # Find the read_file tool
        read_file_tool = None
        for tool in tools:
            if tool.__name__ == "read_file":
                read_file_tool = tool
                break

        assert read_file_tool is not None, "read_file tool not found in created tools"

        read_file_instance = read_file_tool(path=file_path)
        result = run_async_sync(read_file_instance.run)

        # Verify the result
        assert isinstance(result, str), "Tool result is not a string"
        assert len(result) > 0, "Tool returned empty result"
        assert "Error" not in result, f"Tool returned error: {result}"
    finally:
        # Ensure the server process is properly cleaned up
        if server_process and server_process.poll() is None:
            try:
                server_process.terminate()
                server_process.wait(timeout=5)
            except: #noqa
                if server_process.poll() is None:
                    server_process.kill()
                    server_process.wait()

        # Force garbage collection to clean up resources before event loop closes
        import gc

        gc.collect()


def test_mcp_git():
    """Test the ToolFactory.from_mcp method with a Git MCP server"""

    # Check if git is installed
    if not shutil.which("git"):
        pytest.skip("git is not installed")

    # Try to install the MCP Git server Python package if not already installed
    install_process = None
    try:
        install_process = subprocess.Popen(
            [sys.executable, "-m", "pip", "install", "mcp-server-git"],
        )
        install_process.wait(timeout=30)
        print("Installed mcp-server-git Python package")
    except (subprocess.SubprocessError, subprocess.TimeoutExpired):
        print(
            "Note: Failed to install mcp-server-git package (may already be installed)"
        )
    finally:
        # Ensure process is terminated even if wait times out
        if install_process and install_process.poll() is None:
            try:
                install_process.terminate()
                install_process.wait(timeout=2)
            except: #noqa
                if install_process.poll() is None:
                    install_process.kill()

    server_process = None
    try:
        # Create an MCP server for Git operations using Python's module system
        server = MCPServerStdio(
            name="Git Server",
            params={
                "command": "mcp-server-git",
            },
            strict=False,
        )
        # Store the server process for later cleanup
        if hasattr(server, "_process") and server._process:
            server_process = server._process

        # Get tools from the MCP server
        tools = ToolFactory.from_mcp(server)
        assert len(tools) > 0, "No Git tools were created"

        # Verify that at least one tool has a git-related name
        git_tool_found = False
        for tool in tools:
            if any(
                keyword in tool.__name__.lower()
                for keyword in ["git", "commit", "branch", "repo"]
            ):
                git_tool_found = True
                break

        assert git_tool_found, "No Git-related tools were found"

        # Find the git_status tool and test it
        git_status_tool = None
        for tool in tools:
            if tool.__name__ == "git_status":
                git_status_tool = tool
                break

        if git_status_tool is not None:
            repo_path = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
            status_tool = git_status_tool(repo_path=repo_path)

            status_result = run_async_sync(status_tool.run)
            assert isinstance(
                status_result, str
            ), "Expected string result from git tool"
            assert len(status_result) > 0, "Expected non-empty result from git tool"
            assert (
                "Repository status:" in status_result
            ), "Expected 'Repository status:' in result"
        else:
            pytest.skip("No suitable git tool found")
    except asyncio.TimeoutError:
        pytest.skip("Git MCP server test timed out after 30 seconds")
    except Exception as e:
        pytest.skip(f"Git MCP server test failed: {str(e)}")
    finally:
        # Ensure any leftover processes are terminated
        if server_process and server_process.poll() is None:
            try:
                server_process.terminate()
                server_process.wait(timeout=5)
            except: #noqa
                if server_process.poll() is None:
                    server_process.kill()
                    server_process.wait()

        # Force garbage collection to clean up resources before event loop closes
        import gc

        gc.collect()


@pytest.mark.asyncio
async def test_mcp_sse():
    """Test the ToolFactory.from_mcp method with an SSE MCP server"""

    # Skip if Python is not available
    if not shutil.which(sys.executable):
        pytest.skip("Python executable not found")

    # Get the server file
    server_file = os.path.join(os.path.dirname(__file__), "scripts", "server.py")

    if not os.path.exists(server_file):
        pytest.skip(f"Test file {server_file} not found")

    # Start the server process
    process = None
    try:
        # Start the server using Python
        process = subprocess.Popen([sys.executable, server_file])

        # Give it time to start
        time.sleep(5)

        # Create an MCPServerSse instance
        server = MCPServerSse(
            params={"url": "http://localhost:8080/sse"}
        )
        # Get tools from the MCP server
        tools = ToolFactory.from_mcp(server)

        # Verify tools were created successfully
        assert len(tools) == 3, f"Expected 3 tools, got {len(tools)}"

        # Get the add tool
        add_tool = next((tool for tool in tools if tool.__name__ == "add"), None)
        assert add_tool is not None, "add tool not found"

        # Create an instance of the add tool
        add_instance = add_tool(a=7, b=22)
        result = await add_instance.run()
        assert str(result) == "29", f"Expected 29, got {result}"

        # Get the weather tool
        weather_tool = next(
            (tool for tool in tools if tool.__name__ == "get_current_weather"), None
        )
        assert weather_tool is not None, "get_current_weather tool not found"

        # Create an instance of the weather tool
        weather_instance = weather_tool(city="Tokyo")
        result = await weather_instance.run()
        assert "Weather report:" in result

        # Get the secret word tool
        secret_tool = next(
            (tool for tool in tools if tool.__name__ == "get_secret_word"), None
        )
        assert secret_tool is not None, "get_secret_word tool not found"

        # Create an instance of the secret word tool
        secret_instance = secret_tool()
        result = await secret_instance.run()

        assert result.lower() in ["apple", "banana", "cherry", "strawberry"]

    finally:
        # Clean up the server process
        if process:
            process.terminate()
            try:
                process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                process.kill()
                process.wait()

        # Force garbage collection to clean up resources before event loop closes
        import gc

        gc.collect()


if __name__ == "__main__":
    pytest.main()



================================================
FILE: tests/data/files/csv-test.csv
================================================
csv-test
Pivot Table Basics: Sales;;;;;
Date;Product;Power;Units;Revenue;Secret phrase
January;Bicycles;Electric;476;751Â 604,00Â UAH;CSV SECRET PHRASE
January;Bicycles;Manual;302;581Â 350,00Â UAH;
January;Scooters;Electric;387;427Â 248,00Â UAH;
January;Scooters;Manual;309;48Â 513,00Â UAH;
January;Skateboards;Electric;251;135Â 791,00Â UAH;
February;Bicycles;Electric;354;558Â 966,00Â UAH;
February;Bicycles;Manual;219;336Â 165,00Â UAH;
February;Scooters;Electric;312;583Â 128,00Â UAH;
February;Scooters;Manual;419;396Â 793,00Â UAH;
February;Skateboards;Electric;315;388Â 395,00Â UAH;
March;Bicycles;Electric;392;39Â 200,00Â UAH;
March;Bicycles;Manual;464;892Â 736,00Â UAH;
March;Scooters;Electric;211;151Â 498,00Â UAH;
March;Scooters;Manual;293;467Â 628,00Â UAH;
March;Skateboards;Electric;467;798Â 570,00Â UAH;
;;;;;
Pivot Table Basics: Sales Pivot;;;;;
;Date (Month);January;February;March;Grand Total
Power;Product;Units (Sum);;;
Electric;Bicycles;476;354;392;1Â 222
;Scooters;387;312;211;910
;Skateboards;251;315;467;1Â 033
Electric Total;;1Â 114;981;1Â 070;3Â 165
Manual;Bicycles;302;219;464;985
;Scooters;309;419;293;1Â 021
Manual Total;;611;638;757;2Â 006
Grand Total;;1Â 725;1Â 619;1Â 827;5Â 171
;;;;;
Pivot Table Practice: Sales;;;;;
Date;Product;Power;Units;Revenue;
January;Bicycles;Electric;476;751Â 604,00Â UAH;
January;Bicycles;Manual;302;581Â 350,00Â UAH;
January;Scooters;Electric;387;427Â 248,00Â UAH;
January;Scooters;Manual;309;48Â 513,00Â UAH;
January;Skateboards;Electric;251;135Â 791,00Â UAH;
February;Bicycles;Electric;354;558Â 966,00Â UAH;
February;Bicycles;Manual;219;336Â 165,00Â UAH;
February;Scooters;Electric;312;583Â 128,00Â UAH;
February;Scooters;Manual;419;396Â 793,00Â UAH;
February;Skateboards;Electric;315;388Â 395,00Â UAH;
March;Bicycles;Electric;392;39Â 200,00Â UAH;
March;Bicycles;Manual;464;892Â 736,00Â UAH;
March;Scooters;Electric;211;151Â 498,00Â UAH;
March;Scooters;Manual;293;467Â 628,00Â UAH;
March;Skateboards;Electric;467;798Â 570,00Â UAH;
;;;;;
Pivot Table Practice: Sales Pivot;;;;;
;Columns;;;;
Rows;Values;;;;


================================================
FILE: tests/data/files/favorite_books.txt
================================================
1. To Kill a Mockingbird â€“ Harper Lee
2. Pride and Prejudice â€“ Jane Austen
3. 1984 â€“ George Orwell
4. The Hobbit â€“ J.R.R. Tolkien
5. Harry Potter and the Sorcererâ€™s Stone â€“ J.K. Rowling
6. The Great Gatsby â€“ F. Scott Fitzgerald
7. Charlotteâ€™s Web â€“ E.B. White
8. Anne of Green Gables â€“ Lucy Maud Montgomery
9. The Alchemist â€“ Paulo Coelho
10. Little Women â€“ Louisa May Alcott
11. The Catcher in the Rye â€“ J.D. Salinger
12. Animal Farm â€“ George Orwell
13. The Chronicles of Narnia: The Lion, the Witch, and the Wardrobe â€“ C.S. Lewis
14. The Book Thief â€“ Markus Zusak
15. A Wrinkle in Time â€“ Madeleine Lâ€™Engle
16. The Secret Garden â€“ Frances Hodgson Burnett
17. Moby-Dick â€“ Herman Melville
18. Fahrenheit 451 â€“ Ray Bradbury
19. Jane Eyre â€“ Charlotte BrontÃ«
20. The Little Prince â€“ Antoine de Saint-ExupÃ©ry


================================================
FILE: tests/data/files/favorite_cities.txt
================================================
- In the summer, I love visiting London.
- In the winter, Tokyo is great.
- In the spring, San Francisco.
- In the fall, New York is the best.


================================================
FILE: tests/data/files/favorite_songs.txt
================================================
1. "Here Comes the Sun" â€“ The Beatles
2. "Imagine" â€“ John Lennon
3. "Bohemian Rhapsody" â€“ Queen
4. "Shake It Off" â€“ Taylor Swift
5. "Billie Jean" â€“ Michael Jackson
6. "Uptown Funk" â€“ Mark Ronson ft.  Bruno Mars
7. "Donâ€™t Stop Believinâ€™" â€“ Journey
8. "Dancing Queen" â€“ ABBA
9. "Happy" â€“ Pharrell Williams
10. "Wonderwall" â€“ Oasis



================================================
FILE: tests/data/files/generated_data.json
================================================
{"C72aUUla9W": "GFp2jqKZlBCJpwANZlHZBK4KxtAUQSL22PlnKil17U4DY1OzAP", "fIZ5sGdtDr": "G9rfk7kn7Np7ZzObJr2SWidOE1seJH0KanyGsZSt7x934gnfb0", "CCp7UfWbxS": "dtkYHMLwwyxyVvayZanPM0wOE9GopivwF76XTwA1OHpDbgxNQX", "rFNe0bCaGk": "lUMKCptIzFVdxyPTLYYPEZnnGSE6ZAXxOykKYRV5N6QJejjzpQ", "BYx7YYou1O": "B20YUQemcd6KDxJ8Ro40hvcHT2KXHEjrtE33kv1W66ZtVrco3C", "C3bgGJNfjR": "jkTQ5gBwjVWExA1jJ6LE8BDLcK6TzMJLjYhhT21lS1S6wxrQ5T", "lQD4SCdbah": "e2in1CsSWSU5OMZTVQdzSQdO23t7R8Ryr8FRYOkwsF5EdOijeq", "6OgrE4BG3U": "tFtK2jgIyAkHWoEcL7rIJwN0VYCczXxffOZo3GZ4oCuO8xkOE0", "nXUBzCFTiI": "3RNTzGe1pMghXowbMA4JAstYmWFv1x9brH6INXETkEQytbGZTs", "bJWlwCyjpX": "tAlXIOztQtP98jK10t4oPhHws66rbSHTAng7itXOYcuImeoCRp", "osOVD3sm8D": "44pnbwzFEL09LyCrwvHPouvfm85rXonwct2bGMSCPEXoUeanSt", "s09rKtTtvX": "HVlDMGdNvTNRAIsRC2wHw4dWnpCtKzBEtPPqp1q3bhArhH1wn4", "wOS150cHku": "2uoHFIq2KLXc8cK0V6HzDkWq92nB6IUMLFnuF2e4qluksLIptG", "Q4YqJGk8LM": "MvSWVhvgK8TNIWzh6lMSZj0wqIQ7BT9jnZZ1glqFrVKIeBdnbY", "7uZD6nTOjy": "p1dHRjmG3gPPoZ5UhPEtDnagQW37sfNGVHD4VgPdvqOO0A7NTs", "ir25ceDFTK": "9nQD1q7nf4TUctAQSmulxwXw6DJoZfFkqriPHhASmC4GPN7zl7", "fGEQfvcof8": "an1yNP0uVATJkKpVCmwVUPw6kNYUCLt2y8ldyClWuYpD5sSAOG", "41Ut499l4P": "Sny2W8obXvydkM7jIWMwK7pFSLveQUKWM1PU6qsWYnSSPqFo1H", "bk6eDhQnYy": "XHaLkylJ8Fj6wee9gwA46ykdnMYQm7pnHuMswfmcFGibRr3RND", "dmIdHbFd6m": "lFR3thGRApNO42tOZbXIjE3Q30so0LITLnyWPbO9hr1cPFX3sw", "VJYqnKzvUV": "yfGvypMdYJNi3bGd0buruziJu1S2DWEUlKFU5XinDXsO17SQQo", "oeLSXHZ2Tw": "Q1XqgVSNzNqcGIDgM2dChb83ttL0DWCCCUV0BSgXp3A4QqfX36", "gMDcoQNzNN": "3vSgG8MHQWJfn7QQFXJz78rDl0gQFnRrTvJyS0nBEoTg1FHmGw", "uQfgJqFW4m": "0WxYQ4ixtcJ1ZEzAUxnPastXSjRD3cvlbwBgzZtS53zhQkDRGX", "W6OePnoI9w": "6C3nTKMIo5HVmpm45MhvPaRSiOaEpDoLBA1mEw9IiznZEv2BZB", "m6cGbU8KOj": "75s88xTIlYOjycxYd4PORbXtdDZtqgrxUT18E7PfDdSFq5Xmc2", "FXmXLCG6Uq": "Fp6JFT5OhEEXbzUTGFQBYxKLkWlxZNjrIKzWog712yJEtBVECW", "OHZ1mtyquy": "CgBCXlDB2WJxQJuxn8TIu4DwZCmFDwKJqPsV3pqnDJydO29psm", "a8Zd2CST6R": "zuOwceQQvR0sPTgqs3IDDN6CYBkKwpZVuTZBPucO3KNM6MCGNZ", "IKMnpt2ng2": "Y6NUHPz0gOHQBOHf7AlhnuLKJQblLY71D0IYumlCbmFFsf84zj", "pwKEIRyNTX": "cd1QQ9lrX2t6gdkMZhWpM6NPgwq7vftuacDy0hO8gg83BB8pWc", "ko1HyoFecQ": "GWxOonlL8fCVWaAHl9Zbh3HxUXgG7Ito2b7dQrBICd8OsjHvlD", "JzipnmKEEK": "AgzUp6VIogKpPWp7SP6xjjoyWSmR46wxX9qW5IY8CX4bd11IrP", "CIVidRQNCn": "2HlABNeU4v2UdGAXcFMRztYo6KFHfAAZLiY7v3A0ZsR7mu8NnP", "x3JS6j3Nrm": "02XmqIBExx2L1wF7qS4ufeMlGm2d6idzOyZVjrs71H97RigBwj", "GAlf9lFOYd": "6F6jTBXYccb46UHBkzHXt4iK3zXnJlPj9avaYk4drK3OIsD4Vv", "5ZNdSVqzjH": "eO2x8iNM29tqtGgabpPkmHNk4PJ9jTQGjP9wY3hXISYTfzkwkn", "hXxEKE4nt9": "f8Xo1jNwPbAv3BHDuO4zilAVguju9Jok4Nciqjjwcaf4Ytq86h", "21tKnbwId1": "JrPOmcW4qpffaemiTYCL4G8Jq1yKGfWlsAMTK04hxaFZe6QMyF", "MrxKOIj38U": "fNVTVQySjgnATvhE1VywIaPiVFHuUp49Nwbg49Mv2Gh6qJub54", "KohrGPIXfI": "TIQRfxSYndzrllYlgR7ynG5evnmNWzIBfcJ6qs7a831fYOlTva", "8eVOTkLXO7": "QjymESApOqRbM3Wxf1nCaaHuJNtieK2uWxuneg9DjgC8ctQRTT", "VzXJuW8ysO": "aVGLZG74zHRqGN8Jn2N0kt7Brt571c8lp0VEiwtEoLsZal5o3X", "LhXGmZk8ij": "yRNA7DmhIuQkBY1aEK2FYXp1ILIpgRAdP5ASRvK8tJV7dGEWYH", "wh4GHDMFUL": "LpwRAxd8MLH2kO5UAkYzNZDdxMSAxpEp4R2AZMbMzYC3FKTpqB", "AmMczTt11m": "OSzip2uDhSLHOwtT0dMbGe0RE2UXfAmeeYpzkVw9iRCDkEhxT0", "Z5ck9hDAbR": "uD220S55VhuhDGQ0u5KDuyhg06aLVOMRExDrzbn0WQ6YyGtaxT", "e7q37wroCp": "pjm0JInEEZA47xAvT2MJxj8qjZSFjVZ08daTKfKpClO3l7VObq", "ocRfgkZ0BV": "zfodqtUm16srzVYi95TC4otn2RXP5rihxFKKkq2fvnjL75Yg9y", "yCaI03Eybe": "gyO9jgRZWeHS83Ooihu95k9y88VCqDWYfffFZ0OnJJXeqlbCHF", "ON1gLsGb00": "VURBxIqhR2xTWgavi1N6KvqBPT6yJ2fuge1gs4uCVgp2pavdrl", "pMXdUZz64C": "CgsDcuAFfUOlGHnwbO3495fgw1WmkJeytUWyGBJxBxFJHgBFQv", "9xf9Zs0dD3": "I1GRkjkmEi1sQTYgAVq1aFu9TudqshhiE4Ij3qNUYUxIJ2yODs", "o9EYQBL2bd": "4MiJKVDEh5SQr8o99GwJckOkHVsnL0dwNK1ZG6lHFFNJORqBP1", "DKlf9GirJg": "EKIQZPu7sS3lAPQ7gU9G5f8SAkJrSueTSZKs8DKRxmK9kXCsE5", "ApRt7EOXvE": "QMo4KhubgpLKaWC8rmp5nj2ccgx9bCYZGa6vKCnAl9fZYSiemS", "mOEFLwmwJI": "JfM7uyOhZnb5utP48jZJCSLVVJOfL3pEbRDcgUfpNPguCl2ZIf", "3PelCFOdX9": "qYKU8l9sleAcLsDZ8K4TpCF5nBGjS4FL9AggzpzQTYutfERYVl", "0MwRoKpHr9": "TJqQDFkezPlziUfTeuD6Ufj9LoMAolCHNKl7W2DqEhFtr667HT", "hW3Py64ViM": "f52jLjPspPN39SifxdyMt6PWfZUxmIN5EYKyWd7Ox0gymwBctM", "3v6DsTOqXY": "mQsz62l5vz7IUaltG0H7xcIvLWjjxApeDAvz6t0J6gSbINvVZ7", "sTnBjc3bSz": "qSicqFvEhdLHtTwyQS0i7sPxw8cjJx30RTJTXWt7ALBnWBib3J", "o1may7TMLk": "cSmrbzZuOWTyzR79DlyWhJTvQRkmA9hJmmK1hwGRebcAy8mGKy", "ay2dK4ZwuW": "Jd9F3cqt8siCqcdAKhbyQovMSUHr7tRaIZueG0j4MjoGgEp85q", "L4hDx88kMA": "FHU0jSYVbyq1VkqpujkO3xeLAM0JxoK4fgHz1mnnoFu3KDVQT1", "VzlHaSebTy": "vnjCy4r4JCz3iG8nEVna8UexfaEIQwPuenfqZxfgbbuY3bvMgT", "zHeBaV50K5": "6yu6zCl1u6QPpcNKvimL3fwvzOPyMRb9kYK9gx2NVbYgsvORiT", "k6XZLkA20G": "4Bdz6cYANvDHQbKnJlQUQvAXEIcwE87UcCX07KzZBX51QY0Ozr", "TbGXwaWd8t": "resZEllurht3CCwF4rX04JIvYPDq3ct807oFWkxFSUgxrevsOz", "Y7WIazgkxa": "31NHHBRltzQSAxeLMP5RrP0bKC2BHMef5i2svYfv9SzYTei2gW", "n2d3HoTwQu": "qa5NzzJfVsp527BCF1wMC34oXepaq1eFanR3zghojWJStqAXeG", "0Ij3w63kL6": "ReX1qVsbuupyaGwKHNgEKYpfBqtwRJKOE7f1UuRImTYWdCITGQ", "wMfeA5lm4X": "K2FeYpOfMtNJvFDGksyR65gCd93o5vEyZ9mJAoUE4hcygoRg9r", "WiYE9YffzX": "mnfFEhs4vgug7sCiDn0SL2bqJHzoMF2rWuPlhFsY5sAtAcoDC0", "bg2XUpkzRt": "HTGncqAOpCAEcvjBjULbTMILAcaFcNiVhv0tv9qzPVS46MzosW", "stEXHT8WOB": "yi8E1Q0rQr9FlfoRw01yc3uUkOZdChzYsOolCUQy1hqbOZYpL1", "F9tEbQnUyP": "QadIrxzMPsFQjYbqOjXcMI3HjT4qbO3P7BSuqXmJsfB30e6KD2", "ii2Xkinxlv": "40yh7N3GSUaW6TC4pPBdKL0KigLL2XbF0co0jTeqI1zzI6QKv8", "1zwECHyjeu": "HxbJqDQFntyff931OKmxb2KJjZ9QlDp3Dk5JKr0VcIQ2YS4X0T", "8rPBRYt8PI": "w9dgFKwD0R9avUDasmUQ2Ea7ZYchLR6aZE2b3H5zHHYw3JxIJV", "2EuNVs4JLy": "6fEwJLdSP58my44DEb868SPZZCeddYbpkDmZfhb4KcoEZ0HRic", "B8CzdNkpIP": "CVWerWOXqxZZ63ELE6chIgzvF9K3u5uuHDbJeGcq4DQ2YY5CSM", "r3w2u1ecuC": "Qk9CWfYjxt2j90PddoebKiX62rqdeRx4CtvH2gwQuuUh1mBRrq", "B97uvtFho4": "39wY1CCstM4pxquaN3zjniNNkQBajpql7Sm5VdvwQGUE5BHnXO", "aGTixKv1pc": "ZKW5x8gJNmjEkhZ2RXCsADD1gpNs2N3PvEPMNumGDMfhUwU9rM", "pQu0o1za6m": "6d1isOShZwQv1vGSGty8cUf9IX2KdCxP5xN8iztrHLZVCzUiHg", "fK5rVp3IF9": "tS8lfKMWkK2RzzSCnbRk8wFRmclEZbJunAwrTDMwVPEtPU0zlH", "vsSiGI5c3x": "kWn1ccQjvW4BXBmiX9gOVlvHn06qSOvJSerFD1LSZeZWyniMTT", "FO4iIaBkvQ": "hIxUymXWbszGvVJu7Om6H89QxV89kFYqOC3vK3izwGmx8AeD4f", "RyoJBCVra9": "gz8Y1dzWID4QFJgL848HaB3wz45muqIEjLOnN9iMezKQjXSghs", "j1sdb4hyrI": "OF84jZi5XhYYy2gLzOEAOfOhYPK3zNsKcWuMwhwx01D7wJPCrN", "AQ4dO5Rf9l": "dBqATKQE9a9rt0TAA9JhI1B9fDELjiwEOpIcxF9KWGsOUeUjR6", "yrZtqL97qu": "6Kbz8eBq5DwaVhQ4L40sWiS0D65e96iRxJttV0zFH4hPj9tHQF", "HeFkkHhdfB": "mpvUcXNOUICxc1WKvScqr1R0EvgtdZ8o13rrIxXCej5VCTfSNh", "HkkrhBXbyU": "RE92M0RMBQwHmJuzXksGgP92g7VDhd8wXf8m6Pha84RgLoNQ7X", "BfX8Ejzn02": "99bhU5m62OPYfGbGCmxmOeIPtXIDoeYCZf5y1eFydADhrWsabD", "fjzkNCnsGM": "j2Dlq6Dacouo1B4aZ6Vcc9yokEqukCdor2NH5cy4cZWKKCvirx", "w49wetYHv9": "HbJ9IUMLbDIhKXV4m9sDJ1HTHUYMfWq88Nxqga1xBUQk4Wn9XX", "Z9f0sIcf4S": "zeL1IS01V6fQhTMj0v6eQCTOrfkq1JCOPbyq6MapaVpz9NiEsC", "RgCoQzb38G": "CbeVh0N1H0fglbZx8CLU99GdHuKIDQvMwuryZEONH6Mr9Zjgj3", "6zYOOMghIM": "x2RNiNOZ8cGZwKp3m7GclVh8R6edWqzwrOFyIUy8VR28SEGaGC", "m0LnbokJxn": "VzU9ePSvFTsGo6JtWdaE4YKVR6w3hOvZgJ7GdFixUG14hYKtnY", "Bai5RKdLDc": "WkBZkzfPKiU3Yar7QbtEHYb7cZePEvT0ndX5pHLB8D4Ts82ZCZ", "6WomHwhSab": "JbstDYO76I0HJjuQZhskbc82EB91Cqe5O30f6caPkx2Vl7IVH3", "VPyWjtaCgd": "hsHN4jqIeUOuPbBMK6WQS3mONKBzHpYf0tIqXxHyitCWPuOf7Q", "nSAtwGq3wr": "iq12sXkEehPkO8AMvWGxkdvfgWAObTIc9FHw6lUhqbKDgl8lym", "hF2692Yf2X": "drRsXvzCJCpGK0Q5IQVS3WNeTy6VynlCyrnW20OwDmBhtrdHZi", "aOjXWBeB3O": "s4u8rDy7MUSlLLLP2TJrDuQmPL9Nyu4CvPqoAiWXZRByiQri3s", "or9KLsMrpQ": "N32HkOs1Mt0AWGiKOBMt7Sf0GALF7lAtoQ1x09Cb0qU0O5yKaU", "y1Gg6uigHO": "j923zv3f7MB8cTLpF0v0vDHO73SiZYOOMpFy85ISiGVb9oySNv", "ZELA2m42od": "1y93Plv2OB40VwhtIajdLSkmEBUzzbze2CClP93MnBqbqlvPFJ", "MsIT8xH1xV": "RHUr2fJFqj8d0hVxF3UdCKEdCqr2ZDS6ARl7trVALpvzyorYni", "525aPsJrOj": "AoSYKCmW6RvlNK0JMajpuNkC9DV3xmdeuR94P9cJCyhymGfa6o", "sr1dPOnP3e": "5A5JlgzHTppswwITzLTuK85Uc8XU0X4mEu80JG686XCdQWHIWZ", "q39SaBQ5aA": "jmHtlanUmKgZHXwzbIUJhXfOyjCUFuR3mw2JFW59nYUkc9M1iQ", "N8TvJbPjyQ": "aDBB3rtynidAn4PxU6bxSGGd5FQeMLs0oY8RPyMKN7ywKtFMCS", "Vb1I0K1ZNG": "ktdfumcthHRxbA48YOEmSLKIn3YFfhORn0Vav4VWRW0hNqxl26", "imhs3Xdvyr": "IrR7ydvToFeQ2fNnDyYjRxRijXV7W3SmmXYkl5HgEi8wjjd7lQ", "Zoe8Sbb20H": "J6zhHnDDzH9dmEDYUyeU851YlPdMCWtmuhbGNALpu7qH1esUMz", "LR9PTANQYN": "AHDilSn8Nz5E1WsrUgLHomSCIpcryNI7v4nsVAHnjO7zSV8CVQ", "rESBOCvGo8": "wjLy4FsGzqsNpN6N91ugVLbR7btdqtouCJwZCFeO3JbJSbFO1e", "JCDDuX5NWH": "aYT4D0V2rY1DXxrW7ZeJbODT9tTNMP0mRDsjW61a9SX1M6omkf", "09eFNUNA8X": "6bi3Lmc8AXGZnyZXWSX1ZwkpJLbpKxj0b5vUqolLo6lAAe8ITZ", "v7c1L7Op0k": "IgoiHSlz6SiSIiRaEl6eHtxDEZYPfooeZSNBhF3RZRUVtb3Vyz", "U3VQy856pG": "5h0ZyeOBFQtFynZsbOAqfG4dmoYxKAzKZ0zscxhaIaa2rqRcXT", "CFmBcXy87x": "a7CS0sCNgcc8siR0KxFVYGG5YLzVlyWWmxcycnhpE9nztpl6XP", "gPhKk2INBO": "g6rqKdlpIhaiROIkoTSo3CSVbemkQF73wKgBD96I26jVSyyl8E", "ziySGmJGIc": "OCUtoi4HKcHxsc4cwCZV78RIS1chfSoKc1kpPHiv6ZHunJGQcb", "MBKYRd9i1q": "GEBhJHKusbspmiz8xxOwWPAgyk4yFuShBwa2O9V001q2a51yA9", "DLwpsDC2Np": "hm3J1eSyOEbggyIwW87pTVuU42Nx7wh3FoSY255xprXh9sZ4YA", "r5HYzaAGOL": "nuGFYRhsq6hox9iI2YZeTna0vzaLiK1sg1Rpp4wndAqJPoMEXk", "LqXUoEXnug": "Y3ukD9z8xxqknN0H5BAd3kHb9OQXOsVlDlGmBgOLiblmjX8Qho", "m5v2a43Ipi": "ALjywwC5K2A4sJro09Z8RICfc45SzgsLdZ7e1KRftq0zr8q7nh", "cEhmv6K6eM": "OcDXQsSfNUhNXKhS8UfqfxhFpm9U6mIq8CQMeZ1kl5ae4C04h1", "2Tp7pLjCag": "3hyfYa6NUbFNbGjxvGvDnyvd1VbBhusqw4oX7MaWhLpLkCzozu", "SOZ7oPoc4G": "86OKOYAWGCA3hCHCYY7kwrZIJHQE6xnXDyaR9iLJ89BjKMoq0Y", "n5Bm9um4dJ": "iTlpFmtxkAogllKxaBlt57RswfLiPv97NRKFmYgcd64FoXjt7B", "jaPdYTneyw": "5zHs2NhmMVvBhdG47je3pwR69ZhxIr9Zn5Xgb38biQvYUcZ50G", "sk7WRVyHub": "r25DMHmEO3J47HC0L6mYAhVwr3Z5JcCxNFRx5b4cQOm82WvjRj", "yq4wNYYnBv": "LNi9Ov4pZ1W3jEuQwzkvwgDdZ3BJW27w2qtkAiiUdvN267ApJO", "0xr9ylDowV": "nKL6idWSYEcsavWECx7uwqqQpv2paZe5W3TspamSq3THQCsKP7", "fuBhBXt9cA": "Eg79nvGFz9R0fEUIqTSJ7sFiHLJ3oWC3vN0miRajU8QK5Njlao", "Q7e422OfO6": "lW3BxSR8eycnwZRSnpGpQXc8luR5PqxmcyQasmGlNd3yFZvvZH", "V8rRDIHeYb": "O133MLzxRa6wqTViHYqDCsrWQA38UQtCip10SEqSGfPcKwXCtT", "hvZJtReRnK": "woclFGXqVnblxoxUmQyPgJo37oMWWJzTmITHmSbFOqMIWlb1Oj", "1PXmeHXg0Y": "bQUCisOJ36jqgLT6Ie4wJlsGUvG7qqAVLC6Jj88h6jwiW9zdyV", "vykrCJRX2z": "8NyqZ0JYpFz0UZPCnd2NU60EJ619SCHqXinAT5hAeYBl7frgf1", "E0ifr04Oiz": "XpNXFEioSOkaI8FU5lkh8ftFY3r9s4UgtzBi5ZVqGpaTbLGrZJ", "cU2LZitX8y": "qqyl7ucz4yMi6SKsmO3jjrvIYYxGc99yQjGLpjAVxueXYGYUbk", "S2ORMA9dmH": "BEMYdRjkjttCxfnqw8nWfbH3Yj3278SeXM3MZMmfiYKzOGb5Bg", "AvolcQ01oO": "AShXDo2mNA1yqeXM9aykzdHO9I5mWQosJlPTVm7UIwhcD7DX6y", "A7vRasyCMb": "w0ZjwYqLRJe3MoDHELyq2olOneP88uFOTpj8RMeoGP17rRFPEj", "efsNe97ES0": "HETrTEHxidQ9H6VTEOHYXnD1c6KvcMBHxDWQeCuE40QXOd2yZJ", "vf3cxs1jz9": "fJQjOm7cPhgoPloWkC3sm3CyHyYbPMQZhNzSvCVxrmwBloXm0a", "yVTvV62uja": "hv9UI9xRWR4WIDmRf9WUzaYG122r4MAXfsQDFiyk0KG6eSLXCV", "UiChZbQfTA": "bbWU52vmSPB1jMS1SfNkG6idZ7ZaN1aG2iAbkizpr8reEsrJb9", "MOF9b7xlWr": "JNZCRiiE6YV0e5EpoieC5bhPVqdnJBL3kSS8YV0eyXdFsfyYgk", "vyt31HOq1E": "q86HzbafsN6V9eCi2UxZD5DgHy2ChlGvWmKchHuhNBHhAmXBW9", "HVBpcL8Vm6": "CVi7iLWuEar9eKjjLSIAS2l2GzWT7HgXUV3LZQjArViRxU9vZs", "4yyxLKP8J8": "z91xnk6PuYqKz6wAK8Xb3nrRJwZScVFHCXn1etPJ6BvcFJOO7n", "QNcWwgPx7P": "EaUklX17V4IuOXKabieOLkXcVPnIE0mTvqLf3Tb69RtDU0B4HI", "USOtIFdcFG": "tnegvTE55UcVrrPg1vnjrfw2f0UNOYiM28ryTNhCBNBDZPhw9K", "Dmcs6VxfuI": "tHfwEIJXXFZF4U43NRSXQvaFHhCf2ir6cOkW7TAxeHQKmOHUoy", "HclNrtq5Wv": "soZBfbPzqW16MRYbFW7lLuW5708E0OgV1tcsniGeSQWWiGwgsJ", "LmHfd9ItBG": "EQrSvHEuDh4zEXPTrRirdMCHkMc26Nh7XSQrzIQakYxHjC5ID3", "FBoi0RGMVy": "cdbizX9EJzLkcHLnsWXOJhOT2sSoLji8DOKKc3AB6DsL8wYnNx", "ix7Ls3Is82": "F9PJsrsucPCLXsVhN0jbuORpxx0TZnGJQPV0akiyXTm09gQ8Nm", "F7KzYfPRMo": "8PwukdUWCJZ4Wi6UenHL8bR9g9k30fKQtyP9SY3kxjX3omENcL", "c3gse9xVcM": "oj4otjttmvRfT2hvl1L1dkKr6WuRHpwpil9rjiRzeDlJzlBiXD", "hIY4UiRRE5": "grGHaEpZlT5gyKrUZNdmWN6YxJyonrPQgregOqxTZJ3YPdsKEu", "hMcUYN4HQt": "w4LH6NMNd0cJFqc6myOUtyuDVGJ3xJ9J5Eg0FCx2WkFQDR2JKd", "LorCHjVK18": "83DjNZa0i54wOEOG8vpGdAxorj0eI2CVCvMXOq6WUMts9ZW3JG", "AvR949SEGq": "BbGfTe5mSbELTQpaWg33Jf8r3dN6gw500BINFyG6J29x8FZYrs", "T8it1hOCe0": "DUMSRlcwFts2JMyLforbPxk0pfyf3ZeWwgTCrjSY1XjtrRrDQi", "q2XpdY3GDe": "OLzki4YoerfkSEOUFmdkePCrk2KtGZP2F6ukVEvRHEXk2bQAis", "6mMXVdqARe": "Uo1hM2yf10NuxqvCuVsBkpFN42OJRKglys8TCKYqxB4vhFJCaX", "Ukt9B7TLLg": "QUjKe5CGdzQZX2xBZCWX4KG5njvwy4lccgKohd8BeabmAChNu0", "GNLtBKw22L": "syIfP5VPDt7bBZ2N8BX8L0NWSUfseJKgHZn2DYEKcRrQpJuHyg", "6N3S7FqQk4": "lpt9bGFikhi0cjBd5n4pEY0nE6m7ceMmlByy5JX43qZqhXGzRL", "36n8eS4qpp": "BWtBXn8XJvT1pRqm0v0XxLA3aUpqy1c6YoF6luNdc1u7onx1fd", "I2JwvCeNnK": "hM6rskNdjsJRDuVpAHWn3Z6DluTjpzzqFvdqhGWGIVYpyOexnv", "FC7j4inMdz": "9rUVwEoZfYMRctJbFCNSnO9p3UhAkcKwmzhHMAkVggNk2FMNVI", "nP1HHMxp8C": "T547daYmNBqEHqJQMwxWZVD0i5YEKvMjUEPSo3EjI9Oij5uSwl", "ek53NLTV2V": "jJolXmh8L6ll3sM6uO2LRkgcaNtn2OJp9BlMxjd86DmdCaTcQT", "PlZOZtZ1x3": "Ti33dfMVTKloLi3vFKUZpG4Y8ELfI33fhKXCgZRTztdrsG8q79", "Q5PNnDOKWk": "fpYukoLr3Hkgg8qhy7KHAXndPWPX1dBDzhGKwdNSgycZqmPZQZ", "TclnuC1Ltg": "oC7lcjzPGz8Ql7ZzO2alePzU4VyHSmvEan6wOGX5IH8JwqqfpH", "kalaIDmTLj": "NSLYAaVorVbI7iJKlnGwvKfEprndoZP8wtgMpFSwnWINVbonjV", "ylYjFYQWO2": "6Hzs9f19TfTYLENrWofWexJwwsaSSajW6brdz7lsvbkgzBqeNE", "50jg2tIoj9": "wFkk6yWf2pd4YsHaGK9yjjBD2jxv2u5coKuRxbhwcmm3qc4geR", "TzX7zp4ES8": "uuqEFqkNpXLqGDe3Wg9ljgqLBoTEDWPRqDpqs5vCKJFEo7kVaG", "q70fe0ZHaf": "sRiRQ8gyA7lqXEZLnwz2GuDmIL8VMwKbeG80cWFHx3TzTaFpbM", "oJaePOrF3X": "ugLYPi79ljo72cXBmla6IJKF0gSkCr2cGJKx7XKnGHhLO9GrdZ", "66Dpp37YfP": "ZFf5wlqt4K8dSRMPYF2bskChvNgn6HwYmmFpcJXqPxxohqJ5pl", "17n3GGSzF3": "6Xta8kWjdmIvlpeP73J1WXE9b1VuZXEXRnNBqHzWT64HjjC2IJ", "ZWY2ej82d1": "0dKBwvkET1u5aCAHdhReMieoqmxTdRIVXHO4H7T1PJOvjI5Xms", "AuLzJazRei": "RCSepealBg8L3fQsJouqQNkjc0yn00LNMFy9DaPjJ7zyNo3hPI", "nckBTDCqpp": "sjEcGeyAVOusSZLswImNCYJ77ANqJ5YBg8jfXnzDK1JBlyZ4Fr", "UWrb5dOdKl": "tlIF5IwK4VqCTqInNYfnYxpQGS0928HmU2ebfkYumiHUOUW7vL", "88CZbu2LMM": "DWyWtZZDyKqHiel86HmbFkoHcJtYxFIF7lo2Pc8Yhv3WXax7Hs", "l6VAwa9myI": "P89aK5VMfvJJ8idivUJboz5XQEMMp9st5B4foUq4zC6QBR9vYd", "uOn4tmpJSB": "TPg2FUx1aaOTmWo4DR14UEJu549heWpz3xUAbcNp3EfGvIokcg", "ncFMWXjniv": "kz7mdKNi6QuLVMaevLUQtG3TMijJoKKZJfQPJKiWp3u4IqqNb0", "PwTyG4Xdd6": "0JkU1DAYJsriWSfRZMwOZrKSQuEwLEWjjkhMOBek6208vAboXH", "vDxxGQv42K": "F0Y1L0IwdnYu7kAmklovaXaxa60cSt2CATNJfkgMs9f8rh2TUJ", "q6lHJRsKeu": "q8qpOzapvjYqaLZaetsNM7L1mMscQtmFQZF8ZghO8Rnez1LEgB", "T5QoxAIh97": "s5uwO4SvPMvJscxq18KyK6xp9I8AEosjYQSfQmaS930Ft7L7C0", "zGlnH78tJC": "C2nlefrttCpHkk6gStlgTSRd2T7evwDG999u8eKr9DJ2IAO8fA", "OYkDxfUlE5": "UianZ1zzw7U0c3rePMHH733xATKIaRyvxUg4J5r8hnIhH8IGVR", "NsaSUHoMxt": "dgYCcOb15bAbBGKHHibyPDcgdl9ATHEWbb9pueFM1qeb38wWf5", "M9yfp7AiiG": "zXLfwLT33H8pgpNp5F6Tmq1W3Y4ikmK3DVgYXZ8CF0M0qz3nuC", "K7zQaq3Kzd": "1lEhi48oyX252q3JNdVXLniXLAZsvJjv3grM79jPz2z8SDfrTs", "sUxQ3VC3Lv": "MvMBD9ozMhHXXjTtjk9HipZ0v5GcS76abkKqf3kgDnsZ0RC4yj", "QgFEm4KXXz": "XURMPPoALkhM0ULoTwo1dfsuFe6wPzqLJJzJBKfzgQOmowUE8c", "VNNfuRhKRY": "ZJ0Aq9sNimxwwiAxbAGqws8HBwhavzj4ePQET2lAPEAzl78jI1", "29sSKsuGhj": "yyteb55mN57xEwR9pR3J5NtfDx1SJJ1z0hqzKb0L5dPOoQXl31", "bXDgb3uOq2": "cySmxOXnmoGsw24WGunQAWwpArqEHRv3lmBn2y9pdFMmymjLzx", "63H8pvby55": "74AKV8QnzS991bD5PYBlhINaisv9CT73aXWVZOM3QPruTxdoEX", "I8MzHSm3zZ": "P8Fj7DqbtoIqjH4FU9vkxmO8XPGqeYt3YzEddfae6EqFgZRJTz", "nFiwjFRLsw": "Z2LIvcVX1JSOhpBqZbgh8N5j7gawVfbD0a1yyLOBiKv8iy9aUD", "cRmmFKUHgW": "VzpQA4sXbGbPB2aahe88RiYO8mBgDxSLNhx5IWnnHI80Mgc8y9", "HK9ositiT7": "nX6Y9I5HyN0sTOURAiTFXblOfInW2TwDvj5GecvANHy1ONqAs6", "Sb8DygoEuz": "Rsgd7Zt8IGIVqkemzuxqO3snnrPLxikYxKeVfYq7g4pHWtq8JZ", "cKYZDnHGpe": "TF5qHx5MQKs4UFfuNEhvkRVddxil12tdKIoU0fypaEKcTI6WUP", "Dzj18JuOY7": "cdOwWvel8vzJxuqWQ1MFPXnvAOxLOFsf7ibMLIIkVAO2x4gdUc", "sj9PP3tq1I": "r5CpjgY5KlTiJK9aQTla3DRmUytMsTNIrdWhcbtmDI8f2cPGcn", "JkSNcpw7Vw": "Y19h9k04iR3qBQbLjJFtMeJMz8gfFHKEH55Rm4MkPs6HKADGG4", "rQUZE8ISt1": "xw27DGZecaRDRf0dwEtyOdF5j8QyWU0AWSWHal9wKh56BTJZph", "ZXJAwHt8dt": "OwCq0U6TCx3LtE3oS0skYD4QbRL6vXdq1bfJ8CfJvvBzn8AmMn", "nZOo42kyTr": "VMeh1mcemK1XAhIrAvQINEpMlZWTE54WJqOOzsqI081G8BAEUs", "GzVL91eody": "i2NGQ7Q7abR7nxDNRi1So5sXwxdTjiIqS5EQYIBOCUFmBltZ6i", "peIeJTfNEZ": "TuUk4iRFJ3WJptqttTwgq9JjaymgN0Wfshmj26UqEBC1Fo1Jfb", "3Y1kkAMQ1B": "JHA6bMeczXkiOZhNO1RYnMC16TnxYqAYpO3kRDixTFOkmqBTeK", "6Efl3BvPxJ": "foiqBveWwIb8acwZDlVhaWjY4LRLaiExwT7ypMR0E29O0Y7Ulp", "SqMOK5sqRc": "iPCDULPo14v879lYZLxZw7oQKumnilQFFCj1FPowen2y1aue2G", "F8KV20P3Xn": "NANP03IuYd80nF9neyApYeRkvaII1xRL4CcQC2ugAeSwRBcwdE", "tgmHnzUS6p": "o57xTY1SxxbrbTq7A3VcR4cr86ef2UFl9hzbf6TeYglQhii27A", "ZMsqijS71h": "rQHNAddwjagj5Z7TperGluQCvoxaooPsa2WOjXWTxnUCRjzXim", "UkJhu1Su3N": "YmtkpF1h0XNKiFZUHk4WxIdMUoNkl9HIeHU7x6YhQKyoALG1Fa", "wLO3xeXH62": "RAITrteiEAY5lSqkrU7eoX4mEYAkAJ1STXYtmEXMAzULzk92C9", "egyxD6NTTM": "VndoK3fqjZZEknSOqZmbNTFcq1klIkSA8mSVqGz4dE9tCQ1FKu", "GCyJngKziv": "eJI4MDQ6OuXAxWYegbNQc8bricnk7TRMppDDSpolNkiE1EGTfE", "34HZOIX2iV": "P06ZKyOjvtPUC24URqxbglQUM3mxlZmKethxcPDeCit4ri6Mt3", "bTgivOLRF5": "gXnhlHPjNkQKEspAlZSno7235vbLLjqUNQQM0NA5YCXqnhlviY", "2iDoIVZ2hD": "79O6wR5JJRsFMLBhYdb545B3lMqpM7zcH7rPtwCqBhADgost9R", "MWipjd2uv6": "HhYLDJ7F2sdgUTEfjxSR4qW2qqZZvaJ908mC9oxtHFT1J12T2n", "zTsBKSQk9v": "tIYbx39zaJ4xTVX4VJ2DmF6oMnlrpcecy7zeDgW2KqTPPtVKkO", "zMP2rzrwqu": "gFmSE3svtXYd59ZKb9STnhcDEWgmRXcinBTFkEcCIjPafcVKwR", "jigf9DzeZH": "l9l6NDXBfBOrP9q3smm7b3bWebEYu2niwyzKBSM3eTAvCvwRAk", "0OZBp4i9sY": "cArugC2NVNPq7xGuuWoCMU9jjEmo8uAXk6QH2ugihcEuyd9vKY", "YfRF1zcsva": "AvrwCoHB1VcYioHlXYvm6ntHdgNxrA11RZG6C1DmZuxMQ9TaNb", "r18WQMppM5": "QeDwtqGr5zRTxfMsq89mnIFLt2UMojTCS8o9rugQtV0TkkBMBs", "jpPfuNqDDv": "b5MZkSRwXdCOADDMOrUAGGt7suz5OqhbXdeRULmqUSxEYNmCgR", "MtzL5xRIu5": "jKWc0GJ2eSXcK2uhDfnxy359V2RLHe9z1sdj3qmcovEChjqpfd", "foxLy8EHX5": "9w3cokgt2q1JWatFT8YRRha3Kt2jvLXnYYnqzK1qeeqXbD4jQu", "dWhMWvr9ex": "NZht9b0fUaBUlE1caoPfTG4kap7yBkTrIvYMIWsxAimJVkkEIZ", "xz6NiwYMBP": "oWkdfNWmhKE9iYnaF8TaHbaash2f6Nw71braEMPCjl37joqsXo", "Ku1HCrjHHx": "u2dVru9S2bLbgUngkF3wn0ACVBB5lvJGPn9PZ71j7dxFzpcqDV", "tDJT5d9K4A": "RWIwChefWPKMsdFGW6Pa3K47uYQ9hIwyvyBXGACk798KbwWmH6", "Tc455KuXIU": "JHgFvesJUGX4vlhCbQq6P1v8nsaXeI2tWB5WTLZtuqFfNraz4h", "VoZpea6CwN": "GvDRDrupDOSjjxmmYQk435HBFKlvVrpGWqKME0IlkP3r706j6I", "BH5Q0ZSxOu": "QMBIZyxaUpbZeISliBIeuMcO2C5XJVbGlkQdpVNLye5wadTHcQ", "jeknnBU5P6": "lplZXEmAqA9bCRjcBkcxVQ5YcUB9GdOUvgRc3GI5nZ2ze4aFTH", "vWtAtWg5pa": "HICNHyisLNdwBK82iG9qx161XboXK4yEGC6HvWXxwTm9zJnYhM", "NnSOM5FODH": "8Wx2NiKvVmyQSREuQBmoy58lAyihboKGFrwzKPZfiW64uoKkew", "y4f5eTJQzZ": "1Rn7VyYHisu9XsWKJjuc9iB1KtvmBoUDw6knJIwwjlgJixMhya", "zTi0rsguc3": "D89dEFFb5uNgrEgMRvjVyuPYsWA7IgLDTJ38nq31GGxQ1h5fdL", "OaMGojT9vs": "EYhINLCprkKyHACrOU2UPtMz5bJuVFIfGpFq4HLZXI5ulpJfIR", "HlET7aypwJ": "rE2Mdzu2zfsSJZ28fgNkBPjg7GsKkvnOCGbtXccfOjNaXwxVLs", "nOOOV0MZhZ": "VpgxsGCPkfKeDXTUbCJAqEDEpRE5BB3UOsuv7C4ECSzQNz0cy6", "Pf8rcxOn7w": "orrRtesBroVPM1uFXWFVUUsnUfZa0cTfM9PulAt5hu8KH9kCSf", "VvWx1a80In": "1dXhRxHYUKXxG907y0hpXH94x5wIeoYNY2atdoGT1MvugXLwEp", "0WX7iWjl69": "DTtuKJXjbMgi99lWrjFxHhHqf8XdcMnUaQQpQ5QQBNTkGy49O7", "Nk7ANE4LIw": "P6NSWiMbzPWzzGS5kVV6YTNwsel9g3y0echISFf9k5Y44l81q5", "10Eeg6Lr9k": "tTnGnz9lq9eEEQt2D8XeaITMn9kNWSN6cAUBN62o9As5P4hsfM", "eAaTKau7ZE": "oZYKExDPzusfRBRjfxphDb9CmfrFM1wdXcdQEaghZpYBDWD6kX", "8v0mDZct2w": "37SUu2KQvmJK4C0u5nQUlWNl0utlCjDoKmIGd4KV6tL2FLJ8cd", "nN1NMvT6db": "Sado3km8D6ppnTglN0vCRu4CEj8Ky9siJy0tgL7yolObaj3m0v", "E7tw375V8I": "GvYxGGKFIduzzC2thnz8TJp4v3Tc9AQED1LuULIdTnOiiufUUu", "vIvBl1GjXQ": "OTU3YNY7cagNFYJ9k8D7gUaAj6qzWSaLykqZfjehMcHQhocnmZ", "XW8rhcdjUu": "OsAmNUwA2GxzBG2wc96EDugfTudOCQGgK98txRrrNAu865JPIE", "LrmdzIFVyt": "T3xMBLo6ObPB98OeJIB96UKcZzfv9WEeE6WcdOzm1eWKqb1ZEL", "GGGOkqCJjJ": "qM0c4YGkeaFqzp4DbNtnmur2aCOL9tOhe5EFSTPAbWme4wJPit", "wfnd3sxkf5": "gTUM7jJSKy44r5E7c5s4vm1JSyEb1g0aRaieh0qTGRTQT4Nmqs", "8Rg2Yq6UP6": "dYEjIR39mRKC85GWqKAWuDXRxfgAjNE1VWNZGRI3WJrwmaHqMS", "RttX6OjBxK": "Ofc1MHwcBjYAN5XlWmh2L80uqygPUDrHuYBoPuHGfhFcPhKKuh", "xjRDozazPC": "jx8nhdVyzQyIS4C4syarO2J6BWaFpcm5XEqU1LF8OPML4pGGMp", "AsVV6QSeRC": "ionqBBL6W8PnELiTJeUs5jGdveyUz1xj7zP82Zqb8nuBmTNdfu", "02qmBC01aB": "UGpmd6ZLNuuu9lIHRFT80X1HcV8rDtQ4WFrWKyF3ucVZv5Xasx", "1VZCPvhr8c": "7DYLIZiN3GgkCbUtUHXLavvcy9Sl9u1rwi8wmC3W1evwGnC8n1", "c3b72d5T0X": "DBCj6wVwoMwk2L59aHGXeyjHnHoiWJgcHeEqDlNqY6wfhqw7i2", "hxrNqjZvNd": "CoTM079XWohZQAp01NvArevpkltfpI7QzDhwcqK0l2AoEkdUdS", "eAU6PbHCbd": "17Wwyf3rG8i9RJMHNuqMXuSSsPZ0jD8YivacB3eJpxYlcZXYxc", "aFgdtiLN2e": "VpwWYDad2D8nn6Mzdu6eVqVe0tCTltBU5RtqgnMEiQnFVWzrg3", "2wjjQ0qIVU": "wZZP5ZSlrg679ygdpavC4suYLyBHyTPBWxy8Sxh9TVIat571zc", "hvJCdyWJxW": "uEXCipI3tVpFxwLxUdu3lhSSFWK1iF5kMMLeP7b4nDrZltfb5u", "42dppeT05q": "GrqjsyjStKf4hx2KJCsAxkxsd898q2YR9xtYxqOKGTFcp61gyC", "vuikCrNUnG": "j9LunRZuZNcHkGtKEoE6SMRIWlLKE3wavyBTlyYR53mx5ajd0J", "VKsVRLea7f": "TC7uyEmb4cSbvMYbLK9jXm42jyWkR1gtvJx4zesXussS0LEKqU", "bxfj0tcqwb": "NHLZN8AJu3ELHktpkJWpPgTqJg7NeUEzHr5l0nIeBXOcAKEpYA", "RddnrQ4Lst": "qYkXsXdT3vKguUGjzvRTsXB0CJczunT1pW5046bqTZjz314Qi4", "EtraExrXrG": "GahtQuVRk1SFPChe3ivaYbropCBOvGaB2BdgHM9N7ObcbpNMBt", "n8EbzU3H4k": "vXyQCXUkYAV6dR3P6FCMh0lSNhPvC43UDX0jwacK9OQfq5BNRz", "KveucSyH5G": "4z7FfddXfwfohmBcgrJPbgEJpgWG80cFHChaRkjiY6BDQk6T6Y", "7Dawkj1ydb": "IXBShr82HaemGXBZbIbQYtlCU7dP3mZ6116yEjjBiv6IHHZjfV", "5QbKa0GPKt": "YI3Tou58lO70njQHCZUiyTrSDxIOekjUU4mV0CygKYUbg3jLqp", "Gag4WW8dat": "VRY0tQL5Ayzutb7ERqmjKlQ9mXqNd4IHQv9QNXl5MrDnop9WxB", "VfjSxfzIlR": "B2KeD8WZDigfWdnYuh8SISGVfMjtlQEHAZrdge0gOoLqJzIneO", "prZLYYelEN": "LIYSzFyXCrVIPV2gQm36RNNc10ln3MSK0LO8AmbBks5DYRbFu2", "Lp1qrLbxfi": "NdDnTCSyKoLmITTD0hgMxEjqYcZD2yTGgXwMI6KOXOHWlWQMci", "SLWgMPysgU": "qFdI6WlcGtlHrNyHZTKh2QQPr79gNMhQE1dCb0TRd2laJGdddx", "fPwjObuevP": "W0G6agN2NwgJ0SCf5YpEtxlMFI500c0j2UGSHoTeMomUY5g05o", "XzAvXvND7G": "9TuCYgeSIk5a1ZVZxBfY48BgzzHVeGXkyJEuWLNfbpoVoUTEvG", "TLvEd6tAdK": "JOH76Gx1bOydYpycxYcQVu54hDPjrLsDssIcUFSIKLjepFcwMe", "uQM6pBrWrh": "kwZcwpcVQfqxi8H5NJoJB4mkx29UITtRftBSGUthsnVWQQ66N3", "rj3Juaf4Ie": "IOCkpqpt6F9smtqdlOrcwYNduzQPFJMIjODphxB3zefmrRjx5X", "Yymzsxa1i9": "bgtA7YyD5lfMKLrVnVaMW7mD0ED2lFfgVpLrXbyLMVUXAkp8Pl", "Kws9t3YEvk": "eO4TQ5VIh0o1G3ODyfQDpbkv3kDmD3q6IlQcoRdFsrTtPjXFVK", "00Ai8REVEc": "wnvONqDkuXAN7kAsvvHaBzcR3xQQdRlFDpAyXBZ2IDAi5jXwEZ", "lSi8hbDOLi": "RNfnTpSsdWQzXFJOVl8FKkT0yZzbowRbY7Ac74AqafkgT42N2S", "OBthYOFw8N": "jwgLfSLHUINfZs6T36WpkHdRzYtDVsUWjIb0Ml86s0J5aO4hIe", "XrfM7CSUMM": "5Alqb3zzypzC6I0Qnso7cBdl3DCFCv61QsYQyxnCvpx9jgSR7G", "5bx8pCN9hB": "XJiyrrHiYU7NwHNFyAcbYGhQYQCKYuXDeRi8VLWsYZlMGcj58x", "ikGxJUSgT9": "izzWjBrEx5xyfyL7jPBPVjZdxXh8oWpGh19km8Di18Hm3Dg01C", "cacABJnEyZ": "NolJpkVsZLoLIv43Iz5niSFR69tsGglHuhBmpnl8OJWvDGTcLv", "AEGlltEliV": "YWeA4rOlFEUfl1wTDuxxDgeMVmALHdw3obLdRAR6xOHZbCJAYb", "FPZhHXpFKB": "MwYebovxWsNz6V3SHZ9Vuutc43DPsbS03QHwfH8Hqg7MDPnm91", "B3Em8kVgtX": "AkMhFnJcqtaRfNZmDnixMiKoxR3uY863mxomVn5HEw2OKt7F5G", "brrcRjTsK9": "wZV0mFxSIOrxRFKKysHBbjfX5GCLxYyDYHEcm0kMcoMpn2m7d8", "692h86xIQc": "oXkyz6MZJmfScskptw7q9RkxCh3PSmHD0KzcWmhYKClH1A2Lwr", "3RKI7LeCGe": "SC1vQf5pBtzuanPgDIOTLtuqiy2lTFbvE0UfESbPyMvgUaEjqR", "W5iNi4CUxx": "kXXOYQXLT1SOqAA0nDADwE5EQqo36egcQWWZ49T3Y3OQpK3p0L", "P1rmJLq1yR": "9x7GiMRVRKSKNvtJFuNCrgyn9XOORSmmwOiJp0rD1H4NIGq6qO", "gBefd6unfB": "t47ffDiB24BJhd7ufwwetUBj0Oj9p0s2DKWXaAAh2o5eDBBLBY", "dR14jbpTdP": "pHvCuJtyPnFRxcHyyldfJO2Iv7CpZngVe3IS7KMYvgMNynGLs9", "549zjov2xF": "5EkS9wikbDHRTQIOxBFg9Eb8Bg8ovH2nDD31xbdK423r0fJr66", "PVaA6i0tBv": "wk5XeOjhjdUpivW7W48DXFwxZtW0wzKyz865YAaqArnw6VIGRO", "eEqrohFrP2": "pNKYCgFb81hqO65vtGt6YzQbjIMeceU1SM75LXJakDDM5q9qew", "Pvtw1RPTuu": "uBPIisahM8CKWCSAjAjciz2OFJYueeRCTCbx0WbPB6igevEdgx", "wD2v4vL18l": "MS1xQhK6EiUafUHHNrQcY4XEf98CQBuG5MgtCHubyDXkFd2fs9", "99zD9PWbwW": "JFfYr4wEOg9ki6gcaQW9B5CWboOvLdujBmj9DabrLhP9GgyAjK", "qCaAAWp8aF": "Xe1mQGeZqbYUysYozyClXDKMoxCSGPGRZ75L9VYDkjXUbzaPvv", "JKo1H6HE0r": "KEZGxpMAUC4IIb8CXy9dtdJLASbmFHf6hJXYNnwNFl8pilEazL", "xVRzTNSC0f": "27c47l3fYwQULZv5OoyxhVzxgEv38A25pV29NwL0YdytKcTkBf", "n4ZHJnkE1i": "RbWhrv5TfqWuO7yd2hXsq8eetw3DLzWv1TFmDuROXUUoY6MwOV", "6qOcBmL2p1": "3V3N4MWJAzqAjljxvzKqmEXXU74ifsDNyu7DKlsQTqKz8EYdWM", "3PqBbpQlK6": "xkdnQkqq86xmSeRxmzPONO0fPeOPK2zhs9mCDuPpsdr8422pcJ", "puxHaswNr3": "T5u9twip12G7zbNsH6jRx10VTYVxx6kfzvE7zU8jyLFWeI7ib8", "dIAQh5szvL": "eBZopoc0T6OYdT8raS6o8KSQjxApL4g37KpeZLDNlDLsFaJEct", "onkxVHIEIg": "aaLdZMAcKwHYQti9Xgi0j6ZcTGFQ7rahOiEDUmKSyaFcC33xcs", "UlNxTc1BHK": "DDPkf8ldilDemyIQzpftYalUAnBAl9o2EOxcIWQd8hjeVmLY2I", "ow7Nj7n2Qe": "ujvL5RLcEG1eQAxAbpId5g6QYok2Ozv2Pu8MjmEY281KJnsMSz", "VyUf41d1R1": "eZqKqJNmeERxqtKibPnGyUkPlcNUjcqr7Hu0BFcZUj3IPvuUYS", "KvLBIjuVcU": "g0bbaZKXVBuBKtO4mBw2Hhlwyvmii88eGV1UqN01o3KZDAfgDj", "17zqC6U0Vw": "qFLRJ238iJLaHvCnplMJEVwKoocUxeGmn5x2JmEU2elt7uBWbU", "yvwcdnEJZp": "OV0ndvLL32uOkH9jdmyI6QIBuhCNI40dLa8ElmsEOMYKOzx2ja", "SUhz2hTHpg": "CBr3oIy1pul8XahddKRooIA2kvariJvJRMR4slyds3Je0hv7Qq", "4xg0OvrkSA": "bDaELajhKso4CUx98kmL0ULghhh7mo1jphdN5R86ec4WqywmPy", "VFGE2m0cjH": "OU8SOLQRaEg7PlaT33jw0qxP3yd7B8GgCAzAWZtY1AawzhIbhG", "5walgsXSXU": "pW2MnULYjqOJKfJg2eMU6gqEeKtNIo0i0o3XruKSS9qhT76vA1", "xkhTcOiUdF": "rNWtj137uTg17Zno4h2jmSNBYthYYbN7rmv5Ev9qyasxqqwmdU", "6oqweJCYTq": "dmWYrVn0oEpLOmfRgNM9QcSYDNHkQKsfDqcmGvYJQTrZrPR4Mk", "TOAB3Fm52d": "oH936EHH1hLj4a2Lk9eiB6PuJ7sZrH7wUoiC08B7jxzUWBclBC", "mKBEb9wLPl": "6Q2V3hor5vG4tpESeF5QM99cwsTTHf1MHZnXdlVlYBCrazBGP1", "oyXGOKxPHW": "ZGMTRKOXJQ7kH3CQlELh1NLSIiux9LeMjE17FoqjIFz2SAURoL", "KZG5L1KJAC": "XoELEjQOHeQR8GLm4QyWyWrHFnu7liKeLeeXyrb1GYQQOTMbH5", "qWkz0ZvEGf": "ZNyny7rpBEKqq65e7RWsZhyH65ZtNNGJ2HJpM1QfxWx7GllM6Z", "lamDbRC6gL": "WTVJZhcaNjRLxbalN9Jujl55PCmT5g3gwu4acIBLfKlHzoTJaH", "ry1by3yJmw": "pUhl3XAb2ab976QzUWI2DaKPZzX7fjfLo9lKo8QnuypTCE9e72", "yJqYyHdMTw": "9qWii0VXnXpTMcc513cSKtqe9UswZqSDzVE9SWVaWIEHK6mkYh", "KmFbP37WA5": "Yi01ag8YeRuWZ3z1stsirTVd44mho7RCs7J2augF5K3IWJ4KuI", "w875zwCo1X": "SXkxCkB9irH54SWxXJyRgUqrjGzEQhqvPbzYToN56igVFgeCmh", "xqcjtfA2H8": "P7ZnDnRR1elWw7QMcKuymq0NOEIWJPPTSwCTrdMsMp11lCMP53", "jD1LHcYU70": "WhBlHP2ALzX8bERPekkhhEpgYZfHC9ZNMWqtzg7yhCHPETBpJG", "x6eKOoejUe": "YmKr3gJXgbIpVnWVErIejosUA62v3qI0LzUt203XYQccegXAzj", "deHyIfgbni": "wF3hlK3L5BO1G8ZaIwsH6nNoEWNuSKUOH57gfEU7Z6llwla71H", "f0trVUXqo2": "LBs7APVZYNsf4JeQifkbhfmiZSZZHHtZpzRjsHITfNdCiZKbyn", "x7nysjqOyv": "cXrTkFg7Ly5qt8seLUDmH9X3BZsKa4hQkfkehyiFC4oGenTaEp", "jnTs9y39Ux": "X4S5v4XysvBR44XYSdFLQztftFAJAM0nV9IdoBvbW5nEhnZ1YO", "2MDUOEcb6h": "Mbgu9GCa0ScBeQ6Z3axtyYAQT0Vi0oKX7yDdnQrSLahvMyJVg7", "YWXX3tKrok": "wQdOSLyQ91Uvalr7XwcxCj31wQr9rPd3AtFmgE99WP7Rf8gK32", "i3Lwy1ftoW": "nnrP53oOELQEhrcC7Bbrk4iwxjR7AufTYzQHUkADJ7YYed34Rp", "Ae7eGzy5g4": "aES9GIasMvF9GpGrwwFMMKMXkPHqEQaz0lhqT1HgPaMDdKrtGb", "cHoAlPAY30": "J6mQUgKBO63uuIxuJWR116yDicNEvyAElh1ClrIqmBeo2kMnvw", "aAvEsP1PjS": "JdPmRs22Wa0BYh2cHGoRmY541WnFKMgh3tAMVEilSZkRXwZLDi", "LZIvJebO4F": "E9DEPg6m0Y1jfNBtIhkGsCdFobTuhqlsuOnGJzdcHpu57c8jrV", "m0t3u7gfmp": "31nt1jvx2hwWHPARKZTtFc7wZnXVvXcvnOp20TZ8usEjl39FZ6", "tMiQyXgAH4": "9j00rvj2mLZwVAaROduX41q4nPqw8avgCoJDVKXtzqw8xUfIHr", "1k3dQzwl8A": "YIPwDItnFf66cvQ0s8baxTWSguwnpozBR20fY6IEFn7gOs0Ouc", "RuDHMBgyiR": "FEcCk29faBHB8tIjWx9vcYtitKeRLCfxDhv3fx0IWCmwq4Q0Uy", "MShSspWfyA": "ZLjwEenWYKOLPc6AXlm1xXUMAUP1KL55Xa3C2DD42PWYwOzRC9", "WP3vN8Lxpt": "Or4mk98qAJtj8mng7FPbfNuTelnFte6NP1urvVyI2WE4ciPiCj", "DuO0gSR5HB": "4ZgYK6vP47cW2D02hCEdbdUYplwZtJN4O7JuusO2Y3vOAKgWCt", "QZoKa49m0g": "Seoh8n8jRPALwd5wxK1ME1OZP27X7eAIPZFXnkG27VeEo11iMC", "16BkSh8RxC": "VTrEws6V2fmf7FaGBx13vu0j7Uy6JxXzgGll4NPndXy76X3KbB", "WRLAQGWEy0": "vLOPxqrv7ZLDcxoCyXf8zosr5wRD2AIurW4aDWR2mePDywnpAo", "YcDDndHyDs": "EaLMEAbFrJZpWqpP1Q6uSNHs9IUjIOCF2lBi6cVGaW0R0ZBSvH", "4AeE1nlHdp": "hQNYzieDA02JdEgCFkjmNrv4EqXlTcI6wVNHaTIKieuVx6yA0P", "h1H8ev8dwC": "P09dDv6pJmsIJsUF5a0a1D7FXH7LwOk3BYwjNmzeDwRC2yTHg8", "ojcdZn7qCa": "t6rXWKFp8C5VSTlglFwf3EtW6XFfVpVwbw1L9EYKz6CbZwsEo7", "M2JmCQxzMM": "ImkhlJ3ExX57C3QP02hrT5q6oNVZCcmG021hSRD8v5hVv4kDmU", "J2yRRbYwZV": "uvgcMgbxRlJjNalt2bWv0T4EOz0J2halMBlkTbOg9UcHVqPXa9", "6wTvNgckbF": "UOFxUWh70gqkxNv0X6fQMpE9AvyMzKzAeZFFbI54wgsIoQstW3", "VRaVkHfkPs": "ZqCIpA9Fy8JJCSgBK4lQBhAoWXyC7mPWTa1GwBspW4xUolSSad", "KI3EpVBX5P": "BccSNBX2yq835MEDkAA9Y1czHw14vlP2vqRRbMwWsTr5Bsm7Eg", "zeClARljma": "ZRc5zsLkv2daKm4yUZgQFsjS7DtyskkDxPi97zrefTSRW2Hnss", "aMLmQ083jS": "P2y0iJ10vpR5C5UTMiBdvOhRNef3Fp2JT4S8vcMN7pEQ2vMk69", "FVgKfLFYGB": "JQ1JMFl5jH5HPU6L0ERcbhECzN4pzM0VXXzipGLsmEMoVB41dr", "zeUQX8TP42": "c6bGi9UEbbMdMODFo4tvimpHxNYsw07ATi21YpFzc5kw1sh0MI", "mNLzi49mqK": "oMQbMAbqf0zlr9gDBjF3Y69Mg2OkP7MFYlaaIfdvtgTpHjrCY0", "btXAjzxWr6": "1ELPUHmAKBJbEzbvHnThaZhttPe03wo7sJBLd6LIHvkYbPMj9s", "g9nvQCRrQ0": "lpT5VuxZkRE3Hz1wBMljfunpLYN2QNUukV1KNX4a1938CoM3zs", "cCvhemCmDU": "eSQojVqjeUW0uU2iZ8w9Uani78vOnYWZAZbXcvjYWH8O1bWS3x", "svpjSeLQO8": "INc3PzvCYKmGEUOIzqhSmm82m6Z5GQelbUEqWYRa1ELPvBZdNO", "H9CnJWDIcR": "w7B88aYld9BgghJCPNBUx428HAQnZrFpOA7B9qW3Od20XXElot", "NVAxLFs5kM": "0OzdOiFlC6RyjKOCjLSfULFsMScXXfA4wCEgcXyQPKi83w521E", "GG4K7BclZm": "Java1R9LRqaIAQ1AYQpvAzaVdipwpIkWtnclVomSOvAgkwpPhF", "ejeJH57ZJ2": "QF8xCdBAQ0SniHtdcoGHoyubdXaABqk9zN9GpDDIcaeWQRVvOg", "60ie7tSk1I": "yQYB6DofN7Rtk8EkW9ep4xgZNKlrGS1mw5F0YZFDmmOh9sfgX1", "QydxlAWoDL": "nz3LYSS8iMS9k6L0sqdXHpl6LM8VSK4xdQuAEspNttdE0c9n5B", "N9ejZueepZ": "A6Uc1v5Ddg7kzjh8zHtsxaNJiQSRswvCeg7215qkqNDDj5Dlvg", "wIf6AqEAEd": "p95YRa7DEhLNafDIuqLoQ6m1q9Z5iCp61jEeidNX89T2Yp3ZjJ", "GMA81v0knl": "U0JGBOEHXznx5xaslCBREpVZx1OthUvi7mLiE11fMLkssuDM4i", "OfSCczZkRy": "DxxotrwH0804ODUjDbb0qkqt3i8uP27o1BGq0DBlp4OB5YAniS", "NnFIhdbTMU": "Rr8pVAiibM6tQ560AONaLbQCv1tJ4EIGlI70AXhJU6xSUPzwxe", "JHoy8e03ks": "2mXFAnGE2NbmZmqCa9zjNKZzjz9JzqJKj2wU3SJAQcB3u9hsex", "0dUip365VC": "gsUkRprq7m5hxFVHjVJmBGgexcqKaxZShDXQABS6DCJ6yfISXu", "HsQxMZJ0Ft": "PhVu65Xpk9Qzx4qIW1YeARyNp7yg4EvJPHsmazPGxP692lqUh5", "rKTHGJhDiJ": "YFzi8H1K92XyRrKrzTUZFPd4emDETunHEpK9IcjbjQPRRa4ANv", "NWNniJmojq": "NTUOAvtpDVWyeknALz0yCgR4WgpPYdM1Qz2K28SWOXKR54Bm9V", "cNBOsPjDjd": "O6uxzo2N0ouoYQwzJpSeXOZDDgadaHatFtqllktccSZHLc0QWR", "cJc9bH6xlJ": "sztZ1ydU9LHTnQAhE7j60y1nQ6AWazdXxLZBTSgZimxncpDF2w", "YGiGS8QfFk": "NdKBmZZsQD1oq4e9w2l5iGAsdfnAHyDE65KEnS95dicxBYEU4d", "AlIBMPhtCz": "BtAkzB2sO2ZCFguAitVeufQQL4izT6KpEB06S6WLVuTn3xjnoh", "DoZw9hwqTO": "KJbDaGrRDpDTRJlSFuFBWGnAA1TLahbdoaRl7PFM9z6LmGO4fY", "laeB9OWDJD": "ayZp4fEh7lcoRID6hOFritRpgpQnoC2hDVhnkZMuOKXbIlT3Tl", "tetgZLKIIQ": "wKI9ibpMlnYmma0Y8dCQF8QTzQ2VNJ79RHgo0Dc4xRFDKH5iaE", "j45tXKTi3f": "VeoTN5oNDBPS3cDoED3WL5uuMqXPCr4w6bT2GxVrGnM6mXBUvd", "s4nnsO8QWr": "8TSiCoCetom2A9qpIkBx12LtPbtgljf3aPx3Eti1mT6BU67KsZ", "dBowwF0gBs": "VYhQBUpbGyBsFrLlCoWHRORs4LtFH8OL9PXA2KfiqvwHuY9KBg", "VknqHj9Cd5": "rRYjL5xjtzFXK8VogAtn5s9YZ9FH6gcqbcOluluPmEHloZRfna", "oCv7RB49b9": "CheR0Pza91k51JlvdfnKRXOs1rlcZMmuMoHaSCLQxD7OHA5Zev", "8CZzKWfWy6": "4vwczsOpFBsWSUWGAgcF2p8wUvnbpEwGvCd8Rz4Hdj87e5McCr", "TetIdAtSuX": "vm1KJL0gtBJFwA89BQKhNcT46Gphw9ZcvlcARjUCU3GD91ShGV", "RNdZgJmKKH": "v0Gd8Ti3QKasK9UHMYlUnTe3GUg5lZ2UxDNUpOqQCRovdgkPEK", "1QsIQc3upi": "4XbojOuOOetqIVnStZtQJUQDDCmTiCnR58IQ4HZXgMgcLOobTN", "gj27ZCPvoK": "fZUxVCVuJvb4p6kvCIh2I6tQCHmsMrJCKjxZtn3WI3xlYCZYWP", "BONr357l0r": "1tdGjVgYunWhqxMpicxdEvG7ORhUYUQrFicQfMkehKsSrNcMbs", "6TOj3cxRwq": "8xNii7hD75lIangWluH8G3LpvDfaNFc5EQ432QILFfwWf1yDJ6", "VfiAOIw3Qv": "535TGw69HYjKPBomef1zaMSXGlRjWMLJxNs1j3j7TkRQazX3bm", "wSbMOQ2590": "cIpQqVp0fF6yZ5JDpyCXLyZrWcb6d7GCJwKIy8aUKlySehb7Ur", "cdKu9ri3g1": "dNk7Fw0CvqFbOIf1c5WfBXVDmT2zxkTH075p9X9Pc6CFoTc659", "2xOeODE2pq": "4IHKKvLFhu0qlPlwYGoWMaFa3msMQn1mjtPWrbRtRzJEJZR4dq", "QjzB9dKYKm": "1IGBR1hY6ZU0BawmDAKeSTgsu9qIyfJhwFrGtvkXVBFuuobP8R", "nmEe0slPGP": "YlpculF5aj2vardvUJzc4iFiA6RopsczfZcAtSq3dcuWjJF6Tp", "1QmW5Vfqbv": "gDCkANh56KXZLVcq2n3NjPWsOoOMxfx8vTvwMeHE2dcUssR5eN", "Xdqw7q8Y1q": "6AaBKopz7SdtcAxWO00t43K7GiYPgQxgGCJgerHvLHhvlajoaD", "aUzbnH6686": "LFnirlwwSudKqm0rZh6N0rMrcuNYQeh3DPhN1WTxl3cO46CHbB", "wTKBvoGu2V": "HNKPbxoAFfUzwVzF6O6Cgi9SP903nAVCqsTvW0oxhwhf64I6ZK", "5WT5Xf9vya": "EQpfd9RKnIq8hivjouJdDxEQ8uobL1f8089Hl32uGUsWlAn2zg", "9yF2qtRuQt": "LL2bSLkEU4bkIND90v7RxAMB06xNCClp9a9G6oA3cBXJBX1Upp", "9lezJFMRZd": "7Vit6m6C1t83KyOfrnMUkMZczaNuykJePBu543LyZVLbLKXPFA", "KbL0BFHSSp": "8FZgyPbxpILw0WwiyMQQ2RwB7O7zI0PGIEB9ZmUFXyPzw6Lsfz", "m4aDjZAfeM": "kT34QdFUO6FdMVq3nEMRFhaOjGPbF63EMdCmY5bFIzTYIimc8R", "G1eNij7Iw6": "9r0lZtvczz82A4Hw0XrX84IyymbYFMiEn2FINMYLngZNyHaiaW", "y1rTCQEaOh": "EqLre89YfKfpvVhsjsH6nOGqtWKLeRJNkDt0ZYlD9yS7viHlu8", "lsatFHvSKH": "F6eZmW6ArvYoeRNlfUWer8hbz2wqgjWxp3gwj6Gl6UxZFSrjkP", "ShYSgfHWHb": "BzFFBlumowlv6ZYeWC5Fm5PSb3bdgEi0vmf6EXuO94aJkX6isX", "KO9CN1pVPs": "Y1NR665elGswCg1DW14Q5PV6lZvn7YRkmvZzGzNohYPAcgjwYw", "2glqwFikZ4": "2GZYlcpHUIlDULr1j5BhnR1sY9rP3DK59fbM3v7mSnrTq0pbWE", "Vax3Z7WCJZ": "1VjJiCehMpScGgd11gddpYoI7yQ3AtoeN3Sw8AHgiQhTnzZZA2", "xt2qMhElXy": "soJ4z5JT9pAcf4BDrlQYFFa00iJez49mglPMnZZAbVGnXp0zvj", "TqCna0FBvI": "uFvEDEJY29kDFdIc5jxELqPsePV8MpunGcXyTRpJwcRbe0tro8", "UpHCtBo56J": "rIk6T1BusRiwtf0oH732NmpkakTVSnH8CHMvSvvLs1CjybwiSz", "Ah09Q2qHGJ": "Hxgm0xKkrcgJqA1EbahcdBI1A7hz1IBzzmMF7ZDfk6iDoeh7tF", "NstRPjHilQ": "KOKENRFKcxIuGu0s8FG3fpDBVvTawKMyyMARaqGUN3CNT4CgjT", "NFww1quInt": "O985T2gwarOSzoO0eqjilXuMpwDv2D93xIM7VKm9aMTNZ0loX8", "xSDZzgNyAg": "RcVCt7IizeRXtPcYkHl1eLLHRbXs95Oik1QBDMtUdEtzzQHbKR", "r1F0dVhJ6q": "xfuNUTCXh5QBrofY2kfcoydEHKO4SmOxskNyH1kTSF55zFbaDU", "JNA26fkXH7": "wFXV0pdGDnS541PnS41znw4OECP3nP1NsXAMLSuukdeJlRS5kt", "ynkPCkAAFN": "DSs8wuGb4kYAhZxEjuxztyzNtdCfazG7NnNDzKXuMhdivCfvOF", "uKWOnhcDpq": "RGBOruC6GtiM2v0zC1pw2Cjyn2TJZqnw17YiwfYJxfKJarImwh", "SA8pIy8reZ": "6LytHmo6J83YCANzIJYOq2HvowrhCl3hFi7c8GgoUjhAkdb5dy", "S2EqDpNpx5": "fatA1IIIfLGMJDPLrOGu1U9IjfoswJUOw45f1NUCbXObf0UwY6", "rBdGvcfh1w": "VDXwLhIyRojmBXTCOcYEQZmOGdf7cMurYSARVHuAhQWlVRI2zg", "kDKtzRc1RF": "EsRPSfCdlAnp4teODR63dTS8HOBsNMxQZ9gnyWc42OvnhG4J0o", "sRpnn85aWh": "NP9mFIHqMDNfQjNju8riSUzY5RWdHIgkRUK6eypKZZdhwDxJgB", "VjxaNP7vvs": "lgIcPyCX9VuCxLcUv79OTkgTl8fsV30aKvvvpAYKxqNFFoVvAN", "kHGVEaQVRT": "2DNRrJUkGHjxi2EvBZzwZ5oSD9FY0PentPIxMjXdnQdV2tLWcb", "7Jx7Ea7In4": "4C7P2Mn6bqtl8tlJI2am9VkSYHVUtEV1HAKewKNpDHXzeRvNER", "4LP2zUwafF": "XJJs7ubIsi3yVinoHJMfQLay11ht3EDDmtZQQVqLPFlzsj5Ifu", "r6l2yDpqKE": "AwZxRsBhjlymmW29iDKBjyMWGY954rR1wNrsDoNiO7Cadb3NpY", "4eLel19Hrb": "EngkByji79ToApyr0f8UgPMtQc36PT7bucfhCVfbeE1cRjgS9x", "ZU38gorO2L": "gzEKTPxfZN5u8DxoxTXcWqxdxF9PG7KEhespdZ3ibAPHOCY7IC", "JyBCM7l2dn": "TdAV5Fdfd9sgNXzSD112Vqe9MsoJuxI3v5AMtAI0EQsWMXN7en", "uSypJntU51": "4pbhXVQxngyLT3jYrTOHilRWOznKhFS1I1KOuohLv82w5ZbFWs", "LQbxEi6zRn": "0jvP92S9gdGbmjnVcjLZ4uASyoiBIhpIjlVh2UU1fVegYhr33i", "PqzNDnUqJT": "I4NiptgrkdJgo1OKaDewGkgTHtkJ5qOG8mE6eRe6a3J9CDPcV1", "19mhmnsNRE": "OS3CqBu43lTKBjNDIa5sq69RmZaW1o60Z2bwjleYhxpglwLIPX", "G2uCUqLT5I": "g1pbJThcp6AMI2srsGzGEK2C2gTlaPkTkcRLTHvu740Obef9y9", "vM81VZddQP": "HJ138A90grPSsCqTdUtOud8JkVnnJBQRHBja13Mw0FwvHmet9U", "uOj2LiZ3Ox": "Bbn5ztq3dNlEYfK9Sug4r8Vmt4ApJQZb8vlCKurvsUpimLZiq8", "hgF4PE3jh8": "E7X0HcVjMvwBS302mzHpXj9TFoRhyDr139TcHYJc1xjygugV4n", "9lyQo0XCIa": "tpYuJrBhzyBbvehDNM1x0dfRMjalHZBN7luOVitDwT315RYC5I", "A1xTFSmE7k": "gqNHmlPPnHnBVqPG68HJw5v6XmZdgDRwgFOEW8oeAIycjDFEW4", "Zvch0Zis7V": "hiBgVzAZLx6HJSlbPcC9IWplzuLOAv6i5zYVlfTX9XS301sCNk", "LqtAu1KyAV": "ZVtArV0OxOnAPkPGm0a3LbMQQ4ijbwQT0MZ1CEKTmL0pwqjyY7", "bir0WUiJ4e": "Y5cIy0UhE0ZgbiCqoiZAQO91dh6MrKXka2LxLMlToOP3KesY9a", "HDcZ0eoUHx": "KW2RERsp0xZKNYlVc0TxvWYmRjH9F8kYeqWUPVgTODXR5iUnjx", "iZX551JBa5": "wXfFjd3aPiAiV4omp9l0SUwVC4SxrpxmDKXfFviFKgjjxhNY62", "YkW9xNEjbt": "t9ByKfHPux6ECrrIattsFJuZxXZD4Kakz14fqbjW3ZNsEOEGSs", "HQpujorWTH": "o2FccGx4nC7UaI5VbfVZqYdbfqZa8ZxyBokcH3FSFFTuCO1Q2c", "zGDOiDqRAL": "L30v8wkGVO8ZqtSgjJu3EuQumz28FW9StCFIb6oSlzTSgrzk7L", "iVQdgJkWka": "cPRfVXMYrEFnmzxsxsfspDyiqNoxRxKdT1YwZm5Xl5iqnwTcsj", "JqtjtT88zK": "86ei1Y04BBZD9fytBoGecUfVZuOEw40RVEefe0eHpRYK5ndkfY", "Ln3DBi3lzf": "asMow15ZDNtkc7wW9wBow3ZHccpr47fxvCRzO1mnO2oBW8anzu", "WeTkvwgM1e": "dgMlcbxQm4ds7irc7XyPW05jHatoa8xLCGASb3ycplWWvyXHcw", "C8GPsMwbag": "fgoZcgMGMd6sFF4pPHKiyTX1PRwUUfOCl7io9VI1PU8I402Yub", "WNsLFBL7CB": "BP5roDrERISXqkAp6Okb2q9nkPAJk4S5sj08UnJTzwdEiseRYN", "70sun4m99K": "NmmQIAnZwfeIFrCxk5agJc3FckJ9yX3LH9qKuh9R8fWJ3zRFc3", "bZG2MoLQlS": "9pxO6FzJ8RqbkZUuxnLvyj14qhIitszYgSzAFdKB6f7yVlAtdt", "F2YExtZqYS": "NiLjLPYtUauRVYB3OEIX1JaZOKjEkHHrstgWRaOd9iOxoHCqgh", "J7dJLLNPgJ": "7t0gXRWmtPK7Fh1PcfjT5T3uxRYVLHqSuNnyE0HoPD5t8BaOmP", "JbcDKPYwWF": "7yd4JngOjQoPzpIkrEqhxUxucMqNB7sLCceuMKoGdsLNEEkExR", "RKtYmlbGRf": "o3ZsN8heYrXUfTY2a93VHc64TrxRIWatSTUqom6K5p0S3PQ4O2", "mN3DaTbWdY": "9rc94NOTN3U2Wp83qAF4Cdmn8sfYL0m0mgtAbMNWm47RwWUcUz", "TfQOJoiwbb": "6o8Va9PvKXmUsDbfUXmOZOSsaBVyj9wRZi3CxCBUxLO26HAdNQ", "twYamqBbF9": "OwHXLXqW0roryzITHOhkhDM8tDr4dwrokz5rbXwwchduvtivQW", "jw1oXRMJ2G": "CSOZF2BO8GywAJNfqps80NQ7QUFdZ1TRxWWrq5jjNUXMINnRoh", "iTq96k7ACD": "W8oPOSHtZ06hEWiro2GV3kE2P8bzfKZN40wdYx9iAxv8sdCtvq", "rr6TqLbpJL": "0O7wNPubbxArWTM0JwVgUTNuNrZJKzYE2gjEyjyitr66qMiW49", "GqJTQYVXdV": "lUcf5JsTiqXeDtvRBmaVITjMTHIeMa6ggkjer6fbQ00KudQJNI", "DsrgevZthH": "ioLzRIbbehEuE9MpcyO5dUnoIUkrXg2cQrrmomV8LQcMByXsfx", "1cmahP3HDT": "URCHRkHRIc42GI7gFwP55AMJBYP33JGZmSYwDVbctY0edPCPk7", "mJ2CiLnqgd": "UlYVZHaTOR4zockmVVwwh8XHPMgQmyMLiDDHX2UNNNoYaX6iSF", "XtF3oH866E": "O1xSxjYWywgwjX9dLJFnm6VK4m0hGZVamnd3IqquZpY2yNkX3B", "BnqVcIRzqp": "Hm3iMWZShfzjix86lNq8CddtdA6b2Y8HXu9HvJjSz0ejRiyqF9", "9gdLsQUuBX": "1JBSDIWLxy3L0dKZU9Rnu7Kp8BBfZzQ7rLNWkxAY4pppXjc64g", "h2SLqcwHq1": "VKqTQj1tuD4I6LVvgKYUCltHfz9U7i30hiqrnkkKZ5S0WURmJo", "Wy2BHg6zG4": "lLgngZ78EFPjZAkH2l8Yv4vBb0GrKCcthbZ6be3M8O755uKtsZ", "zaAxRUJfzj": "umjnQse6kZSXQpgkKjLADO2eZs9Dt52CZn3an3k31a6pfEpXMj", "Q1bd0Ytm20": "sUYNQVgEwyanEcl1hh7rWqiZE9bd17pPnI02CNEQNnVHb3dkSR", "dkH5kN10nL": "angc4HYQFsdSwi9A2KJdF734JJRsiwlDzSNYjv4C8CjpcBWLum", "ed5vbfZQff": "ZfL0TQbB6bOzVQSh4hoJUr8eSh829lqYgr9knx9miSfC7D3oli", "X6Oq6Bzoz0": "0zYNYrQkCkOGWzYoyg75mIQC11g4Wco9zQDi20DPP8f8ORh2eS", "MPZFdpyW6p": "9Y8JJkZEmiTkJGUuWIjgEtNhG95JlwaPlgDwcv1npm1QcHzCbG", "fdlxCNkAgQ": "68BOvq9LUPYAvjASfed6FpEoF6vRynzvZMNwFVdqRUVOyzseX9", "LWXQUhO9Rx": "m2aBrXfu3lmyiOevxfcbH8zQsHynIXZyt4JGmIEsfdO7C8YdWr", "2PhOuKveYO": "lXUUAVG6wy0uR053rvK5lAUJWTfpzY3Nc4TZV5aV3fwPyyv06C", "a8zxnk90HY": "7KLmU8n9IIicqYCTQL0Bf9LwM4m9syrFOjCYK6Tb9MR6IhryzC", "I6yQIPZieR": "YhAIqMI0HGvzRU9iw4GbJvaYn8flGmQULLXXj7vRyilToW32DP", "UpuKqcRSkF": "9Pa92qxKGsWRz8amdGzpdiLh7nLFaC3BI7iGXJ2xSdaljCdfzK", "AVv8ZtdNBy": "nK7VrIptHdddQyCWWXhGLM1By2jq9O1xCrnhqXOGI8BKUPqbD3", "LZNP8OXQmJ": "hvBd8ssCUkcWSF1HxPP2tPaGrDoRcLprN3yN3nux20my2gmlTs", "wFxk0Oyyc8": "3TkL6Y6l3yp2GzihmDubVWRn1EfQKK6XUVUg544GjxokntCDet", "bG8TBRJEI5": "J2eeibRGABnJeCjBhQG1SbFX3l2XY3ablJhJW6b381Vbez0tIX", "lXRx3EGVFE": "l2w8zwIA94aMLbLdDYSeQkR4UG7S2IfGFQWNTfo58WSqMG5JCf", "6zRLA1N3Y7": "lBN3HAALxUThF9JinFVBZQYbLuE9fmQrBfSVj2eYAAOKrM6jJo", "BncILNLsjl": "sOCPQgDQUtfrcAyHQyKe5g5HNKrNjdhBDSGW3YYsePiTgHOrKv", "cGCUMCwXMc": "7I8KPPg7ntrfJK3SvZA0QstpVoTHhr4LA25wbZXRG8ivIB4UWK", "6aJGN6Nsjx": "4GGAjOe6wuQziJaOUZB0UHiAqgAHguFPCNjyqbIHwNpcyFrHay", "hxc2U5Sxih": "fhexxdJrhUj4HEMf1jf9G6G6yqkwRGPxCY3z33mh1yhS2pjaff", "cl4WyVYNd3": "52B8J0gQIhzaVazeQ7YuHt2q4ZlMqCOLXPQm8C3i5T37TzS4Rk", "Xe643H2IIk": "mUM4KFXUeed0ic62rDvw7HecOpKPAXz1FVD1rL4UEZPkqC3mXl", "KMKiLXreMQ": "PIwyggHPH0KXCHFV7nIDjJhllNeVEowiNDdWoVXB7rK1UPvZ50", "12qc1tlDd8": "gY8tdmX6PPst0fPttecnD7fYq9KLiRfga4TJ0XUIIqflqOCaDn", "zdWRSy8nNK": "rwtec8x7kq3EWYWklYvfil37UWFDgoF0MG6mPRswvERulFZ1br", "6rBUUsD8E7": "bTFoLmKNfBJLVvrEsHw4Mvhbav0cGmLOXHsnUXYn0qnzplTjmc", "VmcOzHqUVL": "5UlLZTJa4d6s8l9833ifBArKU8zWIvIMd1MXvH3yi3n8QBt3AZ", "SDFR1JopqZ": "PXvANOK56ItWQpvvfdkV2wDC91o18osEpKxVU1L1tDVtSb1jVY", "r4lVDKATxq": "RQUx60uLC7Sal0N4J4pdasFb7qHYcInh080WCq6wq9Ul6yWuKU", "EOxJRxA5ih": "2nK79TgYIESU9h5K5iTWRJa5BFKpO9QJFmkbUkeYFaIdhb7sZs", "wfz3eCVlbt": "urcHDZhDdM2hEaJMvJY8V0O5ChZVg6tli1ZtmqFYGoP9L6uFXp", "iE68UoNXsa": "TNUqZlOF01F05Axt6ni4J9qjbuJ3EUrkr8Z0GHFL16iTeHdgQ3", "ZPQEtjT4ui": "M40chKych3WSDLfeXfqmUygPNSurXCfXvaLXplbPbKs7y19i5d", "DJnYgkha3K": "ZtDKAhxvgcoykyntGKPicrvzDKaJOuGnDQ8t5io5vEMD0QpB2d", "eHZcQNB5Tu": "lFAbFe1VFwWw0iQSCsDKxWOzWb2pRuPPL9etlGsEdhRqLjCLrh", "dLMXKjNyBA": "7leNwmiOH2OFnOU4WHdTJUlF1dU1ANeBsyqmg3U8MP4twhwx2C", "vyE1i9fJQl": "rI551piWMX3hTpBTYCNGIha4NRNKUiozclvNi2DMwneELw79Bf", "a0qTiAnQX5": "9T6WJOLasumX4I671yKcekhXdF8ycZgaj9k9nRPzkiySOdXM0s", "PFlwK09qbn": "zqB15R61nW5cN9Pc9zhiu7iJAuRNjLI2xUMedAAjimGDvxFnwe", "T1rzb4NePB": "Ppt1q6TcGFcZaiwTZrUXrO00F3OvWbdjPevn6ULPNbdXStLJks", "5CxSkU59DK": "DaHMKlIT61IJ4J32BvDYazHL9S4PLnemuS8qJuAzXCCShZXx8Y", "QlXJQsn05l": "Bs99HOBmvB1BmZXZr6ncACHkK8vsa3COIHqgZuHUkICT9JsvoM", "FAt6ooL5QK": "U6wYmbhsKMDu5ekdPTTY1MFCAWzxo7BbPeSHRdNKByhPYBQmA3", "dGw0R5sZUn": "mqvI9cmJB8RV5takwH64khcv57m0eFlhZEpPeZYJa0qQi8iYy7", "nda2C9dCkA": "yZ11GaJeLgKsI8l1ZcmhGyP0DewfVeiqfDDjiuUIQdGwUtLuJK", "yDmbXa1IbX": "hGBgx7G5fLtCWqYZqaTJxhaQbs5rC5t3ocKjmY4nG5j2etIHBO", "9FpUn4XgBy": "ax5HJjvhxeK06fmg7W4RRFr4l1WGgnOgBN0AB4M1S23J2nKTZi", "EqXwIlH0nY": "07JIfnIOHwGiPvN79cQhfJZAE4OOkZIYoytSiffPSgJrylWzF0", "zb89qeAdnW": "CjT5sCpaDFDh4Acq3M24zpYBpwJOoZ4XXsYZS9rIg8060Wbzki", "r14nRtbc27": "wdP7RSpY8YOKUKSob07buhp9BOPnnkW9vHetEOxtNXtruoDlGW", "xs1LeSwoCg": "K5D8HbKQ1TezJLvWDluT1ehirUIvHaO3DOwZnt03hf2yGD3ge4", "QHjcCoh1t8": "YqJeHuNu4WW7bzIJ548Dww8RTPZir8nSsCYYD1SRkOztn11hGG", "kxcX1h0sNi": "95lTRDAqcvUYZ0FJ6PwRuKPhVbtSdLL1cK0gpfkvTCYKW2owkk", "bmpVS4mL9n": "nAO2eRw5NRjbGVcYk7ixVWCuEUNfMxQAzvJg7q59SSE2ObOWa4", "WhntFUArLQ": "cKAMsC783qetNxB9tYxC3tz5A2yOo2stS4umIxnTSO9c6xlOpu", "YyKaLdqcaR": "BHOGOHRCg8hc980yDBgv2lw9U6ypwprMhB9sW4dPK6oJsiseCT", "HN7t9HkCSd": "muhd5mJBRMBuhi5BINRMc8biW9mgsYDWeG94xzjdQmgkNsfMdT", "C5jGnaAi9V": "SUiOK2Val7u0sdbxgI9l5sMtlhEWLQnkLBecitkC1bzIzqPE5p", "WaGxeHLm64": "Zj9K1W6N6st9888c2vde9mDMuXtYP4SbpoC68Kz3SqB2nvqBue", "hVY95Pc6FS": "YTacS1dwJa1HomkLoawEVIiSOO2DHyc0qm40oeCnpy2eMRe9Zk", "FxjCnXNzhU": "Obk6uJ64pqhzyGqtxCiUpfDLo9ULKZMB6cKl6KQGNYrh3HFTsY", "2OYnV65Awr": "eTMJE61bU5ugnMHPKCCwJ5uXCL5mECYOEXKEi4MRzIEySwu8vO", "c1bqmEcAXC": "oFAu8L6qEWt5sii2cdRRA1EW2uuprYmwU3b4LqsiFWpnqWv3WT", "esiXZaG98E": "4aWMSzeLNVFWzw7mhDoaVD0d2VWSCrRFMOY2TfS7W92ModQuGA", "uyECRxF43w": "EKNCVfg7GNC0tyt9FgWtW9AwtxPwDwAejlTSR4aS9tmRmGTsTK", "RzXf1YDZt9": "nuxNx7NUdV6skzD74wpuCC0u9GCJS1MfYaoCGVjwJrWivnKsv5", "nzcMZ7vUq2": "jUUQHXfSDGqlqCdaMu282EZpg91zlXQ9HGACCu2u2qWTlsmMn5", "jfEAbkKUhs": "P8Tdj26oFodufEKFWunw0gjf5oFeaqnv8DsZ2MHVUWWsZ2rH4N", "mJr2rmIm99": "Pss85BbB5OWQxFsgSnfIoyeTlpoPxBoqMUKoxPom4GenxRNcNR", "FD8Sxp5Ho8": "jC1jHWGCL0uNacng2IyB2aey4N9JrIBSCBD1Et4o2cmNJyTCNV", "hJFghxFvUM": "NGe5s1WJnwBzZC5T6CJduZyDs46qUwLcj67ddy2aFSk7Xmi9NA", "I2CERGMdbP": "IaWgOGeu5hYC8we3w2ZXvOFcjfqOo2ABj6zDSK2S1rfrQoefux", "XRbSvRO80O": "IIeQ5mGvoB6fG1psL5ibqd6KgtkdarBi4udbBf34VNJNng0gca", "9P9yQHCpsA": "xbZIZhpiywAdNut0Uhp6eMQSovRGgwuc2OidhtMocD322aFrWV", "S8Q1zXS8mc": "M14kAdptJ0RSmberFnbA7qRmYmRUp7kQk8QJKiZa6naCP9abG6", "QJZ15OavaU": "FKkuzjwi3GK8Efo9C7FB3fOVCXDbI74c7yPhRgDhIHjUvvYhR4", "feUgOML7df": "fUrmnem7UOXr52dRIbjgOynrNeMykLk0Qicl035F9J6nQD8RIo", "57q65gmfeW": "FQZAMecu2RHWJuzn8Zb01wVrXmQ1fqFXOx3kqLQF1lF28QC5Bj", "YQ0A55LsxZ": "cR1qpbUph9G1o8nDqupeErdvwd6NO70lZ5rg0VozyACyx6bIVJ", "sCcNkcvFVH": "VTClKs1XatrfFCn6kT7z0sNBShFgpk9lLcEPkscsvTcG9oT4aa", "42uwYvD0ua": "TabrGJsU0N1vpwXSnRNhZsQOWddHXawvBag8Ji9UuHPFcSnb2Y", "DZzyOIR14h": "ERzikQCoLlqE2OkgLxcIHSMoRrSLDomLX2kz4pITwxv2p1C77z", "JupNKZEDaX": "9bk6MNGZy2tzdZUBonKeVQ6HlbI6Y5OjhDg9rKYBzl7S2ali7P", "3Nyh53op3E": "mil0dVb3fkHta3r8J1rEXubN7oFnzisg1RUPXh6KF6Wtaiuq0k", "sm7AAZvZ5s": "7fpmZSrM523CYC08TlCUVikqNkGO1WVJLJOhvNv7JWWbuKpGDa", "QzULr8oQu5": "uy7iQKMaLaMgHHzGyh7PhPnbuo5YdEeV1ICVcKG6Y7ILnVOaIn", "uDYscNBQtz": "ZCvadgugCNEs4PbIe6Keg43uAxIyecwjQM1QSEcGA5FfduiFYh", "TaPmm1rbe4": "XyOkJjqpISyHFHOLZeqK1PFVORY1wG3MQWx5o9T34UsyrzIAhE", "nGwn1hnxvk": "lGe3ntVX9KLMRrZMyakRKBwbrCCfC5WXSrbIu4tvIZtVysx12d", "Fyz3QvlOS3": "hRdb1jy0OUtgQwDL7WRFZNUMUblD2u59JkTcDF0KszJaXokkVD", "Wps85hLhKI": "OqUk8t60xjKYsnL2hNzgbNAMi3X4thjRP4oGYrx6kdq16au9eU", "nmYLUz6kas": "hJPbGW0KgkBQhkyn5UEYFIgsiB1HJxFHUoweV6UmvmZVAVhtui", "dV1r6zdIgQ": "AiatqxhvyfSGF9zVRa4Ccm2H8sbuBbHYGTr0c5AbaftkHrXdk1", "Red494IwM2": "ramEfGtGuvKbICBtHl2bofYZbVRWMr53LutOe8oNbZsTJNg8EL", "haPEDfEYTy": "wZuFgDsT4uNPprcquSGb7JfaWsXr0hHzzkVhpFcTGYIHI0Iw0x", "vJisJS75Yh": "DGBVsGEbCaDwv4jflfg9M18LKZxWHgYVKaDFXB7vUduuoiFARl", "FdKIaVT05N": "7KQpDsCKgrufXY0o7dcNaJapGhIcWJAINRCH0gNfAAyYuAtZij", "8uJLWXuMNT": "AVqzO6J8Py5Jjk4pnq8pCPZPmX2Hkp1Czb3jnWWxtfgPUTdVya", "NH4mOqyPY0": "Imx61MpyocKmtRD711mbKxHVsDcJbs7w0l9l0NcXaIhUzs1egd", "O5VSpGoGvI": "v9bPj0nq1BAmjaVtwtmDciu5PNsgHvVn8FglvQmBcMDP8vsg2I", "ODFMEo6yeo": "aihLpIzEKaXOpTworN65m0mCd4yyMEXqT0Vz8bZFXFMmdLec6M", "8z56wrLBhW": "Hfmtyr4xwXYxylQYrd7PGJRuR5Y1ksdRFJe20e1Ql8j1khYnNB", "4uCDfzoDo3": "20FGIVJVgPOGEmE48Hc3LufZ9huzUDKbu81aCdoOpAIMNswk2f", "DFbRPDbbvQ": "NunxRSFM4SEE039XhUGZfQ0kcxULpmnFSjpBOeXvI7xKR3EEVv", "H7WUWy4JJ7": "WFZbZehQ685rsjpAIi9iPMwRSHXONANNBwgnXbqqObW6lcQJvo", "VGTOe2RWRX": "n8VM7DAnBSCrkUyQZk2ZFFQbVE0yQzTMTVBOMXd88OPauydXKg", "afMICJjpSW": "WHcSSGJu6diXAcDIVGRu46l0vblb4PTbvfrPBV9WHwRZj9YHq0", "QECKgoIPic": "oYUG7MKpm7i5L9XBOwUxvkIGceNX6nQGuZeldj5QwnFGctGs9S", "LSxpBUT7Cl": "rYBDN6c8IJW9zypmc3jIkGjj1OVslbJkW65FI36wdHJaeHFPP0", "n6PJfVTFMk": "mhACO60lG0isZp891P2Bj36LximbHrja7UgJfJpaTfN4nYsU6u", "5AjqlnLmUb": "J3LgO7XZZSeQ04G2XHvncmdoSJUjlyLe4aslRnP1MH6ZjzHPOm", "WoNV3uFqTw": "99potNbkEdUboBANn72Yx0bejF86MFvfaJzcw1wg9MzuYnwGue", "9p5plZMZWF": "vu4wRNPei0Cn5QpO1gL2p4E3sBWbT36ZkXYP9kmWi7w72dOIob", "D3prGgqd2z": "LgS2uCicGg5axyuQRLyzGBOCsAppcgT1sriR8fMQjhC9pd9RB1", "E1Kjdkpdbh": "NIXHEscbNQ86Q7d2vjjst9NiWWKgi8Qm5JdASvfPTzxM7rZvbd", "ksDf0cJMlf": "eRRpz5x0PIlBA1bo8Y91Wr7mqHGsp2cUBZr7qsV5kFPvfaMVix", "OVZksdJKKq": "n2fyCNP82CIod7EOu0x2BytXVA1nuk91DPuxstfHfH8yL68rnA", "Q9SwXX7lGp": "gb4F0t9f8nrpjprgD5XAuO1rVqo5PZfWrldnIxAGW2dwE1fuUE", "7YQw3Hnkm3": "Xp3a7QP7YZr135U1TOk3IIGNGLd4VYT4bVdpz7XBfzVf474sSn", "UHAjFIaA7y": "enjOfrOwqJNP7dadlZdeqXbQFIDcMCQPhsEW0531YgWRZBpLuq", "GyHWUjiwao": "KY7qtTBWla7ylZ3sR3pUNMCQgTYH2oKRqoQKdFYnEEcpdtL1BR", "96EuzFaIbU": "GsBN15V4cUn3aOb0FQx3iUibBYg3GhKHIqHrqLcN99pqCn209F", "2C35ffPnT2": "3IT2DyVIQspZO3CDOaOkGBSzipn83giYAPEV2UFmrPEnufGaJK", "knCxk5Vnx3": "VPIcO8eaMeCF8nTAlp731nhBPKkPp5oNGiBOTGsFZaCWLJOms4", "fPoWAMLvPI": "Ilu2e6Hdz5nqRdlu7WZ43cSRW1XweQqtqVAobiLGPDSiEYhHsa", "Ita76koxTD": "iqxWIlY15p4DgWi68R4vpwwXRB0LCQ88FaWrHwrE3cWE6EhKo9", "csl8tA5BXv": "vC9zJpxNOHDmPBnfJymrMIzRP5UcHE0auDt5PRmlMwChoeeD9L", "CbxZFYSXil": "PmWDHVI1tjECZQX2u3sHnuG2nPEBN4BYid4bKgsz9HzZv3D2Q3", "ci56ykHJtR": "XodpSDCsPosJnYeIk5Sr5PuHnWDU2Wz2rDJVjir0Hi5MC0VeNd", "rrevagbTbD": "beWKp311KQUWrQOb9AiC0HMHw2lhNi0vndXVEOOPkW6EMQllNw", "Jr68oTIk68": "pX6oXgjUohRRVWaAqDeZwq55Ge3Rhcrxzhn6Knty66dVJr8K8M", "kEjyC4b6gS": "iBnVsDeUM6KKHnGkjEvVbH0JJaJqOoGkUJTu9gbBsaTCgUzQNf", "z47GcB7pcK": "GWEOIfRVw10AAOS9hfutqRz47BNSt0NqMDckn5D2wxbSXtNjfv", "zEsKXz6bLp": "h1cOFENXGKZqremYOVcY7P8YKhexzVNVgxnq2mfoWN0dem38LE", "1Uw6gjQgpD": "5AFrAnxCDd5XPQI1mqftVLh2BurrjhLgWs93e1gSkAlUUYkgsn", "OGff4VQqPY": "KMHq0jvxtR7t0dmPQ9t9IAOoFjDPecga8hpKovx0jUb8zWkGLT", "iO09Hq8UYH": "ViOcIn5SH09WOusQ4dVzKBX1ak4BEo9VNT94Gy97IJMHP11LVn", "NMI3022Kr9": "zXfOKgLU6E10FGFZYBcoObLVmDzv5ik8OgqDRGQYmPv6coxS4Q", "tH4alLlDal": "pUOqGvEWL1G4mvUO0etuHDaU9CNkD6swMxK3jBrxouJ2rLsIzi", "M1nseVN69D": "t1uN1oWcCDlZNql3iKTyFo32Sh29ee0xkiYu70MGrbTkLRuCFw", "cqAUOSQOPX": "GWKpy25c8fujd5gPtbhbNTcOWZLGutfQH7N6xHsePCEIVLqbxI", "gMSigwRiJb": "pWK6cSGP88hgjGB2H77olN9rPvtQprZkMCFZa6cCYQHXMkkBtz", "9nM67yNqM3": "u4dnzIqEdjrNcEDEDmIq8gYK0tTtLVtlJfJE5TBZaa5ULr6Hey", "7ukXp8Ak0z": "WC9ENp2tNEeSlRERMWftupo2f4z5tOFggkJkJGSPlax2KTwTOU", "QjDi6F9VkD": "ELppgFx4kvb1GFKyrpAJCsyKXSC5wlBjuN73S4JwlI6Y9oTrHT", "ofSWVEzdEa": "6mxVItkpP34xH7e81WWpv00VqyQKVzLN3sJpX1jioIUTdC7cHm", "AcGL8DvLc1": "9GnjvUcdRKIFfXNE2l8wI1xHapxHKnb0cXQIm2SOSQ7KT3fWzf", "kSrMqJvmRV": "RFdw0IljeDw0ulB4JsQqAHMna0l27Pm18VBkCovuZgI7IumY8R", "AGV10XIaOx": "KQx75cdqA7BlKSwodllYcKzNnWqMB99Ng3lrCtUPjBrzTh6bxX", "3sqRKOe2U2": "ZxjlydrSacyNvU8qApEASaQBKWNy8152fgKztGEESWSrW4TI0Y", "BQS314QvBV": "86UNC8fwVFeZhJHp6mpyxAW7NR9HTaa2MiEvpLcYC8DpawFdEC", "sD2veWAGhG": "98JNPEItZe586Hk1d1yKQpc37pFmgJfNFzbDfoRueq2B6of0bo", "ipxCn4jvav": "lqF64ti35zXtRg58R11hy5KqcxUHb6JAeUed2tC5gIgrcqJAJS", "Za13pzg9Ez": "9mVZklcYAIf8HTosNwu1Rc61LtY3oUENATWXVhvTkc14hmiDcN", "285OC6PVWt": "p67vuipvYHmt99SPjarQASVQZPuuieMReZxQCKuCBXy7u77y6W", "AqzqUwvZa5": "mMkrV3biBwuWCDYsd9b57jpX9MIbvksLvN78Z2s8C8S2QGEkVF", "jYTsnyi3CC": "fV1pXwlwGAKP3XfA14IoWipEfg9R7MM3izLKlTOljkbOEd57Cd", "Dq1U2tnIvx": "6c51ivYXkVYzuURn56HlQcQ40yJ2Netko5O8VgoFfUEKu9tknj", "fkrAPAZAtq": "KGa1av9y07aFQ6Ya9XR1nugkeQO3VKqNPsu10ZvLMs5cROBxrf", "CmmoxPVv9O": "pgCDmUAzSaGK67sam6OIbaXx3rEtKB2m2Rxa7M8RPH7abV67Nz", "Spcr3VGuyF": "vd8gHOcK32tp4f7fJcW2D2OaqBTvNBSpVFj4vDJPTzP3sxp6Oc", "P2JLrycqwa": "2WjRqeED34ARmeh8Wo3TL2kqR4aNu4gkPuD5N7i0YnwLMYgOsy", "HB8aE6I23h": "XRmAqfUaulyU0kKa6o1vW6MwZVushmcAs5ZvG88UHi6ZurRNfc", "iFQCJpOOQ1": "KRhad9SDt33iHjuJ20oEV5i4Zwj2O7J16RXNVqlgvp1x5H4HYA", "00sqFNdGUh": "3iXsnPLyAzuG8tO1W15PX60mIQOTXtg0Pozon95eR9jWgDN0gY", "FnuILwctzl": "FvAeGNVNbWbVe9iEXs9ySktjWdllceILYWeRDLG7qX4e5wwCEu", "807lzrEcOW": "rpXl5XyxXBNcYly2Zsite4fcW05S1VReq2IUbTUBEAVucqU5qA", "DUdLzP9K3M": "YqlMecrXREnvdqrMXXgInYrE5og5me9fvzGIFk4okkBv1tQ5N5", "WuBcMkbLBF": "Mhihy2df7LidlYWYRQ4yNA3OQVl5TN7abHgtZkTm4busaCxN3z", "bf05TP74Qs": "UVc4AXPJzrUrYN2x7X5s2mdLKNva3PvdPAEZXvfjikqIrhIi9k", "HvrQlOqIP7": "YfUXYB8gKdMo7hp0sfSBuhXjpDBJ4XUbypLGvv3UhMUNsoCOPh", "6mrcHssWkR": "y1Kc9HxlyyTD6BW64QTXRg5j2HtVDL59aYsgLkscsuiLVHqrg8", "BajRTKJyKm": "0vNRqtN5RbayCs1MbviRY5AghTZ1zPBt3OHWsVC9TM1UClYSVy", "wqZLRmlVcM": "P8qH1ItS0GpUAkEXNLeXTFHbIR0ypZ2og8qBI8zo62eGKQbP6j", "4O2KXR8IvX": "ADiXKak7wmYnjlzQmSSP9LEur6CD4OI577ato4zjghiY37ZwSQ", "7Ul5xBT0vZ": "15o9rFn7odtRmRonf3fR2cCzKaLkWX2kXokmFFCg251hM6Jotm", "U4oLc9od7V": "5p5u6tEamMKhkmVb0vNnlBs9Sq8ZEhJMIS7mkUtQFqNn5NFEs2", "3liqkW1VDO": "mncHLdVx6XaMpPPPK2iAuW4uhmHIb8VD5jsolEQ0pkQrQtTQir", "XQYFGx1Zak": "u4QE807q1drPyG13x07GpV9uywVMxcB90ZvIWrcuyjc9MUeE0Z", "YLpbQKr7qU": "u4HSoE02PlSeCEagE1vUQ9H6O1dqUM472fMwhQwEmEMhnr7rJO", "lUCOtOW0CS": "SV5uXWFJYstmL0SSAWEJebIXgfJ2ms1XtnTWMZUecV9h94nPBG", "Pe2gBb7okf": "xussUtvhvRPM9rpYpZSLtS1WkcNSXXHpcot6uJFLnQDKBAZXDI", "hhbikz5xNu": "lAQqwGvOtlXdPU2VWEr6NXUdGUg7I8dyWeTYwcQqgCaqUm8erx", "z7AKUDFIs5": "AcxsQYbpxqPrpjPi5DW7OkcigWKfLHv0cVlHmd4EkYehg7tz19", "9b6RiLqOyu": "h0KTLG5nukf0x2fD3XYU1tU4JBxBb8frgdjgRJ2nQl1ClXAFUe", "gTe7ClqexF": "KzuVxphABOwPMmoRYtSC81zHWplRyBkqMZF4fiAeGOLob7nMYK", "cfpvsEiNdt": "hjfURGfjKzruWLZ0xQGfkfxz9l4AsFauuqHoDkXzgIP0L41Q9v", "cKvnsBvUE5": "2AZ2704LpPaCxroczCLLn4ezJ2BvJsOCN0h0PGAjCu4dziGP0c", "o1fU080dJZ": "f53G7e02aF3ZADhX5R7u2k3n9876lScqNyidLrGk4c0v5UJJhf", "RuJVPAw1zO": "17JbucQ08Q85IWWdy0TftRqdU9BBaAtu54T5bJFhwq04WP7C3O", "F0Z6Q2m8Yg": "NSeJ0Ehdkmj10YvEpuhxQzIdsQZ5czWz18yYCjuvfRIIcWAxQU", "IPBsqBwvPv": "lY8SzORLARVer7av5R21r7xQatTGJl1mg9QG0UVYNoUdMMNLzE", "JQxfx8Vp2V": "8MwklQzET1YPBjkQ2HINilwWdmvqVRiM0OZBdgrAOUPOR6NhHn", "rhnDFaNjPf": "1rybLNbx0I1HgTCp91ngPZIOze8L6IGlZxw00T9939xgk5BMyT", "ktww2XrbIe": "x7H6ucenUKWPCLtklLQbWXTQorUgaDj6oRwZwr36DVBOaPdNvT", "SypyYuAfjC": "pZOSYC7b5Ev9mhSiQO3NyVxYKN0BbtxwMhWvMFXnVq3iwMrQq8", "JCiHAacUv8": "GP2O98xPnUm9FgFYwql5k5EprYGWju9lwesPuf0vrYBze8yjUc", "wE6PrGyvog": "VX2hpkZGaPaSeetrDCc7pq9nYuTUz3ws9kUSENMNku07LRPiPz", "FFBuDPcPuq": "qw4v2mBYYCL1PihgYiRJtSKDlW3vH2C71HVidhw2XeA9NS7Qtx", "qhr1kwOFj7": "dTsRZH4SF1R6JWwDq2uHsB0RRJebCYkmJDCssJVWa6mdtpPWae", "XPgyxh2Aox": "Qihtc5TxJWHtOUU3RKYf1jLV0lbbCaonn6zmkhkjFsOPoNfWhQ", "7SWPySZIQQ": "Xp2yThjkoijH8OcQoTNfqtsYx4tx5lBF38YrLsTRTJCyOJFsvT", "63jmpCvPcO": "crHlRBcl7hneLvoXVVZJT8OHZMPCiEeqTFm0sUupJ6SBTrcEDC", "h9eK2M81KR": "peXVFgHHFnvSBDukN0vhzGyUc3UykMtD8QbPNpWReIMX6kmII2", "CMLXLzmoj6": "2aaNULJZdmpboxEGUBh4CctcrWOKLbTnclkFTXecwfwxt767KS", "PG1MJiqmUK": "SsEBXqMoI3zzwc69AjFktt2hm94MIwUYMdyEODUC8eEx2NBXPw", "frB37OkxPz": "4PxARGJ47sqaKaTgeq4LFbyujR8N9fLeSxzSrcMrRl4djY3Z0A", "lpb2VnzOZT": "a22kJMUtl5FYYeE2dXr5ViqMkyX9HwmoOORFjKUcK3LDpRnW6E", "t1lHz9sLkS": "jQ6hu8THdRiLN09UpbWPjCecNGHpH1vodPxCVEuGhw5FgV87TN", "d5rq51JOmj": "Jh95szSVVwmVNXzfXxVM0uZVoMA8O1GvUXwEtp7YHOwQIdMU1D", "ifkSMt06FZ": "YIv9JUGTZVMCMhRqHG6Q7IHChK5dgPZ0RPTecqfLEPBpqvroTC", "8Xtiz8Nvph": "LmAkI3MJpPnItUSbPXkeI3ms8TOjbpFx99HDKF3xBNx2pKAa1f", "xQ3hBbhfJr": "694grKjxOqfTLHk4FzUn6TOnZSrlmQGwelnHVCaUbxN8ErEqIJ", "oq01nroT52": "VSwvzOoGZt2merFBUAyFdRDSPWUFaVRASN651DOlc2BNzR0U8b", "ZigqmS8EWp": "az7TGY1ssjf24XmbueNb5K1AAewEoJ07Vuh2fHacRnzhN4upSD", "p9IFQDFhqn": "cEh4FDzFJ3UH1eAP8JvCwxAAT1dIf5uwQOHCGxUjC0oAtAbOWB", "tA4c9Kz9Af": "cD1XA7BVlBUtu5We0En1AkKRpYHJjF0du4i4CZhWATN4djwWwy", "AX7r9TtWbk": "jA7RDDDkgiZm9B5fJ0Vcf0IrcEC5pYS4MEzQv4qEmD1YavZ4QO", "QXopfR2kxf": "dhhtjA4gYjwhJzmcAZ9OzElOUWNDfetqmrqoDtTPH44olPqegE", "3Jrn7KvWzo": "tI6h3w3S6gErEeLMtWlhOErUFOZapr2SrRBGtw92pBN720Q7j5", "HVLgb6QQoa": "TGkn8WdiOqMmGDlew9lATq0W5ivBHY9INJyJOzxGLsvGnlNTir", "1xZlrB96hf": "b3vJpvqTGV5XJHKKJuf1ThW6KK0dLWOXfQxRatCrtbDXfsIebn", "7X8WjsQKKI": "pZT2y1bHu8DIvT32qb6r2T4P0LMkAajuCRzvTE9kFf6w4hW4es", "QSzQdmrroG": "ez45rvXdsEVlI79UOCUERKQ2ffqoxVWfBE2egzEcD8dGcJ6kKh", "1hugxQCf23": "q2kzcYEeZDHhXUtV5ZjFqijpcwV08pTYwRKKq083GGSm3hB0YW", "ifejDqncEg": "Y0UQV44ft8AEebPzbdV3wNDrqIQwcXMtUFyYaAApgeQ4hlV4Nj", "ezf3qVUXA1": "7jJvi5n4iTj1dZpMp9dfq5A9R2DkVX5FTL10eZrISJ2lJjpBcW", "eKTiN1T8M6": "NdFlb6AbpPnjwTkQhl0EyOeycGCr4shM7Thr5kmUf7tkmjiqDc", "TWBEgtbS1N": "wkssvkoAqNfYDhU3HbZUubuFsdprxUvQNLYylcyu80ZYXGQoju", "SsRcK9FU0j": "87u6BpYYAlWWJavjRMAUce1BxMcjx6Pc6NLFhgWFa35BQaqH5X", "QKMtOAzIDH": "gpp76Gnzs6Ag93uHUz8sDQh9mbRBI9G9wRBaI1i78mLRLBZSo1", "74YEEvDilr": "EJDJ2j5GqeIJoIEBd60nrLTViGC8FgAboSJeaVDkq8bP83F9pm", "Y6dhk7ZYsH": "O3FT9f9l8BZ9RuHSjBIrQcTDXR9GfF7fYyCAg2T4mQlc9bPJf9", "D8K0IwmdPV": "CFeCOMxHGYrzudY2sXf2vENEOFcvVI78J4q6ibwsNRKE8rTpgN", "iArab4Lg78": "2oUQABvl75YamDZ9DSwG9jaaJrG8xKOzR2AvP1ydQCU3sxg6ED", "Vo5N6vVHUy": "HfiM67Z7gHjBQoTcPEV9uF9B4NeDVccS9NMqTyPhZiTEQF2jNj", "fxJlQtSW1c": "7luOLlZT6lexNugGGgnARPs2GNJ7B0K46hSNsToOZf618hPzxY", "cRrzWABORb": "k87I2JJZ5vjnXQ1adf4gSOrfZX18xSZjw0N2uscJC9N1npE1WV", "xgfjiFLrvd": "c4NSxU5YAsBRL8LBqVJgw1AMhxLmbW02zkdca7S7UgSZTRM3hi", "y8oa5IyoTU": "IIzMRGEn1pO2UiFBgRMjAHl6PTm88ahFfsbGrLSAvcwinUkmeh", "oRXw8S5bao": "tVrrP7BNKTsHHpaLiabOWQr0JddjKKYaRU6kDoXOHnbrBd80c1", "CHbuvg3aqz": "D4UL5D0YnJggrZcD2TaVPPb969j3Wd40TNkWEd23gnM2CTlpaF", "RIV5oI82jm": "N35qtwFvJxgNVIs7HdWR7YrBZ7YyzBmCEpZ4rrh3H4x0OhhoXh", "7TA20gF1ez": "dWifFXTs25OFSeG6NJmJMNuNHCH3LXuvtwuR5LtzcDfNFYfCYu", "kxxYRGM1Xg": "i0CdJTRMloeIRtvUi0hBKjdGb9SWWqYLD1OVqstqlEFgGISlft", "uxUUBex4DF": "LpdzpbosDiwVpbMFN6IzgakHm4gLmBT4aV2gJCpCLnRacrcaEC", "kPwo9qANYN": "kUcnVZMCpNVeX9gw5xzxHV3dZJHmXC0Ey1HEJskVQuebdUQdwG", "DEcWZLYuAG": "1gDAGquRYbDhVAx7OT2HB1w4a5A4DQSUItpuq1Yj3L3OLHpc7i", "iiHt29jd0T": "G1PbklNFZ5GEr0fTdYkJGZSmIqvLYUj63AXc8sBfdcZR3jvArk", "0C2vAiB4dx": "gvMM9vGkXBjIUIZM3ouYjw1X0Aljg6UWimdyfZQTsYG7QZLj4m", "fT4Lgb1Xmr": "a2b6vPfsRgSEMKBXgboYB46AaX1XPHgDRoPwTwpKLivcwbpLnS", "KMCIMuYsEQ": "eU1Yb6BtIYWHatQKaTiOj5yNeAMBr6US4ccMXMsPKW2tjcCcZW", "QedJglhz8b": "2yf4eIVPHDgjctO5XOOiDAoqW9WpNdFZkEtjcTZAQ07AWmGIg1", "bCNweGvPoo": "sQWNgrhtPDoYKhVBh4reGQcZpzZXqHnmknyESTyDwneWVX6767", "so39FU6LWS": "DudrfxdnDuw16LVPJ7yelFawCTYN5fdXahqqk52GT38TAFR3pm", "zzHcPRIj8T": "bQGuFDA0KdDXgyBRzEAo5EGwgNQTpmMZbUzpJ4BV7uZ4xBuG83", "Z4nSSS9Cqn": "5QvWz4KkfSt0xuK56Q6OvPuTEeinQOIFQmdBacplMSQP5PG1M0", "0X0ZPbGzm0": "Y5TSEVG3KnasYm648TvWloO49leQnso91eu7kssNVWu7k6XzB8", "O5fcFpnsbZ": "BmUBm0dAc5Nqf759AAdqC1Ocvlg6thi8fmhDlFFuMquxVJNYqV", "Ft6Iaimvg2": "54Oy83BuKHAP1mG9EdX6d1sxwwOK8OwFgzBHLtMrHse0iPWO84", "xVBwrOv6i5": "UiwMFahNBMXBFp5O8YSFrCb9P7YrZMoqXYZuL7tvLj1ycHlIgz", "TsO18xkMIA": "uixtkkRDnFUGwwx4TgAnezE42Nxdssj7yiYPek2MaaTEBNj4Wb", "icv4UBHZoq": "CfHO2Plakcn9cqLv31IapysNfAHpH5Fiyf2tFAmW1o8iA3larJ", "F1bQa6V2d3": "DX1H8odt7qEes42Msm4OHKtEXY5tfhWItBDhDXn1fkE7JNHxRD", "staoey9d9x": "lYyRVda3YctSm9krmFrQQyxb2Lifl38fmkvlYeRe6Y1PXTuOKN", "cppUYIzftV": "HFeLJZPvfKZG34MitMrQ5i3dyLfxnnVzFanUXmiQWGepBLgk23", "jewxF967yR": "d6tNAl1a01q3qIWSprm86OJ2QpEt5YALktp2njVfJ99O2tbwaB", "bdyUTCKkHS": "eD4F3Nuv6ug73xIimV6FmDswOD6Ixb52wGVVAuNtetIFeeVrjA", "AuLnfizK35": "Kc04yf5xSyBGe8hVxYtMDXg1sx706rQmgzGvq5E1tjRecola3i", "x3ie6x8Atd": "K927NnVVxuYEqupyd176f0aAfJok8ljyiP21XIIgegqUJs58bC", "Usymd0frp9": "YDcHIj2EjZMsBFpZjChFZlgrrfINSdA4AS8toYKepzqqshEPMU", "y8DT0hrpuW": "p9ujZMaXd5opfawgzjXQb4ORFW7Lb1sdFMuC6wgqNagiK1Lhm2", "Fvagg8ik3V": "nP1ynGQ7HWkmZgaj5Ql4l2yprVvAHef5QJ80jlI4FsS978POxg", "qiJtYOqj23": "mtnzo7XQAI4zwsLAKvsGkMAYbPqXghCzKjJBpQCQ9nrK6X53xp", "x5UffXfCe7": "wypA8Hn14W0KaT5dIZCropxAppGOUgSVOKCZdGgsWL7fkbJd9f", "W7BJpiP7HY": "Q9l2nNc4JZU9fntKJP5lI3eUP07TYVOgBg3TewGuPS5qUinhWl", "AkZjN10mag": "QPZlvz9vUcPtQx5ubxNfHXpkuaLf4Fmis8qSp3O6lh1klyKxZw", "1iV2UvxD9z": "nVInbRkU8Fq2j3834N9B0XYGVL3La6HAkK8mP1Bbz3mcnt1J5L", "huZ38Zsn4U": "SFurPG7YQcb1RK4WcJIW1zYrSlA9T4aFI5d0hjCCyqp9EM5LAG", "Nm6BLHIFew": "TDdsswXTxeYUYyAcmU5cS6FchM4tsyc123Kqrv6TxFBPHWGqe2", "cb2kCYouwl": "0jt32Umy30QGQM6a1nKz3odVF0QhPWXPzXhfPYquifUAgc8Wc9", "PhxC5kH9tP": "ZsytZoQu0VcdafgS4zzJrRSqbAlIaUikFGknkjmt30MQ4lVE4Z", "syjPONcxT4": "7AFjSgkk45yU7Dn2wbsnZzrZ32PknwtKBMsP2HbCaFltlbJg27", "LTvs1fKYo1": "wVnWjqPPeIOGaexHhO4zjJW889H1OLdKH5VqUUj0J2DG7P2mPK", "qsQcT7XJm7": "vsgXbGVMRM0TzwfyruLfBCd3eRVLxSq4nFksRNzU8GI8XJXXjJ", "exWjd73uV8": "8u2bVgQ7ZUl0YJd51Xf9cumclDFcnC0PshgN7j8LHVmszaGVtf", "TgEgfJQ3t9": "uCesqV08BHoD2wOH1zFECd00WKRY1AUHBvVk2BpqjTkNVtdSa3", "ylnFPqCUML": "cNTsZkhwjhRPtFQBQSEpSDZ5UHGpsFr3lACpi98ihz9ArJZ64G", "bob79EvfT8": "hCKtogcRXflFAF6Uf3gGE6YhR1zFSj80F9tnyqCpW8SJILSzlD", "ZfNVTSaQMz": "48wcznrBo4C5dCkjIjvyrNC5OCRXGkwaRwBcUoaWTeZ9IPYYtX", "bIvmYp51KG": "aADPUGqx5CoupULfS8at9bLJgoXEsRiqMtKg29vLu4dFJqwJGP", "gEPndSjKYt": "UNN9956fWj2lSLRul79GAX1N4X8J0RP6xFNdyKyqdy5CdAvJM6", "MjFd9EsmPK": "7Fd1WOGOJewSY0A3PDGxcG9koXr7V1Dp01E3s55PNYQIiOyE5Q", "VVkQJsFyO3": "I7yNzTovcOMdXxnkIuDl8dePWGdho0K2WudiMvscLUwlVwx3yi", "uyblqn65Mr": "fnlcQTLXKLQskwz2WINVFCg6VrrdnR01RBO4tquHdmo7EsP54C", "AxzC047Q8w": "yUuaeiPedFeck44FF6ShcOUmi9CB2iMZe4zfuJs433b6fsWzGf", "I4hoVOwvMt": "6DnjBE5Gssj86oLrYEZkb3plaUcWcfNzt2H5rXh6PrOdN8fSSV", "ilcJ64B9vK": "VRZs1BsF9yLCfcM2eZ39f8t6JPyxarpuCTWjG3zubPaeS5fxs0", "lPhPxoldC9": "UDYFaRv4jmdrKJTAEs1qT3De1BXqQdDk5TC6FoNMg3iLkmyfyi", "SIFGtAONGg": "iEyX74arnmpXodDMpTZ7jhG5RGVBaDtR7nfZvCkx0yQMQXrPd1", "jTbNFqF6g4": "47znDNxMyLaneYVi8xbqrljIxQR6uXcVI4CGye4GN1iNL53jII", "EvcC6gtpUL": "YQUW8maJxkcaxBAuKszlTQSokzkxqu7WdpazvuLHAD7qQi36Cw", "T5iZLln6vD": "90YtAuuVEf2paCerJ74Q4WyjHjHTQZ9lXbYKMH3VxzD1iJw1D1", "IvH3rlsAAE": "ltdI5OrdQCkSj0CAcVpBCtAqKdfX9v96ZlIVdjPXjIQwOxOV5t", "fNoty9Lb8j": "48Vh6tWihjNvdF7XyS4N4biO2DyfGgHNZmuPkAVBqgsJR9KoKa", "Js7BTqn1lB": "mYQ8bQJos2fE6oF8OOkFVAgL517Gr638sTTv2a9GM8zHwyVVbg", "67mJOzNSkc": "FjFhaprasU36ZEiFCKXCZFTnPm4VASymoZK7NA3Nw7GEykA3ko", "AawnS3rdIx": "RzQCJCnCMDm6vo3iRqDS3Ona1lgoAtTpQSuLyuolByOhkhVeou", "2TYKiHQnvd": "gDmJI30y6aVIUEHo2Y8iqK9XlSBldK4sjaQ97vihW0TZ1KugiO", "2iXiofde5y": "Ks46Wcm1zMGvHGygn1a32ZBLgBJusDgHuSvFVR6mVWu7iFlAWc", "W9agxxMUUA": "YpYud2ZjVNYMKVSgOzQrjuAhqXcdy0rVe0y5mV0F2pVmIl5MO5", "eb2lqVapn7": "i0EjYqvevIvyViVRcwRJRlf8FuiOpidAjaVsWAV3uMROh21zLc", "TuZrUR1eUh": "oC2gZ1eAU5KD9bNxQ9zYQlXmxgwDThVGfD7FuCvJgBBPozcavQ", "IEwUKKbSVr": "FQXy8Lecf9SGLypSkICLUpIpB3WFDfO8HQ1n3MS8kbV2zoQAMD", "R9qRZpqyTs": "xJpr6zGagLWjHgLsMkRWgkBPY6bJmawz1jwqVz0AUsAjK3e1Ei", "6stOOpD4kt": "XQ97JBhzmQrazqtzD8SVkPFB7hfaDhXOZf0takQiimOcKlD1KZ", "Ne1xibK5hK": "lkbSsJgfV7TnWhhBBazZh9kzImHJfBQrkNhh6Tv4DlcvTQ2me3", "73cR8C7Dfu": "fTbnz69ab2ubPEC7kuixliKB5Eu6z7SDLFQLujBD5rKZrZZgZu", "W6X1yhXlyY": "ONeRnkjJ5sUfG41D9SSbr58owWK7v1rOyufiCtpUsqBxavnLez", "7zDOuRDbNl": "LUxW8o236F9S3RpuyjOyzLxPSTuCO2KDPJZKwg8u7ENG8LHnKM", "M6Iu6yvMS3": "XkjlFq0BMHIsVaZwVJ7K2F8F161IGiLBuPg3BpWZbwpaDPAJUi", "s2EvNz8vcL": "tm0k1Ls2XbMEInQs9fzpHxffpjDPVytJ1ZYvn5JVK4fkBlAj9p", "MSv7uYYn28": "hbRy3PH1bakyr5gxU7pLYT0FOB0DfK820YSid8TjrtKXky8CNh", "w9JlSralSu": "9V1aIXC1DdShhyKbwTbgpAuLPrHHVRQUmOkiWiYHqQVOrWHNuR", "CU7SOPVPv7": "svtcHNfAQyEaovbQviijBNE7ILD2Ig16Ns9m5MlaWpaGIE8F01", "xsImbEPBw9": "EUxzOU8XH6YBcc0bEuU8rwr6xrCjcANtNLzktot31enw8i4vRR", "fbRN63H18h": "6tFP0gNdusCzgF3CU9JzzHXHUzPaKrdW7dA5IiO910LZdzogE0", "LDuz0NeIeP": "LcgKZDL8Xqms3MyJI4Luyccke2qr2wx4hsFcpDEeQJ6dJm8HXQ", "18vQ08Dyao": "sgXubvd5n9TL5R8yDalQFJjP9iplGUTZhP2tc26sIHtOfWWPwj", "FgPaWt36IH": "DIGT26YORPSkBwZZFCi7qPOfBHoEQhwTevz6sbvsgv9BuT8xaM", "Tpd8yavBaR": "Qj1FLpQuqTCaOKSytlSceRO9G1JZseSTbzfAZc641kCBLrL2cc", "HEKsOQGGhA": "FOaJyqdWYG87Os93uiVMVNRHAej9NESyQZxGNnvwsUvjozJpVx", "GWsF1Ein4N": "07ohK6w82Wre6tSKdcPw7zbEB8W4KrZMh31OOG9JammhzF8R8I", "44zU1FkBkF": "5jukhYs2qFZe72LlM5f86pYj8xHmmGWCMZFK1zSnFLCml2eZWN", "wqF3ezxwyC": "hBcYZJf9fm7aLL5OPjyUmRwJsRJ5sNZbdgEHLQA6nh3NJVtSDX", "iLBYZUm5fY": "5NBfdWn22uLYzKJkxoSvWHgay6hHaU36z9DrBMYsG8z7RnSQCc", "xAufy8hCv3": "EvCq1rsZkTYSkLjliCKiJoKLWm7hGYI0iaBcwAZ5EqxSq7advz", "PKGYrmKiiz": "5YQYbnFgnUbYF382l57fVUGRlu47iMtcH35ERjmpCevNvSK2iX", "NZLkaVz14k": "jUZvbzGZZKBMssO2DH6TZ3mVJtYbFO7NZ8slfhbLCZW6L54lln", "p2CwoeWvX5": "6FiFUaNe5PSphsFyTutzlAeczHaMK9yEMU4NteuCDh5Ri2apPU", "GZScYm4GOh": "P8Xg25B278oLfkq52Vw3JYEKaawXYoj1BWaUo26UsXiCu8viNP", "fwVQTwTfZD": "hdtLmUAyS4fnFSMWO1MUnSKDy0l65Fo2omdVbK6tajo1Fx4mkx", "SNzuXS5FDO": "7RcvrJmcQxLQxG48F6M2HqJfCrsTpNaHcdADYSY9z9trCgOYpK", "CVC0rRYAuz": "FUoF9PFjn9BVgSB5xgZdII33s039yJVIqKXaeC3R4DJd3Z5LTy", "dryEXAG1DX": "Ow7x3WbEJRrCLLzIpkdf5c7tK0CdILjgNFsnxUEiRgqLglCWN7", "nCqWeyo1S1": "9HMGvisWCJZgKNBXoUa43qy46zSJ5Ms6lzH81kc1QBQ3mkJH61", "DOqMcE77sM": "xO8OEK2NvmA9tapjrPBjFMVqsxydnjxekrRDTInMnXI1QLMErw", "rpS8Evobly": "TjPQFkIUaCT0TCSjSg9VMKdUapRma9MX3U7F97nAzWDLkrGcvx", "q5wiJACGc4": "i5of3ESapZV4AJc4rf8ygh46TtWFTjMlR9J1RHaOi9ZyZvK4VS", "E8dN1wNKVT": "5UfTIYp906ykaCVWgNJGmw97e7fiVaSYHCJWFEYa9dKkUp4rPv", "givaCDYxha": "cDF90M3JQYOloy8SojpJTG5ZpxUxAqjv2wWusmVwXBVwYkePJl", "7Ko5gSMyCE": "oKQdaVf9zIN7GLdyseh7LkLA0oQFuaNTBc0qEhElJjbmfFkU7q", "LNpW42PUXz": "nZdb4vXbHOYjGoslVCuMt5XQfxi8ZAyY8KK2vOXwcm1kOxvjwl", "oFrroZqTtq": "07KJmSWKQQpLVnWyWhhwjVxEqZzqXgz8o4e54fqCA7EP1EPzch", "9egbxRDsIV": "AJqn5iuB5kKPDMHiPVTF9kLoab6fHYJHMlg2zy4NVqPpZimLmf", "KIedkCPFCQ": "Hv23GLjZcYs1dFraukCNAeSLDr3mKxEjreLEYPBrEZAJ1v84Ds", "xIQsdqjQsa": "UAlbFglZJl7fLW0wIduBuZytgIGP3gMYyFRcUICzEMIYrRzgOT", "jrEysnqTBT": "w2Xp3zTxqpmYqqmgW7Xp2Ms2k3D3ObTxkkZ1HAABhbxTJwgRgy", "S3iUDF7Etr": "8YGXB95jdlf0V2BcqIL82omO6SrSM4Q7iycLWdtKiSlY8lM6sU", "uofOumdHwj": "nikc3yty6xZj8f65PiDXm3YLXTCjpQM26TRlT28PIno9H9FUi0", "tl68D7dGRx": "Q6OPwVxQA9K9SFA6wmD4sMwn5auvrO2jlwRZ9tF86QvhSoohYM", "glLAhPzR5R": "C8e0u9uskIIoq2bNu4v7ZaNqvINCcaGhE3rdzaNwioRAksuLt2", "Vhz06bBi6Y": "QtQ3HSBk9h7Nf3HzOIJ2yVfHgjjAOzBqftgEhXJCw5rOwEb55q", "JdshLjGlHb": "g9fkG0YLwclCISjZRd5fa3KMBmwTM2tf56ldvzlRGqfjwRtXOp", "aNDdoTNovs": "TR5NaOtbyJOhm4AcDJGdC385flXW52OBdCVha3tb9fCgcv7Sl6", "uoY89ZXRPm": "dm1wksAnPeCpBQXIgWlEDsr3c2bQR26xuNt62avwo1PsDTakAN", "UumQYaGO7c": "oTXXZYNsO9emgBt1RJW6bmtfbBLomzD11YTJGZGsmtnNZlMDw8", "C39hd3QmTq": "bayOPAZEBRLHei1NBYCW4mdkSdNlWLAt59tKeYDUpRAOVIFkiA", "YRlCiAWD2T": "ZGHmYsZvKzCMbjdVme5jJ8W8LYRXwhiNAqt4x2AIOBNoV0J6LX", "Ygxo5TtHPI": "GLDGJRasNF7h2Fg0sPe3mC4bkjMwoXhmAi9yh6FzUdaanEPTvh", "kzeRpWLp9d": "h9hbUF9m7NRsg3ZT2KHtPa5PSlhdgGdBjlycXrO7vuZ2VAZLs4", "xtv2XxPC09": "PcD3zK5e8dqGAoEogsQ2uPKNt26hsWKbzaNNoLx9aweKImTp0E", "u48N8QizAu": "lbuHepnCLTSfy7qxNdbtPKjagPqMcZSg6Av0JEwVDapZbiwYM6", "SjCkHCdS9p": "ErdmDGOduomFs3QH3DhBTu1xopxFiukMZlf4YgvgeFukzKh8CE", "RlyvTVrP8Y": "pO45KJP0xRUk5fn7y5uT3xNcMK3U6935GZyQErB6rGImMzxL0Q", "8cU5uDbMh2": "l9DUnQCALxsfNmnv5o06EXIWs6pm2pcCpogie1yri3G6nAoX8U", "0pkctyX8EB": "jqlJw1MUrBHZG7XIRUAbIjSKGh0ZWIX6MTrysrLhSrqRlPpPT0", "sresPUCn5E": "MH2CWYFwBgeugz3khiQBbLn5YCLWSBvQu7Ny0eBIh8phmnEeRM", "YN4gKtrFWO": "4sMKljOHnRECLz23VqvXIYltuWpI5Kxiyl1MyOmUgSHEftcmJa", "ElUXZRPQ9g": "aiI8HSpF1laF0R2MaxTZQRcrT2anKnsKEncFaOQSTe9I25gdO1", "mWnQzbAPoX": "zIXATMvxgRvUSp1U9tn1nBbC4lSV0395iwK0s4mDRGn8aL3zqT", "NEkUFZYJ0c": "ZDBNNNgLMdTXaBaQ7yu2d8mSxYxVDJKq8nLeiA0nLZvl5W3KlY", "sm3MvQzF9B": "k98MwscSxGZmPODlpk3GpbhZs1IghqHetPUPsD48I5MUI9Lygx", "eIpKH5MqIG": "YOY3T85JatBkUwPtLq8Yf3RXZ5cG8BPh2pFBUCgvS4qnB2uVx3", "apdvBlat7C": "chvYYAGrV9pFIJxuo0PNMMUzL1y6SSbBRmDW23ANEfP7dfKImZ", "pHt81wDs1p": "gTkl7ZLTCOIvBKEVw6AzQT5c9pUDN0VTjKPPudh88BMk2vYhlT", "sqRhZ6ZJWH": "5wAA267MHjQ81HFTv7xJ96tHGJ3ZOvUthivimWZPi9Rb7dyzcb", "T7y1gtrkyK": "kI54EWwl5ATnsQrdGoWXC20ww2bNNkn9qCZDhvoq90ynI5wIvF", "00WNpaVHpl": "7XyVCp9C45qpuy2feBpGEEdhckAJXyAa8BEkrgiJBIcyCubDCJ", "ydluGyhjRK": "0Ah98RqGGS6lLxph8TRpbup5mMmOeGe83VheUVB8HQ7i2reFsh", "ulZaRbRG4X": "nR5xW0zwj0mKmGkDZjYaFcLaWHwlfv77qxkVBpCr2YpbyagMvS", "Y1Y6Cp7HHf": "zpybvXe5LhyUxouIrw0i6ojSCQZTcioIXWKEvonTkuM0gOFzRi", "G803qErBWU": "x7esoygCTVR5VxTBcT3FV7PNEPwyhB936O5NDrpmy1AinCuQlI", "mHP5LkcKkV": "hVqXY0j3CCIjksGjjffAv6hhN1mZxVbFZ66nDdxTpQ9T62pASc", "wVg7uKuA5N": "EdnZ4kg5MJQT9RKmez9wtN5bORTtHWAJaCGUnekjafHyX3i9zN", "qrz2yuB3wO": "AVbUtRo4sTBKS83EPHod1gxbnPl4jeZxKJbkVIwu8FfK18VI2h", "8WcEMu8mb5": "PfCLPlZ4z6E9hoQnLGZjLoJ7idrMF8fT7H3jSI90IkZ2O0gae0", "jiET03XgFz": "qKD565TlknwPWqSgMLzThfiEed1Sk3nrBK70yhHvafY1cbtzEA", "p7qIf9WZlL": "SGDqIGaFfYNZEJMKpxiUlIzU5a3pQbpr8kKWFEijYJzmJFYNj5", "AYNLqiyOz6": "5h9y7CE2NU6l4jD9tBj4BQsHMf5hGfIE1wDS5OCcd9iwCzQUST", "8pciHfG6wW": "UYp4rzGqZKuZSl4rJ6zAZQpLFY2X5y7xYBXU8gMjSgHYA3sJ2y", "ohgfDzYYYQ": "JKV7PPzqt6Czpzpp6tbUPavBSAiXiyEmOAPNyRkfotYnIodjCl", "Pf5A1739ZG": "Ra8d1bsBka2ead6jXZu5hX1urW9ZzmLVQ7ALixIQ1GlzgkdDfj", "MJvuc9lsHS": "J10CDpNijNEneIP5ApLFBnvhulyZkubvzH2VPmkk5oS99tCWwj", "uxbBfDMx0s": "qiJ0RzxdDtrFb5lZkc6GG4xtxRw80D5pkDd5YRhMo82iiOJ3Cj", "4DgvFw9VGr": "CeexEZus09Bq2u4DCvINin69LZuHYVnbiWpEPdM7awrkOZ4Lw0", "hkW7c0kUhX": "NOFKoqBF8KOMv5pcrKq7S4CK5860IJeH3GPhbKu6MOyDnLWI9I", "nckzyx8UQS": "PN6cXDd6I020icdTHxwsrJ25yhTWmprEVXCFzvMDPb6c4I9qTh", "lIaAfvBzAP": "oUqHnuxrdIYnuqBrPmrcajDRASwk95qDwviEOZKMYRzKIsMx1d", "UXFcDrthv5": "1bkbs0sC5Lh5aJtLoc12Hes3b6vqI9mwuArQHA0wMYlIK94QM9", "uhsLbTKcd8": "guesuKNF3ZcYpmeZXwzFiW7STVhRoAFHyZO5nucBN62ids31pg", "LztJ4bh2hW": "3xrp53VOFQSrKocq35acDq4QwwfMJM0RPv3pWEWT3osiPHxxvI", "WZ1YWCJg8R": "dI4ZY9tc8tH6AuPvK3Q3g9IMJBMk0CM3gOM7cnDYI6h6XeTcDD", "8fDgVXRJ5x": "9w3thsvMmcJlKKdiayhV4XDjSmZ9ysDWKumzwxnDu1RxvhMyZj", "etRJncef6s": "02ggo1DVXldNElAUqYX0XDhoL3OGkyXe8h1UCOXYRoOYXctvqy", "bjfWOx0vxA": "LR58KmFfcLUGYTqmtwVRpBEzFqUOrwN7nWngKilv5XiBAZyHLC", "KT7O4dqUhK": "Jph3WpEDj8nJxVqCqjtYeB4JPqzs9JI0pKQTv8SvfSMru1Nt41", "klSDMg7gLc": "HGdAu85DKAguhORw03bYTC631M2SV2Gs0ZXjlBjJ3RlIzwKbaL", "ZpQDOvvU3O": "9QtkNpd6vtNWpQpsRcH3PdhGmscodkqgGnpCZzBn6b5npm6IJy", "3qgaOknkoR": "wT5VcKBPmZ54xqV5L91BU0oSNDenhFR9wGCdA9myFKzZCHBlBs", "VAIKRDuw5o": "ITbPt0jVpFBzfSgnsAsXBc6XNRFTb9DJtuJ5A656PAZFQX9mI2", "9b5rIu4Pua": "a0M48BTRFle51qFtPVVvcGIRhriPJa0tkatdeONuFcMN7tfUkJ", "OkLu71Awht": "qYLEBWlva5NKlk3gqbSCbCCK5bVas8KvWQRy0fHHpxKblBTJ6G", "xChfD07fBf": "6YryHwSFECALs2EFGG9bsPrDXDeb5XnesqdkV0acUlBgVDXrjy", "ZyzQVQgsqN": "NmBte0FIQwSRmAk78XqrpjpUyjYau1YEf6NAYPDrNPEX4wrg05", "CUkl5SZtgR": "dW7eVpf9sXje7xOzrv6EWTJmgTsODwvG7fzIwGLrTvzXOOksDn", "LgAMcIjV2F": "0yYaiKNmT3i6wd3PnEVnozP6E396IjqTSWsoKOwTT3WkjFds1p", "L975G32v2b": "Dg8XBc5GdKyIthO8W5PiQsP2GXlI8DAWoDRN1P0guiQGZvXNgR", "v1VqCwSHJA": "WQYKBlt7tNgjifTyr4L1TazdjlFiZpxETP2GVIfd4TTxhaoZ87", "NQqFLNjHji": "uPftxhn0xl30LbiYPA395FY2lg1lD7DdhtEdXzJppqsCbDHb0P", "QDipv7HHe2": "kXvzSIc9OrJ8m89v1pTCV30xm3aq5sX8AdYw83zLEI6a5RXugM", "zWyAajHd3x": "0QjYk6KOqI07TGkxDknQ5gl3bnka0Ab4LPHm9r8lUbxRo43Q35", "05H7HxT5I1": "FGrNuKgdFxfpCoMkwjAC92hWIzyXzPb0Jbol9AsjxTZQrDMQlc", "CJibstraTI": "VozkfUNvprqX1nMr7Nclc8XO0Sth2eu10eeeEwWnzNibAHXOBR", "bkHXawse6L": "LR14tRUlWtA7PCQgPufY0yMhKgjcrZWKvxYRtnikgNEaWhPBP9", "xIKubomws0": "VVJEtcxetlQGupIfezkaZT2leJLcsLF947Q1dmzBpJGyJZ0bka", "vNJ7RcVlxx": "1338P1OgEm0hmRrEQARdmBpcyk5xAODUQDC5or1misHareU2cM", "hdtIIYBTZ6": "fnt6NTDeaqO24xX58uQUHC91oVMhvl9YnmKNUmHQsTFsZCZMsH", "Jr0u3v5hbo": "Qg2JlwntBhFNplmbJW3PawrbTA2wLMRDzUNSDPH4Ql6DkEjisD", "CdU7slKDdl": "8dxFo56aLaOmWBG7kQP8YVI0mo5ukb7GMLiMYoN3r1u0DDpkqG", "HeMZFnFAlH": "Viu1kZ4XDXASXysbHmNUcliohoCY5zWfoKH9PWISimdbD8ODGd", "6cePHIiqkO": "22jyg7V3hQrc11EiBAA1oBoEtBN5nyr7RAQIc2vHgwmwYksYnd", "dOx2AC63Yz": "P0cReAY2CYC8ymGcawMdrlAmFMfN1787dB17UXlGWWwszEFJu6", "VhoNwEazx0": "vEAJv3ydoLOiKpVa2hwWF772iTdHjC1mmPrAXvymeVNicEn4M3", "qB1hAKG0Rw": "YKGBN7pe9HvPIIiT47xHRPkUWnMzy8pwFJrYicthKqH2zzapzb", "DeA1fkAl1V": "aVI1EknlSVYka4XKCvLbZOVBXczkOmoZREIsdwuZkWbum4sFI1", "lRrDNlA6Wf": "4OeCZxcFszIciMzFO86dPh9bRjW1jkzrPyxeOuc42da4spdVsx", "ZHXTowqxnf": "PKKsB9hadrXfdT0b6fqEswtUUn8M6l1nOhlvlFmNEZCOzJtfUf", "qNa1DK0YuL": "aDtg2b8XfyRYdQZPI64EPs9xVEfA8NH72UMZPLvzHTs7H2xaQn", "0fkF3C5KbT": "tFuQhqxnqsIDlKojIu6dtl7vgecoLrE5B5De4CUnPAg4gRwZbZ", "mto1I2rK9V": "pfrvNtIvQPCAwLfEUNjKzGLTS2gk2CvbCpd2lBH1GA55cPxVXH", "2d93Unexqc": "jWFNnzdHNXlog586xZwmmi7HiayRbUwm1FJ4Ufn31xCRHSSTUA", "3xmM0YEDgO": "O26InHC5gcd10R8BAF1htOVQqhLXfBuMtTeJ6dWj5zVbrt13im", "zRNcSytpDo": "FZQaND6O5pFwNkzWqTAagFitpiyzAY5HjTXEcWzC7kscjBE8X5", "GlHSCXmEgm": "QsIP3yR8IbbZO64U6no3pnT1I3s3TjnnSZtcKwDYKaUKtFtCmk", "lJrv4EQYuO": "LQlWcXICZQVCGrlibAT4wF0tzPTDXlzlKQgkHMMzZvjvfvMqqc", "KyS7Kou4gj": "6siJVPStARPlgyyCmabfl9ejlt3pJexFXaC3uRvJiJH3hqwYER", "v8R5YFgUAh": "yGAEGtMijvYew2opx0VF7ZnLgavp50qHZvWzFQjP84LI9G4bld", "2nMA5STe2R": "G1bzRXL2dKQ7q3obrLHTBqmAy2AXDFXWq8WmCyQ7ccpDdngnP7", "EaMV0ucNHJ": "Wi2aPG2jf8a0qeMel3jB9ZXZTRphVRo9fPruKi1Qoep7YKQQ90", "wqi6br1NDL": "vo1XuTuB7khvOL3iA7NogWFOqmS03lOlR4JXgp98uPd1REkIxH", "sAoDaSLl9E": "G5akAP6drW39L0hDbvSSwTGyWfmMILd8RumavzLA7FsXeIzjpw", "63XfKifREE": "an0Y5iDGUU8fpjCO7WmKCgHwLc4CS7vdpAEp7s9erID8SLiha5", "M6RFdZFniT": "AsBtKL1XPy06DcnychGQxbcELX82gI2mqhoIByf9W66aFM27OS", "nyzNLiNqNZ": "y8Fg6Yey58FaUVCIRcPLLKOM3y93CJdjUo1QoketTWNYmrUtB5", "fuSXgTw3sn": "lzLIuG10N5ffRD9RVudXWdmzHu1AVUo2ILpEGRmteuZM2AiOuv", "Ib7v0WyKX2": "JXUyFrRngM6jVVT4nv0uCwhmU8Fn6YQygapIwsAgo7DA3PeLtV", "2FpL2wAOMc": "dok8c5flvMyptv0pImRqp5ZsDHXNfWiKZyj6ENbnhR8HU2Ihnz", "MOoP4gGNIg": "KjYQcw4AU2sF8ez6tpltl83gv4uS5KS1ZpcYnpYtZCTbVS6WYo", "DZOVvlvGbI": "VLiwXOSoS8EatqquorVccCU7Bnd33mIws3W7YdCTLtSOHxOqBf", "znHpx0aSwn": "qnapkgoaq2T8Ze3trdEesRgKfqcN0kplSHJZqgbH7WDeQMXRNV", "Xp444K1bk2": "fw5H59Uq2ZtpkZUbr9n7tcCty3czXeZPbUlKCCI0JkghEx9fk5", "eUxWdzFBkk": "BYCBpzpSVIhio88vZdneG5hXySLX7Ey8hTOZ6cWSSOj6clBAOH", "tZqukSiNIb": "QYPUt5xxtM54T0QuIiIQMAlDduFgPvQNge5K0UkeowIXekgaFu", "xiNVAjV3eR": "yk1L1HAY9EhoaRUR085p0eZD5r8Jy6OV5RUUfeQ67Xw1yBxkyT", "yngbJwbvns": "0ME08ztjPXri39VBTLAMDhpdrW42QcR8wTuTGepywvBoL9R1Or", "LWImWU6r2p": "q71LcQYq6LzeeQtq5sehOXJoXCpCsAqU8Xh2RdX7PrYZvt93kE", "FlGrP2cxor": "Fu5d2QLg1r7RqCAzBMh4htp66K68iAP2HmE52giYCHXZ5UHzJm", "wLQeb413Y0": "dQhcW5X4Y51sWqqdAtRvqQ3auuABedGQMoKoK5Sj0dxI8xDU0W", "aqlM74aakg": "i1zfVjds1PAbs2c4ivK0gtPivKo3T2ZXqfEoUo9x8gW2tR7W2i", "wdGJQr5Wxp": "dAKFlsdbMBkvxG5MvH57lytiJG7sSGtQqReBA8hL696tjN7VQO", "vmAyFeS6nu": "qluWFjrBsM0mLRNo9kqdmNUyevcprsxyI8hZ0LacHYitgvwrXs", "cHCMk7Ltlz": "ZS4KUQ2AfcWfN5k8FTffA5rkzGueAGMy4BRZ7uSSiXESv1Q1rr", "BR2s6R28lH": "U5J02dlJ1Jp1Col5zF8pxW31CTPO9Jl81OJO8Z5s8YL6Z6VaI5", "IL9ag5mUUJ": "SeOjv1nT6qaOyRBTXg3qxNSDGDdpOGICbqgeEJp5vXJHQz3oPA", "4FdaENh3wP": "vYRULWgPt0FFgKfOdMNtk2seQMAJxBPbKimbF4At7RZtX9h0e1", "8RlCJJgjGu": "0JIDx9tXJqQbfapuIv2SgT3aCtgLdPW1uYGP6L89Ijb2CBe0er", "RNRRMYzmlL": "rTUYAlgC9SsX63TDSwQEniCvv0kHSO4qSEAO1W3ByETGSaWtEM", "wT0U14JHBa": "as0QL6kbTyZ1dUdsGnELfieD0dZpmKacL0g1cDpOoJpQAte21y", "fBYDFD3Bo2": "7HawNzUBgcetZ8UhxvTvPEfFjndC1gMBDnokTGqRTZTBiwQJRo", "DCYNxGwZrV": "8xDf1HOTxZeSL7x0lnfVN96g2vvA20yZmEfoDOHS2WNGoPnddp", "Q0TNatr6bU": "KcZoyty74Sd5d4iE5gkl0ssYELoWEgiiY5KqCT9qBThqOZ7C8b", "2BD3zVfk7r": "kCmAZY2jWGthtF1tN9KbOWVbrcnIaD8c0tLZ4OiDPpEWpsMQd2", "06yudlKWGp": "ZvePpKf0XWB2qHs05XmxmeH5DgZclOsi4NpLj2TN67sCN0ygys", "cjUcZZhlCc": "ma38U0w05aTmwkruE0sARAaa1gEcVPYI09Nfz3cT5yMHj5qmZd", "C78DenlpAM": "k8IY7PG89Rva8yxO8ewRHbp830OzeHInTC6jdelynEOl4xWa5O", "1hsl6WprJA": "yOCiNZm6RyR1I81NDtX2P5RrEYEggOuiwKypovk4xohzlidnhQ", "HCqK64vfHu": "zvF9YUGTENjSR8a4reT51BPr9DkFaOyhisq6I2P1FaDIwUYtQy", "M7k2PrerYM": "9IKJkSKVrifwiKzZdLTNCLOrTXTR8GXu5DvmP6ZCiFchftbB39", "f9heKCud7b": "JIwmLASA2NO6m4rmwVVlwzS7j8HM1Tqbqvomxqm7FEsQPvRknX", "onKBg4v3yV": "cBeK1JTqMsVT2tE1tkS8mxlFBlY70qUNQ34BWiDv7adHFI7VzB", "wtOFx5aDpe": "zsr7t3GqEcSNjtDgUOnlDY86iOOFrhubcT9IFP2FTRYV7x52ko", "8ncq9SpcCL": "tznbCHbHiPXK1d9UMAFcXQxkYZxCxAm58mFTV0P398wZOOyf44", "QDFrU6AI1X": "lKmVdDuEYM0PCxJXnDEVvgn0vL0rJDHZdSXMHGsWIzUDfpttiI", "lNmvGa1Fiu": "OGMOMB9wVodnIHPDiswnaKag9e9WtrWVergLCDSY9XOSP2AI4A", "myJ0jnWpCq": "HRtTQCIbKsJ8PYLjOy72UDuCc6NcrcbPCWbbTwikBG3dkzmQp7", "U3xS3blY7i": "Oi8fEPvKaAIhucuTpO16JuU3jBrqDrwsTmnYn8DC7nAGlE42ZG", "An56d7wOft": "ADs2hZVvFwfVXuh6ZZWTsmRZSBhFH7ZzFET0OCyGAYI2Ip7saX", "Uws48qog3e": "chWPAL8yYJ2h6RST4smedaq4IggyKwwgpuDlov3iVFBZkfYTFh", "a57ZZsE1Mm": "cqbhXUlNGyh1eLthoOM5jjNGzdbcSJcASPhS6lfTIsTBmopkFA", "VATOVKq1FX": "lHVEFwmYPhKU5RBAu488DhLhg5xMZtHA82qX5d0peE6OQbA2lY", "YoVcujqHyw": "qCPbMLWADF1BpW2B9RunEU4IXXnC5KxQL5OXG65toVOVTIS0zv", "D1RAv5pNxC": "CLeNqik56OXORDnsybaUVJrkN2G5skNT8yfE1Tc75nOARwwc4g", "ZrNIAQtxXb": "vyCTK3YJRSSPycz2zFDWmRxeKuUau7DW3AsUE1c5wTT4aSUTkx", "7uwOzRZucC": "uRZ3fcyVZlaxwasZstOCDxmYxEWEvrFSiCPiYDztNaPoyTdvDe", "sk6WY0qabA": "zb7PkG9thq12XJM13pRXfJ1CJizVJekduLp5krsexPHnx86ZlK", "4alZtrsAnq": "ZAg233TsmzmmSvz8EjhfHwzwYhG2xjYYVSSkURiBXf78E5edcu", "etqGnywUJZ": "tCySyQQg8wLLIuDmvZML5wJ2dOM3gHAxrbjWX5VZmGrvrmiiYe", "aGeGU7lnM3": "HWyVs3wZwI67UY4qIaOzOl9v2FsFOPOLERB3hsqGZ5EV5N6zq8", "L32732c0cz": "9L0WBjJqj5ETutyqkrvYLeuuvmUUBufjgvUYTZ3ZqWCg9RTlx8", "RhbcxDYA4W": "GQGelkW60ZB67gtzwd0p05xxHOmNLdOWKz1wJPf9Tk7TaXw6K3", "28FTQppKkn": "Yq9t3iV4klfyQEOtIzEuu5GQmCn2i1A1ssssGWXFJMrSwTqtph", "mEIyakipL3": "0GR4AA5fiQ2MBBpHAE7l9lxLqciTUJwv9CgC8Z3J1oe4DpdZdA", "nJKVbOGigN": "9Ed3LmW6IHVDGSdgfpyaTsQ5U2n61pbgv6GI9WSYdFQrlPLw1f", "QwoW7tdEc9": "bbJvHgbBkxGO4qe5qON1OYM4RYateDW3G3xevUC7NH5KOZ6HDf", "8IPPPeCtzJ": "pkCpfjvsTAZmlF24mYysCpxQhHP2YeX9mWNQIurzxMa4mvyUjY", "FGDhqm4fND": "BzUjyHVDCYJ7NqbwZI3iA2e8JeatGPr4rJofuD7QAMtYPe4ob2", "Kv9VibHL7B": "7bFYXGpgYgCUZxcXBpif6yXOf59oLDGIRKiytFnQeE3MwwTgyF", "x1BokkbXuC": "fjIMifzenxdx3voDi3yr4dsYmkc2Ojy5wy9SZwxA7D3yzIfv3F", "cqKFclH9q3": "s1GmT8RG7vULsBDVrMOQwvWpgOKErs3W7VU9Burg5b6Vy4GHdQ", "p9XOt8xyAi": "3rRWCIdCnE11ALRDgiNu6Tijmoj3ssoiJAmWharhZS0GtCkNAp", "5nBJJICc4N": "U2I8vyzE15RZ5mQoaDYtGjiFwwE0Q6ZZuw0OsxHQ48g0zZ7jAX", "mIxYz0O3Pf": "bZJZYgB3oBgFxhFldAv4ReA9Sd4A6MKYAAeGGHzfZLryXKa1tJ", "uxbqT7UhOB": "FqaPyqf09JzUIqg6ow5KtN0OfNMkqod8Ejo8qN9ZstioBZEQKJ", "Hn6DB7Wic0": "oP7q7ceWK3H3M1EltwAqCrIMesotlVuWxHAxB3WWh4CkJdqEti", "phBhUyhILn": "mPmBW4SnmZ2pKtOesMwFmUdrkugIGrO6bNScBtrpsY4mrGE3Y5", "kXopEpNOgB": "KK6LkV3Ueax8fAMvqEEgzkNY21dXon6KEZNFvZXVMYsdB4vCsZ", "1x4K2mYNUa": "nvjxKjwI3fGTpWqRYMVwOMXXUb5yJnj4m5V3EPTICx87eYMEDh", "jlx6Kp436x": "7ob8TuPBgv0nzqSluzA42JThsREY4eZkOk8TutXWMMjy4B32gC", "oRwGFT8NF5": "q6c4q8fLMhyG4Bpi6hysHMFpWzRYcrEssDZH2R61pqUXu70jHr", "AlsxZ5BHA7": "Gd3P3INqHnzEEl3OBFshAdDhQVuqbTD6sfJdIVKWUMZYzscbBF", "b6WiS17x6A": "Fbt1UZwxje6evZTZPSNbeGXTvgklAWZlkBcXGxsAU6nyLtFd6e", "D6orzwPkAk": "caUyr2CUZf5E7UcZnvaH0VmUNyh20SVMKzWBodKCKcLpg5ycWQ", "dO7vzWYNdd": "nlAL3bk6kDPBAri6RvxydDFVTfVfz2fmDFpWvHrKV7QNE02MS8", "uMV18MX3fK": "lCKpbXiONmjMiNir58sW97H4qPAyQQukmZ65CSMRpp6VC51tjU", "cY6SlKbx5F": "xtoPWIHXSLldFeR9XUaaRZ5N8AvUhDlFjUZGvNoag9x00AUEeE", "BTKi4dtjaE": "xWg1b0CGZgB9Z7vyA4E2lmJx32f083FOyZu31a5SU87ZKGy19V", "BYsq7wSuBq": "22wBoGCPiALEuHyPYy65mBCOdIJsO2wYLUXNRFJjqTqvNl5kFJ", "asKxn0TRK3": "c9zFtIqbmxjgroHvYmwrn8rI7URYblpQegUvAxNTVAVkRmtNb2", "quMPqdCm86": "IQYNDfVLAedtNoJVkb1Cpb90WhWgn0z8TbPwVdIvW30xcfIsCe", "UqYwywG7qC": "mFpNLvkIGPSFSswHayOflzC7QZ3Xrd6RYwtpGDgUhXElStRHmW", "e09L0S9yvj": "OKInGU7aGvpGkiZzFkGeVBRVnZMgAPf6TXBDXN6khZujpqowun", "ptypuNWaBU": "dbtJFvipwwa3g6MyaGvC73QozKMyRGhTJ8RFyoiUfxPc0oMEJc", "Mi07OMse1b": "uXePx0w5nM3UBTlU1xyQfbg65cdhbEw9wyheLYWE2R8ByiGM4G", "t61cwnatAt": "AZzRQe7wXGTSwtITPdvcxNoyRq3rgMtXDoYLPjxhxO1m8Q6VQy", "MA4BS1nW77": "x0c1AH3jt05Si8vXUVYoDSKjJx01pcy5mj4bYplIIqvRyYX8Ze", "yVjTDEuDUK": "PTzajAvWUlvG17rTLNss2Ro78zadIIzpfXZxqjndSPXB1zHzUh", "jJXqGoHiAp": "6pSuJHuBBL9vmuZMr2kxF2Wo3M6hyTH30Kiw6L2whFQ2ikc8Pg", "mqLuES7bMb": "3zJmFL4t7GH3TgquoZcLB0bc9GQnQ4q0ixytbBviGkXVMCSXJS", "dVsPNKP0Ao": "7dpejCiyEhAr5oT3HEHHiA936BLTokVWz10SdOayrCGlYCv9kj", "TT4OLryP0J": "5vte5qMwCUsTk2uaMqf8nfSVQfoWEmUD4BWWChEUQQQLU1zVlP", "e0fu95M8sn": "tTTkItCaWqZRy3QZjTzQ5zCQHBR1BuYFPu3jFsLcsP88Se7XqW", "LRkjFSvb5p": "Z9zHk2bAvHjisMmejkvqkpTtyDIf7tfJI5KKTJ2tfY2LibLlc2", "S7sncY6tOo": "CBJDQVuw8j6vddql92OWZJ58VxHGmL5V9jvTjRi6M6PqoDpAm3", "rbo7iNfB7t": "cG4RKrX3012uqgrRFCSQXukZ1G181uesk8VacIDwtKmZrKMZoc", "6yqMy87AeM": "3Usyeke2FvfWplO6OgG3fOBy4XWaHDLoJGpDZ8ILTjRkgWh0ff", "V1TdgDbLIW": "4jekBLeQWd4p6zY6EnQgRMPdcwhZf5ctt1L7sO3RXvhGjEWFrc", "g7ZCLX8VfR": "8dIvHiW0SdmBg4slwYMVM1yEMB5O5RqnbOZ0m95uCXpTi632do", "GDSNqWdunK": "ANSaYAQdU6upgXji2LXsF2FwMxaqIvWezsYbPvzTwWRtSeyNxU", "QWQ1xGiGzQ": "6a2WJRGFzgOca4trcnfuER9zR7kpBPo4aQVLPCjdNLGUIjMwh5", "4uih4jtIge": "7uVDCKsi2ELfvPgbAZSdRzGOomoUMzTwNkuzAUEVkbyww6drmZ", "Y6Th0oRrh1": "fjLUfMrFQ04yN3XjrNFzWVxNBMX2dc63mKhE7kEAg4Gy0XZaEb", "7mbWOnaKoM": "STL32yFmreUqE7gV5WJEFbJLTX50bshTz2r16b7fKRMsgeTogf", "KRaLmhkBhj": "01wDb4DlAUxnoIQuYtHuXv1WHTWW6TTk5VsMQ4ib0yhdMgcFPg", "kEOQnUSUwP": "AyikRWiFzckpUNn7qHN3RKJNXvXcMDS9zOlKmuqc4yxniajTLw", "gajxgQn6MJ": "HY7n58wSmDDmb0aZL1JYwzr3hMpGGJFjamCWjXGtzvQ6QVjIp9", "c4aUh9GQ5N": "idxOxayDCuqOVDChk2293wycosd3gkI24WUj4ctiao13Yyavdv", "R2OVbNq75c": "qKsHdyj772nFfSNYGCvDlib5rJ43pIoe6jOztQzqw1LLxJyH2V", "LsMUL3KxXF": "90llX2dwNUwDiIjvWkTTnrnua1YUgb3r4DPhstSQ3j7H70Npjf", "5Q9yyaIyt5": "qbjuJvcqZcXg6FpXpbR2GtodQGALNc1moyE4e1fllDUyTfsOZh", "BzKzoImbYZ": "PzyTSp7Oy5DdvnV3hrZwxhox26PPW6nmpCiVIHKGLSz6uIjDOw", "uHmJBj2Iyr": "D1AQk0MpHsGxx3HTsO7MDGSEB5OY7KyhY5sffwcnRCmJT2qOtU", "XVPj3Mignp": "K3TsBC8n1NsPud4dwbXFd0EKpI3YemW9WqHqX4XDFojVQdilyn", "h9a5DrD1c6": "E8RIp3RoEdjA6V47iy3hC7D3MNsZa9GIzrL21B9gbIjN5Zq6QK", "a2nG9yH8Pe": "2ErukGvjMxWODPZVAxvmz472r5GeCLyyCczNrQP7wXuSU6dMfr", "rHW7AcyJ8p": "q47isnuOA7JghnTtCbKFKacYDNqyGoPSWmzFptk8td5R6QlXJy", "WKyTZFn0fB": "fzeZaG3keV6aN1KuVnHpMy92l9NE8whhArgJJhJv7u0biCjdgK", "MPLyjWncjW": "AnODK7YizGIndHDMcfxUPh9j3SNChkFtaA8IyRE4RIW7gyH9ae", "uTbFujQEtL": "bPYIVcYLEziR6UD6FgGbK31UgYPM629yK0VeNyA8PdNjsyp4KE", "yC7o6CPrXc": "HJcNXYyL14ASfs8HgSJKrf7jQkgoWjlYMPKGRHArBQPZu3MR0Q", "wQHzwGQ4D7": "68GHLdnYWkzPgqusBHZTeaIL3EFSas7Y3shkfABtlhjnwARSTF", "Oj1E099oCA": "hYj4sIYjyusjobBb9flkxQSM26YVWaUBAWkHrgeenEew6TJHkx", "lfHTX9XUnf": "W66TUfKIPdLydtI0oz7fmgi9DGaeLDtFdOAW3lvc5nQgUw8gKP", "zvRpljglp5": "ITTW3iFVkSgnECboHwGFQdXT3c9iZdv1P7JHJ30mXXSxFiTgLr", "C68NP4WFkW": "ZsdrZxA2TsNJuPke5lX4dxk2RXkIILrozRuO142uV0nCy6GDhe", "CcypJZ40oT": "5em79SF1O29SFhvLAxADEmds4oNY6HQtvemAjeZQc8XapSrwmF", "ZoWXl4Aua8": "YHz5pOn2BgeUfB61u7EHIiHGUp9l4JxewgNBncuVVsNMAVyXOD", "ebYWDwn1wb": "X9Y0YJqQ8uyg7xs0aoTrixFX6wkuzDIabFquLm9jHyqm8iYclZ", "vidw1JzAzV": "bIlNYbyY7B2KULkTjwST59t7purBThamwP1fXHOFOs96hng5R7", "u8RuYyXsQY": "IDbif33AFLVMTt5fk8sO3xYzJ66EFO3RbPZGkW8xpcbbLTUTAj", "n2APq0qSGv": "l0I6BCFf78eEJhBbiVvzFCaR3QdBfuz3mvDAXkYHS2VqdK3Zq3", "kLur210aVq": "Ai2uXxtnRiue3UPdeVHA3XglXk5wMnChZin6umOfTYsAdd4ySq", "uROrM0D4vM": "LHjjZ8e4luh1a5eJh182GB875Z7AEpCQKVss6v1OFosvZPYIJF", "WjyMctIxYw": "58udXEeGSAcMkJhYE3VVOUdV67zldSZvDxvVRssSN6HcLv1uUc", "4AkZT95EMR": "rJF81Xx0MkdMzmS75aH3O70lpSh6kDihfz2bCOackOdNNmVZDo", "YPcwIssthV": "LlyR1gPu7oSsFvHQIcnw98qm3v3frL6NbxbMgNu5X82dt9cp0t", "FgpM0kF11p": "j54WHzsQAP39Kuoq5PjM5L3jDU7ClD8ByLtIrC1KgFzcFgvbx0", "nQOeujGOkr": "hkShVJaz3jXj9eDehiDbn4ou4QEaxxQq1vYuoFNukM8vA3sY60", "rFafzQBajl": "y0kZuNm9x4yxl8IyC38YYWuTa157LabTd8L5K3fZ2ifBo3KsFv", "VrFitrAK4r": "DjK0q6PLKQSGFFoK1BWuZwyk4ktMez8vJZpaOuJObiQC5KHNNy", "PrC5ukD9PZ": "g86ysG7wlgVHByGERFQDrxyayDpkDH2BoRdkD26JURHUHOFYlg", "d3IAqHofxn": "oKuy3I50QQASp30uzXw1YuaYzPGRCTIot62xywN40ZDA2UY8Bm", "OypuFzMtL1": "XZvcz9xTU8d0qmoCiRyobapa0lpJW0FSx8Uq9hktWI78ZD9yJd", "5PXrAYmo9Z": "lzItXyTbBbcNCwuALA1AsxsR6DEPdcTkOxqh682OE9dXQ5GErf", "G3t1ZOREQO": "wugrdHqaFf8rBtoRMZCygpxUJQRx9llkIDlZVEwDNqC8mKZadd", "mT88HNAKBf": "dGVbdLepF72W18CywceHCTR6GWpbUux8sPdXLJftMQjbysa73Y", "gj73zKJ5rX": "CdsW9BfZTbO2JVDzdZPVVO8FjJGbdDHotZuyAFoTVWKINoeQrb", "WS346SrSQA": "EwI9VIGulNQZ7DQOZtSwS8mBmYThxtqyihPPXsNLfdNY2eOcMI", "SHO4cq3bzN": "5HgUkQk4G8CAZQqaLnFsRWUV9JJuzCpP5S8fHi7mYF0KhGyfa4", "V7YXAAnXnl": "pznaoU9F8uroNfoRfC6PxOQ2uaq8AVRPQZk41SuhbCIzLiM1ks", "5C6O8fHpuv": "7Ts8xSvXg2ZaZ7IqHvmfYWqv5pJXpB2imGPnnOcFF5T3pPAZOH", "HJUzm6OoLT": "LnVq1RJKbWFDLQDA7JhXNbhLash7vAuh347GmrwBkqAEUfiuZv", "DjwqKysZEr": "z1BIt5mSIfyuOb8s1Mz8kWO2lnHPaIi1IT70kJF9vlD3Yvav87", "ZIoQtimbui": "fkVcmRpd6pSJ9X5g8KnpfiqYPhxb1ZXBkMQwSsj0gZKUTpZcWB", "r3NCnoJedc": "xEdUTKP6qjnJS2ZlGdDHP9dyDONyTPBFRDMpNkIU4DNDsozypt", "d1Usq5DtZj": "Dbw16ZhhqAoZN6bAtcoyhSUescJu8UE2VZTSIT2g61H3fCpHWp", "G5PhHjVG4S": "lhKN7HMApSUyAaqnlrRjxWbI8Uk29M63Flja4Xd0DUjgdQXpeP", "iKaitpxEak": "nULZZmHKwTcn5CXtZayIQMuVgIb5Pj3ZFjOy0XSRaWfwfBTkii", "FByfJruTDH": "rTWLsTZrLJoEHFRMXSwKyYewJhIJJXe8OJOzgs2TGvKvtgUWRA", "2yPv7IeX0Z": "uValtrZyZUEblIePFjPLAYUlUHbZjVufi6zGXFbKU6Tv2bYxqp", "hZAiY0qECb": "qplmsHN572cSe3Sss7Xsqq7iM9PtJaumaWRFGGXpi5VM1cvTny", "Hk2EM0i1AA": "B1IHGhLumjtSLhDVcduuyudLA17VWAMb6JD6LK3r5F6LNEhyW7", "TygF1Gwyht": "IEJaHXedGMqeaL03KwE3gFWx7a0quz8zr3aQBY6KCYtouFA3XX", "PrvHTQV8Tb": "d4tgNJipHShqfunyNSs05P8u8bKJGx3G2qp7vrxCmsEOHmwTZV", "R1gEBsw0gL": "U3E2K9K6H3CjGmwzzIIzLRLacOjrMtr6Q2ksvLwXnQT9Mi9VEp", "0oBtDYxlQP": "2SNrTQcELV0c7DAxhvxWMn7DQ3QTlGZqqhIC8eoRYz59HHjWEQ", "ig9oe6qMr4": "rCLyayGZesCCrwspfWteRALYdjo46aWfihL9Ry0t7zt2LYEYye", "hdl2DCcPOb": "qGphdqFLJwCm6MTTVQxmvcoBgxeSawJVV5j7az8U9m9Q81RHdu", "Lzyp36S3KB": "KufaIwkPqsYWlSP8aMgHbMLPdS2NJzroONOGGhzOj1Wl8zVISO", "sZoEMBy4ak": "pgjlTNdtHSUeCv15Io1PtQLa7sOu1kCsOlE4lkIQEiRWCuCKzo", "gdjapL6rzM": "xqlV4OZjFUe5he07dDBZadkxA4hKSaLPiHygk49u0OoksY1RT4", "v2IcnMu534": "Tpt8O051IUfPk4QzeQFV3DbDqRePdyfvaGKMyZAzZsMUFOQG5y", "f6n6w8YMeu": "hHBcfIfREAFQAD8cmC92vPkSM3bUcjoOtyc99KNN4H2UBSFGtz", "TAjZqHoup5": "Ho5AD0uwLi6shTdALWcm461FHRbkvbreNZkEJ6PgY5SJYfsnTv", "XRanh0D95e": "mgaYnBWarXSFXjpbOCC0B6M7yeTozePlFgJzAkYrXXPtrtK5Jl", "tTwBibrZaf": "C917W4vT57PfIr7byxEewL1cHLZaUV6YxXlv1FjTtkFiqEo6nN", "hwxmOYyBkH": "tEBZnXt3iTRNmxWDzIiiFgFI8VGqvf2iawTbkAhhRMT8wNBTHI", "m7e20T9Zsz": "PTCQfHNLe5AuXlTgnrw1wSUS30YEBLIUV2gSKZrL7BqkYpSz58", "7Ng6dbUHjR": "rFo5l9zjL9WJoxHOLEkCx1cV9c3VtqoHqMqa58e6dEtycmzOYd", "FWoNJkrKZK": "5MZN089xcPm3aisLPtV1AXcuS3xjrl8tNxJZsL6aRBgoPapmF3", "vyK0tPrRc4": "3NrKuDhCNx1mhBkGTFTfzbHq8szw0WGNMLZl1QoHGvRH40gqrP", "QeLbLstKj5": "9urRZ1eI0pI5JiIgvWKl0jHe2dxBUQ9cGTfXjSPRAKB0gWWNT4", "NAkkKtI8sT": "RU3zUMdXy94a4dCYs62W6WMQGCE6QpccUT7J5HyncVyEHLftDs", "h3pzasqmYs": "eXVS08QVF7MqVbfrMXrhYpfTNMC0iiVtMLLhsrjQHQVpVX1aJL", "ejNh2lYsWt": "YpSI96tW0n30Ogmw0Nwk94k9REdZmET9oLHUEUKVsTyyZUMK7u", "iI6qMVw7sf": "YJ2jXHxBikgPqBvhiFiNg4psJ1cUOOIV2fTZkKICQIJGJuBwMz", "D9ANR3piEM": "BzGmYBrUHAk3jtpWVJsNr7mkFuTjKnucCeuFrN1ZVsLCUovy4c", "YkJKshqM0B": "XCRxEzJ6tx1GIgBbMMpnm9qxUsesCB2K35KtSftTwfLhXDMSou", "PQRc59ETSN": "krzi6iFPvBMdTStBrHLIw3RZrcdVGaE8gfeMxQIF3ssLFCbcZX", "GtxC12rfp5": "XOuRScyZZ3MhqaVKY7E5BLLuSepkZqlDSw2GUSNbRPs96MbQ7J", "dHzIxIUzVx": "RHuJvTmGLHvJ2TvWI0pkuoriyz9Ye4wCAUGP6BwtEcNmvpdrsZ", "cFIaAanHlE": "GELADk2tFqPRuAEnnjPPXgmXQWzkPzbqmacGS4r1gWqC7xQ64Q", "tUZZobePAm": "Pjxap9NyGUvwi9ZCekr3w3cqwaZKGIxK5dnDnxO0CTPCLcb3ee", "wINHDueMr9": "ZTCvyrtG5l339jWFxCeF7UyQ1i9oTAjBeBKTEpSzkcyoWXemGJ", "NrdKOtEMhL": "6LwqY4V8dZphhwLBFSu5q1jpqHFWJzmX7rm6CiaVtIKhFLPCXB", "8AukJjStjo": "wvNrl6QJxuOb4oFDNxzbUxe7YRkXD0pR51RND3do4ucDTpSOru", "Xuirj6XHUK": "pTa9dEr32LLA6x9u0LLmGRSikbgpCe5OdNGclmoPL4FoQ5rY4H", "mLxfOcjXU5": "jMTr1Cd2iiG48fyrZa257Z0qYBzYYW8iIfIdkyfaABmpiVjuRn", "6e08gFP4Zk": "U9lHZBiMnFtlx04Yh4Nh1ZvcWopeZnShBTbWco0ZHxD0yS5BtU", "PV7KXR0r0z": "a2HlCxLndto21QiZMj5RCEwEo1GmunlDhPjbrldiAxC0HaLdXa", "yQGcjmNl3U": "2reoDfDZ65BY8RXQImT0HQVxxs2sJ3W1tkKu71VAUM82CWQZh1", "G0XCUcYo6w": "G3fD3CAdlCw4O4fdQ1Tgl8YUqSqoFQJOdiAhBNE4Y4izcuIyMM", "Jl1IyQIFp2": "KtNuvYcNRP0iQLPBZnmu044U0WI4dthqGPH2Pt4o3Cx9yz3Tw0", "XwlMQvXNAN": "jL0Vjg8YTkKWx8HVUjaSYRra5X8vY3NvBGIVdNHy05NdxhMdsF", "VD6aoFPdQz": "faXEnNTgENJa1vDosonOMVwLBFwAMqbxp8Ahq6K1nWH5bgj9PA", "NbhUBHERX8": "tQtWOfhF66DbgOK6YisdHqGdUB7vvi1eTwA6VKXnbETQ6czi62", "i6cHweBfku": "uh1XIdkeqfgKIqHRX6W7QXu4EVHFtCwa2fH3ikwhS7QQ65BEwt", "ulQMsD03GE": "bw3gokzMSS3AHpH14iXj1qfPOalraCuJEegJTtrba6X8aWTuuV", "a1cqW50Egb": "uxf50lAULly8UiXV4CKqeRU6w3763x1w4HIciVO1YVXkIlmAlv", "9Ztd8v95DV": "OOOKrVp6vpjHG1txJoy6TTW4fY3LVKYk2sLzGNtglprQ1cgNWJ", "q3BGE7tP9d": "9JQEV79XbWaWTkE7mlKFsD0gOYoHo5rUrCowGSJTtpGGHnNpsP", "0I9EGPnb6N": "uOF5WGXNkLaXqvAR5BUuT9I4gaxFezlbZ5Or4MIZF5BGPDFMUA", "6JiZ6FljA7": "TZgjXwgPpVVt0R6gaw7ELoFR6hwzXm0EtN2rJeOFrQuXr92VMp", "yYiXLalV62": "zqWmnIVIZfHhAbq336ZeWTwvFNKvOYeNKWh2LHgb7i8WPY9T6K", "U6W0rZFGTU": "ynBoFCdq2z3y6UQKh6PGHMJl878VZHU62xTxfRKcbdaoZM1TGQ", "q83wnC47vV": "0KYromN4NIbqrrnCZtKtkCdJeECLGvbliLDhTeFC29cgmhnqLN", "SIFMycxPGg": "N606WQmk0NglrEih4EjqV6HmKDVOHIiGEWVRNttHbAX3qLfH1X", "vxZ6LkkcDf": "lZo2OgGE9fgn1sa7MZh33v1AQBMBcBpRcsQ2EeXWmDz0JiwzBj", "YUdvPxZsI3": "xYGVlpYY2sSYbn4vUtCgY64SjQ5NVx0YQlmuBvMTbNGXPBUzoU", "9rS5mjp3Sh": "QR52SSSIHzyJDfNU0kjtU5hOzhGmiVVAKqmSUY1o0pO7xh3of7", "WkAFYN1c9V": "HREvkQCmoU6SQxt07aH0ziUapywKL29Ami5GnoVNbDJ3hr5Y3i", "nOxoAvVsOo": "eCEvayl8Ms52lhU8XOUvM23nvqJMuH4doipwmNzioWEkVa9DHL", "5dnVG3sR4Z": "e9Kq49KMbRiPg8EswiKmuRq10D650cqzvq0QPzrEyYxbIAyBFz", "ZIczjuRgvZ": "Rrfo45voEso26ucDbcYunpTNsPV7K0LCCwpMe42YmT07n5UIUA", "fR3SHySel8": "IfshH9fqblwkJzKCvW0Lj8Gt5UHRvxSnKOwg9K1Rz0EK2reECm", "NN2pc0EvqR": "0VJouYrIhX84YkSQPudvY9clLAa1fAEGfcAoyi9WecLaSdvZGp", "J2raUaaFwc": "VXa93SkZ3883fseejBgB49CvzqXqoyC7VfrqjkeMDctGsvjglh", "258eOhnf4h": "ZArjHtqyxvkEo2YVhutXPE3hYF60tNEIrSjMjIrv0k61KwMla5", "DBf6Tpw8us": "SSzA4H9rfsQRuDD6M2GyyE2eSHxTh28VoYUzTUayO63ryza3pM", "1URjTBUEwI": "O8MYb6kGEa5k2FpanoykQ2PYsjDokul5Kcm6l6G6HHk2aKLZ3h", "rQAld9fbq6": "Ww6FqcGBnoFCfereS4uckYypDK9Ms6XVKBKYc0Mumw4wfwGhBv", "XTPcm1R5Hq": "6F3328fU5LN7Roe1rJ2UM9ZRFlB2Fn6dYqYZ8lIotCr2vaJj7A", "ZJbUc3CiJl": "ExFQSEmRf7zRn8mopRbsisaalJqpNR31KTum7j44FHvbXhCLr9", "k2IIEkgOBr": "KzgpwDkKkLxJwdhFftrj75Ch0EnXszyUM1398r373n4bK7s1wz", "cXh6IN1TDI": "osV9nrxzgLoYiILw5Ej6Zkmgb0uCWbUXCzJwjNER2W5Tf0t8I6", "iUGq4VxvkZ": "hQ2XtW4Ju4lYcCNwaBWRJcWCmGpMIaSweFv8wIu6xRKowBomOe", "e89DjAJi4v": "eF0lTUUE6tpTiOdyUwuzw1o8QlN5YkwxYYo7yeE8z3eRedpIH4", "1z4SFiwZbo": "9EUPyXxx00Lq7dQbMCJt6lAnsGWmpqTlwvFVhgzRCL2qtGMxh2", "OKFm0ongjA": "nZbeQPImZI2MbyQNk8c5s3jbvF9vUILFrY9cp3GU5okDnvTj9h", "0PSwyTEZ9M": "IRSfO0zg7Oqdm1BEcIqXrMDQFipqE7sOSFqLUzoyVU7lMdARoo", "DOThVoNp5B": "xIoXdFNyIGddXzD4HLVc9Qb1GyM5GqAYcCAL7yTHz35mhz5Azp", "8o9aFIXfuN": "xP0IXYKqzvPa7wU3fqsZFNV44Tde25iVrCjy9ZSVBylrYyajOT", "3j2LJ7LsWr": "vFUDncfkKUnnFU8vDeOnLBROQmY9Eo6CzSnyGHttl5xB1oE7WC", "yYo387XISF": "57Y6sQfrXU18ZwhSAKK0BxHp8II4LsINkSw0zHUlUKoV3uUNw9", "G03e6t3Vwb": "OuCKeIvJpXg1sSy5r1YIRW3uASJMW5zIOMsJTbUQ8J66SKfLDl", "hIBFLZkr6k": "vckKMRErqlNMbJoZJSXtcWoYN0g2zgVeeh2NUw9miVnSfxLouW", "gHBgG7B7V4": "8mEUTEzIFQDV6lhGo3X7mrwrBY60mpA6CjzRSSW1GbAh8sIFg3", "AHeP2CS5bo": "xuLknc0rZAvxMkIkkoPRw17bFmvepqTebfBO7ATxpT6X3jqyOg", "2jxjAUkhBg": "tTIb432aOJ1FgCJT7wSBnsy5EI1Orxbr4jKhP1nHP4Twa0Ea4r", "p6OjYqDCBq": "kacfm1qEnpuohzOsGn1BEMJMVbQYfi3U04BkUCqYzIIKSm2ag6", "91q0JbPg9j": "2tdmCzFWiOcSkkSpkBZRaQauDBF7qxTG0sgfrZqdmkfV9SGBHH", "dwzr16WdHh": "MpGtBvGbhPEueteKTsAaqKPneC6m9CwbDMexRU2w8P8W5bHDsJ", "KewlEMa8qt": "JS5Hr6eDuUWGcIvP3x4kgS4X1A0q69LjU6DcspXRyvYzbTsFt2", "VYwo8wnQZe": "fIUhrYLcQFNewbfblM34XgPDt6y2BknAQot9l2RpjL7gCrKQ5z", "lq0c92Yg2W": "xtgwuCQWD2XUtzLYQAsZ0hRw50iuj3OCgcc2ZjL8r2wsoY4yvK", "afl7eRrfuw": "NxcqTp2k3OVrNrIKxJp2oJMUIP8vgXx2cL9xsuCpwddoP4S5eK", "ct2Ps4oHIp": "HDAmfcbeRuPlvVjzrHL1QRBbsS99GDdomxMJxckK47y3MYQhQ1", "ukNQUoirBq": "tuYBmbIsDI7241QQaMVRYaw5OJMzVkokpyIKL2uTTyJf0jPYAQ", "DYZSVaQ7Ua": "zexI8kw1lyMCYoo5eNHq2lRVSWINVRCFhmU8tAu1M6KAWolsXk", "KlGxBQwJ9l": "hFF9UFJrwZkMzz8ASzGUdsb3Fg2cYZQCjjBJY8ifrQRiEUyUCZ", "sZbcVkqshC": "lwePK0z3sD55ZiyKzq5rBiUGvWayEtzXYWb7XJ5QbC305EI6Ir", "vhXgXhYwBa": "EiGRRvfMLsd6tzpIr9P23nayD3dkFXDTkN83p9WhzFtcBUSski", "d1xGTI3fML": "o1qOKnT80h7NkCOpNKq23utiOCwotWRWVPOrO4q74T4luxP9vh", "xA8l2fEBL3": "VrPrpm1vVcVwTv5VoLiFxpquJxc17ybGaongc2gVAWoHToMFYf", "KcGemCcwyI": "wRMcMgbSUUNYwWVcpBFhGb1Rtm5QktLaiXhYIKiH6N3Acue2Xi", "gpZErLb2Pe": "DWu0mZGWxmNfnEjUGHs46HXls0ITIyVSPbCsOXmOZyQqbnzi70", "oJx4cuFLHY": "Smqb8BkHJnVxttlYUmJ8uvDo0BflC8I2dtlIQVRTCBnfbtSgor", "UixZOD7KpN": "EK5HEydg4cViHNFPlHzZc3XvgXVr4RfVm7Q96zKs22AIuBATUs", "VkE3R8PE4E": "cAHM07NP9z5l7uE1UOdV35mfEyvjcM0R8SngYY1DpGLJK9jOrC", "c3aqaXl2nk": "CBJAyioY4W3U4ztiHBgpWV1vqGU8yfrPuApwg2J5VB4xyl0PNv", "QZFjjPIFgx": "qyCcF8xSeUpSIL8Tz7gCi2ePwpyxBYdvY7y5LoIb0lWzfjF7Bs", "QXD4HwoLRV": "4CH8m4RxADsfzzW6GRnXpZleve8s1w2mkYQJrt6bvZQjlY5noZ", "zc7r2GrNeP": "Br4syF4W1jj6tMSmX7aUYhKE67kmRlVnQjCo10fL5HO4c4HDBl", "NR7ylzLwN4": "eX7ihjzSuLBQe2fQff8DcF7waFLPRxT43nRHWr9pnGl2Px5Ltq", "Ij3ZNjJawN": "mrBHkiSOhymZGGpiHAG6RauM0tZ7UjdAASd5xW4A1KmZlgQFSQ", "QsWyXzxQBR": "e8EUDbUiLUuyC7zCjHT4EFxD39xS3y6Rx3dFBq7P0STn6tkdJu", "mUCfm2gd5m": "VlKBpIVQmLUaF4HP5bWIaadzW5HFQNkAXHakR5VTFNfYeeewWY", "MQ6UVpUHJj": "n65wMZNDBaQwlb3BaG7XBldBf9nirPPJpqIF0ZaFglYmXlqqvw", "tq40eveAeL": "f8IbePElRFjRJVgL3uodYBphS7DQ1BOTi8tAEQytsneuxOvMtf", "qTHCKHGJ6r": "UTrzgjxxLFiWe3U61DnFVdAbdC4uxwfXiuXGSPQ4vvTPobPHqO", "2AnQbNI8zN": "E0R4ujm22x9Dm3kGjpjkxX1tGLvWH7aegSCzdqvjyMXoT9Rt2h", "ogEc1WraAt": "yr3RYCN7ThnQVZ8wmLa4GLb2uY6fYz2gdDv20qIKQpcwyI3Zsf", "x0QMjeiEEB": "q5Rr0ZpFVButSfndMHAzrS79ofDxR4NFix8EQdejXuX5czxCFX", "a9YzjVj5be": "p2ON4vkpPrK0BKkveHQjRyh2YBO8HcLz2DDCclmQ9BIAvOwlki", "x7Az8lsu6A": "NtiDGTb0S3jMuY3kMKcX5sn5xYAoOuXg9U8Z5dcQml7OCaMUsc", "wBkapftDXG": "R6CQA8xz55e9k9oMYdWKXkEeCM563iVCTZGS5Ljkd2gXnY0KLB", "p24YoRh6zA": "A02GtHLKFg84ioa4Kdl0tbitwMq0mBq2XdXFWNZJI1BN3blPTJ", "FJHNYinte4": "9PT8v58uyjuXYCMnAVwRszcfWXsb3jf34ulmb9akyqfB9U2wGA", "FBaABXq8aQ": "5Ix89DBAdc1SMtRhSs9V9UcuaIP3ibNfL9Iz0BM5znsx9jU1Ew", "9oNEjwyR7U": "BtsoU90K79Sr3fNCYsawGhleeM2Ys9NYJgDm3CDL7rZY2y4tjJ", "AxYLDQvD3V": "CMLtpFSV7lBFGKffbrcuO2lnZZbr59fqBigQOHozcuoAJ0j1mV", "Jj7TCKEFlW": "IkQqqKItxtgfx7SEGMLhq9YtsN8vZuCw6aj6phlkY3OhPw7kNm", "tsBl6wbUtr": "iKynpHc4dY5f4aEJPrZm3AHWaZSNwfo0jkteBnkH6LW9EXkGSI", "qvMhd8BFCD": "gqF6BM3FXku7ioBydIB8LdoRSIYX8ookNUGdTeUBxI4r0r05iM", "oPgj6wVkHO": "iptVylczsE54we8N6OsgbbTykMRrR43WItj872OhxsCNeRwPFt", "mNPwRMhPle": "Y5fnL7yc2ftIvD2ywxi6AjkyxrKWW4d2CSk7kJFxOsbPF6jRMp", "eOZyhB7wH8": "CMbyl2KLaX6NL0BN6lS6nW5mdyFrDDDvVoTZF9hHnzmArmpE1O", "GEwrtNrC00": "a6xIZSqGUft40qhJhZDdQf370eNBvtuQknANVpxAMVYZImFGs7", "zmU6m9Mg7m": "BZpuyVAwS0zbfJ3yHaPlYwm41d1Yid9DXtoG0LmGEo0unHEv4f", "HA9l9PqQ69": "PBmRfQgeckX5yVoIjs6guvCFOEqbnkXcEBze9dOMdyForTYv04", "GAJjp53Aie": "mn51d1OPJpq4mwdvtTdZXlEkZ4DHZjjHzGkfs55h9Bo4l1EHsv", "seTeCQpVIX": "VGvO7eBmaa48rkqTujqWJbJwfEAk50589FB0BkxSOBY3bQXriO", "12gJ5wFAdf": "OK7GIyIVJ7f0sCyf4Hbz9DMLSTt66y2t694YpTRv8hOAn8A63p", "3wnouMqVcN": "tJXXjKGLOuTxoT64r1oDJdFEAqxjzSKYEoFrMhNLVS1vSi9q8Z", "ZPO8EcTuOW": "WZ1JnfGmz8dZOU03DQ49cKdSKWxnNeWYm0Hpxlb1F5oUpB6aWc", "OiyqiwIN7M": "H9bZEUogSferN3Zr7AxZ8upmtGjUBUZgfLhDP1zTwSDsfQSjI1", "6T0B0GMUfj": "a4cSLi356PGIaPOGymAdHpLI4SsI6eL15vAwqcEspcdudD3qZ8", "lJHzdHQ8tj": "CGG2SmX5PuYmri3OWEqxWVmwbDLyrhnB0zFIcevP3lxhzB2LMh", "2hPdBISLHF": "P8v7cwr2uzPvh6PEWpY229xWzXiZBr6MSpW4TD48zWofHekIwD", "F21Nimxd4D": "8jOQ1OjKKlA8OmSJ4kkkJtKT3LWCTMME0Jm1qCkgJ54StLh6FS", "gYIfva3G18": "P5QuCTugedUdWT95x518vK6hrs7oFiLA3lyQz5Yt4aDzKQu4O8", "GuELt0HdOt": "yVKZ5SPgjYHbW9ZaJ4h6r6dz8sC8P644M139jOcMfy27ilQkdU", "G9BRygNzd9": "dxXeLnSA33XZBvMqL3RdLfBQDNs8OuR6TOD6YLicmfTtqr74xl", "9AX40UQcpp": "GOAsDOiy5ZzSANBy5mNIOxva9EAOzQoEXQ5SlQsStEKh03iCuK", "Blu9e74RiG": "1jtt1uAL8g0V54dsj2FjZQYf9srih9NQb0hKDOcEDEFnSph7aB", "YgQYKEHkV0": "RtQZErlk8SGRmA4EuiP2j7vMSB6yLEtd9ADo8EnFlCKRye3Gtm", "6ucT5mN1Pe": "jjxTtiQPEprTGAvOVJyleP5MJH5Ru5cBYwdHYKoF4dtypML56E", "FJXl0PPZO9": "i7nkld52qfnaORewZchAQvC1HVJ1T13kf9x3SMYlt0zReM3cim", "FfzY46V12x": "CAnkPRH9MI9dM41yI7dWfDtHxoKCONef0zFMUQt7nXZAYBBVhC", "vwiUBwmNL7": "2VjTFhUAJOXnWMYeeKIZG9XwPUQyiQvE5su3l5ymGmwTKz9unn", "vgIfjWnNCC": "nsjMNAJYhWguAe8E2QOFuN4uEVqCbQVDAh7mUdxZfLrSTefTak", "hmZxSSV1T6": "uG6cnuKc9fIyrwpmrR80Pukr3aOWcYmzYLry5qPajvOBzFj0x8", "RoD3oiWKGE": "Yn8eUuX9Uq6MT4N1wI5Z6WpN6IPSwoaHLQjZjjAdR2FMhLY9zk", "BYcIyUtavO": "eVuvDgLEdaZGpQ3vzDxVrBA6kONgO7sJxLzXHx0XhCkoyHDjrM", "daXp9Wxewt": "EilBAPHxLJMrN32pXiroS0nS5IbriPf0n5vnfxzgzqu5Cgdpw5", "KXJ0LHNjyk": "9jGChxO2QkBOzmBMkNwIorMbzLwUeITxfdjY5K3ItTShS4j1Pl", "nFqtgPJGSW": "65ORTcmwfIu13NCxxVVY83pfWoiHUXoBeULba6SOnVgzSW0x2B", "nlZGtdx2l3": "trhJk2OpAv3QDutQwCwqC4zFC7PYTZ7LLkTvUjbtYODQCKi3D1", "Qt6gmf9NTd": "rHap0fUPmpyhwSFaDTFIicS96aVZIRV4vE5GiVACihwalx2rQX", "VWg4eDtMWY": "qDnNcXuV4oEvGtMwjwmLsAIGlLEFwr7Ivt0SLXG2BTxGaXz1b9", "MImbPsPfuj": "tphonuSfLmYCQLy6dN936VWWhtmPDUJ8OjhzjfxpmlvXYfDjBO", "0cKRBgGBvu": "wzqZCn5VF6bwN1qhGrJMtTEIT8slfgDvnRyvKM4XoJQGEhXWPV", "XjCvTRGgxG": "5zEERrACntn5HDJfmKJGvPVvvu1uwKJFzXT5rOHdHn2ZxEKXG9", "kJToI8eI3Q": "csW4vFBTgSmGH9Q8iPEFJeY1Yc5rYL70IYKgZsR9DCllyaJvAC", "UOehRRyq1A": "IXnaCGzoJieQrfusEWk1YbUYvL8mNKiIWXSiRKAG6fPjvAhwou", "qBAhCL1JI1": "fdyacolNluGxq0caLPfEKdq5IH1tzlHoKwQLmogPmZkempKRkA", "Mt0tCIMLid": "F4m1kBlN8eOtmQ5CbJ1xJiRGR9dTI4IPeKwGlPSopb0VFpNztF", "SeWviwhBjq": "1N0aO6kDPQAcu2aBuqkiH0wvUGAlh3JeOR7BGhdv0TUIKk1DCm", "aBbAGdcqm7": "ToneQbuXhZeKb0aXpe85Ppv0JWVptuAtrr5TDTUfPTJSBkLTKv", "6EO4RxcEGp": "DRY2xw7jHxVz264XbFtxxKRiOq3ei8czneKrxCZqL5PsI849zz", "2ICRb7WW68": "z7lTJhFipcVSOq2O07XltU3J26z9Ia4tjd6uwU0ab0tFuEnPZB", "ZZJTHJoqf0": "hRntnngitk9F9H8eNEB8QPwM9GLsjDm0yDqEdkpqW4uCOewg9m", "kGH9crP1Ul": "6ncMxFkG5NMCk9B7xE0btoK28U093ZKp9oZ1lSAwQXm1eDuTCn", "owgrNGB6dg": "IpErdzEsfALH60BZMIAA61znDaks5bvpv6NGKMMIgq0Nk1T6jJ", "4vcmgUTM5T": "TujMzDHDuvsicwY2JsROnMG7JCQZ3uwasZZD9qugYQSVYmLi2J", "nU5HGDCO19": "1TEPthQc56gpjSQmyGCfelNJ3RmA9Tp9p3ui5BZSYUcW2wFn8B", "ijuzB3UP3f": "OpAxcjwDE9iEB6LHmuWilYM8PaIbGdCVuCdQegCViMLGnLSYpT", "tWclfvAXxv": "Qr2Gmc1dbSe9oMeccv58Kh53Voq3LUCu1PoT2urRtLeZx6arm4", "LENCl7thEv": "t28v04SmZXu1QQV89FpuZtmv5Ggu9jT1AcTwdduF82fEe3yrXs", "SLb47jXPqz": "JcthR6OsObN71nTlKPLOkPeeXFe7yklYY6Hr2ccd9wjKtp35Ss", "RmlH7jMNxm": "UaYJwhsS2cDqHIPODxsEf4JjRbD2Zzg2PojD6sm4ChyosI9Ipn", "BQvPXuBJDJ": "9ZnrlFb8kUCKBpGXzYAQIeqietLL57XHJnntAAUlFJcPUJl0dP", "O0ariYTnnp": "jSfflJa0s29MQctN8WGGwOkHRhy2dwS9biLK1gwL0TukxFIgRV", "1UCYEKU6hh": "Ke9HOu8hgAjGIVIoklGY0Lhzv42mBYvxVfgJyyICwN6Ps2iNyq", "GBvUlXbPlU": "GkEJdVt8WwESIfWZh72fCFQmbP28bj0FpygP1HFGW3B33zdeCx", "yE4MaFKaWa": "dhJpgBat1NgJQaMEEBqZDST4ESoloYc25EEmf5E0PU1EanD7qv", "Q8NpC0rBZL": "SIP6JEe28NDqJiHp9DTHC0n7nFD3DmXxSyKRrMaLiJMHxPVwDh", "Qk1C7ad9Wt": "0tOCt6RAwCTEx6eSZSUzfB4eDyBMa2nkHmb64juWvWKJB8qzU4", "ZjMKEIDEzJ": "tIIcfageYwBls4OQIINrlHpqZzpx59q42RZahXy0L6tqP3YsKO", "4iEUFO4Mgl": "dwzVErZHuCZery8jIkB57bTsj60ljjvkn9Gm2x1J32Q4dWdQzu", "XYbCKstgZ8": "rdknuXntYlnBUizBEnKSk6ChJgrVRoD7laWKB9VZ7FE2jjc0xN", "xqvJiyF1VP": "Eic9e0sFJgQOwjvUPUIuDQ7z8AP1lG4urIr3g5sIxNIfoYwLQQ", "CTE5J4PNu0": "Pig3OJxG9A50iebnDVGErPrgRnxMBlmBgkoTwr75EqYarGXq6X", "sggpfnqwZS": "1JfvrOxUvmWx2rC56Q65YI0kXtOZs2lNRhgsDStTSoaAgKzS7l", "D4oxPQd3Na": "4pA7hy4QiKGULPhgzJh9tTcuDzmmlSZ48tqK53CGzUJn6MZkOP", "03EQzwx6u4": "VIjNuLsHS9BEJfnIqqQZ6GWsGBcERRAv3aqHL0CZCgTYYNOCSK", "EaQs0YgM9H": "qb3RytBtKxIcVlgiQcR4R6RaWRKwFcN9Uo6k49UuBpqHnJJqQi", "gBbYKk4OX5": "oMmibywT536abOE3JQ1TXF4UdsaZdWnZ0i9au1Si2s1BnBihpv", "6dHUe4x9mt": "ELTYhDVxoX6rCWFad6JbBraVSD6gE4NqYt2QQj18ZncJBLDLyk", "NDshR459Ia": "HFT2ws7TMKw7xoqs6KIRmTFp7vKnVLdXEq4TXHlSx84hDYCinD", "5vS17Es5QH": "JInJW9wy4SkjVRjbpPNH1n4fuDEJAKxTjhqfBBBq7Nqcj175EE", "VmTrm5Pcer": "9FtajgmjiYbf6rL1srVPl2FHgZo6nEAQTaNnZmOtbEmQ3cKFnS", "nF8XrSdxhd": "7pH2PfWr3qSBGQzQducCmtg62wYE2MnrRWY6C7vWrnj7UyxmVh", "CYNMGx0V4j": "jFs5FDbrteZDuOBlt40NI2cylvhkW03hk8SgvrtS5DhX1qwq7B", "iUXRBc4g7l": "IxJjoakBihY1VSFquiNZXtoqJJWXZEML3HV6mqYsQ719ENKIYw", "iN8akXspwb": "ZvpNxKPC0D9IsrBcDr7gEWrUtGYcWAyYXf4NUvo8MejHRIU65b", "h3sGD2Q1oh": "OvxrT0OF9loNpckMysYWL0RTC6cpCVuo9LT99YJ1ViylK0MI2I", "KtqOvAWxa0": "A0IxZt61rn2LcAM73DFMsVQGwaYoY0bAEDl8MHfO8AVvURAkh7", "kAb8DKKONz": "Tq30H99bUDNXs825WoBOBLxaGYNY8X43zueEHiYkOLJg7Z0Eye", "myWjzOxJcO": "uHaUmKQn6banGCwmFumKkp69vfkdqYzzenYnaz3MEUbyoqL3dy", "MJiiDvQloZ": "yD47SUH4iA5DWxATZ45sbwtkhZqYeD0HaFASHXvIYLeV1gsx52", "hj2VGFzJvc": "puEeyRy18U69CtdYpvb7X0xumLcjgDg0uL1CCX9IhEtYl0VmfQ", "KsbJQGihmS": "Z3truNds88MvvDnAaEYqBq4s3O08irTyKVWlpjJo9m5t75OAwg", "88DcQGvkwN": "NRAeIZcDPqnjuihLCBBhwsqfF173vf9AZAWSVMtsWQKoVRXDwU", "gUtJzDhftY": "pIQoPw3X5I50A9FWt7vvw8y6Wy0eaYv5rcwm5jr8A1Zo6ZUKzQ", "jClPEd9IgK": "bSiQkQvKVWQQAApfAmP1lolszeorbzvsKTXDsDouxINELPgt5u", "g7dRJ56NBc": "amRHImU0uV2plQh7CUmMCOWLaVqh7yXg2nmEYfaxaza2SsqZNJ", "8ebalqa01L": "oZfi0pGagvNQolV2a56TZamgm3k97PDwvWKXrgNyhTJIr69b6w", "prdhMDmQFu": "xvdDoyjLLocu9vtYdcxAPnysk39nAOdoIw6T5y1j3KpfSKPr5q", "TavVmIIdAQ": "dzENXlVbgUh8Wdtkz7LZCNHpUe0NLtAXcdgqE5z6uJFYj8P9A3", "8dPYFRMbFO": "s53FCJGSYPpzHb3ljOv7fV23MZZ0gj67M7giQiTIcNv6w0O5BN", "GM4aaHYaRc": "oIFUmUoRAZRz3u5BxiAWOZVyC00G9mjwh883hafuCu4rjlB4u2", "l1hTQcxsl6": "plNQjWMAXTBcDdCXXoIxwhW7peXeJKfKZgQjqZeEx7pmUFE8gO", "nL8hoZxmke": "sPLURcIFTMFZkbrGiV4XiSQx250yd1VUduoG3x5DI6ZPsZV0wB", "RBPbJLkXfV": "CiFoFZS6hQ36nHf1If3s3ngiNbI4aRfEx5yNhz9MOIT8nmGmND", "UJNSyOc8w7": "7MsdjTKm5RrV3Dhtki7aNciyVbRdA8I6fJFCRoGE9DRjwqH5iC", "43dTF9n9PK": "Xw7I7s0GPEFcMU4hBlfq0kg80kJDJRoo4EwEwJ9tgKgKoZWabA", "FWfki0wTJB": "Dr61obcdBq0FKPSYFEwCHGOJ9ZecHwsDs6fJnjzzzip1dWkhWL", "VNPreOz3AU": "VWZQhWqMtLPJdP883aOvAX9tWrDOBrkooDRGjv2bJWhJeLsP4n", "KbBjSP3KNQ": "HURWjYngbj7FWSzOJR2aa5FDftRBq7jutYZJOru0utqqoDkbaq", "qwTCkP8hxs": "921ht3YU0JoUOLFe3gk4seRMqi3lNTYwmDIdoaj2dhY2eYf606", "b93OHmC4v6": "al6HrRKW1wzKAv7EUhyEm6GjrHYqo6Eohr5lUrktAUFUNj6Wcb", "imeDhsYenG": "qNqpx46966bH4bsT3ChSEoJerDEM3rnTH1RGubFFjmr0sOy9T7", "py6qIz053N": "xqLHyR5WZG5hrl0yViRda5R1Efup7bcdKMn5rftFZIdxzmKF7C", "UYEKHGW7AC": "A1FQyy7CoCkqvgISKxat5bDrK9YcmTxHhmVtp70KtnYlr53WAF", "iYRTAQcHYb": "fpcBpwYhZPR8LTOM8U3RMyHOVUyzWwriQNcuLiOMq3TFbBRxGX", "0AiBXP53Sx": "qFWkpFh8qei9iI98Yn04UC8viNogyTp7z8Qp0hlnTk1wfDdAM4", "BGuvVVZ87m": "9gN4Xf3GjlG0hXJmJGDpSTQRFuDUqGmU2mSTNt29eRYBAyn5dn", "Emcy4Xwcd4": "HBjXSQ99Ob2PQ0dLw9wtePihaRTcQ243YPnl3XnqeXzsFNtrTm", "F8NPfHMZjM": "qc4uBdspVfWWRrtsuZpU1u0Ar5mcnMD8AiipPpDIm2EW5PSteR", "S85Zp4tPiN": "JVAOT6w8PObCJB8werBOsyj0FVkuTFDnsyxoDEEfnwAnG47QCd", "FpIspARB8L": "U5huzomiwyIBWOdcont9LXAb1nxdDayAfrKDQt439QxbQaKDCY", "LCY19w45EI": "oOLChv6OY0u4k39DeJxLZTOpkvGAlPcPnvBbJqrP7o3QSuxlsw", "Tb0Pca2rvy": "RUbDK0Tblp9lJJoVguhgif4xES3juGwbCAaC7QbfEkURlSTKaw", "wgs4Byth20": "6E41JqpxxpBanUF5hraRN5tgVHTS3GmOxDeubA6bXfBKSkh77E", "0U9Kgyc73m": "w72jNnjqBQyTQtGvC8sj5jbuu6N5yB1PFuEQDaJpxzc2MP9d09", "l4u8EMUtMy": "MP95DO9MejlyTQx24EmOqWhpWimy6rvzn6Q4OnPoiuHo6fYy1g", "uPgWEEldfa": "aF4PnBe3WfZVmlgi2WKZ1Q9h9YloNTDZp53MNs94qGMNPedJwe", "dbsqzsW5kz": "eyVEsEnW3jDMEmY19ghi8ws4Ca2XdtC1CmkU5MylSq4EPiD1Zt", "frBu64OrNM": "rIk04EgaM7wBhsplzAbBPW26oBs3giEam6w9FzKy7EvxU1DGF9", "XA1VgPBMc8": "fZHB2RaWdt3BWcwi94TMwkWPuLeB29b4tFFQmDyMc2STjYfrcc", "fWFOfLCLq2": "hSMeD5ftoChCGlQWlBHuCPnQZpn4YMxvjuJXcqbtmLR4a5YYwR", "IG8rBmoCLP": "2rjrIsor7oVhmcJ4ukazX8d5AChMYAmglSWFjN6vVGTqBjAxnn", "SuRs5JbTu3": "DiZrLVe7JqJXf6WtnuBj4IYpTNZSBe7MlItMBJ7U4NsJTwhvrT", "dzxxgYcyxq": "dcwrdGKDigL2AKHycNWWnpsoITXqVBrt91J6p4dkCKKRMqnRfA", "rngI8gLd7P": "Oi7OVtSn2J93pv0ocpiwRXCIII0bs7ntQEY1OcWlPW7wzOAGZd", "jMOSkJ3O7K": "pnc7JHESSlJZFvXMdnCzzORnTGCPMSNEyBMuaqEOZiGG7kuxmP", "Ey31DW15iq": "q7vtANcI6s6UyZHp8Uliox1FIKtHoGxSMWghZHVXWGkc7r5kGw", "WYyGnw8FjI": "nMDpoJ14ZwOE9PKMLCPdlycbfQxHGAr5aCUJY9UoL7jqdjO0xz", "88abywFq3g": "OkS9uo5rIHcRSykZg5formZxmMG98b9yykrXpY1a76kxvl01Tb", "ejlCBtr16F": "3b5yuYQaBhiqpbeOnAGvvIwHzhQ2Tap29Z61R5SLAXLuBOiBU6", "zYHFMRSGpv": "gmx60suBJAMCpZ9waHYlmA0jei1ZfLo9QwdkYp6VRSTRMxy9zI", "Tudwv1e4YD": "HmDx6C2Ztpi3OdH0TsNFhqO2b2iPDDifjjA0GGTIgdG9Xehl4Q", "lXLMxU0kK8": "2EMOajMoUglcMavOMTLsug5nFOa1wUQqQopppbtMLlNGBx046W", "C9tmsuVUFW": "bOFlE0M9slqCSnjTPu4Tj6uXM9tpuXJ6p6sDyQxCv91sWCtnFw", "1TY97rLz5F": "HDciTNZVwVaWt6GGF0d3fFdkYubX5WpOqsfX5On2r2GkKWw56o", "ZvAntipLrt": "kFmVTxtBW088igfpJFXBchttabreHiosPpudJkgxsPO9kBDv2N", "bhbYGXSU6e": "a0Ggh9vyBG4dVKC6RVMRxe06Ia63iiGogJIG8ZGTware0IhV1E", "mEiP4ko4Nd": "z44zp9AUP3fILAqu9jQOuXjWjmoI2SmNPnnjH34umGupjrRjP9", "Vv6ITo99E8": "6u2gHvSvcflntsIr7R554PxmBLmcdAH5UBc3dUa5ELi82a1HrH", "QOE2C0DCaP": "XwlPbkABq74sBjOSER6j8lFpcho6AUZohZx0q5HincaXuC2R1f", "uNTxXAnuRs": "r4x1i4zcPAtUVJaxiUSRMiDwhRBiScZXEIIjAeHQkbO3J1hjQJ", "lDK7spl1ec": "nAVx1P8TdwLUNYkhMUfE9tFoTxRB8zhfJEMsPMm4cSNTAJkEyC", "F2Db2VH573": "qTkHCQYRg9OPzOKDgGwgNC9YWaDZyzAgDrfQgVNW7onXVgGjrH", "3zbLzbAjn3": "97oPocB9rqUCeSNPsp1xRw6zJTxWDuA31WrvSXGdfsKHWmsMcP", "3WiJfOtn4Y": "3hkk4ARReuYPTeKok932Jc4vzqwDxL839Db3scQ1TxeKijzbtZ", "tDVL0JZOHp": "zDAHLxRYmFenbqpeyWuVXPEpv0ugt2YziaPcYD0i3we1PuHcrZ", "pY964Difxg": "dy6NOoINetkU8eAASWARG7biIMAmS3iufVzoY84iA0kADnKe18", "HaNtX9khZ7": "AO6BXDWWgEMw6VMaCGxjWm5BWBLZmdUJdttZE69CMCSKoAwVAX", "QXYhjHxLH7": "e0YC7ZpzBPKUYAFwmTUFOaerzYJlA4N9kVi2LLZOG6bV5vlqOY", "wLTYyJXzmq": "Iz54kxdIe2r9xcAxfbMZZ1umkOWMtcR6tDqkI5jjwboISH4bzh", "aEzIfiRh6W": "yzjKa1kRvRhkvkCWpaflBlf1S1lxMCSlmCeV23GZovLqR6ln6M", "KhDbwTBCMX": "HUV2lPHpRzQcut4AyRHbLWlxYGiwR8InSrCRM1zU6LvKbTZtvf", "Z8ylcNPb7D": "vK28xx8ctW0ynxqIlPByDWxNuBttck3KmErS4aMtLvtoYXHBlL", "J2pbyd26kn": "uIVU2WXqwbYCOzSjp9G28JiiVMFX3YlZQukR7JN18ysAJaeLeT", "tnoE8UMXuf": "4aWvweOXFh0sWAC6kii8Ua6GXbILNrhy8o4FwtjUnNV33uW1Vi", "Z2DJKCTi4b": "3FaeXYxFco3Q49czLHNu0dLHjJxz6maQrtMSvBJrQiH0aP5KoE", "ZZNLVA68kr": "jQ3EGir0IQZv9ESM3vJAbJg2g49tuUEe80oyumdMYTq9CLsKFk", "VdjyL8Y4M6": "MizKVnhwSDiEZJK1PnO0MPdKZJeUv5yEvltWfcVSU29NxwCGPg", "ZzqXszmWVW": "eKiU714hADGd7EH14cBMNwtKkfMMXwmgTfs81CDmd05Y8btZ9p", "kJTPKepNMy": "arZSrfBBBS0MWMEP2MHCgDIMPObJ2lnztoGjVWUHa2RRWLdYqo", "KBTsJsJReO": "j7N4t67NR5EX7BXqGT39MQfZMef75q9GtdX9oZMuIkokOy1dS6", "HbSRlBFEPT": "kSfV2jNKMLc5TmdtzrgXjTMyYe7mpZjjZK12jJm6xZ7Hj13I56", "dQkNkJbvXs": "N5JSw66ImKmJ331xc2hAOzSzc69iAeurfCvXdvF57XwlkbsQyO", "kAc72N8pQ2": "q4rhDJA0PiAQSj8sRhRzuYVLtKuF5DHOGS8cnUf8TMRqctvMgv", "WlIz8w2MEi": "xf7aTGQdQ2QGxUFnFI8wmdRX7jG0EfwRcmbEjVqdbNoFSeHKjW", "faJrI28cHo": "23IKGc9iYwp6vm1qmKxIc1ubnIV6qCPjfDNr6Cq01dSzfzzgD4", "7NSIPYfkqx": "aNG1Njg0pZXCasTmihN6XMvuabOP2wqqXAaqm2GduEpFMUzakv", "T7CuRX0sn3": "3SNBzKxvJ3gUab1R63rD7qQsZAssAGcpMwat5DcJZ8OcR7hLRD", "czwSWcT2qK": "EgVUiAsbXdEKV24NEl5k2PYYuWqm5s8ksaINX19VRLzzGTCsoZ", "T3T7TYZUzb": "vKs8ZuTtx1MMCkKrSm81JNmtYyRDICI7mz0FqqE9xHbTNhK6UK", "0xEwQaIuHu": "PhF2zLesYnYPhFgKjJ6jguz4sDtyL91yFrDi4kCTINLoGkopEX", "Pj1Ns87ZIw": "2WhBkjzp79JLoiIbuhyzZcW1Eqf8DsJcBfX3Mf7muLGCu29aLj", "JisWiiuOuN": "fcipVfGSI0ui82h0iP83Ij6rVpQifgCey6WPEYK9Nzx1OJqaH8", "TmqT6QrO69": "NNDnsnv6LM27cQaTUZIAxgS3jLfBLprST1orYQOruiWBzIVQdd", "v6BnPNaR6X": "RSlNISMir21A36Su4WRyQWEeN1D7pgZRFesv0cjIKX3ft1wBWc", "RMVdVuiYCi": "daf6EeNmQosc5JXuK8Jd6rxi5Wrp99wGStSYXBkqQF8J1o9fme", "vwUDGwNC02": "f81Eu907pgBY2No3DSBw1pVsUQIVF7qowqBTDPi6mT54WrxGC0", "eyUMmjx6z3": "PIp20GF5NMq6hwa16uLOJpYmijILfJ0ITQv8KsS9VQk0WUFxGp", "siJnrcouKa": "xt6NkWYv7X7TQOfO8XrE1pFi3UPdncxpT1VJmxRKXkZoHhSRFg", "KhrgkkF2qn": "uZawMN0NyqDHIzfHF0dbrxVZbtXs8F7L1Q3uRBjAgrqyqbMDAU", "Mjdm7IOPGE": "yOVvcNaofta3G9P9PO7sw2PLtvzXQBjFMHqoEnatOCnwvi89Xp", "cOBAmCeZT1": "dOzyLytrk7nok25eQp6TzPwtnvNFJBmgMyXbRgaXso5J1KQtTu", "RX8zzE1uch": "dfGV451NGXMOocG0IXwaVYiN0UlfQq3l95fdMttgpYeU7F5koC", "P8EbX0AONK": "DgHt0hlRTmNlPau0pXQvNTjpN523cqYxJZmFC0fFrJJCVRwVLx", "ksL3e2rB0a": "m3eNWVMJMvxvFLG7qfdVQyvCKqGSvoAmerKTvaqLvykYoq6exP", "WVqQi6DSBe": "4h3z7fAsnQSXh8c1JNyPWgLxM5q9s4fIYhyxp3tz6LboR8V6qJ", "Ij8xASdp1f": "4lwTew4mLA5GwoOpWbjwLRz7cCTaDxpzZLbgiHziMDLbaYTQAz", "SpzWVcMXMB": "RQMIwP6jNuKTPIyaguWi1wNVxbr7FwYpIBGX3PsUWWD16f56ml", "s4Evsie7m6": "IL2YJ8s60ozzTxWrQaeZpqu3Skao4JvBJw5gbEzt2nBFGtBgPL", "0XSVlS45GO": "FdgkVC0lXDoXwUnvqRJCWObbDeeExbBBaZq7KOqOeOXFwW1Zrp", "XFn1ixGW1g": "h6FP6WoxjaD13FD13qPPXGuNWeaq3Nc2wm07zvhM2HsWJxCbqY", "2jja0AL3Rn": "kbNZjKC32zVvSas7nODpV57AifD9xVcWYvMnoYhhvOe4mfI1ol", "spmhomxSDw": "bb4sFM2LHLogBw96G3trjUYjACepDe66cEEghsD8QFn9AgpAtN"}



================================================
FILE: tests/data/files/test-docx.docx
================================================
[Non-text file]


================================================
FILE: tests/data/files/test-html.html
================================================
<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <link rel="shortcut icon" href="%PUBLIC_URL%/favicon.ico" />
    <meta name="viewport" content="initial-scale=1, width=device-width" />
    <title>
      my secret phrase from html head TITLE is FIRST HTML SECRET PHRASE from
      head TITLE
    </title>
    <!-- Fonts to support Material Design -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;600;700&display=swap"
    />

    <link
      href="https://fonts.googleapis.com/css2?family=Public+Sans:wght@400;500;600;700;800;900&family=Barlow:wght@400;500;600;700;800;900&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <noscript>You need to enable JavaScript to run this app.</noscript>
    <div id="root">my secret phrase from html is SECOND HTML SECRET PHRASE</div>
  </body>
</html>



================================================
FILE: tests/data/files/test-md.md
================================================
# My Markdown File

This is a test markdown file. Feel free to add your own content here.

My secret pharse is: **"FIRST MD SECRET PHRASE"**



================================================
FILE: tests/data/files/test-txt.txt
================================================
Hello, world! This is a test file.

My secret is: FIRST TXT SECRET PHRASE



================================================
FILE: tests/data/files/test-xml.xml
================================================
<root>
    <element1>Value 1</element1>
    <element2>Value 2</element2>
    <element3>My secret phrase is</element3>
    <element3>"FIRST XML SECRET PHRASE "</element3>
</root>



================================================
FILE: tests/data/schemas/ga4.json
================================================
{
  "openapi": "3.1.0",
  "info": {
    "title": "Query GA4 Data",
    "description": "Google Analytics 4 API",
    "version": "v1.0.0"
  },
  "servers": [
    {
      "url": "https://query-ga4-data-gntxktyfsq-uc.a.run.app"
    }
  ],
  "paths": {
    "/": {
      "post": {
        "description": "Parameters for querying the Google Analytics 4 API runReport endpoint.",
        "operationId": "runReport",
        "parameters": [],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/RunReportParams"
              }
            }
          },
          "required": true
        },
        "deprecated": false,
        "security": [
          {
            "apiKey": []
          }
        ]
      }
    }
  },
  "components": {
    "schemas": {
      "RunReportParams": {
        "properties": {
          "date_ranges": {
            "description": "List of date ranges to query.",
            "items": {
              "$ref": "#/components/schemas/DateRangeSchema"
            },
            "title": "Date Ranges",
            "type": "array"
          },
          "metrics": {
            "description": "List of metric names to query.",
            "items": {
              "$ref": "#/components/schemas/MetricSchema"
            },
            "title": "Metrics",
            "type": "array"
          },
          "dimensions": {
            "anyOf": [
              {
                "items": {
                  "$ref": "#/components/schemas/DimensionSchema"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "default": [],
            "description": "List of dimension names to query.",
            "title": "Dimensions"
          },
          "order_bys": {
            "anyOf": [
              {
                "items": {
                  "$ref": "#/components/schemas/OrderBySchema"
                },
                "type": "array"
              },
              {
                "type": "null"
              }
            ],
            "default": [],
            "description": "List of order bys to query.",
            "title": "Order Bys"
          },
          "limit": {
            "default": 5,
            "description": "Limit of the query. Defaults to 5.",
            "title": "Limit",
            "type": "integer"
          }
        },
        "required": ["date_ranges", "metrics"],
        "type": "object"
      },
      "DateRangeSchema": {
        "description": "Represents a date range for the GA4 query.",
        "properties": {
          "start_date": {
            "description": "Start date of the query.",
            "title": "Start Date",
            "type": "string"
          },
          "end_date": {
            "description": "End date of the query.",
            "title": "End Date",
            "type": "string"
          }
        },
        "required": ["start_date", "end_date"],
        "title": "DateRangeSchema",
        "type": "object"
      },
      "DimensionSchema": {
        "description": "Represents a dimension for the GA4 query.",
        "properties": {
          "name": {
            "description": "Name of the dimension.",
            "title": "Name",
            "type": "string"
          }
        },
        "required": ["name"],
        "title": "DimensionSchema",
        "type": "object"
      },
      "MetricSchema": {
        "description": "Represents a metric for the GA4 query.",
        "properties": {
          "name": {
            "description": "Name of the metric.",
            "title": "Name",
            "type": "string"
          }
        },
        "required": ["name"],
        "title": "MetricSchema",
        "type": "object"
      },
      "OrderBySchema": {
        "description": "Represents an order by condition for the GA4 query.",
        "properties": {
          "dimension_name": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "description": "Dimension name to order by. Can either be a metric or a dimension.",
            "title": "Dimension Name"
          },
          "metric_name": {
            "anyOf": [
              {
                "type": "string"
              },
              {
                "type": "null"
              }
            ],
            "description": "Metric name to order by. Can either be a metric or a dimension.",
            "title": "Metric Name"
          },
          "desc": {
            "default": true,
            "description": "Whether to order by descending or ascending.",
            "title": "Desc",
            "type": "boolean"
          }
        },
        "required": ["dimension_name", "metric_name"],
        "title": "OrderBySchema",
        "type": "object"
      }
    },
    "securitySchemes": {
      "apiKey": {
        "type": "apiKey"
      }
    }
  }
}



================================================
FILE: tests/data/schemas/get-headers-params.json
================================================
{
  "openapi": "3.1.0",
  "info": {
    "title": "Get Headers",
    "description": "Get headers endpoint",
    "version": "v1.0.0"
  },
  "servers": [
    {
      "url": "https://{domain}-gntxktyfsq-uc.a.run.app/"
    }
  ],
  "paths": {
    "/": {
      "get": {
        "description": "This is a test function to return all request headers.",
        "operationId": "PrintHeaders",
        "parameters": [
            {
                "name": "query",
                "in": "query",
                "description": "Query test parameter. Should be 'test'",
                "required": true,
                "schema": {
                    "type": "string"
                },
                "example": "test"
            },
            {
                "name": "domain",
                "in": "path",
                "description": "Domain parameter. Should be 'print-headers'",
                "required": true,
                "schema": {
                    "type": "string"
                },
                "example": "print-headers"
            }
        ],
        "requestBody": {},
        "deprecated": false,
        "security": [
          {
            "apiKey": []
          }
        ]
      }
    }
  },
  "components": {
    "schemas": {
      "RunReportParams": {
        "properties": {},
        "type": "object",
        "required": []
      }
    },
    "securitySchemes": {
      "apiKey": {
        "type": "apiKey"
      }
    }
  }
}



================================================
FILE: tests/data/schemas/get-weather.json
================================================
{
  "openapi": "3.1.0",
  "info": {
    "title": "Get weather data",
    "description": "Retrieves current weather data for a location.",
    "version": "v1.0.0"
  },
  "servers": [
    {
      "url": "https://weather.example.com"
    }
  ],
  "paths": {
    "/location": {
      "get": {
        "description": "Get temperature for a specific location",
        "operationId": "GetCurrentWeather",
        "parameters": [
          {
            "name": "location",
            "in": "query",
            "description": "The city and state to retrieve the weather for",
            "required": true,
            "schema": {
              "type": "string"
            }
          }
        ],
        "deprecated": false
      }
    }
  },
  "components": {
    "schemas": {}
  }
}



================================================
FILE: tests/data/schemas/relevance.json
================================================
{
  "info": { "title": "Relevance AI Tools", "version": "latest" },
  "paths": {
    "/studios/0d0bc745-53da-4c11-9893-bb7c93011a43/trigger_llm_friendly": {
      "post": {
        "operationId": "Test_tool",
        "summary": "Test Tool",
        "description": "",
        "security": [{ "AuthorizationHeader": [] }],
        "requestBody": {
          "content": {
            "application/json": {
              "schema": {
                "$ref": "#/components/schemas/0d0bc745-53da-4c11-9893-bb7c93011a43RequestBodySchema"
              }
            }
          },
          "required": true
        },
        "responses": {
          "200": {
            "description": "successful operation",
            "content": { "application/json": {} }
          }
        }
      }
    }
  },
  "openapi": "3.0.0",
  "servers": [{ "url": "https://api-bcbe5a.stack.tryrelevance.com/latest" }],
  "components": {
    "schemas": {
      "0d0bc745-53da-4c11-9893-bb7c93011a43RequestBodySchema": {
        "properties": {
          "text": {
            "type": "string",
            "frontend_metadata": { "required": true },
            "order": 0,
            "title": "test_field",
            "description": "Test field"
          }
        },
        "required": ["text"],
        "type": "object"
      }
    },
    "securitySchemes": {
      "AuthorizationHeader": {
        "type": "apiKey",
        "in": "header",
        "name": "Authorization",
        "description": "Authorization credentials. Header authorization should be in the form of: project:api_key"
      }
    }
  },
  "security": [{ "AuthorizationHeader": ["Authorization"] }]
}



================================================
FILE: tests/data/tools/ExampleTool1.py
================================================
from pydantic import Field

from agency_swarm.tools import BaseTool


class ExampleTool1(BaseTool):
    """Enter your tool description here. It should be informative for the Agent."""

    content: str = Field(
        ...,
        description="Enter parameter descriptions using pydantic for the model here.",
    )

    def run(self):
        # Enter your tool code here. It should return a string.

        # do_something(self.content)

        return "Tool output"



================================================
FILE: tests/demos/__init__.py
================================================



================================================
FILE: tests/demos/demo_gradio.py
================================================
import sys

sys.path.insert(0, "./agency-swarm")

from agency_swarm import Agent
from agency_swarm.agency.agency import Agency
from agency_swarm.tools.BaseTool import BaseTool
from agency_swarm.tools.oai import CodeInterpreter, FileSearch


class PrintTool(BaseTool):
    def run(self, **kwargs):
        print("This is a test tool from BaseTool.")
        return "Printed successfully."


class AnotherPrintTool(BaseTool):
    def run(self, **kwargs):
        print("This is another test tool from BaseTool.")
        return "Another print successful."


ceo = Agent(
    name="CEO",
    description="Responsible for client communication, task planning and management.",
    instructions="Analyze uploaded files with myfiles_browser tool.",  # can be a file like ./instructions.md
    tools=[FileSearch, CodeInterpreter, PrintTool, AnotherPrintTool],
    file_search={"max_num_results": 50},
)


test_agent = Agent(
    name="Test Agent1",
    description="Responsible for testing.",
    instructions="Read files with myfiles_browser tool.",  # can be a file like ./instructions.md
    tools=[FileSearch],
)

test_agent2 = Agent(
    name="Test Agent2",
    description="Responsible for testing.",
    instructions="Read files with myfiles_browser tool.",  # can be a file like ./instructions.md
    tools=[FileSearch],
)


agency = Agency(
    [
        ceo,
        [ceo, test_agent],
        [test_agent, test_agent2],
    ],
    shared_instructions="",
    settings_path="./test_settings.json",
)

# agency.demo_gradio()

print(agency.get_completion("Use 2 print tools", yield_messages=False))



================================================
FILE: tests/demos/demo_mcp.py
================================================
import sys

# Ensure the agency_swarm package is found
sys.path.insert(0, "./agency-swarm")

from agency_swarm import Agent
from agency_swarm.agency.agency import Agency
from agency_swarm.tools.mcp import MCPServerSse, MCPServerStdio

# --- IMPORTANT ---
# This demo requires the example SSE server to be running.
# Please run the following command in a separate terminal before executing this script:
# python tests/scripts/server.py
# --- IMPORTANT ---

# Define the SSE MCP Server connection
sse_server = MCPServerSse(
    name="SSE_Python_Server",
    params={"url": "http://localhost:8080/sse"},
    strict=False,
)

# Define an MCP server for filesystem access
filesystem_server = MCPServerStdio(
    name="Filesystem_Server",
    params={
        "command": "npx",
        "args": ["-y", "@modelcontextprotocol/server-filesystem", "."],
    },
    strict=False,
    # If you want to restrict agent to certain tools from the server, specify them in the allowed_tools
    allowed_tools=["list_allowed_directories", "list_directory", "read_file"]
)

# Define an agent that uses both MCP servers
mcp_agent = Agent(
    name="MCPAgent",
    description="An agent demonstrating MCP SSE and Stdio server usage.",
    instructions="You have access to an SSE server and a Filesystem server. Use the 'get_secret_word' function from the SSE_Python_Server tool OR list files using the Filesystem_Server tool.",
    mcp_servers=[sse_server, filesystem_server],
    temperature=0.1,
)

# Create the agency
agency = Agency([mcp_agent])

print("-----------------------------------------------------")
print(" Agency Swarm - MCP Demo")
print("-----------------------------------------------------")
print("This demo showcases an agent (`MCPAgent`) equipped with two MCP servers:")
print(
    "  1. SSE Server: Connects to a local SSE server to fetch a secret word or get the current weather."
)
print(
    "  2. Filesystem Server: Connects to a local filesystem server to list/read files."
)
print("-----------------------------------------------------")
print("IMPORTANT: Ensure the SSE server is running in a separate terminal:")
print("$ python tests/scripts/server.py")
print("-----------------------------------------------------")
print("Starting interactive demo session...")
print("Try asking the agent to perform tasks using its MCP tools, for example:")
print("  - 'Get the secret word'")
print("  - 'Summarize the contents of the README.md file in 5 bullet points'")
print("  - 'What is the weather in Tokyo?'")
print("-----------------------------------------------------")

try:
    agency.run_demo()
except Exception as e:
    # Using logger.error for consistency after refactoring
    # Assuming logger setup exists or adding basic setup if needed
    import logging

    logger = logging.getLogger(__name__)
    if not logger.hasHandlers():  # Check if logger is already configured
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        )
    logger.error(f"\nAn error occurred during the demo: {e}", exc_info=True)



================================================
FILE: tests/demos/demo_observability.py
================================================
import logging

from dotenv import load_dotenv

from agency_swarm import Agency, Agent
from agency_swarm.util import init_tracking, stop_tracking

# Configure logging
logging.basicConfig(level=logging.DEBUG)
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("openai").setLevel(logging.WARNING)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()


def setup_agency():
    """Create agents and configure the agency with communication flows"""
    ceo = Agent(
        name="CEO",
        instructions="You are the CEO.",
        description="Manages projects and coordinates between team members",
    )

    developer = Agent(
        name="Developer",
        instructions="You are the Developer.",
        description="Implements technical solutions and writes code",
    )

    analyst = Agent(
        name="Data Analyst",
        instructions="You are the Data Analyst.",
        description="Analyzes data and provides insights",
    )

    return Agency(
        [
            ceo,  # CEO is the entry point
            [ceo, developer],  # CEO can communicate with Developer
            [ceo, analyst],  # CEO can communicate with Analyst
            [developer, analyst],  # Developer can communicate with Analyst
        ],
        temperature=0.01,
    )


def run_demo():
    """Run the observability demo"""
    init_tracking("langfuse")
    init_tracking("agentops")
    init_tracking("local")

    agency = setup_agency()

    output = agency.get_completion("Send a test message to Developer")
    logger.info(f"Response: {str(output)}")

    stop_tracking()
    print(
        "\nDemo completed. Check AgentOps/Langfuse dashboard and local SQLite database for the results."
    )


if __name__ == "__main__":
    run_demo()



================================================
FILE: tests/demos/streaming_demo.py
================================================
import time

from agency_swarm import Agent, BaseTool
from agency_swarm.agency.agency import Agency
from agency_swarm.constants import DEFAULT_MODEL_MINI


class TestTool(BaseTool):
    def run(self):
        time.sleep(10)
        print("done")
        return "Test Successful"


def main():
    ceo = Agent(
        name="ceo",
        instructions="You are a CEO of an agency made for testing purposes.",
        model=DEFAULT_MODEL_MINI,
    )
    test_agent1 = Agent(name="test_agent1", tools=[TestTool], model=DEFAULT_MODEL_MINI)
    test_agent2 = Agent(name="test_agent2", model=DEFAULT_MODEL_MINI)

    agency = Agency(
        [
            ceo,
            [ceo, test_agent1, test_agent2],
            [ceo, test_agent2],
        ]
    )

    agency.demo_gradio()


if __name__ == "__main__":
    main()



================================================
FILE: tests/demos/term_demo.py
================================================
import json
import sys

from agency_swarm.agency.agency import Agency, Agent
from agency_swarm.threads import Thread

sys.path.insert(0, "../agency-swarm")


def custom_serializer(obj):
    if isinstance(obj, Thread):
        return {
            "agent": obj.agent.name,
            "recipient_agent": obj.recipient_agent.name,
        }
    raise TypeError(f"Type {type(obj)} not serializable")

ceo = Agent(
    name="CEO",
    description="Responsible for client communication, task planning and management.",
    instructions="Test agent",
)


test_agent1 = Agent(
    name="test_agent1",
    description="Responsible for testing.",
    instructions="Test agent",
)

test_agent2 = Agent(
    name="test_agent2",
    description="Responsible for testing.",
    instructions="Test agent",
)

def main():

    agency = Agency(
        [
            ceo,
            [ceo, test_agent1],
            [ceo, test_agent2],
        ],
    )

    print(json.dumps(agency.agents_and_threads, indent=4, default=custom_serializer))

    agency.run_demo()


if __name__ == "__main__":
    main()



================================================
FILE: tests/scripts/server.py
================================================
from mcp.server.fastmcp import FastMCP

# Create server with explicit uppercase log_level
mcp = FastMCP("Echo Server", log_level="INFO", port=8080)


@mcp.tool()
def add(a: int, b: int) -> int:
    """Add two numbers"""
    # print(f"[debug-server] add({a}, {b})")
    return a + b


@mcp.tool()
def get_secret_word() -> str:
    # print("[debug-server] get_secret_word()")
    return "Strawberry"


@mcp.tool()
def get_current_weather(city: str) -> str:
    # print(f"[debug-server] get_current_weather({city})")

    # Return mocked weather data to avoid external dependencies in tests
    return f"Weather report: {city}\nTemperature: 22Â°C (72Â°F)\nCondition: Partly cloudy\nHumidity: 65%\nWind: 10 km/h"


if __name__ == "__main__":
    mcp.run(transport="sse")



================================================
FILE: .github/workflows/close-issues.yml
================================================
name: Close inactive issues
on:
  schedule:
    - cron: "30 1 * * *"

  workflow_dispatch:

jobs:
  close-issues:
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    steps:
      - uses: actions/stale@v5
        with:
          days-before-issue-stale: 30
          days-before-issue-close: 14
          stale-issue-label: "stale"
          stale-issue-message: "This issue is stale because it has been open for 30 days with no activity. Please upgrade to the latest version and test it again."
          close-issue-message: "This issue was closed because it has been inactive for 14 days since being marked as stale. If the issue still persists, please reopen."
          days-before-pr-stale: -1
          days-before-pr-close: -1
          repo-token: ${{ secrets.GITHUB_TOKEN }}



================================================
FILE: .github/workflows/publish.yml
================================================
name: Publish to PyPI.org
on:
  release:
    types: [published]
  workflow_dispatch:
jobs:
  pypi:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'
      - run: python3 -m pip install --upgrade build && python3 -m build
      - name: Publish package
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_API_TOKEN }}



================================================
FILE: .github/workflows/test.yml
================================================
name: Python Unittest

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '20.x'
    - uses: actions/setup-python@v5
      with:
        python-version: '3.13'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install ".[dev]"

    - name: Run tests
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      run: |
        cd tests && pytest -v


