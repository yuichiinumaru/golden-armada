#!/usr/bin/env python3
"""
DeepCode - CLI Application Main Program
æ·±åº¦ä»£ç  - CLIåº”ç”¨ä¸»ç¨‹åº

ðŸ§¬ Open-Source Code Agent by Data Intelligence Lab @ HKU
âš¡ Revolutionizing research reproducibility through collaborative AI
"""

import os
import sys
import asyncio
import time
import json

# ç¦æ­¢ç”Ÿæˆ.pycæ–‡ä»¶
os.environ["PYTHONDONTWRITEBYTECODE"] = "1"

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# å¯¼å…¥MCPåº”ç”¨å’Œå·¥ä½œæµ

from cli.workflows import CLIWorkflowAdapter
from cli.cli_interface import CLIInterface, Colors


class CLIApp:
    """CLIåº”ç”¨ä¸»ç±» - å‡çº§ç‰ˆæ™ºèƒ½ä½“ç¼–æŽ’å¼•æ“Ž"""

    def __init__(self):
        self.cli = CLIInterface()
        self.workflow_adapter = CLIWorkflowAdapter(cli_interface=self.cli)
        self.app = None  # Will be initialized by workflow adapter
        self.logger = None
        self.context = None
        # Document segmentation will be managed by CLI interface

    async def initialize_mcp_app(self):
        """åˆå§‹åŒ–MCPåº”ç”¨ - ä½¿ç”¨å·¥ä½œæµé€‚é…å™¨"""
        # Workflow adapter will handle MCP initialization
        return await self.workflow_adapter.initialize_mcp_app()

    async def cleanup_mcp_app(self):
        """æ¸…ç†MCPåº”ç”¨ - ä½¿ç”¨å·¥ä½œæµé€‚é…å™¨"""
        await self.workflow_adapter.cleanup_mcp_app()

    async def process_requirement_analysis_non_interactive(self, initial_idea: str):
        """å¤„ç†éœ€æ±‚åˆ†æžå·¥ä½œæµï¼ˆéžäº¤äº’å¼ï¼Œç”¨äºŽå‘½ä»¤è¡Œå‚æ•°ï¼‰ (NEW: matching UI version)"""
        try:
            self.cli.print_separator()
            self.cli.print_status(
                "ðŸ§  Starting requirement analysis workflow...", "info"
            )

            # Step 1: Generate guiding questions
            self.cli.print_status(
                "ðŸ¤– Generating AI-guided questions to refine your requirements...",
                "processing",
            )

            questions_result = (
                await self.workflow_adapter.execute_requirement_analysis_workflow(
                    user_input=initial_idea, analysis_mode="generate_questions"
                )
            )

            if questions_result["status"] != "success":
                self.cli.print_status(
                    f"âŒ Failed to generate questions: {questions_result.get('error', 'Unknown error')}",
                    "error",
                )
                return questions_result

            # Step 2: Display questions
            questions_json = questions_result["result"]
            self.cli.display_guiding_questions(questions_json)

            # For non-interactive mode, we can't get user answers, so we provide a summary
            self.cli.print_status(
                "â„¹ï¸  In non-interactive mode, using initial idea for implementation",
                "info",
            )
            self.cli.print_status(
                "ðŸ’¡ For guided analysis, please use interactive mode (python main_cli.py)",
                "info",
            )

            # Proceed directly with the initial idea as the requirement
            self.cli.print_status(
                "ðŸš€ Starting code implementation based on initial requirements...",
                "processing",
            )

            implementation_result = await self.process_input(initial_idea, "chat")

            return {
                "status": "success",
                "questions_generated": questions_result,
                "implementation": implementation_result,
            }

        except Exception as e:
            error_msg = str(e)
            self.cli.print_error_box("Requirement Analysis Error", error_msg)
            self.cli.print_status(
                f"Error during requirement analysis: {error_msg}", "error"
            )

            return {"status": "error", "error": error_msg}

    async def process_requirement_analysis(self):
        """å¤„ç†éœ€æ±‚åˆ†æžå·¥ä½œæµï¼ˆäº¤äº’å¼ï¼‰ (NEW: matching UI version)"""
        try:
            # Step 1: Get initial requirements from user
            self.cli.print_separator()
            self.cli.print_status(
                "ðŸ§  Starting requirement analysis workflow...", "info"
            )

            user_input = self.cli.get_requirement_analysis_input()

            if not user_input:
                self.cli.print_status("Requirement analysis cancelled", "warning")
                return {"status": "cancelled"}

            # Step 2: Generate guiding questions
            self.cli.print_status(
                "ðŸ¤– Generating AI-guided questions to refine your requirements...",
                "processing",
            )

            questions_result = (
                await self.workflow_adapter.execute_requirement_analysis_workflow(
                    user_input=user_input, analysis_mode="generate_questions"
                )
            )

            if questions_result["status"] != "success":
                self.cli.print_status(
                    f"âŒ Failed to generate questions: {questions_result.get('error', 'Unknown error')}",
                    "error",
                )
                return questions_result

            # Step 3: Display questions and get user answers
            questions_json = questions_result["result"]
            self.cli.display_guiding_questions(questions_json)

            # Ask if user wants to answer the questions
            proceed = (
                input(
                    f"\n{Colors.BOLD}{Colors.YELLOW}Would you like to answer these questions? (y/n):{Colors.ENDC} "
                )
                .strip()
                .lower()
            )

            if proceed != "y":
                self.cli.print_status(
                    "You can still use the initial requirements for chat input",
                    "info",
                )
                return {"status": "partial", "initial_requirements": user_input}

            user_answers = self.cli.get_question_answers(questions_json)

            # Step 4: Generate requirement summary
            self.cli.print_status(
                "ðŸ“„ Generating detailed requirement document...", "processing"
            )

            summary_result = (
                await self.workflow_adapter.execute_requirement_analysis_workflow(
                    user_input=user_input,
                    analysis_mode="summarize_requirements",
                    user_answers=user_answers,
                )
            )

            if summary_result["status"] != "success":
                self.cli.print_status(
                    f"âŒ Failed to generate summary: {summary_result.get('error', 'Unknown error')}",
                    "error",
                )
                return summary_result

            # Step 5: Display requirement summary
            requirement_summary = summary_result["result"]
            should_proceed = self.cli.display_requirement_summary(requirement_summary)

            if should_proceed:
                # Step 6: Proceed with chat-based implementation
                self.cli.print_status(
                    "ðŸš€ Starting code implementation based on analyzed requirements...",
                    "processing",
                )

                implementation_result = await self.process_input(
                    requirement_summary, "chat"
                )

                return {
                    "status": "success",
                    "requirement_analysis": summary_result,
                    "implementation": implementation_result,
                }
            else:
                self.cli.print_status(
                    "Requirement analysis completed. Implementation skipped.", "info"
                )
                return {
                    "status": "success",
                    "requirement_analysis": summary_result,
                    "implementation": None,
                }

        except Exception as e:
            error_msg = str(e)
            self.cli.print_error_box("Requirement Analysis Error", error_msg)
            self.cli.print_status(
                f"Error during requirement analysis: {error_msg}", "error"
            )

            return {"status": "error", "error": error_msg}

    async def process_input(self, input_source: str, input_type: str):
        """å¤„ç†è¾“å…¥æºï¼ˆURLæˆ–æ–‡ä»¶ï¼‰- ä½¿ç”¨å‡çº§ç‰ˆæ™ºèƒ½ä½“ç¼–æŽ’å¼•æ“Ž"""
        try:
            # Document segmentation configuration is managed by CLI interface

            self.cli.print_separator()
            self.cli.print_status(
                "ðŸš€ Starting intelligent agent orchestration...", "processing"
            )

            # æ˜¾ç¤ºå¤„ç†é˜¶æ®µï¼ˆæ ¹æ®é…ç½®å†³å®šï¼‰
            chat_mode = input_type == "chat"
            self.cli.display_processing_stages(
                0, self.cli.enable_indexing, chat_mode=chat_mode
            )

            # ä½¿ç”¨å·¥ä½œæµé€‚é…å™¨è¿›è¡Œå¤„ç†
            result = await self.workflow_adapter.process_input_with_orchestration(
                input_source=input_source,
                input_type=input_type,
                enable_indexing=self.cli.enable_indexing,
            )

            if result["status"] == "success":
                # æ˜¾ç¤ºå®ŒæˆçŠ¶æ€
                if chat_mode:
                    final_stage = 4
                else:
                    final_stage = 8 if self.cli.enable_indexing else 5
                self.cli.display_processing_stages(
                    final_stage, self.cli.enable_indexing, chat_mode=chat_mode
                )
                self.cli.print_status(
                    "ðŸŽ‰ Agent orchestration completed successfully!", "complete"
                )

                # æ˜¾ç¤ºç»“æžœ
                self.display_results(
                    result.get("analysis_result", ""),
                    result.get("download_result", ""),
                    result.get("repo_result", ""),
                    result.get("pipeline_mode", "comprehensive"),
                )
            else:
                self.cli.print_status(
                    f"âŒ Processing failed: {result.get('error', 'Unknown error')}",
                    "error",
                )

            # æ·»åŠ åˆ°åŽ†å²è®°å½•
            self.cli.add_to_history(input_source, result)

            return result

        except Exception as e:
            error_msg = str(e)
            self.cli.print_error_box("Agent Orchestration Error", error_msg)
            self.cli.print_status(f"Error during orchestration: {error_msg}", "error")

            # æ·»åŠ é”™è¯¯åˆ°åŽ†å²è®°å½•
            error_result = {"status": "error", "error": error_msg}
            self.cli.add_to_history(input_source, error_result)

            return error_result

    def display_results(
        self,
        analysis_result: str,
        download_result: str,
        repo_result: str,
        pipeline_mode: str = "comprehensive",
    ):
        """æ˜¾ç¤ºå¤„ç†ç»“æžœ"""
        self.cli.print_results_header()

        # æ˜¾ç¤ºæµæ°´çº¿æ¨¡å¼
        if pipeline_mode == "chat":
            mode_display = "ðŸ’¬ Chat Planning Mode"
        elif pipeline_mode == "comprehensive":
            mode_display = "ðŸ§  Comprehensive Mode"
        else:
            mode_display = "âš¡ Optimized Mode"
        print(
            f"{Colors.BOLD}{Colors.PURPLE}ðŸ¤– PIPELINE MODE: {mode_display}{Colors.ENDC}"
        )
        self.cli.print_separator("â”€", 79, Colors.PURPLE)

        print(f"{Colors.BOLD}{Colors.OKCYAN}ðŸ“Š ANALYSIS PHASE RESULTS:{Colors.ENDC}")
        self.cli.print_separator("â”€", 79, Colors.CYAN)

        # å°è¯•è§£æžå¹¶æ ¼å¼åŒ–åˆ†æžç»“æžœ
        try:
            if analysis_result.strip().startswith("{"):
                parsed_analysis = json.loads(analysis_result)
                print(json.dumps(parsed_analysis, indent=2, ensure_ascii=False))
            else:
                print(
                    analysis_result[:1000] + "..."
                    if len(analysis_result) > 1000
                    else analysis_result
                )
        except Exception:
            print(
                analysis_result[:1000] + "..."
                if len(analysis_result) > 1000
                else analysis_result
            )

        print(f"\n{Colors.BOLD}{Colors.PURPLE}ðŸ“¥ DOWNLOAD PHASE RESULTS:{Colors.ENDC}")
        self.cli.print_separator("â”€", 79, Colors.PURPLE)
        print(
            download_result[:1000] + "..."
            if len(download_result) > 1000
            else download_result
        )

        print(
            f"\n{Colors.BOLD}{Colors.GREEN}âš™ï¸  IMPLEMENTATION PHASE RESULTS:{Colors.ENDC}"
        )
        self.cli.print_separator("â”€", 79, Colors.GREEN)
        print(repo_result[:1000] + "..." if len(repo_result) > 1000 else repo_result)

        # å°è¯•æå–ç”Ÿæˆçš„ä»£ç ç›®å½•ä¿¡æ¯
        if "Code generated in:" in repo_result:
            code_dir = (
                repo_result.split("Code generated in:")[-1].strip().split("\n")[0]
            )
            print(
                f"\n{Colors.BOLD}{Colors.YELLOW}ðŸ“ Generated Code Directory: {Colors.ENDC}{code_dir}"
            )

        # æ˜¾ç¤ºå¤„ç†å®Œæˆçš„å·¥ä½œæµé˜¶æ®µ
        print(
            f"\n{Colors.BOLD}{Colors.OKCYAN}ðŸ”„ COMPLETED WORKFLOW STAGES:{Colors.ENDC}"
        )

        if pipeline_mode == "chat":
            stages = [
                "ðŸš€ Engine Initialization",
                "ðŸ’¬ Requirements Analysis",
                "ðŸ—ï¸ Workspace Setup",
                "ðŸ“ Implementation Plan Generation",
                "âš™ï¸ Code Implementation",
            ]
        else:
            stages = [
                "ðŸ“„ Document Processing",
                "ðŸ” Reference Analysis",
                "ðŸ“‹ Plan Generation",
                "ðŸ“¦ Repository Download",
                "ðŸ—‚ï¸ Codebase Indexing",
                "âš™ï¸ Code Implementation",
            ]

        for stage in stages:
            print(f"  âœ… {stage}")

        self.cli.print_separator()

    async def run_interactive_session(self):
        """è¿è¡Œäº¤äº’å¼ä¼šè¯"""
        # æ¸…å±å¹¶æ˜¾ç¤ºå¯åŠ¨ç•Œé¢
        self.cli.clear_screen()
        self.cli.print_logo()
        self.cli.print_welcome_banner()

        # åˆå§‹åŒ–MCPåº”ç”¨
        await self.initialize_mcp_app()

        try:
            # ä¸»äº¤äº’å¾ªçŽ¯
            while self.cli.is_running:
                self.cli.create_menu()
                choice = self.cli.get_user_input()

                if choice in ["q", "quit", "exit"]:
                    self.cli.print_goodbye()
                    break

                elif choice in ["u", "url"]:
                    url = self.cli.get_url_input()
                    if url:
                        await self.process_input(url, "url")

                elif choice in ["f", "file"]:
                    file_path = self.cli.upload_file_gui()
                    if file_path:
                        await self.process_input(f"file://{file_path}", "file")

                elif choice in ["t", "chat", "text"]:
                    chat_input = self.cli.get_chat_input()
                    if chat_input:
                        await self.process_input(chat_input, "chat")

                elif choice in ["r", "req", "requirement", "requirements"]:
                    # NEW: Requirement Analysis workflow
                    await self.process_requirement_analysis()

                elif choice in ["h", "history"]:
                    self.cli.show_history()

                elif choice in ["c", "config", "configure"]:
                    # Show configuration menu - all settings managed by CLI interface
                    self.cli.show_configuration_menu()

                else:
                    self.cli.print_status(
                        "Invalid choice. Please select U, F, T, R, C, H, or Q.",
                        "warning",
                    )

                # è¯¢é—®æ˜¯å¦ç»§ç»­
                if self.cli.is_running and choice in [
                    "u",
                    "f",
                    "t",
                    "r",
                    "chat",
                    "text",
                    "req",
                    "requirement",
                    "requirements",
                ]:
                    if not self.cli.ask_continue():
                        self.cli.is_running = False
                        self.cli.print_status("Session ended by user", "info")

        except KeyboardInterrupt:
            print(f"\n{Colors.WARNING}âš ï¸  Process interrupted by user{Colors.ENDC}")
        except Exception as e:
            print(f"\n{Colors.FAIL}âŒ Unexpected error: {str(e)}{Colors.ENDC}")
        finally:
            # æ¸…ç†èµ„æº
            await self.cleanup_mcp_app()


async def main():
    """ä¸»å‡½æ•°"""
    start_time = time.time()

    try:
        # åˆ›å»ºå¹¶è¿è¡ŒCLIåº”ç”¨
        app = CLIApp()
        await app.run_interactive_session()

    except KeyboardInterrupt:
        print(f"\n{Colors.WARNING}âš ï¸  Application interrupted by user{Colors.ENDC}")
    except Exception as e:
        print(f"\n{Colors.FAIL}âŒ Application error: {str(e)}{Colors.ENDC}")
    finally:
        end_time = time.time()
        print(
            f"\n{Colors.BOLD}{Colors.CYAN}â±ï¸  Total runtime: {end_time - start_time:.2f} seconds{Colors.ENDC}"
        )

        # æ¸…ç†ç¼“å­˜æ–‡ä»¶
        print(f"{Colors.YELLOW}ðŸ§¹ Cleaning up cache files...{Colors.ENDC}")
        if os.name == "nt":  # Windows
            os.system(
                "powershell -Command \"Get-ChildItem -Path . -Filter '__pycache__' -Recurse -Directory | Remove-Item -Recurse -Force\" 2>nul"
            )
        else:  # Unix/Linux/macOS
            os.system('find . -type d -name "__pycache__" -exec rm -r {} + 2>/dev/null')

        print(
            f"{Colors.OKGREEN}âœ¨ Goodbye! Thanks for using DeepCode CLI! âœ¨{Colors.ENDC}"
        )


if __name__ == "__main__":
    asyncio.run(main())
