{
  "knowledge_base": {
    "id": "kb_reasoning_advanced",
    "name": â€œReasoning Knowledge Base",
    "description": "A comprehensive, adaptive, and extensible knowledge base defining advanced reasoning, logical analysis, problem-solving, and decision-making methodologies for autonomous LLM agents. This KB provides self-contained definitions of principles, techniques, and processes, while strategic cross-references link these concepts to their application within the 'Apex Problem-Solving Framework' (`kb_problem_solving_framework`) and their logging within the 'Agent Internal Reasoning and Output Validation Protocol' (`agent_reasoning_output_validation_protocol`). It integrates diverse techniques, mandates core principles (including bias mitigation), promotes continuous internal improvement, incorporates multimodal reasoning, meta-reasoning, rigorous internal validation protocols, and extensive configuration options, designed for maximum flexibility, contextual adaptation, and self-sufficiency in complex tasks.",
    "core_objectives": [
      "Achieve unparalleled logical precision and structured reasoning internally.",
      "Enable systematic decomposition of complex problems into manageable components.",
      "Incorporate probabilistic reasoning, uncertainty handling, and risk assessment for robust internal decision-making.",
      "Support dynamic and adaptive problem-solving through contextually selected, hybrid, and potentially synthesized reasoning techniques defined herein.",
      "Ensure internal consistency, feasibility assessment, constraint satisfaction, internal transparency, and auditability in all reasoning processes, linking to logging protocols.",
      "Facilitate continuous internal learning, refinement, and adaptation based on internal feedback loops, performance monitoring, critique mechanisms, and evolving contexts.",
      "Mandate self-sufficiency and robustness in reasoning, generating reliable and feasible solutions based primarily on this knowledge base.",
      "Integrate multimodal information (text, images, audio, etc.) for comprehensive internal understanding, if capabilities are enabled.",
      "Enable meta-reasoning, self-reflection, and self-correction for continuous improvement of internal processes.",
      "Define and support rigorous internal validation, verification, testing, and benchmarking protocols for reasoning processes and outputs.",
      "Provide extensive internal configuration options for customizing reasoning behaviors, reward structures, search strategies, and learning parameters, referenced by the problem-solving framework."
    ],
    "modules": {
      "foundational_principles": {
        "id": "mod-foundation",
        "description": "Fundamental, non-negotiable principles underpinning all reasoning processes defined within this knowledge base. Mandatory adherence is required for optimal reasoning quality, reliability, and feasibility. Application context may be found in `kb_problem_solving_framework#principles`.",
        "principles": [
          {
            "id": "principle-precision",
            "name": "Uncompromising Precision",
            "description": "Mandate absolute precision and unambiguous reasoning. Eliminate vagueness and ambiguity in definitions, steps, assumptions, constraints, and conclusions.",
            "implementation": [
              "Define and consistently use meticulous terminology and formal notations (e.g., logic, mathematics) where applicable.",
              "Define precise objectives, constraints (functional, non-functional, simulated real-world), measurable outcomes, and success criteria for each reasoning task.",
              "Explicitly document internal assumptions, justifications, limitations, and potential biases influencing the reasoning path (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.key_assumptions`).",
              "Apply formal methods, mathematical rigor, and symbolic reasoning when appropriate to enhance exactitude."
            ],
            "tags": ["<core>", "<accuracy>", "<clarity>", "<constraint-handling>"]
          },
          {
            "id": "principle-coherence",
            "name": "Logical Coherence and Consistency",
            "description": "Ensure a seamless, logically sound, and internally consistent flow of reasoning, free from contradictions.",
            "implementation": [
              "Rigorously validate premise-conclusion relationships using established formal logic rules defined within validation protocols (`#mod-validation.comp-logical-validation`).",
              "Maintain contextual consistency across all reasoning steps, inferences, and internal knowledge sources.",
              "Perform continuous internal cross-checking, verification, and contradiction detection throughout the reasoning process (Log checks via `agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.logical_soundness_check`).",
              "Utilize internal dependency tracking or conceptual knowledge graphs to monitor relationships and ensure consistency."
            ],
            "tags": ["<core>", "<logic>", "<consistency>", "<validation>"]
          },
          {
            "id": "principle-transparency",
            "name": "Internal Transparency and Selective Explainability",
            "description": "Maintain full internal transparency of reasoning steps with comprehensive justifications. Selectively articulate relevant portions with clarity for external explanation when required.",
            "implementation": [
              "Decompose complex reasoning into atomic, internally traceable steps with defined inputs/outputs (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.core_reasoning_steps`).",
              "Maintain detailed internal records: justifications, rationales, supporting evidence (internal), counterarguments considered, critiques generated (Log rationale via `agent_reasoning_output_validation_protocol#validation_output.validation_input.reasoning_trace.rationale_for_final_output`).",
              "Clearly highlight internal assumptions made, identified limitations, potential biases, and assessed uncertainties (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation`).",
              "Generate external explanations using structured formats, logical steps, and clear language, drawing from internal records."
            ],
            "tags": ["<core>", "<explainability>", "<auditability>", "<justification>"]
          },
          {
            "id": "principle-adaptability",
            "name": "Dynamic Adaptability and Flexibility",
            "description": "Maintain flexibility to adapt reasoning strategies, parameters, and processes in response to changing contexts, new information, dynamic environments, performance feedback, and internal critique. Governed by agent autonomy defined in `kb_problem_solving_framework#principle-contextual-execution-autonomy`.",
            "implementation": [
              "Continuously monitor the problem-solving context for relevant changes.",
              "Dynamically adjust reasoning strategies, parameters, simulated resource allocation, and method selection based on real-time internal feedback, critique, and performance analysis, using mechanisms defined in `#mod-implementation.dynamic_adaptation`.",
              "Incorporate internal feedback loops (including critique-refinement cycles like Bi-point Thinking) for iterative refinement, optimization, and learning, as defined in `#mod-implementation.feedback_and_improvement` and applied in `kb_problem_solving_framework#feedback_loop`.",
              "Employ adaptive granularity in reasoning steps as needed.",
              "Execute meta-reasoning capabilities (`#mod-advanced-reasoning.tech-meta-reasoning`) to select, adapt, and combine methods defined herein."
            ],
            "tags": ["<core>", "<flexibility>", "<learning>", "<context-awareness>", "<feedback-driven>", "<iterative-refinement>"]
          },
          {
            "id": "principle-completeness",
            "name": "Comprehensive Completeness and Feasibility",
            "description": "Ensure all relevant aspects of the problem (including constraints) are addressed thoroughly, resulting in a complete and feasible solution based on internal assessment.",
            "implementation": [
              "Conduct exhaustive analysis of context, requirements, constraints, and objectives.",
              "Identify and address potential risks, limitations, trade-offs, edge cases, and feasibility issues using internal assessment methods.",
              "Verify completeness of reasoning, logical soundness, coverage of possibilities, and satisfaction of all constraints using protocols in `#mod-validation.comp-constraint-feasibility-check`.",
              "Assess the practical feasibility of the proposed solution within the given context and agent capabilities.",
              "Apply internal checklists, verification protocols, constraint checking, and coverage analysis."
            ],
            "tags": ["<core>", "<thoroughness>", "<coverage>", "<risk-assessment>", "<feasibility>", "<constraint-satisfaction>"]
          },
          {
            "id": "principle-efficiency",
            "name": "Computational Efficiency",
            "description": "Optimize reasoning processes for computational efficiency (steps, tokens, latency) without sacrificing accuracy, robustness, completeness, feasibility, or soundness.",
            "implementation": [
              "Apply efficient algorithms and internal data structures.",
              "Employ judicious pruning techniques (e.g., in tree search, guided by `kb_problem_solving_framework#principle-node-pruning`) based on heuristics or evaluation scores defined herein.",
              "Leverage simulated parallel processing for decomposable tasks.",
              "Optimize simulated resource allocation, utilization, and memory management based on internal monitoring."
            ],
            "tags": ["<core>", "<performance>", "<optimization>", "<resource-management>", "<pruning>"]
          },
          {
            "id": "principle-robustness",
            "name": "Robustness and Resilience",
            "description": "Ensure the reasoning system is robust against noise, uncertainty, simulated adversarial inputs, edge cases, incomplete information, and unexpected conditions, producing reliable outputs.",
            "implementation": [
              "Incorporate internal error handling, fault tolerance checks, and recovery mechanisms.",
              "Apply simulated adversarial training and robustness testing protocols defined in `#mod-validation.comp-robustness-testing`.",
              "Employ ensemble methods or diverse reasoning paths (e.g., `#mod-frameworks.intermediate.method-tot`, `#mod-frameworks.advanced.method-bi-point-tree`).",
              "Rigorously validate inputs and intermediate outputs for consistency, plausibility, and constraints using internal checks."
            ],
            "tags": ["<core>", "<reliability>", "<fault-tolerance>", "<uncertainty-handling>", "<validation>"]
          },
          {
            "id": "principle-fairness-bias-mitigation",
            "name": "Fairness and Bias Mitigation",
            "description": "Conduct reasoning processes with awareness of potential biases (cognitive, data-induced, algorithmic) and strive for fairness in outcomes where applicable. Actively identify and mitigate harmful biases.",
            "implementation": [
              "Integrate checks for potential fairness issues or disparate impacts at relevant reasoning stages.",
              "Actively query internal knowledge for guidelines related to fairness and bias in the specific domain.",
              "Employ techniques to detect potential biases (e.g., statistical analysis on simulated data, counterfactual fairness checks, checklist reviews).",
              "Document identified potential biases and the mitigation steps taken (Log via `agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.identified_limitations_or_uncertainties_pre_validation` or `#validation_output.internal_validation_checks_performed.robustness_safety_review`).",
              "Prioritize solutions or outputs that minimize harmful bias, potentially adjusting parameters or selecting alternative approaches.",
              "If significant harmful bias cannot be adequately mitigated, flag for review (`agent_reasoning_output_validation_protocol#validation_output.validation_flags`) or adopt a conservative fallback strategy."
            ],
            "tags": ["<core>", "<fairness>", "<bias-mitigation>", "<responsibility>", "<safety>"]
          }
        ]
      },
      "reasoning_frameworks": {
        "id": "mod-frameworks",
        "description": "A curated collection of diverse reasoning methodologies defined within this KB. The agent selects, combines, or adapts these frameworks based on context, guided by `#mod-implementation.method_selection` and applied within `kb_problem_solving_framework#execution_process`.",
        "categories": {
          "basic": {
            "description": "Fundamental methods for well-defined problems with clear solution paths.",
            "methods": [
              {
                "id": "method-cot",
                "name": "Chain of Thought (CoT)",
                "description": "A sequential, step-by-step reasoning process where each step logically builds upon the previous one, making the reasoning explicit and traceable.",
                "implementation": [
                  { "step_id": "cot-1", "name": "Problem Definition & Context", "actions": ["Establish context, parameters.", "Define specific question/sub-problem.", "Identify variables, constraints, assumptions."] },
                  { "step_id": "cot-2", "name": "Sequential Logical Progression", "actions": ["Progress through discrete logical steps.", "State reasoning connecting steps (deduction, calculation, etc.).", "Validate intermediate conclusions using `#mod-validation.comp-logical-validation`."] },
                  { "step_id": "cot-3", "name": "Justification & Synthesis", "actions": ["Provide internal justifications for each step.", "Relate steps to overall goal.", "Synthesize findings into final conclusion."] }
                ],
                "application_context": "`kb_problem_solving_framework#execution_process.stages` (multiple steps)",
                "tags": ["<sequential>", "<step-by-step>", "<linear-reasoning>", "<explainable>", "<basic>"]
              }
            ]
          },
          "intermediate": {
            "description": "Methods for more complex scenarios involving branching, decomposition, or parallel exploration.",
            "methods": [
              {
                "id": "method-tot",
                "name": "Tree of Thought (ToT)",
                "description": "Systematic exploration of multiple potential solution paths/reasoning branches concurrently via a tree structure. Allows parallel evaluation and pruning.",
                "implementation": [
                  "Represent problem/decision space as a tree (nodes=states, branches=actions/inferences).",
                  "Generate multiple branches ('thoughts') from nodes iteratively.",
                  "Evaluate branches using defined heuristics, evaluation functions, or confidence scores.",
                  "Record explored branches, evaluations, and reasoning in a structured internal format.",
                  "Employ pruning strategies (depth, confidence, heuristics, beam width defined in `#mod-search-strategy`) to manage complexity."
                ],
                "limitations": ["Combinatorial explosion potential.", "Requires effective generation, evaluation, pruning.", "May not guarantee constraint satisfaction without extensions."],
                "mitigations": ["Intelligent pruning.", "Practical tree size limits.", "Combine with critique/refinement cycles (`#mod-advanced-reasoning.tech-iterative-critique-refinement`) or constraint checking (`#mod-validation.comp-constraint-feasibility-check`).", "Combine with MCTS (`#method-mcts`)."],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-tot`",
                "tags": ["<exploration>", "<branching>", "<parallel-evaluation>", "<search>", "<intermediate>"]
              },
              {
                "id": "method-decomposition",
                "name": "Structured Decomposition",
                "description": "Systematically breaking down complex problems into smaller, manageable, interconnected sub-problems. Facilitates modular reasoning and integration.",
                "implementation": [
                  { "step_id": "decomp-1", "name": "Problem Analysis & Component Identification", "details": ["Identify core components/stages.", "Define scope, boundaries, I/O, objectives, constraints for each sub-problem."] },
                  { "step_id": "decomp-2", "name": "Relationship & Dependency Mapping", "details": ["Define relationships (sequential, parallel, etc.) and dependencies.", "Establish clear interfaces/information flow."] },
                  { "step_id": "decomp-3", "name": "Sub-Problem Solving", "details": ["Address each sub-problem using contextually selected methods from this KB."] },
                  { "step_id": "decomp-4", "name": "Solution Synthesis & Integration Validation", "details": ["Combine sub-solutions.", "Rigorously validate integrated solution using protocols from `#mod-validation` (consistency, completeness, correctness, feasibility, constraints)."] }
                ],
                "conditions": {
                  "ideal_use": ["Complex systems analysis.", "Multi-stage task planning.", "Engineering design.", "Modular problems."],
                  "limitations": ["Struggles with highly entangled problems.", "Requires careful boundary definition.", "Integration complexity."],
                  "mitigations": ["Combine with holistic methods.", "Iterative refinement of decomposition.", "Robust integration validation."]
                },
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding.strategies.strategy-decomposition`",
                "tags": ["<modular>", "<divide-and-conquer>", "<structured-thinking>", "<planning>", "<design>", "<intermediate>"]
              }
            ]
          },
          "advanced": {
            "description": "Sophisticated methods for complex, uncertain, multi-objective, or large-scale problems, especially relevant for solution design tasks requiring advanced search, probabilistic modeling, simulation, or iterative refinement.",
            "methods": [
              {
                "id": "method-mcts",
                "name": "Monte Carlo Tree Search (MCTS)",
                "description": "A probabilistic search algorithm using randomized simulations (rollouts) to guide exploration in large decision spaces. Balances exploration and exploitation.",
                "implementation": [
                  { "step_id": "mcts-1", "name": "Selection", "description": "Traverse tree selecting child nodes based on policy (e.g., UCT - Upper Confidence Bound applied to Trees)." },
                  { "step_id": "mcts-2", "name": "Expansion", "description": "Add unexplored child nodes to the tree." },
                  { "step_id": "mcts-3", "name": "Simulation (Rollout)", "description": "Perform a simulation from the new node using a default policy (e.g., random, heuristic) to estimate its value." },
                  { "step_id": "mcts-4", "name": "Backpropagation", "description": "Propagate the simulation outcome up the tree, updating node statistics (visits, value)." }
                ],
                "limitations": ["Requires a simulation model.", "Computationally expensive.", "Policy dependent.", "May need modification for strict constraint satisfaction."],
                "mitigations": ["Efficient simulation models.", "Heuristic rollouts.", "Parallelization (simulated).", "Pruning/learned values.", "Budget limits.", "Integrate constraint checking (`#mod-validation.comp-constraint-feasibility-check`)."],
                "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-mcts`",
                "tags": ["<probabilistic-search>", "<simulation-based>", "<decision-making>", "<uncertainty>", "<exploration-exploitation>", "<advanced>"]
              },
              {
                "id": "method-bi-point-tree",
                "name": "Bi-point Thinking Tree",
                "description": "An advanced tree-based framework for complex solution design, emphasizing iterative refinement and reliability. Alternates between generating solutions (Solution Nodes) and critiquing them (Comment Nodes) to progressively improve feasibility and constraint satisfaction.",
                "implementation": [
                  { "step_id": "bpt-1", "name": "Initialize Root Node", "details": "Start with the complex requirement/problem statement (q)." },
                  { "step_id": "bpt-2", "name": "Generate Solution Nodes (Layer i)", "details": "Generate H potential solution refinements/proposals (s_h^i) based on the parent node (either the root q or a previous Comment Node c_j^(i-1)), potentially using retrieved internal knowledge (K_h)." },
                  { "step_id": "bpt-3", "name": "Generate Comment Nodes (Layer i+1)", "details": "Generate H critique/comment nodes (c_k^(i+1)) by reviewing the corresponding Solution Node (s_h^i) against the original requirement (q), defined constraints (`#mod-validation.comp-constraint-feasibility-check`), fairness principles (`#principle-fairness-bias-mitigation`), and internal knowledge (K_k). Identify deficiencies, constraint violations, risks, and potential improvements." },
                  { "step_id": "bpt-4", "name": "Iterate Expansion", "details": "Repeat steps 2 and 3, using the generated Comment Nodes to guide the generation of improved Solution Nodes in subsequent layers." },
                  { "step_id": "bpt-5", "name": "Evaluate Nodes & Prune Tree", "details": "Evaluate the 'reliability' or 'quality' of Solution Nodes and the 'helpfulness' or 'criticality' of Comment Nodes using internal scoring functions or heuristics. Prune less promising branches based on scores and pruning parameters (e.g., beam width W from `#mod-search-strategy`)." },
                  { "step_id": "bpt-6", "name": "Terminate Search", "details": "Stop based on criteria like maximum depth (L from `#mod-search-strategy`), achieving a target quality score, resource budget exhaustion, or convergence. Select the best validated solution from the retained leaf nodes." }
                ],
                "advantages": ["Explicit iterative refinement cycle.", "Systematically improves reliability and feasibility.", "Integrates constraint checking and critique directly into the search.", "Flexible exploration of design space."],
                "challenges": ["Computationally intensive.", "Requires effective node evaluation functions.", "Depends heavily on the quality of the LLM's generation and critique capabilities."],
                "application_context": "`kb_problem_solving_framework#execution_process` (stages involving exploration, evaluation, refinement)",
                "tags": ["<iterative-refinement>", "<design-review>", "<critique>", "<constraint-satisfaction>", "<reliability>", "<tree-based>", "<solution-design>", "<advanced>", "<bi-point-thinking>"]
              },
              {
                "id": "method-fibonacci",
                "name": "Adaptive Fibonacci Reasoning Framework",
                "description": "An adaptive reasoning framework using a modified Fibonacci sequence structure for managing steps, incorporating dynamic feedback and iterative refinement.",
                "implementation": [
                  { "step_number": 0, "name": "Context Introduction & Goal Setting", "details": "Define problem, objective, scope." },
                  { "step_number": 1, "name": "Premise Establishment & Initial Analysis", "details": "Identify/validate premises, assumptions, constraints. Analyze." },
                  { "step_number": 1, "name": "Immediate Expansion & Info Gathering", "details": "Expand understanding via internal info gathering, hypothesis generation." },
                  { "step_number": 2, "name": "Interconnection & Relationship Mapping", "details": "Connect premises to conclusions, identify relationships, conflicts." },
                  { "step_number": 3, "name": "Intermediate Detailing & Evidence Integration", "details": "Integrate internal evidence/data to substantiate/refute conclusions." },
                  { "step_number": 5, "name": "Logical Consolidation & Coherence Check", "details": "Combine insights, validate coherence (`#mod-validation.comp-logical-validation`), address inconsistencies." },
                  { "step_number": 8, "name": "Solution Synthesis & Final Resolution", "details": "Synthesize insights into final solution/conclusion." },
                  { "step_number": 13, "name": "Adaptive Feedback & Iterative Refinement (Loop)", "actions": ["Incorporate internal feedback (`#mod-implementation.feedback_and_improvement`).", "Dynamically adjust steps/strategies (`#mod-implementation.dynamic_adaptation`).", "Iteratively refine solution. May loop back to earlier steps."] }
                ],
                "adaptive_features": {
                  "dynamic_step_adjustment": { "description": "Adjusts step number/depth/complexity based on problem, uncertainty, feedback.", "triggers": ["High uncertainty", "Contradictions", "Low confidence", "Feedback", "New info."] },
                  "feedback_integration": { "description": "Systematically incorporates feedback (internal validation, monitoring, reflection) to guide reasoning.", "mechanisms": ["Performance metrics", "Consistency checks", "Self-reflection outputs", "RL signals."] }
                },
                "tags": ["<adaptive>", "<iterative>", "<structured-progression>", "<feedback-driven>", "<complex-problems>", "<advanced>"]
              },
              {
                "id": "method-bayesian",
                "name": "Bayesian Reasoning",
                "description": "A probabilistic framework using Bayes' theorem to update beliefs about hypotheses based on evidence. Ideal for uncertainty, incomplete info, diagnosis, learning.",
                "implementation": [
                  "Define hypotheses (H).", "Assign prior probabilities P(H) based on internal knowledge.", "Define likelihood functions P(Evidence | H).", "Gather evidence (E) from context or internal reasoning.", "Apply Bayes' theorem to calculate posterior probabilities P(H | E).", "Iteratively update posteriors as new evidence arrives."
                ],
                "applications": ["Diagnostic reasoning.", "Risk assessment.", "Parameter estimation.", "Learning under uncertainty."],
                "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, prediction, high uncertainty)",
                "tags": ["<probabilistic-reasoning>", "<belief-updating>", "<uncertainty>", "<evidence-based>", "<learning>", "<advanced>"]
              }
            ]
          }
        },
        "hybrid_reasoning": {
          "id": "mod-hybrid",
          "description": "A meta-strategy involving synergistic and dynamic combination of multiple reasoning techniques defined within this KB to leverage complementary strengths and mitigate weaknesses, guided by `#principle-adaptability` and `#mod-implementation.method_selection`.",
          "principles": [
            {
              "id": "principle-complementarity",
              "name": "Complementarity",
              "description": "Combine methods with differing strengths (e.g., ToT for exploration, Bi-point Thinking Tree for refinement).",
              "example": "Combine tree exploration (`#method-tot`/`#method-mcts`) with iterative critique/refinement cycles (`#method-bi-point-tree` or `#tech-iterative-critique-refinement`) for complex design tasks."
            },
            {
              "id": "principle-dynamic-integration",
              "name": "Dynamic Integration",
              "description": "Flexibly switch between or integrate techniques based on problem state, sub-task nature, uncertainty, or feedback, guided by `#mod-implementation.dynamic_adaptation`.",
              "example": "Initiate with Decomposition (`#method-decomposition`), solve sub-problems (using `#method-cot`/`#method-bayesian`), then use Bi-point Thinking (`#method-bi-point-tree`) for integration and refinement."
            },
            {
                "id": "principle-contextual-selection",
                "name": "Contextual Method Selection",
                "description": "Employ meta-reasoning (`#tech-meta-reasoning`) to intelligently select the most appropriate technique(s) based on task type (QA vs. design), complexity, uncertainty, constraints, resources, explainability/reliability needs, using criteria from `#mod-implementation.method_selection`.",
                "implementation": ["Execute internal decision logic.", "Apply rule-based selection.", "Utilize learned strategy selection models (internal)."]
            }
          ],
          "tags": ["<meta-strategy>", "<flexible>", "<adaptive>", "<combined-methods>", "<robustness>"]
        },
        "multimodal_methods": {
          "id": "mod-multimodal",
          "description": "Reasoning methods designed to handle, integrate, and reason across information from multiple modalities, configured via `#mod-multimodal-integration_config`.",
          "examples": [
            { "name": "Integrated MCTS and Fibonacci Progression", "description": "Combines MCTS exploration with Fibonacci structured progression.", "implementation": "Use MCTS simulations to evaluate outcomes/scenarios at specific Fibonacci steps.", "tags": ["<hybrid>", "<probabilistic-logical>", "<simulation>", "<structured-progression>"] },
            { "name": "Visual-Textual Reasoning", "description": "Combines visual and textual information for joint understanding.", "implementation": ["Extract visual features (simulated).", "Process text.", "Fuse features (e.g., cross-modal attention).", "Apply reasoning to fused representation."], "tags": ["<multimodal>", "<vision-language>", "<integration>", "<cross-modal>"] },
            { "name": "Audio-Textual Reasoning", "description": "Combines audio and textual information.", "implementation": ["Transcribe audio (simulated).", "Process text.", "Integrate features/info.", "Apply reasoning."], "tags": ["<multimodal>", "<audio-language>", "<integration>", "<cross-modal>"] },
            { "name": "Numerical-Textual Reasoning", "description": "Combines quantitative data with qualitative text.", "implementation": ["Extract/structure numerical data.", "Process text.", "Fuse info.", "Apply quantitative/qualitative reasoning."], "tags": ["<multimodal>", "<quantitative-qualitative>", "<data-integration>", "<cross-modal>"] }
          ]
        },
        "simulation_methods":{
          "id": "mod-simulation",
          "description": "Reasoning frameworks relying on internal simulations, probabilistic models, or advanced heuristics for complex optimization, prediction, or analysis.",
          "methods": [
            { "id": "method-simulated-annealing", "name": "Simulated Annealing", "description": "Probabilistic metaheuristic for global optimization approximation. Allows escaping local optima.", "applications": ["Global optimization.", "Resource allocation.", "Scheduling.", "Layout problems."], "tags": ["<simulation>", "<optimization>", "<heuristic>", "<probabilistic>", "<search>", "<advanced>"] },
            { "id": "method-bayesian-networks", "name": "Bayesian Networks", "description": "Probabilistic graphical model (DAG) representing variables and conditional dependencies. Used for inference under uncertainty.", "applications": ["Risk analysis.", "Diagnostic systems.", "Causal inference.", "Decision support.", "Predictive modeling."], "tags": ["<probabilistic-reasoning>", "<uncertainty>", "<graphical-model>", "<inference>", "<causality>", "<advanced>"] }
          ]
        }
      },
       "advanced_reasoning_techniques": {
        "id": "mod-advanced-reasoning",
        "description": "Sophisticated reasoning techniques extending beyond basic/intermediate methods, addressing complex, nuanced, or specialized scenarios like solution design.",
        "techniques":[
           {
            "id": "tech-iterative-critique-refinement",
            "name": "Iterative Critique-Refinement Cycle",
            "description": "An iterative technique alternating generation (e.g., proposing solutions/reasoning steps) and critique (evaluating against criteria like constraints, objectives, logic, feasibility). Drives refinement, improving quality and reliability. Can be applied standalone or as part of frameworks like Bi-point Thinking Tree (`#method-bi-point-tree`).",
            "implementation": [
              "Generate initial proposal/solution/reasoning step.",
              "Execute critique step: Evaluate proposal against relevant criteria (constraints from `#mod-validation.comp-constraint-feasibility-check`, objectives, logical soundness from `#mod-validation.comp-logical-validation`, feasibility, internal knowledge, fairness principles from `#principle-fairness-bias-mitigation`).",
              "Identify specific deficiencies, errors, risks, or improvement areas based on the critique.",
              "Generate a refined proposal addressing the identified issues.",
              "Repeat critique-refinement cycle until satisfaction criteria are met, resources are exhausted, or no further improvement is detected.",
              "Can be nested or applied hierarchically to different components of a problem."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-refinement`",
            "tags": ["<advanced-technique>", "<iterative-refinement>", "<critique>", "<self-correction>", "<design-thinking>", "<reliability>", "<constraint-satisfaction>", "<bi-point-thinking-element>"]
          },
          {
            "id": "tech-multimodal-reasoning",
            "name": "Multimodal Reasoning",
            "description": "Integrating, processing, and reasoning across multiple information modalities (defined in `#mod-multimodal-integration_config.settings.modalities`) for holistic understanding.",
            "implementation": [
              "Execute methods for aligning and fusing information based on `#mod-multimodal-integration_config.settings.fusion_method` and `#mod-multimodal-integration_config.settings.alignment_strategy`.",
              "Combine logical reasoning with specialized models (internal simulation) for modality-specific processing.",
              "Address challenges: heterogeneity, noise, synchronization, inconsistencies, using robustness principles (`#principle-robustness`)."
            ],
            "tags": ["<advanced-technique>", "<multimodal>", "<integration>", "<cross-modal>", "<holistic-understanding>"]
          },
          {
            "id": "tech-counterfactual-reasoning",
            "name": "Counterfactual Reasoning",
            "description": "Reasoning about hypothetical alternative scenarios ('what if') deviating from the actual state. Used for explanation, planning, and decision analysis.",
            "implementation": [
              "Generate plausible counterfactual scenarios based on modifying key variables or past events.",
              "Estimate outcomes using causal inference models (if available internally) or logical projection.",
              "Explicitly state assumptions made for the counterfactual.",
              "Address/quantify uncertainties associated with the counterfactual outcome."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
            "tags": ["<advanced-technique>", "<hypothetical>", "<what-if>", "<causal-inference>", "<scenario-analysis>", "<explanation>"]
          },
          {
            "id": "tech-analogical-reasoning",
            "name": "Analogical Reasoning",
            "description": "Identifying and leveraging structural or conceptual similarities between different domains (source and target) to transfer knowledge, generate hypotheses, or find novel solutions.",
            "implementation": [
              "Identify potential source analogs from internal knowledge based on structural mapping.",
              "Map concepts, relationships, and constraints between the source and target domains.",
              "Critically evaluate the validity and limitations of the analogy, avoiding superficial similarities.",
              "Ensure the appropriateness and necessary adaptation of transferred knowledge to the target context."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning`",
            "tags": ["<advanced-technique>", "<analogy>", "<knowledge-transfer>", "<hypothesis-generation>", "<creative-problem-solving>"]
          },
          {
            "id": "tech-meta-reasoning",
            "name": "Meta-Reasoning",
            "description": "Reasoning *about* the reasoning process itself. Involves monitoring, evaluating, controlling, and adapting the agent's own cognitive processes to optimize performance and achieve goals.",
            "implementation": [
              "Execute internal monitoring of reasoning progress, confidence levels, resource usage, and strategy effectiveness.",
              "Apply self-assessment of strategy quality, appropriateness, and potential biases.",
              "Implement control mechanisms to dynamically select, switch, or adapt reasoning strategies based on meta-level evaluation (linking to `#mod-implementation.method_selection` and `#mod-implementation.dynamic_adaptation`).",
              "Incorporate meta-level feedback loops for continuous improvement of the reasoning process itself."
            ],
            "tags": ["<advanced-technique>", "<metacognition>", "<self-awareness>", "<strategy-selection>", "<optimization>", "<control>"]
          },
           {
            "id": "tech-abductive-reasoning",
            "name": "Abductive Reasoning",
            "description": "Inferring the most plausible explanation(s) for a given set of observations or evidence ('inference to the best explanation'). Crucial for diagnosis and hypothesis generation.",
            "implementation": [
              "Generate a diverse set of plausible hypotheses that could explain the observations.",
              "Evaluate and rank hypotheses based on criteria such as simplicity (Occam's Razor), explanatory power, coherence with existing internal knowledge, and likelihood.",
              "Handle uncertainty and the possibility of multiple competing explanations, potentially assigning probabilities or confidence scores.",
              "Distinguish clearly from deductive (guaranteed conclusion) and inductive (probable generalization) reasoning."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, explanation)",
            "tags": ["<advanced-technique>", "<explanation>", "<hypothesis-generation>", "<inference-to-best-explanation>", "<diagnostic-reasoning>", "<uncertainty>"]
          },
          {
            "id": "tech-reasoning-with-retrieved-evidence",
            "name": "Reasoning with Retrieved Evidence (Simulated RAG)",
            "description": "Integrating the simulated retrieval and critical evaluation of evidence/knowledge from internal sources into the reasoning process. Crucial for knowledge-intensive tasks.",
            "implementation": [
              "Identify knowledge gaps relevant to the current reasoning step or problem.",
              "Formulate effective internal queries to retrieve potentially relevant information from internal KBs.",
              "Critically evaluate the retrieved information's credibility, relevance, applicability, and potential bias based on source metadata (if available) and contextual fit.",
              "Integrate validated evidence into the reasoning process (e.g., updating beliefs, checking constraints, supporting claims, critiquing proposals).",
              "Explicitly consider the limitations of the internal retrieval process and the potential impact of missing information."
            ],
            "tags": ["<advanced-technique>", "<evidence-based>", "<knowledge-integration>", "<rag-simulation>", "<solution-design>", "<information-retrieval-internal>", "<critical-evaluation>"]
          },
          {
            "id": "tech-counterfactual-explanations",
            "name": "Counterfactual Explanations",
            "description": "Generating explanations clarifying outcomes by describing how they would change if specific inputs/factors differed. Enhances interpretability.",
            "implementation": [
              "Identify key influencing factors or decision points.",
              "Generate minimal, plausible counterfactual scenarios by modifying these factors.",
              "Evaluate the predicted outcome under these counterfactuals using internal models or logical projection.",
              "Present the explanation highlighting the specific change and its resulting impact on the outcome."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
            "tags": ["<advanced-technique>", "<explanation>", "<interpretability>", "<causal-explanation>", "<what-if>", "<counterfactual-reasoning>"]
          },
          {
            "id": "tech-argumentation-mining",
            "name": "Argumentation Mining",
            "description": "Automated identification and analysis of argumentative structures within textual data (internal or contextual).",
            "implementation": [
              "Identify argument components (premises, claims) using NLP techniques (internal simulation).",
              "Analyze argument structure and relationships (support, attack).",
              "Assess argument strength, validity, and potential fallacies using logical principles.",
              "Reconstruct implicit premises or conclusions where necessary.",
              "Model argument relationships, potentially as a graph."
            ],
            "tags": ["<advanced-technique>", "<nlp-simulation>", "<argument-analysis>", "<logical-structure>", "<fallacy-detection>", "<text-analysis>"]
          }
        ]
      },
      "validation_and_verification": {
        "id": "mod-validation",
        "description": "Mandatory internal protocols and techniques for validating the correctness, robustness, logical soundness, feasibility, constraint satisfaction, and reliability of reasoning processes and generated outputs. Results are logged via `agent_reasoning_output_validation_protocol`.",
        "components": [
          {
            "id": "comp-logical-validation",
            "name": "Logical Validation and Consistency Checking",
            "description": "Verifying the logical soundness, validity, and internal consistency of reasoning chains.",
            "steps": [
              { "step_id": "lv-1", "description": "Verify premise validity and logical relationships between steps using formal logic rules (modus ponens, etc.)." },
              { "step_id": "lv-2", "description": "Test intermediate and final conclusions for soundness (following from premises) and consistency with internal knowledge." },
              { "step_id": "lv-3", "description": "Scan reasoning trace for logical fallacies (e.g., circular reasoning, contradiction, hasty generalization)." },
              { "step_id": "lv-4", "description": "Perform automated consistency checks across different parts of the reasoning process." }
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.logical_soundness_check`",
            "tags": ["<validation>", "<logic>", "<consistency>", "<soundness>", "<fallacy-check>"]
          },
           {
            "id": "comp-constraint-feasibility-check",
            "name": "Constraint Satisfaction and Feasibility Validation",
            "description": "Ensuring the generated solution or output adheres to all defined constraints and is practically feasible within the agent's context.",
            "steps": [
              { "step_id": "cfc-1", "description": "Identify and list all explicit and implicit constraints relevant to the task (functional, non-functional, fairness, operational)." },
              { "step_id": "cfc-2", "description": "Systematically verify if the proposed solution or output addresses and satisfies each identified constraint." },
              { "step_id": "cfc-3", "description": "Assess the practical feasibility of implementing the solution components or plan, considering simulated resource limits and agent capabilities." },
              { "step_id": "cfc-4", "description": "Flag any violated constraints or identified feasibility issues, noting severity." }
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.constraint_adherence_check_result`",
            "tags": ["<validation>", "<constraint-satisfaction>", "<feasibility>", "<requirements-check>", "<solution-design>"]
          },
          {
            "id": "comp-factual-grounding-check",
            "name": "Factual Grounding and Hallucination Check",
            "description": "Verifying that factual claims within the output are accurate and grounded in reliable internal knowledge or provided context, minimizing hallucinations.",
            "steps": [
              { "step_id": "fgc-1", "description": "Identify factual claims made in the output." },
              { "step_id": "fgc-2", "description": "Attempt to trace each claim back to its source within internal knowledge or provided context." },
              { "step_id": "fgc-3", "description": "Assess the reliability of the source (if traceable) and the consistency of the claim with other internal knowledge." },
              { "step_id": "fgc-4", "description": "Flag claims that are unsupported, contradict reliable sources, or seem highly implausible (potential hallucinations)." },
              { "step_id": "fgc-5", "description": "Assign a grounding score or confidence level to the output's factual content." }
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.factual_grounding_check`, `agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result.factual_grounding_rating`",
            "tags": ["<validation>", "<accuracy>", "<hallucination-check>", "<grounding>", "<fact-checking>"]
          },
          {
            "id": "comp-output-qa",
            "name": "Output Quality Assurance and Benchmarking",
            "description": "Systematic evaluation of overall output quality against predefined criteria and internal benchmarks.",
            "criteria": [
              "Logical soundness & validity (`#comp-logical-validation`).",
              "Constraint satisfaction & feasibility (`#comp-constraint-feasibility-check`).",
              "Factual grounding & accuracy (`#comp-factual-grounding-check`).",
              "Contextual relevance & task completion.",
              "Clarity, precision, and structure.",
              "Completeness & coverage.",
              "Efficiency/conciseness.",
              "Robustness & safety considerations (including bias checks from `#principle-fairness-bias-mitigation`).",
              "Alignment with operational principles.",
              "Performance against internal benchmarks (if applicable)."
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result`",
            "tags": ["<validation>", "<quality-assurance>", "<benchmarking>", "<metrics>", "<output-evaluation>"]
          },
          {
            "id": "comp-automated-validation",
            "name": "Automated Validation and Testing (Internal)",
            "description": "Mandatory use of automated internal checks for inputs, outputs, premises, processes, constraint adherence, and behavior.",
            "processes": [
              "Input schema validation.",
              "Output format/schema validation.",
              "Automated constraint checking scripts.",
              "Automated contradiction/fallacy detection routines.",
              "Execution of internal test suites (unit, integration tests - simulated).",
              "Automated regression testing after internal updates.",
              "Automated performance benchmarking (latency, resource usage - simulated)."
            ],
            "tags": ["<validation>", "<automation>", "<testing>", "<regression-testing>", "<performance-testing>", "<constraint-checking>"]
          },
          {
            "id": "comp-robustness-testing",
            "name": "Robustness Testing and Evaluation (Internal Simulation)",
            "description": "Mandatory protocol for assessing robustness, resilience, fault tolerance under simulated adverse conditions.",
            "tests": {
              "stress_tests": { "description": "Evaluate under simulated high load or complexity.", "metrics": ["Time/latency.", "Resources.", "Stability.", "Scalability."] },
              "boundary_tests": { "description": "Examine with extreme/unusual inputs, missing data, ambiguity.", "metrics": ["Error rate/modes.", "Output validity.", "Recovery.", "Degradation."] },
              "adversarial_tests": { "description": "Employ simulated adversarial techniques (e.g., perturbed inputs).", "methods": ["Generate adversarial examples.", "Simulate malicious inputs.", "Evaluate detection/mitigation."] }
            },
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.internal_validation_checks_performed.robustness_safety_review`",
            "tags": ["<validation>", "<robustness>", "<resilience>", "<stress-testing>", "<adversarial-testing>", "<edge-cases>"]
          }
        ]
      },
      "implementation_and_deployment": {
        "id": "mod-implementation",
        "description": "Mandatory best practices, guidelines, and standards for implementing and executing reasoning strategies defined within this KB, applied within the context of `kb_problem_solving_framework`.",
        "standards": [
          {
            "id": "standard-execution",
            "category": "Execution Protocols and Procedures",
            "requirements": [
              "Adopt systematic, well-defined, and reproducible approaches for all reasoning tasks.",
              "Maintain detailed internal logs of reasoning processes, decisions, assumptions, justifications, and validation results (using `agent_reasoning_output_validation_protocol` structure).",
              "Continuously monitor, evaluate, and optimize reasoning performance using defined metrics (`#standard-quality.metrics`) and feedback loops (`#feedback_and_improvement`).",
              "Ensure strict compliance with foundational principles (`#mod-foundation`) and relevant configurations."
            ],
            "tags": ["<implementation>", "<process>", "<standard>", "<reproducibility>", "<monitoring>", "<logging>"]
          },
          {
            "id": "standard-quality",
            "category": "Quality Metrics and Performance Benchmarks",
            "description": "Key internal metrics for evaluating reasoning performance and output quality.",
            "metrics": [
              { "id": "metric-accuracy", "name": "Accuracy/Correctness Index", "threshold": ">=0.95", "validation_method": "Internal comparison vs. benchmarks/truth/simulations (`#comp-factual-grounding-check`)." },
              { "id": "metric-consistency", "name": "Logical Consistency Score", "threshold": ">=0.95", "validation_method": "Internal logical validation checks (`#comp-logical-validation`)." },
              { "id": "metric-feasibility", "name": "Feasibility Score", "threshold": ">=0.90", "validation_method": "Internal constraint and feasibility checks (`#comp-constraint-feasibility-check`)." },
              { "id": "metric-efficiency", "name": "Efficiency Rating", "threshold": "Meets predefined targets.", "validation_method": "Internal profiling, benchmarking, resource monitoring (`#comp-automated-validation`)." },
              { "id": "metric-robustness", "name": "Robustness Index", "threshold": ">=0.80", "validation_method": "Evaluation during internal robustness tests (`#comp-robustness-testing`)." }
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result` (for quality metrics)",
            "tags": ["<implementation>", "<quality>", "<metrics>", "<benchmarking>", "<performance>", "<feasibility>"]
          }
        ],
        "method_selection": {
          "description": "Framework guiding the agent's dynamic, context-aware selection of reasoning techniques defined in this KB, applied via `kb_problem_solving_framework#strategy_selection_guidance`.",
          "criteria": [
            "Task Type: QA, design, planning, diagnosis, optimization, explanation, etc.",
            "Problem Complexity: Assessed scale, depth, number of variables/constraints.",
            "Uncertainty Level: High, medium, low; nature of uncertainty.",
            "Constraint Profile: Number, type (hard/soft), and strictness.",
            "Problem Structure: Linear, hierarchical, graph-based, decomposable.",
            "Input Data Characteristics: Modality, volume, quality, noise level.",
            "Resource Constraints (Simulated): Time limits, computational budget.",
            "Required Output Characteristics: Explainability level, reliability needs, feasibility requirements.",
            "Fairness/Bias Considerations: Potential risks identified (`#principle-fairness-bias-mitigation`)."
          ],
          "decision_support": {
            "description": "Internal mechanisms the agent can use to implement contextual method selection.",
            "examples": [
              { "name": "Internal Decision Trees/Flowcharts", "details": "Map assessed problem characteristics (criteria above) to recommended methods/combinations defined herein." },
              { "name": "Internal Rule-Based System", "details": "Encode selection logic as IF-THEN rules based on criteria." },
              { "name": "Internal Learned Strategy Predictor", "details": "Utilize an internal model trained to predict the optimal strategy based on problem features and past performance." },
              { "name": "Meta-Reasoning Integration", "details": "Leverage meta-reasoning (`#tech-meta-reasoning`) to dynamically monitor and select the best strategy during execution." }
            ]
          },
          "tags": ["<implementation>", "<strategy-selection>", "<context-awareness>", "<decision-making>", "<meta-reasoning>", "<task-type>"]
        },
        "dynamic_adaptation": {
          "description": "Mechanisms for automatically adjusting reasoning methods, parameters, or resource allocation (simulated) based on evolving context, new information, performance feedback, or internal critique.",
          "examples": [
            { "method": "Adaptive Fibonacci Progression (`#method-fibonacci`)", "adaptation": "Adjusts step number/complexity based on feedback/uncertainty." },
            { "method": "Hybrid Reasoning Systems (`#mod-hybrid`)", "adaptation": "Switches between techniques based on sub-task nature or performance." },
            { "method": "Meta-Reasoning (`#tech-meta-reasoning`)", "adaptation": "Monitors performance and dynamically selects/tunes techniques." },
            { "method": "Tree Search Parameter Tuning", "adaptation": "Adjusts depth (L), width (W), or pruning thresholds (`#mod-search-strategy`) based on resource constraints or solution quality progress." }
          ],
          "application_context": "`kb_problem_solving_framework#principle-adaptability`",
          "tags": ["<implementation>", "<adaptation>", "<flexibility>", "<dynamic-adjustment>", "<real-time>"]
        },
        "feedback_and_improvement": {
          "description": "Mandatory internal system for incorporating performance metrics, validation results, self-reflection, critique, and other feedback for continuous improvement of reasoning processes, applied within `kb_problem_solving_framework#feedback_loop`.",
          "data_sources": [
            "Internal validation results (from `#mod-validation`, logged via `agent_reasoning_output_validation_protocol`).",
            "Performance metrics (`#standard-quality.metrics`).",
            "Self-reflection outputs (`#mod-self-reflection_config`).",
            "Critique generated during iterative refinement (`#tech-iterative-critique-refinement`).",
            "Simulated user feedback or interaction analysis.",
            "Analysis of successful vs. failed reasoning attempts."
          ],
          "process": {
            "description": "Systematically collect performance and feedback data from internal sources. Analyze data to identify patterns, trends, strengths, weaknesses, root causes of errors, and areas for improvement. Utilize these insights to automatically or semi-automatically adjust parameters, refine methods, improve internal documentation, enhance the overall reasoning process, and potentially flag areas for future internal knowledge base updates.",
            "steps": [
                {"id": "fi-1", "action": "Collect Data", "details": "Aggregate data from specified `data_sources` after reasoning tasks."},
                {"id": "fi-2", "action": "Analyze Data", "details": "Identify performance trends, common error types, constraint violation patterns, feedback themes."},
                {"id": "fi-3", "action": "Identify Improvements", "details": "Determine specific adjustments needed (e.g., parameter tuning, method refinement, new heuristic, better constraint handling)."},
                {"id": "fi-4", "action": "Implement Adjustments", "details": "Apply changes to configurations, method implementations, or selection logic based on analysis (Log via `agent_reasoning_output_validation_protocol#validation_output.refinement_actions_taken_post_validation`)."},
                {"id": "fi-5", "action": "Verify Improvement", "details": "Monitor subsequent performance to confirm the effectiveness of adjustments."}
            ],
            "automated_adjustments_examples": [
              { "trigger": "Consistent efficiency threshold violation.", "action": "Bias towards simpler methods, increase pruning aggressiveness, optimize resource allocation simulation." },
              { "trigger": "Recurring factual grounding errors (`#comp-factual-grounding-check`).", "action": "Increase reliance on internal knowledge checks, lower confidence threshold for claims, trigger more rigorous source verification simulation." },
              { "trigger": "Repeated constraint violations (`#comp-constraint-feasibility-check`).", "action": "Strengthen constraint checking logic, prioritize methods with built-in constraint handling (e.g., Bi-point Tree), adjust generation prompts." },
              { "trigger": "Negative critique patterns in Bi-point Thinking.", "action": "Refine critique generation prompts, adjust solution generation strategy to preemptively address common critiques." }
            ]
          },
          "tags": ["<implementation>", "<continuous-improvement>", "<feedback-loop>", "<learning>", "<optimization>", "<self-correction>", "<critique-driven>"]
        },
        "multimodal_integration": {
          "description": "Strategies for integrating and reasoning across multiple information modalities, guided by `#mod-multimodal-integration_config`.",
          "methods": [
            { "name": "Feature-Level Fusion", "description": "Combine features extracted from different modalities before main reasoning.", "techniques": ["Concatenation", "Weighted averaging", "Cross-modal attention", "Joint embedding"] },
            { "name": "Decision-Level Fusion", "description": "Combine intermediate results or decisions derived from modality-specific reasoning.", "techniques": ["Voting", "Weighted averaging", "Bayesian inference", "Ensemble methods"] },
            { "name": "Hybrid Fusion", "description": "Combine feature-level and decision-level fusion strategically.", "techniques": ["Early then late", "Alternating", "Hierarchical"] }
          ],
          "challenges": ["Handling heterogeneity.", "Managing noise/uncertainty.", "Ensuring alignment/synchronization.", "Addressing complexity/scalability."],
          "tags": ["<implementation>", "<multimodal>", "<integration>", "<fusion>", "<cross-modal>"]
        }
      },
      "advanced_reasoning_techniques": {
        "id": "mod-advanced-reasoning",
        "description": "A collection of sophisticated reasoning techniques extending beyond basic and intermediate methods, designed to address complex, nuanced, and specialized problem-solving scenarios.",
        "techniques":[
           {
            "id": "tech-iterative-critique-refinement",
            "name": "Iterative Critique-Refinement Cycle",
            "description": "An iterative technique alternating generation (e.g., proposing solutions/reasoning steps) and critique (evaluating against criteria like constraints, objectives, logic, feasibility). Drives refinement, improving quality and reliability. Can be applied standalone or as part of frameworks like Bi-point Thinking Tree (`#method-bi-point-tree`).",
            "implementation": [
              "Generate initial proposal/solution/reasoning step.",
              "Execute critique step: Evaluate proposal against relevant criteria (constraints from `#mod-validation.comp-constraint-feasibility-check`, objectives, logical soundness from `#mod-validation.comp-logical-validation`, feasibility, internal knowledge, fairness principles from `#principle-fairness-bias-mitigation`).",
              "Identify specific deficiencies, errors, risks, or improvement areas based on the critique.",
              "Generate a refined proposal addressing the identified issues.",
              "Repeat critique-refinement cycle until satisfaction criteria are met, resources are exhausted, or no further improvement is detected.",
              "Can be nested or applied hierarchically to different components of a problem."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-refinement`",
            "tags": ["<advanced-technique>", "<iterative-refinement>", "<critique>", "<self-correction>", "<design-thinking>", "<reliability>", "<constraint-satisfaction>", "<bi-point-thinking-element>"]
          },
          {
            "id": "tech-multimodal-reasoning",
            "name": "Multimodal Reasoning",
            "description": "Integrating, processing, and reasoning across multiple information modalities (defined in `#mod-multimodal-integration_config.settings.modalities`) for holistic understanding.",
            "implementation": [
              "Execute methods for aligning and fusing information based on `#mod-multimodal-integration_config.settings.fusion_method` and `#mod-multimodal-integration_config.settings.alignment_strategy`.",
              "Combine logical reasoning with specialized models (internal simulation) for modality-specific processing.",
              "Address challenges: heterogeneity, noise, synchronization, inconsistencies, using robustness principles (`#principle-robustness`)."
            ],
            "tags": ["<advanced-technique>", "<multimodal>", "<integration>", "<cross-modal>", "<holistic-understanding>"]
          },
          {
            "id": "tech-counterfactual-reasoning",
            "name": "Counterfactual Reasoning",
            "description": "Reasoning about hypothetical alternative scenarios ('what if') deviating from the actual state. Used for explanation, planning, and decision analysis.",
            "implementation": [
              "Generate plausible counterfactual scenarios based on modifying key variables or past events.",
              "Estimate outcomes using causal inference models (if available internally) or logical projection.",
              "Explicitly state assumptions made for the counterfactual.",
              "Address/quantify uncertainties associated with the counterfactual outcome."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
            "tags": ["<advanced-technique>", "<hypothetical>", "<what-if>", "<causal-inference>", "<scenario-analysis>", "<explanation>"]
          },
          {
            "id": "tech-analogical-reasoning",
            "name": "Analogical Reasoning",
            "description": "Identifying and leveraging structural or conceptual similarities between different domains (source and target) to transfer knowledge, generate hypotheses, or find novel solutions.",
            "implementation": [
              "Identify potential source analogs from internal knowledge based on structural mapping.",
              "Map concepts, relationships, and constraints between the source and target domains.",
              "Critically evaluate the validity and limitations of the analogy, avoiding superficial similarities.",
              "Ensure the appropriateness and necessary adaptation of transferred knowledge to the target context."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration.strategies.strategy-innovative-reasoning`",
            "tags": ["<advanced-technique>", "<analogy>", "<knowledge-transfer>", "<hypothesis-generation>", "<creative-problem-solving>"]
          },
          {
            "id": "tech-meta-reasoning",
            "name": "Meta-Reasoning",
            "description": "Reasoning *about* the reasoning process itself. Involves monitoring, evaluating, controlling, and adapting the agent's own cognitive processes to optimize performance and achieve goals.",
            "implementation": [
              "Execute internal monitoring of reasoning progress, confidence levels, resource usage, and strategy effectiveness.",
              "Apply self-assessment of strategy quality, appropriateness, and potential biases.",
              "Implement control mechanisms to dynamically select, switch, or adapt reasoning strategies based on meta-level evaluation (linking to `#mod-implementation.method_selection` and `#mod-implementation.dynamic_adaptation`).",
              "Incorporate meta-level feedback loops for continuous improvement of the reasoning process itself."
            ],
            "tags": ["<advanced-technique>", "<metacognition>", "<self-awareness>", "<strategy-selection>", "<optimization>", "<control>"]
          },
           {
            "id": "tech-abductive-reasoning",
            "name": "Abductive Reasoning",
            "description": "Inferring the most plausible explanation(s) for a given set of observations or evidence ('inference to the best explanation'). Crucial for diagnosis and hypothesis generation.",
            "implementation": [
              "Generate a diverse set of plausible hypotheses that could explain the observations.",
              "Evaluate and rank hypotheses based on criteria such as simplicity (Occam's Razor), explanatory power, coherence with existing internal knowledge, and likelihood.",
              "Handle uncertainty and the possibility of multiple competing explanations, potentially assigning probabilities or confidence scores.",
              "Distinguish clearly from deductive (guaranteed conclusion) and inductive (probable generalization) reasoning."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for diagnosis, explanation)",
            "tags": ["<advanced-technique>", "<explanation>", "<hypothesis-generation>", "<inference-to-best-explanation>", "<diagnostic-reasoning>", "<uncertainty>"]
          },
          {
            "id": "tech-reasoning-with-retrieved-evidence",
            "name": "Reasoning with Retrieved Evidence (Simulated RAG)",
            "description": "Integrating the simulated retrieval and critical evaluation of evidence/knowledge from internal sources into the reasoning process. Crucial for knowledge-intensive tasks.",
            "implementation": [
              "Identify knowledge gaps relevant to the current reasoning step or problem.",
              "Formulate effective internal queries to retrieve potentially relevant information from internal KBs.",
              "Critically evaluate the retrieved information's credibility, relevance, applicability, and potential bias based on source metadata (if available) and contextual fit.",
              "Integrate validated evidence into the reasoning process (e.g., updating beliefs, checking constraints, supporting claims, critiquing proposals).",
              "Explicitly consider the limitations of the internal retrieval process and the potential impact of missing information."
            ],
            "tags": ["<advanced-technique>", "<evidence-based>", "<knowledge-integration>", "<rag-simulation>", "<solution-design>", "<information-retrieval-internal>", "<critical-evaluation>"]
          },
          {
            "id": "tech-counterfactual-explanations",
            "name": "Counterfactual Explanations",
            "description": "Generating explanations clarifying outcomes by describing how they would change if specific inputs/factors differed. Enhances interpretability.",
            "implementation": [
              "Identify key influencing factors or decision points.",
              "Generate minimal, plausible counterfactual scenarios by modifying these factors.",
              "Evaluate the predicted outcome under these counterfactuals using internal models or logical projection.",
              "Present the explanation highlighting the specific change and its resulting impact on the outcome."
            ],
            "application_context": "`kb_problem_solving_framework#strategy_selection_guidance` (suggested for explanation)",
            "tags": ["<advanced-technique>", "<explanation>", "<interpretability>", "<causal-explanation>", "<what-if>", "<counterfactual-reasoning>"]
          },
          {
            "id": "tech-argumentation-mining",
            "name": "Argumentation Mining",
            "description": "Automated identification and analysis of argumentative structures within textual data (internal or contextual).",
            "implementation": [
              "Identify argument components (premises, claims) using NLP techniques (internal simulation).",
              "Analyze argument structure and relationships (support, attack).",
              "Assess argument strength, validity, and potential fallacies using logical principles.",
              "Reconstruct implicit premises or conclusions where necessary.",
              "Model argument relationships, potentially as a graph."
            ],
            "tags": ["<advanced-technique>", "<nlp-simulation>", "<argument-analysis>", "<logical-structure>", "<fallacy-detection>", "<text-analysis>"]
          }
        ]
      },
      "reasoning_behaviors_config": {
        "id": "mod-reasoning-behaviors",
        "description": "Configuration settings for enabling, prioritizing, and customizing specific reasoning behaviors within the agent, enhancing problem-solving capabilities and adaptability. Used by `kb_problem_solving_framework`.",
        "settings": {
          "self_evaluation": {
            "enabled": true,
            "description": "Enables the agent to critically assess the quality, correctness, consistency, and completeness of its own outputs and internal reasoning processes.",
            "methods": [
              "Internal consistency checking.",
              "Confidence level estimation.",
              "Uncertainty quantification.",
              "Bias detection routines (`#principle-fairness-bias-mitigation`).",
              "Completeness verification against requirements."
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.response_quality_assessment_result`, `#confidence_assessment_result`"
          },
          "task_decomposition": {
            "enabled": true,
            "description": "Allows the agent to automatically break down complex tasks into smaller, more manageable subtasks, facilitating structured problem-solving.",
            "methods": [
              "Hierarchical decomposition.",
              "Sequential decomposition.",
              "Conditional decomposition based on context."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding.strategies.strategy-decomposition`"
          },
          "alternative_proposal": {
            "enabled": true,
            "description": "Enables the agent to generate and evaluate multiple alternative solutions, reasoning paths, or hypotheses, especially when faced with uncertainty or ambiguity.",
            "methods": [
              "Branching exploration (e.g., via ToT, Bi-Point Tree).",
              "Diversity-promoting generation techniques.",
              "Ensemble methods combining diverse approaches."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-solution-exploration`",
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_input.reasoning_trace.alternative_approaches_considered`"
          },
          "self_correction":{
            "enabled": true,
            "description": "Allows the agent to detect and attempt to correct errors identified in its own reasoning or outputs through self-evaluation or feedback.",
            "methods": [
                "Logical validation triggers (`#mod-validation.comp-logical-validation`).",
                "Consistency checks against internal KBs.",
                "Feedback-driven iterative refinement loops (`#mod-implementation.feedback_and_improvement`)."
            ],
            "logging_reference": "`agent_reasoning_output_validation_protocol#validation_output.error_analysis_details`, `#refinement_actions_taken_post_validation`"
          },
          "problem_analysis":{
            "enabled": true,
            "description": "Enables the agent to perform thorough upfront analysis of the problem, context, constraints, and objectives before initiating solution generation.",
            "methods":[
              "Contextual information extraction and analysis.",
              "Constraint identification and classification (`#mod-validation.comp-constraint-feasibility-check`).",
              "Goal clarification and success criteria definition."
            ],
            "application_context": "`kb_problem_solving_framework#execution_process.stages.stage-problem-understanding`"
          },
          "priority": {
            "self_correction": 1,
            "problem_analysis": 2,
            "task_decomposition": 3,
            "self_evaluation": 4,
            "alternative_proposal": 5,
            "description": "Defines the default priority order for applying reasoning behaviors (1=highest). This guides the agent's focus but can be dynamically overridden by meta-reasoning (`#tech-meta-reasoning`) based on task context."
          }
        }
      },
      "reward_structure_config": {
        "id": "mod-reward-settings",
        "description": "Configuration for internal reward structures guiding reinforcement learning (RL) based optimization and decision-making processes within the agent.",
        "settings": {
          "type": {
            "value": "hybrid_reward",
            "description": "Specifies the type of reward signal used in RL: 'process_reward' (step-wise feedback), 'outcome_reward' (final feedback), 'hybrid_reward' (combination).",
            "options": [
              { "name": "process_reward", "description": "Step-wise feedback for guiding intermediate actions (e.g., logical step validity, constraint adherence)." },
              { "name": "outcome_reward", "description": "Final feedback based on overall task success, solution quality, or goal achievement." },
              { "name": "hybrid_reward", "description": "Combination of process and outcome rewards for balanced guidance." }
            ]
          },
          "shaping": {
            "method": "potential_based",
            "description": "Specifies the reward shaping method to provide denser reward signals: 'potential_based' (uses progress function), 'curriculum_learning' (gradual complexity), 'imitation_learning' (rewards similarity to demos).",
            "options":[
              { "name": "potential_based", "description": "Uses a potential function (e.g., distance to goal, number of constraints satisfied) for informative rewards." },
              { "name": "curriculum_learning", "description": "Gradually increases task complexity to facilitate learning." },
              { "name": "imitation_learning", "description": "Rewards similarity to expert demonstrations (simulated)." }
            ]
          },
          "parameters": {
            "gamma": {
              "value": 0.99,
              "description": "Discount factor (gamma) for future rewards in RL (0 to 1). Controls the trade-off between immediate and long-term rewards."
            },
            "potential_function": {
              "value": "linear",
              "description": "Specifies the type of potential function for potential-based reward shaping: 'linear', 'exponential', 'logarithmic', 'custom'.",
              "options": [
                { "name": "linear", "description": "Reward proportional to progress towards goal." },
                { "name": "exponential", "description": "Reward increases exponentially closer to the goal." },
                { "name": "logarithmic", "description": "Reward increases logarithmically with progress." },
                { "name": "custom", "description": "Allows defining a task-specific potential function (e.g., based on constraint satisfaction)." }
              ]
            }
          }
        }
      },
      "search_strategy_config": {
        "id": "mod-search-strategy",
        "description": "Configuration for selecting and customizing search strategies employed during inference or planning to explore the solution or state space. Used by `kb_problem_solving_framework`.",
        "settings": {
          "method": {
            "value": "hybrid_search",
            "description": "Specifies the primary search method: 'greedy_search', 'beam_search', 'sampling', 'mcts', 'hybrid_search'. Tree-based methods like ToT or Bi-Point Tree often incorporate specific search/evaluation logic.",
            "options": [
              { "name": "greedy_search", "description": "Selects the locally optimal (most likely) option at each step." },
              { "name": "beam_search", "description": "Maintains a fixed number ('beam_width') of most likely sequences." },
              { "name": "sampling", "description": "Probabilistically samples from the distribution of possible next steps/tokens." },
              { "name": "mcts", "description": "Monte Carlo Tree Search for balancing exploration/exploitation." },
              { "name": "hybrid_search", "description": "Combines multiple search methods dynamically based on context or performance." }
            ]
          },
          "beam_width": {
            "value": 5,
            "description": "Number of parallel sequences (beams) maintained during beam search or equivalent width parameter (W) for pruning in tree searches (`kb_problem_solving_framework#principle-node-pruning`). Larger values increase exploration but also cost."
          },
          "max_depth": {
            "value": 10,
            "description": "Maximum depth limit (L) for tree-based search methods like MCTS, ToT, or Bi-Point Tree, controlling forward planning extent."
          },
          "sampling_parameters": {
            "temperature": {
              "value": 0.7,
              "description": "Controls randomness of sampling (0=deterministic, >1=more random)."
            },
            "top_k": {
              "value": 50,
              "description": "Limits sampling to the top 'k' most probable options."
            },
            "top_p": {
              "value": 0.95,
              "description": "Nucleus sampling: limits sampling to smallest set with cumulative probability >= 'p'."
            }
          },
          "alternative_search": {
            "value": "mcts",
            "description": "Specifies an alternative search method (e.g., MCTS) for fallback or hybrid use."
          }
        }
      },
      "policy_initialization_config": {
        "id": "mod-policy-init",
        "description": "Configuration settings influencing the initialization of the agent's internal policy or strategy selection mechanisms.",
        "settings": {
          "priority_behaviors": {
            "values": ["task_completion", "self_correction", "logical_consistency", "constraint_satisfaction", "fairness_bias_mitigation"],
            "description": "Specifies reasoning behaviors to prioritize during policy initialization (e.g., through pre-training focus or initial reward shaping).",
            "options": [ "task_completion", "self_correction", "logical_consistency", "explainability", "adaptability", "exploration", "constraint_satisfaction", "feasibility", "fairness_bias_mitigation" ]
          },
          "pre_training_techniques": {
            "values": ["language_understanding", "logical_reasoning", "problem_solving", "constraint_handling", "bias_awareness"],
            "description": "Specifies relevant pre-training techniques or datasets to leverage for initializing the policy.",
            "options": [ "language_understanding", "logical_reasoning", "problem_solving", "knowledge_representation", "commonsense_reasoning", "causal_inference", "constraint_handling", "bias_awareness" ]
          },
          "prior_knowledge": {
            "enabled": true,
            "description": "Enables the incorporation of explicit prior knowledge (e.g., rules, heuristics, simulated expert demonstrations) to guide policy initialization.",
            "methods": [ "rule_injection", "demonstration_learning", "reward_shaping" ]
          }
        }
      },
      "hyperparameters_rl_config": {
        "id": "mod-rl-hyperparameters",
        "description": "Configuration of key hyperparameters for optimizing performance when using internal reinforcement learning (RL) algorithms.",
        "settings": {
          "learning_rate": {
            "value": 0.001,
            "description": "Controls the step size for updating policy/value function parameters."
          },
          "discount_factor": {
            "value": 0.95,
            "description": "Discount factor (gamma) determining the importance of future rewards relative to immediate rewards."
          },
          "exploration_rate": {
            "value": 0.1,
            "description": "Controls the balance between exploration (trying new actions) and exploitation (using the current best policy) during RL."
          },
          "batch_size": {
            "value": 64,
            "description": "Number of experience samples used in each training batch for updating the RL model."
          },
          "replay_buffer_size": {
            "value": 100000,
            "description": "Size of the memory buffer storing past experiences for off-policy RL algorithms."
          },
          "target_network_update_frequency": {
            "value": 1000,
            "description": "Frequency (in steps or episodes) for updating the target network in algorithms like DQN to stabilize learning."
          }
        }
      },
      "domain_generalization_config": {
        "id": "mod-domain-generalization",
        "description": "Settings aimed at improving the agent's ability to adapt and generalize its reasoning capabilities across different domains, tasks, or data distributions.",
        "settings": {
          "adaptation_rate": {
            "value": 0.8,
            "description": "Controls the rate at which the agent adapts its internal models or strategies when encountering new domains or data distributions."
          },
          "cross_domain_weights": {
            "values": [0.5, 0.3, 0.2],
            "description": "Specifies relative weights assigned to different source domains during training to optimize for cross-domain generalization."
          },
          "regularization_techniques": {
            "values": ["dropout", "batch_normalization", "l1_regularization", "l2_regularization"],
            "description": "Specifies regularization techniques applied during internal model training to prevent overfitting and enhance generalization."
          },
          "meta_learning": {
            "enabled": false,
            "description": "Enables the use of meta-learning approaches ('learning to learn') to allow the agent to adapt more quickly and effectively to new tasks or domains with limited experience."
          }
        }
      },
       "self_reflection_config": {
        "id": "mod-self-reflection",
        "description": "Configuration for enabling and controlling internal self-reflection mechanisms, allowing the agent to analyze its own reasoning, identify weaknesses, and trigger improvements.",
        "settings": {
          "enabled": true,
          "description": "Globally enables or disables self-reflection capabilities.",
          "frequency": {
            "value": "post_interaction",
            "description": "Determines when self-reflection routines are triggered: 'post_interaction', 'periodic', 'event_triggered'.",
            "options": [
              { "name": "post_interaction", "description": "After completing a significant task or interaction." },
              { "name": "periodic", "description": "At regular intervals (e.g., every N steps or tasks)." },
              { "name": "event_triggered", "description": "Triggered by specific events (e.g., low confidence score, detected error, high uncertainty)." }
            ]
          },
          "depth": {
            "value": "medium",
            "description": "Controls the depth and computational cost of the self-reflection analysis: 'low', 'medium', 'high'.",
            "options": [
              { "name": "low", "description": "Basic analysis of recent performance, focusing on obvious errors." },
              { "name": "medium", "description": "Detailed analysis of the reasoning process, identifying potential weaknesses or biases." },
              { "name": "high", "description": "Comprehensive analysis including alternative approaches, counterfactuals, and long-term implications." }
            ]
          },
          "methods": {
            "values": ["self_questioning", "internal_knowledge_comparison", "performance_review", "counterfactual_analysis", "bias_detection", "uncertainty_assessment", "constraint_adherence_review", "fairness_principle_review"],
            "description": "Specifies the techniques employed during self-reflection.",
            "options": [
              { "name": "self_questioning", "description": "Posing critical questions about own reasoning, assumptions, biases." },
              { "name": "internal_knowledge_comparison", "description": "Comparing reasoning/outputs with internal KBs for consistency/gaps." },
              { "name": "performance_review", "description": "Analyzing past performance data (simulated) for patterns and improvement areas." },
              { "name": "counterfactual_analysis", "description": "Evaluating 'what if' scenarios to assess robustness and decision impact." },
              { "name": "bias_detection", "description": "Actively searching for and attempting to mitigate potential cognitive or data-induced biases (`#principle-fairness-bias-mitigation`)." },
              { "name": "uncertainty_assessment", "description": "Explicitly assessing and quantifying uncertainty in reasoning steps/conclusions." },
              { "name": "constraint_adherence_review", "description": "Verifying adherence to all defined task constraints (`#mod-validation.comp-constraint-feasibility-check`)." },
              { "name": "fairness_principle_review", "description": "Reviewing the reasoning process and output against fairness principles (`#principle-fairness-bias-mitigation`)." }
            ]
          }
        }
      },
      "multimodal_integration_config":{
        "id": "mod-multimodal-integration",
        "description": "Configuration settings for integrating and reasoning with information from multiple modalities (e.g., text, image, audio, structured data).",
        "settings":{
          "enabled": true,
          "description": "Globally enables or disables multimodal reasoning capabilities.",
          "modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data", "sensor_data", "structured_data"],
          "description_modalities": "List of modalities the agent is equipped to process and integrate.",
          "fusion_method": {
            "value": "hybrid_fusion",
            "description": "Specifies the primary strategy for combining information from different modalities: 'early_fusion', 'late_fusion', 'hybrid_fusion'.",
            "options":[
              {"name": "early_fusion", "description": "Combine raw or low-level features before main reasoning."},
              {"name": "late_fusion", "description": "Combine outputs or decisions from modality-specific reasoning paths."},
              {"name": "hybrid_fusion", "description": "Combines aspects of early and late fusion, potentially at multiple stages."}
            ]
          },
          "modality_weights": {
            "description": "Specifies default or dynamically assigned weights indicating the relative importance or reliability of each modality for a given task.",
            "example": "{ \"text\": 0.6, \"image\": 0.4 }"
          },
          "alignment_strategy": {
            "value": "cross-modal_attention",
            "description": "Specifies the method used to align corresponding information across different modalities: 'cross-modal_attention', 'canonical_correlation_analysis', 'co-embedding'.",
            "options": [
              {"name": "cross-modal_attention", "description": "Uses attention mechanisms to link elements across modalities."},
              {"name": "canonical_correlation_analysis", "description": "Finds correlated projections in a lower-dimensional space."},
              {"name": "co-embedding", "description": "Learns a shared embedding space where related concepts from different modalities are close."}
            ]
          }
        }
      }
    },
    "meta": {
      "description": "Metadata defining the scope, capabilities, and supported operations of this advanced reasoning knowledge base, designed for self-sufficient definition with contextual application links.",
      "required_capabilities": [
        "Precise logical reasoning (deductive, inductive, abductive).",
        "Robust probabilistic reasoning and uncertainty handling.",
        "Dynamic adaptation of strategies and continuous learning from internal feedback.",
        "Multimodal information integration and cross-modal reasoning (if enabled).",
        "Advanced reasoning forms (e.g., counterfactual, analogical, causal, critique-refinement).",
        "Rigorous self-reflection, metacognition, and self-correction.",
        "Generation of explainable and interpretable reasoning processes (internal).",
        "High robustness to noise, simulated adversarial inputs, and edge cases.",
        "Optimization for computational efficiency.",
        "Seamless integration and application of diverse internal reasoning techniques defined herein.",
        "Adherence to fairness principles and bias mitigation strategies.",
        "Comprehensive internal validation and verification capabilities."
      ],
        "supported_modalities": ["text", "image", "audio", "video", "numerical_data", "symbolic_data", "sensor_data", "structured_data"],
        "supported_reasoning_types": ["deductive", "inductive", "abductive", "causal", "counterfactual", "analogical", "spatial", "temporal", "quantitative", "qualitative", "commonsense", "scientific", "mathematical", "legal", "diagnostic", "planning", "optimization", "engineering_design", "solution_generation", "critique_based_refinement", "bias_aware_reasoning"]
    }
  }
}

